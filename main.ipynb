{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d05ab8a",
   "metadata": {},
   "source": [
    "# Load thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd15c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from tabulate import tabulate\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import SimpleRNN\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import pandas_datareader.data as web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62625b21",
   "metadata": {},
   "source": [
    "# Chuẩn bị dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b91ce7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_name = \"MANU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc88cf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = web.DataReader(stock_name,data_source=\"yahoo\",start=\"01/01/2005\",end=\"01/01/2019\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c874f93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1607.000000</td>\n",
       "      <td>1607.000000</td>\n",
       "      <td>1607.000000</td>\n",
       "      <td>1607.000000</td>\n",
       "      <td>1.607000e+03</td>\n",
       "      <td>1607.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.324294</td>\n",
       "      <td>16.875924</td>\n",
       "      <td>17.102620</td>\n",
       "      <td>17.084941</td>\n",
       "      <td>9.891637e+04</td>\n",
       "      <td>16.007120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.256755</td>\n",
       "      <td>2.174038</td>\n",
       "      <td>2.217825</td>\n",
       "      <td>2.216720</td>\n",
       "      <td>8.117236e+05</td>\n",
       "      <td>2.213693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.350000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.060000</td>\n",
       "      <td>12.180000</td>\n",
       "      <td>1.600000e+03</td>\n",
       "      <td>11.291115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.035001</td>\n",
       "      <td>15.700000</td>\n",
       "      <td>15.860000</td>\n",
       "      <td>15.850000</td>\n",
       "      <td>2.165000e+04</td>\n",
       "      <td>14.762630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.070000</td>\n",
       "      <td>16.650000</td>\n",
       "      <td>16.870001</td>\n",
       "      <td>16.850000</td>\n",
       "      <td>3.780000e+04</td>\n",
       "      <td>15.713005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.299999</td>\n",
       "      <td>17.835000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>18.070000</td>\n",
       "      <td>7.050000e+04</td>\n",
       "      <td>16.856253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27.700001</td>\n",
       "      <td>25.780001</td>\n",
       "      <td>26.049999</td>\n",
       "      <td>26.200001</td>\n",
       "      <td>3.184620e+07</td>\n",
       "      <td>25.054594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              High          Low         Open        Close        Volume  \\\n",
       "count  1607.000000  1607.000000  1607.000000  1607.000000  1.607000e+03   \n",
       "mean     17.324294    16.875924    17.102620    17.084941  9.891637e+04   \n",
       "std       2.256755     2.174038     2.217825     2.216720  8.117236e+05   \n",
       "min      12.350000    12.000000    12.060000    12.180000  1.600000e+03   \n",
       "25%      16.035001    15.700000    15.860000    15.850000  2.165000e+04   \n",
       "50%      17.070000    16.650000    16.870001    16.850000  3.780000e+04   \n",
       "75%      18.299999    17.835000    18.100000    18.070000  7.050000e+04   \n",
       "max      27.700001    25.780001    26.049999    26.200001  3.184620e+07   \n",
       "\n",
       "         Adj Close  \n",
       "count  1607.000000  \n",
       "mean     16.007120  \n",
       "std       2.213693  \n",
       "min      11.291115  \n",
       "25%      14.762630  \n",
       "50%      15.713005  \n",
       "75%      16.856253  \n",
       "max      25.054594  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27453666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1607, 1)             Close\n",
      "Date             \n",
      "2012-08-10  14.00\n",
      "2012-08-13  14.15\n",
      "2012-08-14  14.20\n",
      "2012-08-15  14.05\n",
      "2012-08-16  13.77\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = raw_data.dropna()\n",
    "df = df[['Close']]\n",
    "first_price = df.Close.iloc[0]\n",
    "print(df.shape, df.head())\n",
    "\n",
    "df.Close.plot()\n",
    "def create_ds(ds, look_back):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(ds)-look_back-1): \n",
    "        data = ds[i:(i+look_back), 0]      \n",
    "        dataX.append(data)\n",
    "        dataY.append(ds[i + look_back, 0]) \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "ds = df.values\n",
    "ds = ds.astype('float32')\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "ds = scaler.fit_transform(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90a229de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Chia tập train và tập test theo ty lệ 0.85, 0.15\n",
    "# train_size = int(len(ds) * 0.85)\n",
    "# test_size = len(ds) - train_size\n",
    "# train, test = ds[0:train_size,:], ds[train_size:len(ds)+1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560617e4",
   "metadata": {},
   "source": [
    "# outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6323037",
   "metadata": {},
   "source": [
    "#### 1:\n",
    "#### Đầu vào: train, test, look_back, opt, epochs, batch_size, validation_split\n",
    "#### Đầu ra: Trained model\n",
    "#### 2:\n",
    "#### Đầu vào: 4 trained models\n",
    "#### Đầu ra: 4 plots + bảng so sánh độ chính xác"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865ea794",
   "metadata": {},
   "source": [
    "# Xây dựng models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1f28081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_data(train, test, look_back):\n",
    "    trainX, trainY = create_ds(train, look_back)\n",
    "    testX, testY = create_ds(test, look_back)\n",
    "\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "    testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21a7835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainX, trainY, testX, testY = create_train_test_data(train, test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c4a1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_nodes = math.sqrt(len(trainX) * 3) + 2 * math.sqrt(len(trainX) / 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b7e608",
   "metadata": {},
   "source": [
    "## FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2713269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ffnn_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split):\n",
    "    # create model\n",
    "    hidden_nodes = int(math.sqrt(len(trainX) * 3) + 2 * math.sqrt(len(trainX) / 3))\n",
    "    model_ffnn = Sequential()\n",
    "    model_ffnn.add(Dense(hidden_nodes, input_shape = (trainX.shape[1],trainX.shape[2]), activation = 'relu', kernel_initializer='uniform'))\n",
    "#     model_ffnn.add(Dropout(0.4))\n",
    "#     model_ffnn.add(Dense(400, activation = 'relu', kernel_initializer='uniform' ))\n",
    "#     model_ffnn.add(Dropout(0.3))\n",
    "#     model_ffnn.add(Dense(150, activation = 'relu' ))\n",
    "#     model_ffnn.add(Dropout(0.3))\n",
    "#     model_ffnn.add(Dense(100, activation = 'hard_sigmoid' ))\n",
    "#     model_ffnn.add(Dropout(0.2))\n",
    "#     model_ffnn.add(Dense(50, activation = 'relu' ))\n",
    "#     model_ffnn.add(Dropout(0.1))\n",
    "#     model_ffnn.add(Dense(10, activation = 'relu' ))\n",
    "    model_ffnn.add(Flatten())\n",
    "    model_ffnn.add(Dense(1, activation = 'relu'))\n",
    "    # train created model\n",
    "    model_ffnn.compile(optimizer= opt, loss = \"mean_squared_error\")\n",
    "    start = time.time()\n",
    "    history = model_ffnn.fit(trainX, trainY, epochs = epochs , batch_size= batch_size, shuffle=True ,validation_split = validation_split)\n",
    "    print('Thời gian huấn luyện: ', time.time() - start)\n",
    "    model_ffnn.summary()\n",
    "    delta = time.time() - start\n",
    "    return delta, model_ffnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb585959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6feb7f00",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3b056c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split):\n",
    "    # create model\n",
    "    hidden_nodes = int(math.sqrt(len(trainX) * 3) + 2 * math.sqrt(len(trainX) / 3))\n",
    "    model_rnn = Sequential()\n",
    "    model_rnn.add(SimpleRNN(units = hidden_nodes, activation = \"tanh\", return_sequences = True, input_shape = (look_back,1)))\n",
    "#     model_rnn.add(Dropout(0.3))\n",
    "#     model_rnn.add(SimpleRNN(units = 50, activation = \"tanh\", return_sequences = True))\n",
    "#     model_rnn.add(Dropout(0.2))\n",
    "#     model_rnn.add(SimpleRNN(units = 50, activation = \"tanh\", return_sequences = True))\n",
    "#     model_rnn.add(Dropout(0.1))\n",
    "#     model_rnn.add(SimpleRNN(units = 50))\n",
    "    model_rnn.add(Flatten())\n",
    "    model_rnn.add(Dense(units = 1))\n",
    "    # train created model\n",
    "    model_rnn.compile(optimizer= opt, loss = \"mean_squared_error\")\n",
    "    start = time.time()\n",
    "    history = model_rnn.fit(trainX, trainY, epochs = epochs , batch_size= batch_size, shuffle=True ,validation_split = validation_split)\n",
    "    print('Thời gian huấn luyện: ', time.time() - start)\n",
    "    model_rnn.summary()\n",
    "    delta = time.time() - start\n",
    "    return delta, model_rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdadcde",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c306e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split):\n",
    "    # create model\n",
    "    hidden_nodes = int(math.sqrt(len(trainX) * 3) + 2 * math.sqrt(len(trainX) / 3))\n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(LSTM(hidden_nodes, activation = 'tanh', input_shape=(look_back,1),return_sequences=True))\n",
    "    model_lstm.add(Flatten())\n",
    "    model_lstm.add(Dense(1, activation = 'relu'))\n",
    "    # train created model\n",
    "    model_lstm.compile(optimizer= opt, loss = \"mean_squared_error\")\n",
    "    start = time.time()\n",
    "    history = model_lstm.fit(trainX, trainY, epochs = epochs , batch_size= batch_size, shuffle=True ,validation_split = validation_split)\n",
    "    print('Thời gian huấn luyện: ', time.time() - start)\n",
    "    model_lstm.summary()\n",
    "    delta = time.time() - start\n",
    "    return delta, model_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b222798",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fbf25ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gru_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split):\n",
    "    # create model\n",
    "    hidden_nodes = int(math.sqrt(len(trainX) * 3) + 2 * math.sqrt(len(trainX) / 3))\n",
    "    model_gru = Sequential()\n",
    "    model_gru.add(GRU(hidden_nodes, activation='tanh', recurrent_activation='sigmoid', input_shape=(look_back,1), return_sequences=True)) \n",
    "    model_gru.add(Flatten())\n",
    "    model_gru.add(Dense(1, activation = 'relu'))\n",
    "    # train created model\n",
    "    model_gru.compile(optimizer= opt, loss = \"mean_squared_error\")\n",
    "    start = time.time()\n",
    "    history = model_gru.fit(trainX, trainY, epochs = epochs , batch_size= batch_size, shuffle=True ,validation_split = validation_split)\n",
    "    print('Thời gian huấn luyện: ', time.time() - start)\n",
    "    model_gru.summary()\n",
    "    delta = time.time() - start\n",
    "    return delta, model_gru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0acfa5",
   "metadata": {},
   "source": [
    "# Trực quan hóa, so sánh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb06f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def calculate_performance(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    return round(mse, 3), round(mae, 3), round(mape, 3), round(rmse, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a2452ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_accuracy(trained_model, scaler, trainX, trainY, testX, testY):\n",
    "    trainPredict = trained_model.predict(trainX)\n",
    "    testPredict = trained_model.predict(testX)\n",
    "\n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform([trainY])\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY = scaler.inverse_transform([testY])\n",
    "\n",
    "    mse, mae, mape, rmse = calculate_performance(trainY[0],trainPredict[:, 0])\n",
    "    return mse, mae, mape, rmse, trainPredict, testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9eefe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(ds, trainPredict, testPredict, scaler, look_back, model_name, stock_name):\n",
    "    trainPredictPlot = np.empty_like(ds)\n",
    "    trainPredictPlot[:, :] = np.nan\n",
    "    trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "    testPredictPlot = np.empty_like(ds)\n",
    "    testPredictPlot[:, :] = np.nan\n",
    "    testPredictPlot[len(trainPredict)+(look_back*2)+1:len(ds)-1, :] = testPredict\n",
    "\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure(figsize=(13,7), dpi=110)\n",
    "    plt.grid(color='grey', linestyle='dashed')\n",
    "    plt.xlabel(\"{0} result\".format(model_name))\n",
    "    plt.ylabel('{0}'.format(stock_name),rotation=90)\n",
    "    plt.plot(scaler.inverse_transform(ds), label = 'Actual Closing Prices', linewidth = 1.2, color = 'c')\n",
    "    plt.plot(trainPredictPlot, label = 'A.I. Train Data Price Predictions_After fit', linewidth = 0.9, color = 'k')\n",
    "    plt.plot(testPredictPlot, label = 'A.I. Test Data Price Predictions', linewidth = 0.9, color = 'r')\n",
    "    legend = plt.legend(fontsize = 12,frameon = True)\n",
    "    legend.get_frame().set_edgecolor('b')\n",
    "    legend.get_frame().set_linewidth(0.4)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116dbf09",
   "metadata": {},
   "source": [
    "# Thực nghiệm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6f7494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 10\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "import itertools\n",
    "def get_combinations(parameters):\n",
    "    return list(itertools.product(*parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d74ce315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27/27 [==============================] - 1s 9ms/step - loss: 0.0804 - val_loss: 0.0379\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0621 - val_loss: 0.0272\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0449 - val_loss: 0.0175\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0294 - val_loss: 0.0101\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0174 - val_loss: 0.0058\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0046\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0058\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0062\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0063\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0063\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0062\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0061\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0060\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0058\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0058\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0055\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Thời gian huấn luyện:  4.193561792373657\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10, 89)            178       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 890)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069\n",
      "Trainable params: 1,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "27/27 [==============================] - 1s 13ms/step - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.6866e-04 - val_loss: 0.0015\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.2992e-04 - val_loss: 0.0015\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.9258e-04 - val_loss: 0.0015\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.5290e-04 - val_loss: 0.0014\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.6541e-04 - val_loss: 0.0013\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.1899e-04 - val_loss: 0.0014\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.0836e-04 - val_loss: 0.0012\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.3404e-04 - val_loss: 0.0012\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.6284e-04 - val_loss: 0.0012\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.6049e-04 - val_loss: 0.0012\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.4657e-04 - val_loss: 0.0012\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.3731e-04 - val_loss: 0.0011\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.6440e-04 - val_loss: 0.0011\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.2562e-04 - val_loss: 0.0011\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.0101e-04 - val_loss: 0.0011\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.2875e-04 - val_loss: 0.0011\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 6.9114e-04 - val_loss: 0.0011\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.6850e-04 - val_loss: 0.0010\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 3ms/step - loss: 6.8665e-04 - val_loss: 0.0010\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.6029e-04 - val_loss: 9.9642e-04\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.9780e-04 - val_loss: 0.0010\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.8486e-04 - val_loss: 9.9598e-04\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.8424e-04 - val_loss: 9.5530e-04\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.5023e-04 - val_loss: 9.4626e-04\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.2913e-04 - val_loss: 9.3819e-04\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.5507e-04 - val_loss: 9.5791e-04\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.3287e-04 - val_loss: 9.5141e-04\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.4102e-04 - val_loss: 9.0894e-04\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.7583e-04 - val_loss: 9.3305e-04\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 6.8019e-04 - val_loss: 9.6279e-04\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 6.1139e-04 - val_loss: 8.9303e-04\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.9908e-04 - val_loss: 8.7608e-04\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.9471e-04 - val_loss: 8.7434e-04\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.8873e-04 - val_loss: 8.7180e-04\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.8110e-04 - val_loss: 8.6851e-04\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0227e-04 - val_loss: 8.7636e-04\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.7861e-04 - val_loss: 8.4967e-04\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.8932e-04 - val_loss: 8.4716e-04\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.6953e-04 - val_loss: 8.8622e-04\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.4745e-04 - val_loss: 8.5136e-04\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.2452e-04 - val_loss: 8.3921e-04\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.7906e-04 - val_loss: 8.1595e-04\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.6756e-04 - val_loss: 8.1514e-04\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.7726e-04 - val_loss: 8.2062e-04\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5465e-04 - val_loss: 8.0166e-04\n",
      "Thời gian huấn luyện:  5.395712375640869\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 10, 89)            8099      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 890)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,990\n",
      "Trainable params: 8,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "27/27 [==============================] - 2s 20ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Thời gian huấn luyện:  10.01625108718872\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 10, 89)            32396     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 890)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,287\n",
      "Trainable params: 33,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "27/27 [==============================] - 2s 19ms/step - loss: 0.0217 - val_loss: 0.0034\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 9.9411e-04 - val_loss: 0.0017\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 9.7693e-04 - val_loss: 0.0017\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 9.6954e-04 - val_loss: 0.0016\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 9.8351e-04 - val_loss: 0.0017\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 9.7244e-04 - val_loss: 0.0016\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 9.3127e-04 - val_loss: 0.0016\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 9.3535e-04 - val_loss: 0.0016\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 9.0329e-04 - val_loss: 0.0016\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 8.9548e-04 - val_loss: 0.0015\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 8.8714e-04 - val_loss: 0.0015\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 8.8276e-04 - val_loss: 0.0015\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 8.6609e-04 - val_loss: 0.0015\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 8.5761e-04 - val_loss: 0.0015\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.5660e-04 - val_loss: 0.0014\n",
      "Thời gian huấn luyện:  9.52461314201355\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 10, 89)            24564     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 890)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,455\n",
      "Trainable params: 25,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "30/30 [==============================] - 0s 1000us/step\n",
      "20/20 [==============================] - 0s 948us/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0664 - val_loss: 0.0231\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0077\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0066\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0061\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0059\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 13/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 14/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 15/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 16/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 17/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 18/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 19/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 20/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 21/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 22/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 23/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 24/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 25/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 26/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 27/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 28/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 29/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 30/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 31/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 32/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 33/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 34/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 35/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 36/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 37/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 38/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 39/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 40/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 41/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 42/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 43/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 44/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 45/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 46/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 47/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 48/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 49/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 50/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Thời gian huấn luyện:  3.4003400802612305\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 10, 89)            178       \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 890)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069\n",
      "Trainable params: 1,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "26/26 [==============================] - 1s 9ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 9.6222e-04 - val_loss: 0.0015\n",
      "Epoch 7/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.4615e-04 - val_loss: 0.0015\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.0382e-04 - val_loss: 0.0014\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 8.8950e-04 - val_loss: 0.0013\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 8.7695e-04 - val_loss: 0.0013\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.2272e-04 - val_loss: 0.0015\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 9.0018e-04 - val_loss: 0.0015\n",
      "Epoch 13/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 8.5469e-04 - val_loss: 0.0013\n",
      "Epoch 14/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.2086e-04 - val_loss: 0.0012\n",
      "Epoch 15/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.8216e-04 - val_loss: 0.0013\n",
      "Epoch 16/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.8250e-04 - val_loss: 0.0012\n",
      "Epoch 17/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.8766e-04 - val_loss: 0.0011\n",
      "Epoch 18/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.5465e-04 - val_loss: 0.0013\n",
      "Epoch 19/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.5931e-04 - val_loss: 0.0011\n",
      "Epoch 20/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.6359e-04 - val_loss: 0.0011\n",
      "Epoch 21/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.4461e-04 - val_loss: 0.0011\n",
      "Epoch 22/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1105e-04 - val_loss: 0.0012\n",
      "Epoch 23/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.0390e-04 - val_loss: 0.0011\n",
      "Epoch 24/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9926e-04 - val_loss: 9.9665e-04\n",
      "Epoch 25/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1652e-04 - val_loss: 9.9169e-04\n",
      "Epoch 26/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.2018e-04 - val_loss: 0.0010\n",
      "Epoch 27/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8410e-04 - val_loss: 0.0011\n",
      "Epoch 28/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.2372e-04 - val_loss: 0.0010\n",
      "Epoch 29/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.8411e-04 - val_loss: 9.5556e-04\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6491e-04 - val_loss: 9.2838e-04\n",
      "Epoch 31/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6715e-04 - val_loss: 9.8867e-04\n",
      "Epoch 32/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.6226e-04 - val_loss: 9.9147e-04\n",
      "Epoch 33/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5714e-04 - val_loss: 9.3018e-04\n",
      "Epoch 34/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3404e-04 - val_loss: 9.1229e-04\n",
      "Epoch 35/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4514e-04 - val_loss: 9.2228e-04\n",
      "Epoch 36/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.4389e-04 - val_loss: 8.8275e-04\n",
      "Epoch 37/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.4452e-04 - val_loss: 9.2161e-04\n",
      "Epoch 38/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5999e-04 - val_loss: 8.7330e-04\n",
      "Epoch 39/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1434e-04 - val_loss: 8.6427e-04\n",
      "Epoch 40/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4285e-04 - val_loss: 8.6475e-04\n",
      "Epoch 41/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.3672e-04 - val_loss: 8.4911e-04\n",
      "Epoch 42/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4736e-04 - val_loss: 8.4565e-04\n",
      "Epoch 43/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9853e-04 - val_loss: 8.4555e-04\n",
      "Epoch 44/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9561e-04 - val_loss: 8.3151e-04\n",
      "Epoch 45/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2310e-04 - val_loss: 8.2768e-04\n",
      "Epoch 46/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9074e-04 - val_loss: 8.3526e-04\n",
      "Epoch 47/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.9647e-04 - val_loss: 8.2956e-04\n",
      "Epoch 48/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.8907e-04 - val_loss: 8.0685e-04\n",
      "Epoch 49/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9099e-04 - val_loss: 8.0070e-04\n",
      "Epoch 50/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8413e-04 - val_loss: 8.2044e-04\n",
      "Thời gian huấn luyện:  5.257981777191162\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_1 (SimpleRNN)    (None, 10, 89)            8099      \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 890)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,990\n",
      "Trainable params: 8,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "26/26 [==============================] - 2s 20ms/step - loss: 0.0300 - val_loss: 0.0062\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 7/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 13/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 14/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 15/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 16/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 17/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 18/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 19/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 20/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 21/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 22/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 23/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 24/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 25/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 26/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 27/50\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 28/50\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 29/50\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 30/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 31/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 32/50\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 33/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 34/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 35/50\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 36/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 37/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 38/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 39/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 40/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 41/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 42/50\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 43/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 44/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 45/50\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 46/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 47/50\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 48/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 49/50\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 50/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Thời gian huấn luyện:  9.782893180847168\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 10, 89)            32396     \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 890)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,287\n",
      "Trainable params: 33,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "26/26 [==============================] - 2s 19ms/step - loss: 0.0180 - val_loss: 0.0030\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 7/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 13/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 14/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 15/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 16/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 17/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 18/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 19/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 20/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 21/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 22/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 23/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 24/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 25/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 26/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 27/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 28/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 29/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 30/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 31/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 32/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 33/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 34/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 35/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 36/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 37/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 38/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 39/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 40/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.8894e-04 - val_loss: 0.0017\n",
      "Epoch 41/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.6507e-04 - val_loss: 0.0016\n",
      "Epoch 42/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.5909e-04 - val_loss: 0.0016\n",
      "Epoch 43/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.4876e-04 - val_loss: 0.0016\n",
      "Epoch 44/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.3850e-04 - val_loss: 0.0015\n",
      "Epoch 45/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.4437e-04 - val_loss: 0.0016\n",
      "Epoch 46/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.1956e-04 - val_loss: 0.0015\n",
      "Epoch 47/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.2615e-04 - val_loss: 0.0014\n",
      "Epoch 48/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.0484e-04 - val_loss: 0.0015\n",
      "Epoch 49/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.9283e-04 - val_loss: 0.0014\n",
      "Epoch 50/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.8476e-04 - val_loss: 0.0014\n",
      "Thời gian huấn luyện:  9.30380654335022\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_1 (GRU)                 (None, 10, 89)            24564     \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 890)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,455\n",
      "Trainable params: 25,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0475 - val_loss: 0.0119\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Thời gian huấn luyện:  3.2871880531311035\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 10, 89)            178       \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 890)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069\n",
      "Trainable params: 1,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 1s 10ms/step - loss: 0.0191 - val_loss: 0.0053\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.9525e-04 - val_loss: 0.0014\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.6871e-04 - val_loss: 0.0014\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.8498e-04 - val_loss: 0.0013\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.8735e-04 - val_loss: 0.0012\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.2781e-04 - val_loss: 0.0012\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.1715e-04 - val_loss: 0.0012\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.0553e-04 - val_loss: 0.0012\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.0518e-04 - val_loss: 0.0011\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.8970e-04 - val_loss: 0.0012\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.8720e-04 - val_loss: 0.0011\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.7083e-04 - val_loss: 0.0011\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.6378e-04 - val_loss: 0.0011\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.5592e-04 - val_loss: 0.0011\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step - loss: 8.5311e-04 - val_loss: 0.0011\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.6585e-04 - val_loss: 0.0012\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.3841e-04 - val_loss: 0.0010\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.3447e-04 - val_loss: 0.0011\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.5517e-04 - val_loss: 0.0011\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.5914e-04 - val_loss: 0.0010\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.9742e-04 - val_loss: 0.0010\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.0900e-04 - val_loss: 9.9840e-04\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.1820e-04 - val_loss: 9.9867e-04\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.2085e-04 - val_loss: 9.9001e-04\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.1984e-04 - val_loss: 0.0010\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.8583e-04 - val_loss: 9.7359e-04\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.7520e-04 - val_loss: 9.6453e-04\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.7007e-04 - val_loss: 9.6129e-04\n",
      "Thời gian huấn luyện:  5.317591190338135\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_2 (SimpleRNN)    (None, 10, 89)            8099      \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 890)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,990\n",
      "Trainable params: 8,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 2s 21ms/step - loss: 0.0324 - val_loss: 0.0065\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Thời gian huấn luyện:  9.814332246780396\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 10, 89)            32396     \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,287\n",
      "Trainable params: 33,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 2s 19ms/step - loss: 0.0171 - val_loss: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 9.9497e-04 - val_loss: 0.0013\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 9.8424e-04 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 9.7094e-04 - val_loss: 0.0013\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 9.6454e-04 - val_loss: 0.0012\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 9.4414e-04 - val_loss: 0.0012\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 9.3323e-04 - val_loss: 0.0012\n",
      "Thời gian huấn luyện:  9.16268515586853\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_2 (GRU)                 (None, 10, 89)            24564     \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,455\n",
      "Trainable params: 25,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "30/30 [==============================] - 0s 931us/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 49/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 58/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 59/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 73/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 95/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 96/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 97/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 98/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Thời gian huấn luyện:  5.877689838409424\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_15 (Dense)            (None, 10, 89)            178       \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069\n",
      "Trainable params: 1,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "27/27 [==============================] - 1s 8ms/step - loss: 0.0089 - val_loss: 0.0037\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.8143e-04 - val_loss: 0.0016\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.7445e-04 - val_loss: 0.0016\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.2318e-04 - val_loss: 0.0016\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.0639e-04 - val_loss: 0.0015\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.9197e-04 - val_loss: 0.0015\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.8140e-04 - val_loss: 0.0015\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.5863e-04 - val_loss: 0.0014\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.5402e-04 - val_loss: 0.0014\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.3092e-04 - val_loss: 0.0014\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.3526e-04 - val_loss: 0.0013\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.2737e-04 - val_loss: 0.0013\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.0100e-04 - val_loss: 0.0013\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.9245e-04 - val_loss: 0.0013\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.0880e-04 - val_loss: 0.0013\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.7790e-04 - val_loss: 0.0012\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.7400e-04 - val_loss: 0.0012\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.5376e-04 - val_loss: 0.0013\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.5196e-04 - val_loss: 0.0012\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.6412e-04 - val_loss: 0.0012\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.2809e-04 - val_loss: 0.0012\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.4151e-04 - val_loss: 0.0011\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.2170e-04 - val_loss: 0.0012\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.2716e-04 - val_loss: 0.0011\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.0406e-04 - val_loss: 0.0011\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.0162e-04 - val_loss: 0.0011\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.1203e-04 - val_loss: 0.0011\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.9496e-04 - val_loss: 0.0011\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.1937e-04 - val_loss: 0.0011\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.9118e-04 - val_loss: 0.0011\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.8588e-04 - val_loss: 0.0010\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.5990e-04 - val_loss: 0.0011\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.6864e-04 - val_loss: 0.0011\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.6637e-04 - val_loss: 0.0011\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.5350e-04 - val_loss: 0.0010\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.4624e-04 - val_loss: 9.9071e-04\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.4725e-04 - val_loss: 9.8140e-04\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.7616e-04 - val_loss: 9.8254e-04\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.3531e-04 - val_loss: 9.7639e-04\n",
      "Epoch 49/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.1995e-04 - val_loss: 0.0010\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.3289e-04 - val_loss: 9.5154e-04\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.7353e-04 - val_loss: 9.7199e-04\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.1677e-04 - val_loss: 0.0010\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.4638e-04 - val_loss: 0.0010\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0871e-04 - val_loss: 9.2415e-04\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0995e-04 - val_loss: 9.3876e-04\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.2281e-04 - val_loss: 9.2361e-04\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0054e-04 - val_loss: 9.1097e-04\n",
      "Epoch 58/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.9222e-04 - val_loss: 9.0727e-04\n",
      "Epoch 59/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.9206e-04 - val_loss: 9.0014e-04\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.9893e-04 - val_loss: 9.0550e-04\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.9562e-04 - val_loss: 8.8875e-04\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.8659e-04 - val_loss: 9.0212e-04\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0286e-04 - val_loss: 8.7182e-04\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.9274e-04 - val_loss: 9.0925e-04\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.9557e-04 - val_loss: 8.8069e-04\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0172e-04 - val_loss: 8.7751e-04\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.9063e-04 - val_loss: 8.7294e-04\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.7388e-04 - val_loss: 9.2598e-04\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.7885e-04 - val_loss: 8.4203e-04\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.7445e-04 - val_loss: 8.4469e-04\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.7897e-04 - val_loss: 8.7039e-04\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 5.6193e-04 - val_loss: 8.3056e-04\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 3ms/step - loss: 5.6324e-04 - val_loss: 8.2369e-04\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.6372e-04 - val_loss: 9.0276e-04\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.1103e-04 - val_loss: 8.3444e-04\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.4819e-04 - val_loss: 8.5297e-04\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.6043e-04 - val_loss: 8.9164e-04\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5401e-04 - val_loss: 8.0094e-04\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5535e-04 - val_loss: 7.9751e-04\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.6124e-04 - val_loss: 7.9382e-04\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3786e-04 - val_loss: 7.9328e-04\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5584e-04 - val_loss: 8.2989e-04\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3357e-04 - val_loss: 8.0658e-04\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.4647e-04 - val_loss: 7.8450e-04\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.4915e-04 - val_loss: 7.9395e-04\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2994e-04 - val_loss: 7.7227e-04\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3833e-04 - val_loss: 7.6664e-04\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3077e-04 - val_loss: 7.7219e-04\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3876e-04 - val_loss: 7.5957e-04\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2656e-04 - val_loss: 7.5702e-04\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3548e-04 - val_loss: 7.6842e-04\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2865e-04 - val_loss: 7.6376e-04\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3391e-04 - val_loss: 8.2054e-04\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2579e-04 - val_loss: 7.4280e-04\n",
      "Epoch 95/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2404e-04 - val_loss: 7.4383e-04\n",
      "Epoch 96/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.1038e-04 - val_loss: 7.3712e-04\n",
      "Epoch 97/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.4986e-04 - val_loss: 7.3486e-04\n",
      "Epoch 98/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2069e-04 - val_loss: 7.3816e-04\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2157e-04 - val_loss: 7.6869e-04\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2621e-04 - val_loss: 7.9180e-04\n",
      "Thời gian huấn luyện:  9.265209436416626\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_3 (SimpleRNN)    (None, 10, 89)            8099      \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,990\n",
      "Trainable params: 8,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "27/27 [==============================] - 2s 18ms/step - loss: 0.0320 - val_loss: 0.0057\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 49/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 58/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 59/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 73/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 9.9931e-04 - val_loss: 0.0019\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 9.9472e-04 - val_loss: 0.0018\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.8646e-04 - val_loss: 0.0018\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.7604e-04 - val_loss: 0.0018\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.8601e-04 - val_loss: 0.0018\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.7045e-04 - val_loss: 0.0018\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.7287e-04 - val_loss: 0.0018\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.5586e-04 - val_loss: 0.0018\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.6269e-04 - val_loss: 0.0017\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.7595e-04 - val_loss: 0.0018\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.7671e-04 - val_loss: 0.0018\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.4193e-04 - val_loss: 0.0017\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.6228e-04 - val_loss: 0.0018\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.3514e-04 - val_loss: 0.0017\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.3622e-04 - val_loss: 0.0017\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.3788e-04 - val_loss: 0.0018\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.4115e-04 - val_loss: 0.0017\n",
      "Epoch 95/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.4903e-04 - val_loss: 0.0017\n",
      "Epoch 96/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.2023e-04 - val_loss: 0.0018\n",
      "Epoch 97/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.5732e-04 - val_loss: 0.0017\n",
      "Epoch 98/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 9.2839e-04 - val_loss: 0.0017\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.2459e-04 - val_loss: 0.0017\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.3211e-04 - val_loss: 0.0017\n",
      "Thời gian huấn luyện:  17.721712827682495\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 10, 89)            32396     \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,287\n",
      "Trainable params: 33,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "27/27 [==============================] - 2s 18ms/step - loss: 0.0196 - val_loss: 0.0034\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.9040e-04 - val_loss: 0.0017\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.7510e-04 - val_loss: 0.0016\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.6235e-04 - val_loss: 0.0016\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.6232e-04 - val_loss: 0.0016\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.3353e-04 - val_loss: 0.0016\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.3069e-04 - val_loss: 0.0015\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.1658e-04 - val_loss: 0.0015\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.2206e-04 - val_loss: 0.0015\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.9754e-04 - val_loss: 0.0015\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.8688e-04 - val_loss: 0.0015\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.6352e-04 - val_loss: 0.0015\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.8506e-04 - val_loss: 0.0015\n",
      "Epoch 49/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.4335e-04 - val_loss: 0.0014\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.3136e-04 - val_loss: 0.0014\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.2052e-04 - val_loss: 0.0014\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.1849e-04 - val_loss: 0.0014\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.2093e-04 - val_loss: 0.0014\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.0942e-04 - val_loss: 0.0013\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.8836e-04 - val_loss: 0.0013\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.7946e-04 - val_loss: 0.0013\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.7425e-04 - val_loss: 0.0013\n",
      "Epoch 58/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.8343e-04 - val_loss: 0.0013\n",
      "Epoch 59/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.7295e-04 - val_loss: 0.0013\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.6084e-04 - val_loss: 0.0013\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.5437e-04 - val_loss: 0.0013\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.5242e-04 - val_loss: 0.0012\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.4834e-04 - val_loss: 0.0013\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.6189e-04 - val_loss: 0.0013\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.3408e-04 - val_loss: 0.0012\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.3265e-04 - val_loss: 0.0012\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.1900e-04 - val_loss: 0.0012\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.1645e-04 - val_loss: 0.0012\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.2126e-04 - val_loss: 0.0012\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.2991e-04 - val_loss: 0.0012\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.4286e-04 - val_loss: 0.0012\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.2202e-04 - val_loss: 0.0012\n",
      "Epoch 73/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 6.9190e-04 - val_loss: 0.0012\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.9780e-04 - val_loss: 0.0012\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.9159e-04 - val_loss: 0.0012\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.0312e-04 - val_loss: 0.0011\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.8643e-04 - val_loss: 0.0012\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.7977e-04 - val_loss: 0.0011\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.0371e-04 - val_loss: 0.0011\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.7508e-04 - val_loss: 0.0011\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.8734e-04 - val_loss: 0.0011\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.7773e-04 - val_loss: 0.0011\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.6984e-04 - val_loss: 0.0011\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.6625e-04 - val_loss: 0.0011\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.5758e-04 - val_loss: 0.0011\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.5692e-04 - val_loss: 0.0011\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.5276e-04 - val_loss: 0.0011\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.4912e-04 - val_loss: 0.0011\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.5029e-04 - val_loss: 0.0011\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.4294e-04 - val_loss: 0.0011\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.4030e-04 - val_loss: 0.0010\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.4120e-04 - val_loss: 0.0010\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.5273e-04 - val_loss: 0.0011\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.3535e-04 - val_loss: 0.0010\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 6ms/step - loss: 6.3199e-04 - val_loss: 0.0010\n",
      "Epoch 96/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.5046e-04 - val_loss: 0.0010\n",
      "Epoch 97/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.4002e-04 - val_loss: 0.0010\n",
      "Epoch 98/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2194e-04 - val_loss: 0.0010\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2558e-04 - val_loss: 9.9860e-04\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.1520e-04 - val_loss: 9.9623e-04\n",
      "Thời gian huấn luyện:  18.105236768722534\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_3 (GRU)                 (None, 10, 89)            24564     \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,455\n",
      "Trainable params: 25,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "30/30 [==============================] - 0s 897us/step\n",
      "20/20 [==============================] - 0s 948us/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0686 - val_loss: 0.0210\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0089\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0065\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0062\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0059\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0055\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.9178e-04 - val_loss: 0.0017\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.8653e-04 - val_loss: 0.0017\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.8268e-04 - val_loss: 0.0017\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.7888e-04 - val_loss: 0.0017\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.6995e-04 - val_loss: 0.0016\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 2ms/step - loss: 9.6673e-04 - val_loss: 0.0016\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.5768e-04 - val_loss: 0.0016\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.5101e-04 - val_loss: 0.0016\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.4326e-04 - val_loss: 0.0016\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.4103e-04 - val_loss: 0.0016\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.3144e-04 - val_loss: 0.0016\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.3466e-04 - val_loss: 0.0015\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 9.1789e-04 - val_loss: 0.0016\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.1787e-04 - val_loss: 0.0015\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.0828e-04 - val_loss: 0.0015\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.0212e-04 - val_loss: 0.0015\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.9631e-04 - val_loss: 0.0015\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.9093e-04 - val_loss: 0.0015\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.8481e-04 - val_loss: 0.0015\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.7962e-04 - val_loss: 0.0015\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.7499e-04 - val_loss: 0.0014\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.6914e-04 - val_loss: 0.0014\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.6336e-04 - val_loss: 0.0014\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.5337e-04 - val_loss: 0.0014\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.5148e-04 - val_loss: 0.0014\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.4479e-04 - val_loss: 0.0014\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.3690e-04 - val_loss: 0.0014\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.3527e-04 - val_loss: 0.0014\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.3733e-04 - val_loss: 0.0014\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.1975e-04 - val_loss: 0.0013\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.2020e-04 - val_loss: 0.0013\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.1101e-04 - val_loss: 0.0013\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.0405e-04 - val_loss: 0.0013\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.0259e-04 - val_loss: 0.0013\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7.9436e-04 - val_loss: 0.0013\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7.9048e-04 - val_loss: 0.0013\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7.8755e-04 - val_loss: 0.0013\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7.7637e-04 - val_loss: 0.0013\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7.7429e-04 - val_loss: 0.0012\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7.7434e-04 - val_loss: 0.0013\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7.6401e-04 - val_loss: 0.0012\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7.5704e-04 - val_loss: 0.0012\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7.5300e-04 - val_loss: 0.0012\n",
      "Thời gian huấn luyện:  6.457669973373413\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 10, 89)            178       \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069\n",
      "Trainable params: 1,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "26/26 [==============================] - 1s 9ms/step - loss: 0.0155 - val_loss: 0.0082\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 9.9672e-04 - val_loss: 0.0016\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.9257e-04 - val_loss: 0.0017\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.7007e-04 - val_loss: 0.0015\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.6043e-04 - val_loss: 0.0015\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.5391e-04 - val_loss: 0.0015\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.3708e-04 - val_loss: 0.0014\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.0215e-04 - val_loss: 0.0015\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.1990e-04 - val_loss: 0.0014\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.3458e-04 - val_loss: 0.0015\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.9425e-04 - val_loss: 0.0014\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.1903e-04 - val_loss: 0.0013\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.5494e-04 - val_loss: 0.0013\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.3898e-04 - val_loss: 0.0013\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.2344e-04 - val_loss: 0.0013\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.2120e-04 - val_loss: 0.0014\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.2814e-04 - val_loss: 0.0014\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 3ms/step - loss: 8.1795e-04 - val_loss: 0.0013\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.8984e-04 - val_loss: 0.0012\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.1183e-04 - val_loss: 0.0013\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.0596e-04 - val_loss: 0.0013\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.8974e-04 - val_loss: 0.0012\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.7508e-04 - val_loss: 0.0013\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.6974e-04 - val_loss: 0.0011\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.7033e-04 - val_loss: 0.0012\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 8.0146e-04 - val_loss: 0.0011\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.4990e-04 - val_loss: 0.0011\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.6153e-04 - val_loss: 0.0012\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.8362e-04 - val_loss: 0.0011\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.4844e-04 - val_loss: 0.0011\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.4479e-04 - val_loss: 0.0011\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.3276e-04 - val_loss: 0.0011\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1884e-04 - val_loss: 0.0011\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.2051e-04 - val_loss: 0.0011\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9993e-04 - val_loss: 0.0011\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.3274e-04 - val_loss: 0.0010\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.1256e-04 - val_loss: 0.0010\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1763e-04 - val_loss: 0.0011\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9704e-04 - val_loss: 0.0010\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9534e-04 - val_loss: 0.0010\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9199e-04 - val_loss: 9.9617e-04\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8976e-04 - val_loss: 0.0010\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8347e-04 - val_loss: 0.0010\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.7854e-04 - val_loss: 9.9006e-04\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6897e-04 - val_loss: 9.6833e-04\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1602e-04 - val_loss: 9.8863e-04\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.7799e-04 - val_loss: 9.7484e-04\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6143e-04 - val_loss: 9.4961e-04\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.6940e-04 - val_loss: 9.4286e-04\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.8351e-04 - val_loss: 9.8852e-04\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.7946e-04 - val_loss: 9.5920e-04\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.5898e-04 - val_loss: 9.5718e-04\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.6296e-04 - val_loss: 9.4215e-04\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.4822e-04 - val_loss: 9.1585e-04\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5982e-04 - val_loss: 9.2383e-04\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4551e-04 - val_loss: 9.5967e-04\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3913e-04 - val_loss: 9.0577e-04\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3371e-04 - val_loss: 0.0010\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4374e-04 - val_loss: 9.0510e-04\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3592e-04 - val_loss: 9.1727e-04\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3777e-04 - val_loss: 9.2421e-04\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3439e-04 - val_loss: 8.8209e-04\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3389e-04 - val_loss: 8.7416e-04\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4568e-04 - val_loss: 9.0550e-04\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.3413e-04 - val_loss: 8.6749e-04\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6658e-04 - val_loss: 9.5167e-04\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0730e-04 - val_loss: 8.7611e-04\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1499e-04 - val_loss: 9.4059e-04\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2519e-04 - val_loss: 8.7165e-04\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1202e-04 - val_loss: 9.1587e-04\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1725e-04 - val_loss: 9.2329e-04\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0559e-04 - val_loss: 8.4157e-04\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9723e-04 - val_loss: 9.2749e-04\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9218e-04 - val_loss: 8.3234e-04\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0638e-04 - val_loss: 8.4798e-04\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9495e-04 - val_loss: 8.2419e-04\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0805e-04 - val_loss: 8.4345e-04\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1984e-04 - val_loss: 8.2132e-04\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0005e-04 - val_loss: 9.1927e-04\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6128e-04 - val_loss: 8.1004e-04\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0797e-04 - val_loss: 8.1173e-04\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9153e-04 - val_loss: 8.1151e-04\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2263e-04 - val_loss: 0.0011\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4954e-04 - val_loss: 9.5393e-04\n",
      "Thời gian huấn luyện:  9.796491622924805\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_4 (SimpleRNN)    (None, 10, 89)            8099      \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,990\n",
      "Trainable params: 8,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "26/26 [==============================] - 2s 20ms/step - loss: 0.0287 - val_loss: 0.0054\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 9.9857e-04 - val_loss: 0.0017\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 9.9104e-04 - val_loss: 0.0017\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.8125e-04 - val_loss: 0.0017\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.7199e-04 - val_loss: 0.0016\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.7361e-04 - val_loss: 0.0016\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.6617e-04 - val_loss: 0.0017\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.5778e-04 - val_loss: 0.0016\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.3995e-04 - val_loss: 0.0016\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.3818e-04 - val_loss: 0.0016\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.3305e-04 - val_loss: 0.0016\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.2728e-04 - val_loss: 0.0016\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.1571e-04 - val_loss: 0.0015\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.0897e-04 - val_loss: 0.0016\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.9626e-04 - val_loss: 0.0016\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 9.1922e-04 - val_loss: 0.0015\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.0172e-04 - val_loss: 0.0015\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.9784e-04 - val_loss: 0.0015\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 6ms/step - loss: 8.8251e-04 - val_loss: 0.0015\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.8920e-04 - val_loss: 0.0015\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.1142e-04 - val_loss: 0.0015\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.5543e-04 - val_loss: 0.0016\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.9843e-04 - val_loss: 0.0014\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.7006e-04 - val_loss: 0.0014\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.7597e-04 - val_loss: 0.0014\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.6708e-04 - val_loss: 0.0014\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.7574e-04 - val_loss: 0.0015\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.5390e-04 - val_loss: 0.0014\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.4706e-04 - val_loss: 0.0015\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.5948e-04 - val_loss: 0.0014\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.5124e-04 - val_loss: 0.0014\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.5245e-04 - val_loss: 0.0014\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.4882e-04 - val_loss: 0.0014\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.5294e-04 - val_loss: 0.0014\n",
      "Thời gian huấn luyện:  18.168768882751465\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 10, 89)            32396     \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,287\n",
      "Trainable params: 33,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "26/26 [==============================] - 2s 18ms/step - loss: 0.0226 - val_loss: 0.0036\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.9172e-04 - val_loss: 0.0016\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.7304e-04 - val_loss: 0.0017\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.7148e-04 - val_loss: 0.0016\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.6191e-04 - val_loss: 0.0017\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.5410e-04 - val_loss: 0.0016\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.3734e-04 - val_loss: 0.0015\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.3984e-04 - val_loss: 0.0015\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.2596e-04 - val_loss: 0.0015\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.0963e-04 - val_loss: 0.0015\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.0031e-04 - val_loss: 0.0014\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.9862e-04 - val_loss: 0.0014\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.8236e-04 - val_loss: 0.0014\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.8767e-04 - val_loss: 0.0014\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.6715e-04 - val_loss: 0.0014\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.6088e-04 - val_loss: 0.0014\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.5933e-04 - val_loss: 0.0013\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.4795e-04 - val_loss: 0.0013\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.3478e-04 - val_loss: 0.0013\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.2781e-04 - val_loss: 0.0013\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.2551e-04 - val_loss: 0.0013\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 6ms/step - loss: 8.2098e-04 - val_loss: 0.0013\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.0885e-04 - val_loss: 0.0013\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.2314e-04 - val_loss: 0.0013\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.9841e-04 - val_loss: 0.0012\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.8817e-04 - val_loss: 0.0013\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.8916e-04 - val_loss: 0.0012\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.8071e-04 - val_loss: 0.0012\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.7649e-04 - val_loss: 0.0012\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.7549e-04 - val_loss: 0.0012\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.6928e-04 - val_loss: 0.0012\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.7227e-04 - val_loss: 0.0011\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.5420e-04 - val_loss: 0.0012\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 7.5020e-04 - val_loss: 0.0011\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 7.4890e-04 - val_loss: 0.0011\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.4280e-04 - val_loss: 0.0011\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.5432e-04 - val_loss: 0.0011\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.4757e-04 - val_loss: 0.0011\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.2970e-04 - val_loss: 0.0011\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.2618e-04 - val_loss: 0.0011\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.2239e-04 - val_loss: 0.0011\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.1876e-04 - val_loss: 0.0011\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.1561e-04 - val_loss: 0.0011\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.1025e-04 - val_loss: 0.0011\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.0910e-04 - val_loss: 0.0011\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.0958e-04 - val_loss: 0.0011\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.1336e-04 - val_loss: 0.0010\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.9951e-04 - val_loss: 0.0011\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.9955e-04 - val_loss: 0.0011\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.9254e-04 - val_loss: 0.0010\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.9738e-04 - val_loss: 0.0010\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.0138e-04 - val_loss: 0.0010\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.8400e-04 - val_loss: 0.0010\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.8053e-04 - val_loss: 9.9667e-04\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.7693e-04 - val_loss: 9.9264e-04\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.7343e-04 - val_loss: 0.0010\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.6881e-04 - val_loss: 0.0010\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.6450e-04 - val_loss: 9.7714e-04\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.6579e-04 - val_loss: 0.0010\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.5945e-04 - val_loss: 0.0010\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.8363e-04 - val_loss: 9.7177e-04\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.5636e-04 - val_loss: 9.7338e-04\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.5604e-04 - val_loss: 9.4817e-04\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.6795e-04 - val_loss: 9.9453e-04\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.4655e-04 - val_loss: 9.4587e-04\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.4556e-04 - val_loss: 9.4764e-04\n",
      "Thời gian huấn luyện:  17.205350399017334\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_4 (GRU)                 (None, 10, 89)            24564     \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,455\n",
      "Trainable params: 25,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "30/30 [==============================] - 0s 931us/step\n",
      "20/20 [==============================] - 0s 894us/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 1s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 58/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 59/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 61/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 62/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 63/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 64/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 65/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 66/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 67/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 69/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 70/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 72/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 73/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 74/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 75/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 76/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 78/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 79/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 80/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 81/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 82/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 83/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 84/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 85/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 86/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 87/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 88/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 89/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 90/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 91/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 92/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 93/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 94/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 95/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 96/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 97/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 98/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 99/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 100/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Thời gian huấn luyện:  6.391704082489014\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_25 (Dense)            (None, 10, 89)            178       \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 890)               0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069\n",
      "Trainable params: 1,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 1s 10ms/step - loss: 0.0304 - val_loss: 0.0041\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.9462e-04 - val_loss: 0.0013\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.9280e-04 - val_loss: 0.0013\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.7327e-04 - val_loss: 0.0012\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.7389e-04 - val_loss: 0.0012\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.6103e-04 - val_loss: 0.0012\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.6147e-04 - val_loss: 0.0013\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.4687e-04 - val_loss: 0.0012\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.1902e-04 - val_loss: 0.0012\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.0543e-04 - val_loss: 0.0012\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.9632e-04 - val_loss: 0.0011\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.8795e-04 - val_loss: 0.0011\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.7537e-04 - val_loss: 0.0011\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.7174e-04 - val_loss: 0.0011\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.6327e-04 - val_loss: 0.0011\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.6271e-04 - val_loss: 0.0011\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.7998e-04 - val_loss: 0.0011\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.4056e-04 - val_loss: 0.0011\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.5902e-04 - val_loss: 0.0011\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.5224e-04 - val_loss: 0.0011\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.7115e-04 - val_loss: 0.0010\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.2511e-04 - val_loss: 0.0010\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.2759e-04 - val_loss: 0.0010\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.1199e-04 - val_loss: 0.0010\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.1252e-04 - val_loss: 9.9988e-04\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.1326e-04 - val_loss: 9.8953e-04\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.8905e-04 - val_loss: 9.8139e-04\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.8767e-04 - val_loss: 9.8029e-04\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.6617e-04 - val_loss: 9.7730e-04\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.7290e-04 - val_loss: 9.9546e-04\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.8802e-04 - val_loss: 9.5281e-04\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.8135e-04 - val_loss: 9.6052e-04\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.6195e-04 - val_loss: 9.4545e-04\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.4973e-04 - val_loss: 9.4124e-04\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.7745e-04 - val_loss: 9.2805e-04\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.5755e-04 - val_loss: 9.2057e-04\n",
      "Epoch 58/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.6897e-04 - val_loss: 9.4903e-04\n",
      "Epoch 59/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.7041e-04 - val_loss: 9.1401e-04\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.2859e-04 - val_loss: 9.1548e-04\n",
      "Epoch 61/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.2885e-04 - val_loss: 8.9719e-04\n",
      "Epoch 62/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.3205e-04 - val_loss: 8.9135e-04\n",
      "Epoch 63/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.2228e-04 - val_loss: 9.0784e-04\n",
      "Epoch 64/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.2906e-04 - val_loss: 8.8823e-04\n",
      "Epoch 65/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.1572e-04 - val_loss: 9.0383e-04\n",
      "Epoch 66/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.3849e-04 - val_loss: 8.9409e-04\n",
      "Epoch 67/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.1347e-04 - val_loss: 8.9922e-04\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.0197e-04 - val_loss: 8.5949e-04\n",
      "Epoch 69/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.9806e-04 - val_loss: 8.5492e-04\n",
      "Epoch 70/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.9567e-04 - val_loss: 8.5074e-04\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.0577e-04 - val_loss: 8.7645e-04\n",
      "Epoch 72/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.3263e-04 - val_loss: 9.8052e-04\n",
      "Epoch 73/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.9908e-04 - val_loss: 8.5455e-04\n",
      "Epoch 74/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7660e-04 - val_loss: 8.3672e-04\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7933e-04 - val_loss: 8.2917e-04\n",
      "Epoch 76/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7542e-04 - val_loss: 8.2059e-04\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.8914e-04 - val_loss: 8.7484e-04\n",
      "Epoch 78/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.0828e-04 - val_loss: 8.8826e-04\n",
      "Epoch 79/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7264e-04 - val_loss: 8.1959e-04\n",
      "Epoch 80/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7142e-04 - val_loss: 8.0378e-04\n",
      "Epoch 81/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.5329e-04 - val_loss: 8.7112e-04\n",
      "Epoch 82/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7103e-04 - val_loss: 8.0835e-04\n",
      "Epoch 83/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.1526e-04 - val_loss: 8.6629e-04\n",
      "Epoch 84/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.6716e-04 - val_loss: 7.8843e-04\n",
      "Epoch 85/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.5986e-04 - val_loss: 8.0140e-04\n",
      "Epoch 86/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.4354e-04 - val_loss: 7.8155e-04\n",
      "Epoch 87/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.5613e-04 - val_loss: 7.7951e-04\n",
      "Epoch 88/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3580e-04 - val_loss: 7.8007e-04\n",
      "Epoch 89/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.4322e-04 - val_loss: 7.8211e-04\n",
      "Epoch 90/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.4129e-04 - val_loss: 7.7856e-04\n",
      "Epoch 91/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.2827e-04 - val_loss: 7.6392e-04\n",
      "Epoch 92/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3664e-04 - val_loss: 7.6623e-04\n",
      "Epoch 93/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3585e-04 - val_loss: 7.5353e-04\n",
      "Epoch 94/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3680e-04 - val_loss: 7.5343e-04\n",
      "Epoch 95/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.2628e-04 - val_loss: 7.4667e-04\n",
      "Epoch 96/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.2890e-04 - val_loss: 7.4267e-04\n",
      "Epoch 97/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3689e-04 - val_loss: 7.4436e-04\n",
      "Epoch 98/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.1153e-04 - val_loss: 7.7707e-04\n",
      "Epoch 99/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.1208e-04 - val_loss: 7.5048e-04\n",
      "Epoch 100/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.2280e-04 - val_loss: 7.3690e-04\n",
      "Thời gian huấn luyện:  9.849021434783936\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_5 (SimpleRNN)    (None, 10, 89)            8099      \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,990\n",
      "Trainable params: 8,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 2s 23ms/step - loss: 0.0362 - val_loss: 0.0075\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 58/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 59/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 61/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 62/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 63/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 64/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 65/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 66/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 67/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 69/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 70/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 72/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 73/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 74/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 75/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 76/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 78/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 79/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 80/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 81/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 82/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 83/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 84/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 85/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.8826e-04 - val_loss: 0.0013\n",
      "Epoch 86/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.8361e-04 - val_loss: 0.0013\n",
      "Epoch 87/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.8613e-04 - val_loss: 0.0014\n",
      "Epoch 88/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.7813e-04 - val_loss: 0.0013\n",
      "Epoch 89/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.8194e-04 - val_loss: 0.0013\n",
      "Epoch 90/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.9331e-04 - val_loss: 0.0013\n",
      "Epoch 91/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.6843e-04 - val_loss: 0.0013\n",
      "Epoch 92/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.6741e-04 - val_loss: 0.0013\n",
      "Epoch 93/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.6594e-04 - val_loss: 0.0013\n",
      "Epoch 94/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.6445e-04 - val_loss: 0.0013\n",
      "Epoch 95/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.4691e-04 - val_loss: 0.0013\n",
      "Epoch 96/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.6631e-04 - val_loss: 0.0013\n",
      "Epoch 97/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.4221e-04 - val_loss: 0.0014\n",
      "Epoch 98/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.6646e-04 - val_loss: 0.0014\n",
      "Epoch 99/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.6293e-04 - val_loss: 0.0013\n",
      "Epoch 100/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.3031e-04 - val_loss: 0.0013\n",
      "Thời gian huấn luyện:  20.567808866500854\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_5 (LSTM)               (None, 10, 89)            32396     \n",
      "                                                                 \n",
      " flatten_22 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,287\n",
      "Trainable params: 33,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 2s 20ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 58/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 59/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 61/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 62/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 63/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 64/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 65/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 66/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 67/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 69/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 70/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 72/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 73/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 74/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 75/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 76/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 78/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 79/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 80/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 81/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 82/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 83/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 84/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 85/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 86/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 87/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 88/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 89/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 90/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 91/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 92/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 93/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 94/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 95/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 96/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 97/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 98/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 99/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 100/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thời gian huấn luyện:  18.30964231491089\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_5 (GRU)                 (None, 10, 89)            24564     \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,455\n",
      "Trainable params: 25,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "30/30 [==============================] - 0s 931us/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0707 - val_loss: 0.0121\n",
      "Epoch 2/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 3/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0074\n",
      "Epoch 4/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0071\n",
      "Epoch 5/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0069\n",
      "Epoch 6/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0065\n",
      "Epoch 7/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0062\n",
      "Epoch 8/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0057\n",
      "Epoch 9/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 10/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 11/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 12/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 13/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 14/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 15/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 16/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 17/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 18/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 19/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 20/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 21/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 22/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 23/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 24/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 25/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 26/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 27/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 28/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 29/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 30/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 31/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 32/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 33/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 34/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 35/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 36/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 37/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 38/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 39/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 40/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 41/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 42/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 43/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 44/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 45/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 46/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 47/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 48/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 49/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 50/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 51/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 52/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 53/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 54/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 55/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 56/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 57/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 58/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 59/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 60/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 61/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 62/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 63/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 64/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 65/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 66/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 67/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 68/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 69/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 70/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 71/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 72/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 73/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 74/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 75/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 76/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.9857e-04 - val_loss: 0.0017\n",
      "Epoch 77/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 78/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.8379e-04 - val_loss: 0.0016\n",
      "Epoch 79/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.8804e-04 - val_loss: 0.0016\n",
      "Epoch 80/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.7231e-04 - val_loss: 0.0016\n",
      "Epoch 81/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.6462e-04 - val_loss: 0.0016\n",
      "Epoch 82/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.6174e-04 - val_loss: 0.0016\n",
      "Epoch 83/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.5658e-04 - val_loss: 0.0016\n",
      "Epoch 84/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.5029e-04 - val_loss: 0.0015\n",
      "Epoch 85/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.4511e-04 - val_loss: 0.0015\n",
      "Epoch 86/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.3287e-04 - val_loss: 0.0015\n",
      "Epoch 87/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.2577e-04 - val_loss: 0.0015\n",
      "Epoch 88/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.1675e-04 - val_loss: 0.0015\n",
      "Epoch 89/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.0899e-04 - val_loss: 0.0015\n",
      "Epoch 90/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.0420e-04 - val_loss: 0.0015\n",
      "Epoch 91/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.9679e-04 - val_loss: 0.0015\n",
      "Epoch 92/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.9274e-04 - val_loss: 0.0015\n",
      "Epoch 93/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.8684e-04 - val_loss: 0.0014\n",
      "Epoch 94/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.8153e-04 - val_loss: 0.0014\n",
      "Epoch 95/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.7289e-04 - val_loss: 0.0014\n",
      "Epoch 96/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.7153e-04 - val_loss: 0.0014\n",
      "Epoch 97/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.6656e-04 - val_loss: 0.0014\n",
      "Epoch 98/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.5429e-04 - val_loss: 0.0014\n",
      "Epoch 99/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.4481e-04 - val_loss: 0.0014\n",
      "Epoch 100/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.3982e-04 - val_loss: 0.0014\n",
      "Epoch 101/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.3291e-04 - val_loss: 0.0014\n",
      "Epoch 102/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.2913e-04 - val_loss: 0.0013\n",
      "Epoch 103/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.3086e-04 - val_loss: 0.0013\n",
      "Epoch 104/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.1647e-04 - val_loss: 0.0013\n",
      "Epoch 105/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.0953e-04 - val_loss: 0.0013\n",
      "Epoch 106/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.0305e-04 - val_loss: 0.0013\n",
      "Epoch 107/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.0087e-04 - val_loss: 0.0013\n",
      "Epoch 108/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.9449e-04 - val_loss: 0.0013\n",
      "Epoch 109/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.9084e-04 - val_loss: 0.0013\n",
      "Epoch 110/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.8582e-04 - val_loss: 0.0013\n",
      "Epoch 111/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.8040e-04 - val_loss: 0.0012\n",
      "Epoch 112/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.7317e-04 - val_loss: 0.0012\n",
      "Epoch 113/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.6780e-04 - val_loss: 0.0012\n",
      "Epoch 114/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.6391e-04 - val_loss: 0.0012\n",
      "Epoch 115/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.5794e-04 - val_loss: 0.0012\n",
      "Epoch 116/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.5262e-04 - val_loss: 0.0012\n",
      "Epoch 117/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.4810e-04 - val_loss: 0.0012\n",
      "Epoch 118/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.4039e-04 - val_loss: 0.0012\n",
      "Epoch 119/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.3672e-04 - val_loss: 0.0012\n",
      "Epoch 120/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.3146e-04 - val_loss: 0.0012\n",
      "Epoch 121/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.2361e-04 - val_loss: 0.0012\n",
      "Epoch 122/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.3150e-04 - val_loss: 0.0011\n",
      "Epoch 123/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.2072e-04 - val_loss: 0.0011\n",
      "Epoch 124/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.1076e-04 - val_loss: 0.0011\n",
      "Epoch 125/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.0710e-04 - val_loss: 0.0011\n",
      "Epoch 126/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.0352e-04 - val_loss: 0.0011\n",
      "Epoch 127/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.9948e-04 - val_loss: 0.0011\n",
      "Epoch 128/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.9684e-04 - val_loss: 0.0011\n",
      "Epoch 129/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.9019e-04 - val_loss: 0.0011\n",
      "Epoch 130/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.8761e-04 - val_loss: 0.0011\n",
      "Epoch 131/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.8976e-04 - val_loss: 0.0011\n",
      "Epoch 132/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.7797e-04 - val_loss: 0.0011\n",
      "Epoch 133/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.7251e-04 - val_loss: 0.0011\n",
      "Epoch 134/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.7076e-04 - val_loss: 0.0010\n",
      "Epoch 135/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.6403e-04 - val_loss: 0.0010\n",
      "Epoch 136/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.6412e-04 - val_loss: 0.0010\n",
      "Epoch 137/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.5739e-04 - val_loss: 0.0010\n",
      "Epoch 138/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.6144e-04 - val_loss: 0.0010\n",
      "Epoch 139/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.5077e-04 - val_loss: 0.0010\n",
      "Epoch 140/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.4743e-04 - val_loss: 0.0010\n",
      "Epoch 141/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.4909e-04 - val_loss: 0.0010\n",
      "Epoch 142/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.4293e-04 - val_loss: 9.9818e-04\n",
      "Epoch 143/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.3938e-04 - val_loss: 9.8839e-04\n",
      "Epoch 144/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.3606e-04 - val_loss: 9.8412e-04\n",
      "Epoch 145/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.3825e-04 - val_loss: 9.8235e-04\n",
      "Epoch 146/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.3842e-04 - val_loss: 9.6909e-04\n",
      "Epoch 147/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.2696e-04 - val_loss: 9.7727e-04\n",
      "Epoch 148/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 2ms/step - loss: 6.2577e-04 - val_loss: 9.6305e-04\n",
      "Epoch 149/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.1996e-04 - val_loss: 9.5332e-04\n",
      "Epoch 150/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.2092e-04 - val_loss: 9.4899e-04\n",
      "Epoch 151/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.1435e-04 - val_loss: 9.4286e-04\n",
      "Epoch 152/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.1090e-04 - val_loss: 9.3858e-04\n",
      "Epoch 153/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.1336e-04 - val_loss: 9.4065e-04\n",
      "Epoch 154/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.0487e-04 - val_loss: 9.2727e-04\n",
      "Epoch 155/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.0398e-04 - val_loss: 9.2275e-04\n",
      "Epoch 156/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.0425e-04 - val_loss: 9.1931e-04\n",
      "Epoch 157/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.9893e-04 - val_loss: 9.1327e-04\n",
      "Epoch 158/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.9500e-04 - val_loss: 9.1329e-04\n",
      "Epoch 159/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.9464e-04 - val_loss: 9.0679e-04\n",
      "Epoch 160/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.9329e-04 - val_loss: 9.0268e-04\n",
      "Epoch 161/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.0181e-04 - val_loss: 8.9875e-04\n",
      "Epoch 162/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.9647e-04 - val_loss: 8.9454e-04\n",
      "Epoch 163/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.8591e-04 - val_loss: 8.8771e-04\n",
      "Epoch 164/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.8178e-04 - val_loss: 8.9332e-04\n",
      "Epoch 165/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.8209e-04 - val_loss: 8.8624e-04\n",
      "Epoch 166/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.8097e-04 - val_loss: 8.8002e-04\n",
      "Epoch 167/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.8121e-04 - val_loss: 8.9027e-04\n",
      "Epoch 168/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.7973e-04 - val_loss: 8.6889e-04\n",
      "Epoch 169/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.7393e-04 - val_loss: 8.6486e-04\n",
      "Epoch 170/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.7156e-04 - val_loss: 8.6107e-04\n",
      "Epoch 171/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.7389e-04 - val_loss: 8.5943e-04\n",
      "Epoch 172/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.7450e-04 - val_loss: 8.5498e-04\n",
      "Epoch 173/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.7675e-04 - val_loss: 8.5201e-04\n",
      "Epoch 174/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.6334e-04 - val_loss: 8.4846e-04\n",
      "Epoch 175/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.7841e-04 - val_loss: 8.8078e-04\n",
      "Epoch 176/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.6260e-04 - val_loss: 8.4638e-04\n",
      "Epoch 177/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.6868e-04 - val_loss: 8.3849e-04\n",
      "Epoch 178/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.6139e-04 - val_loss: 8.4002e-04\n",
      "Epoch 179/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.5683e-04 - val_loss: 8.3303e-04\n",
      "Epoch 180/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.5717e-04 - val_loss: 8.3198e-04\n",
      "Epoch 181/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.6295e-04 - val_loss: 8.2694e-04\n",
      "Epoch 182/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.5159e-04 - val_loss: 8.2892e-04\n",
      "Epoch 183/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.5772e-04 - val_loss: 8.2305e-04\n",
      "Epoch 184/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.5322e-04 - val_loss: 8.2254e-04\n",
      "Epoch 185/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.5067e-04 - val_loss: 8.1919e-04\n",
      "Epoch 186/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.5027e-04 - val_loss: 8.1471e-04\n",
      "Epoch 187/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.4838e-04 - val_loss: 8.1222e-04\n",
      "Epoch 188/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.4741e-04 - val_loss: 8.1417e-04\n",
      "Epoch 189/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.4412e-04 - val_loss: 8.1489e-04\n",
      "Epoch 190/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.4600e-04 - val_loss: 8.1640e-04\n",
      "Epoch 191/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.4441e-04 - val_loss: 8.0918e-04\n",
      "Epoch 192/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.4073e-04 - val_loss: 7.9979e-04\n",
      "Epoch 193/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.4056e-04 - val_loss: 8.0655e-04\n",
      "Epoch 194/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.3989e-04 - val_loss: 7.9816e-04\n",
      "Epoch 195/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.3769e-04 - val_loss: 7.9559e-04\n",
      "Epoch 196/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.3908e-04 - val_loss: 7.9077e-04\n",
      "Epoch 197/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.4008e-04 - val_loss: 7.8990e-04\n",
      "Epoch 198/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.3830e-04 - val_loss: 7.8675e-04\n",
      "Epoch 199/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.4033e-04 - val_loss: 7.8835e-04\n",
      "Epoch 200/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.3262e-04 - val_loss: 7.8206e-04\n",
      "Thời gian huấn luyện:  12.304442167282104\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 10, 89)            178       \n",
      "                                                                 \n",
      " flatten_24 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069\n",
      "Trainable params: 1,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "27/27 [==============================] - 1s 10ms/step - loss: 0.0185 - val_loss: 0.0052\n",
      "Epoch 2/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 3/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 4/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 5/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 6/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 7/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 8/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 9/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 10/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 11/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 12/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 13/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 14/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 15/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 16/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 18/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 19/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 20/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 21/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 22/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 23/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 24/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 25/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.9982e-04 - val_loss: 0.0017\n",
      "Epoch 26/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 27/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.7568e-04 - val_loss: 0.0017\n",
      "Epoch 28/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 9.7308e-04 - val_loss: 0.0016\n",
      "Epoch 29/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.5442e-04 - val_loss: 0.0017\n",
      "Epoch 30/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.6667e-04 - val_loss: 0.0016\n",
      "Epoch 31/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.8159e-04 - val_loss: 0.0016\n",
      "Epoch 32/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.2330e-04 - val_loss: 0.0016\n",
      "Epoch 33/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 9.3896e-04 - val_loss: 0.0015\n",
      "Epoch 34/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.1374e-04 - val_loss: 0.0015\n",
      "Epoch 35/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.9855e-04 - val_loss: 0.0015\n",
      "Epoch 36/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.8579e-04 - val_loss: 0.0015\n",
      "Epoch 37/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.7946e-04 - val_loss: 0.0015\n",
      "Epoch 38/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 8.7484e-04 - val_loss: 0.0015\n",
      "Epoch 39/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.7999e-04 - val_loss: 0.0014\n",
      "Epoch 40/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.7744e-04 - val_loss: 0.0014\n",
      "Epoch 41/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.9513e-04 - val_loss: 0.0015\n",
      "Epoch 42/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.5296e-04 - val_loss: 0.0014\n",
      "Epoch 43/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.4879e-04 - val_loss: 0.0014\n",
      "Epoch 44/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.3356e-04 - val_loss: 0.0014\n",
      "Epoch 45/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.3228e-04 - val_loss: 0.0014\n",
      "Epoch 46/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.2345e-04 - val_loss: 0.0014\n",
      "Epoch 47/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.0905e-04 - val_loss: 0.0014\n",
      "Epoch 48/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.7439e-04 - val_loss: 0.0013\n",
      "Epoch 49/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.7291e-04 - val_loss: 0.0013\n",
      "Epoch 50/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.1971e-04 - val_loss: 0.0013\n",
      "Epoch 51/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 8.1677e-04 - val_loss: 0.0013\n",
      "Epoch 52/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 7.8379e-04 - val_loss: 0.0014\n",
      "Epoch 53/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 7.8782e-04 - val_loss: 0.0013\n",
      "Epoch 54/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.8249e-04 - val_loss: 0.0013\n",
      "Epoch 55/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.7288e-04 - val_loss: 0.0012\n",
      "Epoch 56/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.8255e-04 - val_loss: 0.0012\n",
      "Epoch 57/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.1185e-04 - val_loss: 0.0012\n",
      "Epoch 58/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.7521e-04 - val_loss: 0.0012\n",
      "Epoch 59/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.7222e-04 - val_loss: 0.0013\n",
      "Epoch 60/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.6903e-04 - val_loss: 0.0013\n",
      "Epoch 61/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.8029e-04 - val_loss: 0.0012\n",
      "Epoch 62/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 7.3692e-04 - val_loss: 0.0012\n",
      "Epoch 63/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 7.8282e-04 - val_loss: 0.0012\n",
      "Epoch 64/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.4050e-04 - val_loss: 0.0012\n",
      "Epoch 65/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.2683e-04 - val_loss: 0.0011\n",
      "Epoch 66/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.1941e-04 - val_loss: 0.0012\n",
      "Epoch 67/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.2367e-04 - val_loss: 0.0011\n",
      "Epoch 68/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.4024e-04 - val_loss: 0.0011\n",
      "Epoch 69/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.5389e-04 - val_loss: 0.0011\n",
      "Epoch 70/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.1328e-04 - val_loss: 0.0011\n",
      "Epoch 71/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.0590e-04 - val_loss: 0.0011\n",
      "Epoch 72/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.0006e-04 - val_loss: 0.0011\n",
      "Epoch 73/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.9256e-04 - val_loss: 0.0011\n",
      "Epoch 74/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.9913e-04 - val_loss: 0.0011\n",
      "Epoch 75/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.9374e-04 - val_loss: 0.0011\n",
      "Epoch 76/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.9979e-04 - val_loss: 0.0011\n",
      "Epoch 77/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 7.0884e-04 - val_loss: 0.0011\n",
      "Epoch 78/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.8705e-04 - val_loss: 0.0011\n",
      "Epoch 79/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.7552e-04 - val_loss: 0.0011\n",
      "Epoch 80/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.1549e-04 - val_loss: 0.0011\n",
      "Epoch 81/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.9020e-04 - val_loss: 0.0011\n",
      "Epoch 82/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.5842e-04 - val_loss: 0.0010\n",
      "Epoch 83/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.5985e-04 - val_loss: 0.0010\n",
      "Epoch 84/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.5308e-04 - val_loss: 0.0010\n",
      "Epoch 85/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.8460e-04 - val_loss: 0.0010\n",
      "Epoch 86/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.5287e-04 - val_loss: 0.0010\n",
      "Epoch 87/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.7477e-04 - val_loss: 9.9660e-04\n",
      "Epoch 88/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.6240e-04 - val_loss: 9.9130e-04\n",
      "Epoch 89/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.6192e-04 - val_loss: 9.8963e-04\n",
      "Epoch 90/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.5435e-04 - val_loss: 9.9396e-04\n",
      "Epoch 91/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.4501e-04 - val_loss: 9.7712e-04\n",
      "Epoch 92/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.3960e-04 - val_loss: 9.7666e-04\n",
      "Epoch 93/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 6.8371e-04 - val_loss: 9.6471e-04\n",
      "Epoch 94/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 6.2722e-04 - val_loss: 0.0010\n",
      "Epoch 95/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.2671e-04 - val_loss: 9.5356e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.2563e-04 - val_loss: 9.8229e-04\n",
      "Epoch 97/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.2619e-04 - val_loss: 9.5143e-04\n",
      "Epoch 98/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.2691e-04 - val_loss: 9.3982e-04\n",
      "Epoch 99/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.1851e-04 - val_loss: 9.3251e-04\n",
      "Epoch 100/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.1607e-04 - val_loss: 9.2727e-04\n",
      "Epoch 101/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0881e-04 - val_loss: 9.6496e-04\n",
      "Epoch 102/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0935e-04 - val_loss: 9.5968e-04\n",
      "Epoch 103/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.9955e-04 - val_loss: 9.1245e-04\n",
      "Epoch 104/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.1214e-04 - val_loss: 9.2589e-04\n",
      "Epoch 105/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0473e-04 - val_loss: 9.0650e-04\n",
      "Epoch 106/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.1398e-04 - val_loss: 9.2131e-04\n",
      "Epoch 107/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.9566e-04 - val_loss: 8.9432e-04\n",
      "Epoch 108/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 5.9403e-04 - val_loss: 8.8976e-04\n",
      "Epoch 109/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.8880e-04 - val_loss: 8.8554e-04\n",
      "Epoch 110/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.8893e-04 - val_loss: 8.8969e-04\n",
      "Epoch 111/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.8516e-04 - val_loss: 8.7552e-04\n",
      "Epoch 112/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0152e-04 - val_loss: 8.7231e-04\n",
      "Epoch 113/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0602e-04 - val_loss: 9.0726e-04\n",
      "Epoch 114/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.7860e-04 - val_loss: 8.6315e-04\n",
      "Epoch 115/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.8836e-04 - val_loss: 8.8607e-04\n",
      "Epoch 116/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.8150e-04 - val_loss: 8.7309e-04\n",
      "Epoch 117/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.6948e-04 - val_loss: 8.5729e-04\n",
      "Epoch 118/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0629e-04 - val_loss: 8.6472e-04\n",
      "Epoch 119/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 5.8327e-04 - val_loss: 8.9104e-04\n",
      "Epoch 120/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.8488e-04 - val_loss: 9.3222e-04\n",
      "Epoch 121/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.6533e-04 - val_loss: 8.8034e-04\n",
      "Epoch 122/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.1337e-04 - val_loss: 8.7519e-04\n",
      "Epoch 123/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5948e-04 - val_loss: 8.3492e-04\n",
      "Epoch 124/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.6406e-04 - val_loss: 8.2475e-04\n",
      "Epoch 125/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.7056e-04 - val_loss: 8.4790e-04\n",
      "Epoch 126/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5344e-04 - val_loss: 8.2865e-04\n",
      "Epoch 127/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.7029e-04 - val_loss: 8.2496e-04\n",
      "Epoch 128/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5736e-04 - val_loss: 8.1017e-04\n",
      "Epoch 129/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5205e-04 - val_loss: 8.0783e-04\n",
      "Epoch 130/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.6160e-04 - val_loss: 8.0942e-04\n",
      "Epoch 131/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5849e-04 - val_loss: 8.4426e-04\n",
      "Epoch 132/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5649e-04 - val_loss: 7.9671e-04\n",
      "Epoch 133/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.6405e-04 - val_loss: 8.1813e-04\n",
      "Epoch 134/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5427e-04 - val_loss: 8.5481e-04\n",
      "Epoch 135/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.4924e-04 - val_loss: 7.9001e-04\n",
      "Epoch 136/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.4413e-04 - val_loss: 8.7812e-04\n",
      "Epoch 137/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 5.7531e-04 - val_loss: 7.8176e-04\n",
      "Epoch 138/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.8742e-04 - val_loss: 7.8638e-04\n",
      "Epoch 139/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.4517e-04 - val_loss: 7.7604e-04\n",
      "Epoch 140/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3439e-04 - val_loss: 7.7700e-04\n",
      "Epoch 141/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.4919e-04 - val_loss: 7.6943e-04\n",
      "Epoch 142/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3970e-04 - val_loss: 8.0378e-04\n",
      "Epoch 143/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3802e-04 - val_loss: 8.2644e-04\n",
      "Epoch 144/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5431e-04 - val_loss: 7.6207e-04\n",
      "Epoch 145/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5521e-04 - val_loss: 8.7690e-04\n",
      "Epoch 146/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5540e-04 - val_loss: 7.6906e-04\n",
      "Epoch 147/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.1970e-04 - val_loss: 7.7181e-04\n",
      "Epoch 148/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.4640e-04 - val_loss: 8.2602e-04\n",
      "Epoch 149/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3961e-04 - val_loss: 7.6044e-04\n",
      "Epoch 150/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.1882e-04 - val_loss: 7.5264e-04\n",
      "Epoch 151/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2291e-04 - val_loss: 7.7843e-04\n",
      "Epoch 152/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2507e-04 - val_loss: 7.6687e-04\n",
      "Epoch 153/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2434e-04 - val_loss: 7.5151e-04\n",
      "Epoch 154/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.1140e-04 - val_loss: 7.6006e-04\n",
      "Epoch 155/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.0945e-04 - val_loss: 7.8784e-04\n",
      "Epoch 156/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3014e-04 - val_loss: 7.2842e-04\n",
      "Epoch 157/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.0600e-04 - val_loss: 7.2700e-04\n",
      "Epoch 158/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.1387e-04 - val_loss: 7.2520e-04\n",
      "Epoch 159/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.1810e-04 - val_loss: 7.4438e-04\n",
      "Epoch 160/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 5.2289e-04 - val_loss: 7.3247e-04\n",
      "Epoch 161/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.1413e-04 - val_loss: 7.6193e-04\n",
      "Epoch 162/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.1589e-04 - val_loss: 7.1493e-04\n",
      "Epoch 163/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.0304e-04 - val_loss: 7.2608e-04\n",
      "Epoch 164/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.1288e-04 - val_loss: 7.1468e-04\n",
      "Epoch 165/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2400e-04 - val_loss: 7.1538e-04\n",
      "Epoch 166/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2793e-04 - val_loss: 7.0466e-04\n",
      "Epoch 167/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2242e-04 - val_loss: 7.5062e-04\n",
      "Epoch 168/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.1108e-04 - val_loss: 7.0043e-04\n",
      "Epoch 169/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.9888e-04 - val_loss: 7.0108e-04\n",
      "Epoch 170/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.9549e-04 - val_loss: 6.9415e-04\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 3ms/step - loss: 5.0233e-04 - val_loss: 7.0190e-04\n",
      "Epoch 172/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.0133e-04 - val_loss: 6.8982e-04\n",
      "Epoch 173/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.9581e-04 - val_loss: 6.9973e-04\n",
      "Epoch 174/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.8943e-04 - val_loss: 7.0345e-04\n",
      "Epoch 175/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.8781e-04 - val_loss: 6.8062e-04\n",
      "Epoch 176/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.9181e-04 - val_loss: 6.9184e-04\n",
      "Epoch 177/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.9296e-04 - val_loss: 6.7664e-04\n",
      "Epoch 178/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.0028e-04 - val_loss: 6.8428e-04\n",
      "Epoch 179/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.9511e-04 - val_loss: 6.7373e-04\n",
      "Epoch 180/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.0830e-04 - val_loss: 7.2598e-04\n",
      "Epoch 181/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.8562e-04 - val_loss: 7.1555e-04\n",
      "Epoch 182/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.8542e-04 - val_loss: 6.9273e-04\n",
      "Epoch 183/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.0431e-04 - val_loss: 6.7015e-04\n",
      "Epoch 184/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 5.0077e-04 - val_loss: 6.6440e-04\n",
      "Epoch 185/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.7960e-04 - val_loss: 7.6433e-04\n",
      "Epoch 186/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.1653e-04 - val_loss: 6.6664e-04\n",
      "Epoch 187/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.9135e-04 - val_loss: 6.8032e-04\n",
      "Epoch 188/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.7994e-04 - val_loss: 6.6281e-04\n",
      "Epoch 189/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.8995e-04 - val_loss: 6.5600e-04\n",
      "Epoch 190/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.8277e-04 - val_loss: 6.5875e-04\n",
      "Epoch 191/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.8863e-04 - val_loss: 6.6420e-04\n",
      "Epoch 192/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.9088e-04 - val_loss: 6.6531e-04\n",
      "Epoch 193/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.6720e-04 - val_loss: 6.4904e-04\n",
      "Epoch 194/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.9247e-04 - val_loss: 6.5277e-04\n",
      "Epoch 195/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.8515e-04 - val_loss: 6.9592e-04\n",
      "Epoch 196/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.0334e-04 - val_loss: 6.4376e-04\n",
      "Epoch 197/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.8362e-04 - val_loss: 6.4343e-04\n",
      "Epoch 198/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.8470e-04 - val_loss: 6.4332e-04\n",
      "Epoch 199/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.7472e-04 - val_loss: 6.7060e-04\n",
      "Epoch 200/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.7452e-04 - val_loss: 6.3620e-04\n",
      "Thời gian huấn luyện:  19.156447887420654\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_6 (SimpleRNN)    (None, 10, 89)            8099      \n",
      "                                                                 \n",
      " flatten_25 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,990\n",
      "Trainable params: 8,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "27/27 [==============================] - 2s 20ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 2/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 3/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 4/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 5/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 6/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 7/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 8/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 9/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 10/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 11/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 12/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 13/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 14/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 15/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 16/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 17/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 18/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 19/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 20/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 21/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 22/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 23/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 24/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 25/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 26/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 27/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 28/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 29/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 30/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 31/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 32/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 33/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 34/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 35/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 36/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 37/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 38/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 39/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 40/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 41/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 43/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 44/200\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 45/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 46/200\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 47/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 48/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 49/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 50/200\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 51/200\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 52/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 53/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 54/200\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 55/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 56/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 57/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 58/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 59/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 60/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 61/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 62/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 63/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 64/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 65/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 66/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 67/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 68/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 69/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 70/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 71/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 72/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 73/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 74/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 75/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 76/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 77/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 78/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 79/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 80/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 81/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 82/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 83/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 84/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 85/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 86/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 87/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 88/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 89/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 90/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 91/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 92/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 93/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 94/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 95/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 96/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 97/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 98/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 99/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 100/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 101/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 102/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 103/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 104/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 105/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 106/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 107/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 108/200\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 109/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 110/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 111/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 112/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 113/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 114/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 115/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 116/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 117/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 118/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 119/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 120/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 121/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 122/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 123/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 124/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 125/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 126/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 127/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 128/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 129/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 130/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 131/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 132/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 133/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 134/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 135/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 136/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 137/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 138/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 139/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 140/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 141/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 142/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 143/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 144/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 145/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 146/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 147/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 148/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 149/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 150/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 151/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 152/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 153/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 154/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 155/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 156/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 157/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 158/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 159/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 160/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 161/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 162/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 163/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 164/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 165/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 166/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 167/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 168/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 169/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 170/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 171/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 172/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 173/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 174/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 175/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 176/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 177/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 178/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 179/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 180/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 181/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 182/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 183/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 184/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 185/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 186/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 187/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 188/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 189/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 190/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 191/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 192/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 193/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 194/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 195/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 196/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 197/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 198/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 199/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 200/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Thời gian huấn luyện:  39.320109844207764\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 10, 89)            32396     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " flatten_26 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,287\n",
      "Trainable params: 33,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "27/27 [==============================] - 2s 18ms/step - loss: 0.0233 - val_loss: 0.0036\n",
      "Epoch 2/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 3/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 4/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 5/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 6/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 7/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 8/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 9/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 10/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 11/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 12/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 13/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 14/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 15/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 16/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 17/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 18/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 19/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 20/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 21/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 22/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 23/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 24/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 25/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 26/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 27/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 28/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 29/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 30/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 31/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 32/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.8591e-04 - val_loss: 0.0016\n",
      "Epoch 33/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.5933e-04 - val_loss: 0.0016\n",
      "Epoch 34/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.5330e-04 - val_loss: 0.0016\n",
      "Epoch 35/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.3814e-04 - val_loss: 0.0016\n",
      "Epoch 36/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.3745e-04 - val_loss: 0.0016\n",
      "Epoch 37/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.1580e-04 - val_loss: 0.0015\n",
      "Epoch 38/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.0572e-04 - val_loss: 0.0015\n",
      "Epoch 39/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.0301e-04 - val_loss: 0.0015\n",
      "Epoch 40/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.8289e-04 - val_loss: 0.0015\n",
      "Epoch 41/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.8744e-04 - val_loss: 0.0015\n",
      "Epoch 42/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.7156e-04 - val_loss: 0.0015\n",
      "Epoch 43/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.6033e-04 - val_loss: 0.0014\n",
      "Epoch 44/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.5062e-04 - val_loss: 0.0014\n",
      "Epoch 45/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.4100e-04 - val_loss: 0.0014\n",
      "Epoch 46/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.4325e-04 - val_loss: 0.0014\n",
      "Epoch 47/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.3673e-04 - val_loss: 0.0014\n",
      "Epoch 48/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.2214e-04 - val_loss: 0.0014\n",
      "Epoch 49/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.1575e-04 - val_loss: 0.0014\n",
      "Epoch 50/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.1038e-04 - val_loss: 0.0014\n",
      "Epoch 51/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.0450e-04 - val_loss: 0.0013\n",
      "Epoch 52/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.9769e-04 - val_loss: 0.0014\n",
      "Epoch 53/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.9775e-04 - val_loss: 0.0013\n",
      "Epoch 54/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.8553e-04 - val_loss: 0.0013\n",
      "Epoch 55/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.7771e-04 - val_loss: 0.0013\n",
      "Epoch 56/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.7445e-04 - val_loss: 0.0013\n",
      "Epoch 57/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.7465e-04 - val_loss: 0.0013\n",
      "Epoch 58/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.6719e-04 - val_loss: 0.0013\n",
      "Epoch 59/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.6058e-04 - val_loss: 0.0013\n",
      "Epoch 60/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.5556e-04 - val_loss: 0.0013\n",
      "Epoch 61/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.5067e-04 - val_loss: 0.0013\n",
      "Epoch 62/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.5110e-04 - val_loss: 0.0013\n",
      "Epoch 63/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.4946e-04 - val_loss: 0.0012\n",
      "Epoch 64/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.4971e-04 - val_loss: 0.0012\n",
      "Epoch 65/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.3947e-04 - val_loss: 0.0012\n",
      "Epoch 66/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.5334e-04 - val_loss: 0.0012\n",
      "Epoch 67/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.4462e-04 - val_loss: 0.0012\n",
      "Epoch 68/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.3409e-04 - val_loss: 0.0012\n",
      "Epoch 69/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.4366e-04 - val_loss: 0.0012\n",
      "Epoch 70/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.2171e-04 - val_loss: 0.0012\n",
      "Epoch 71/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.1071e-04 - val_loss: 0.0012\n",
      "Epoch 72/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.1805e-04 - val_loss: 0.0012\n",
      "Epoch 73/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.1700e-04 - val_loss: 0.0012\n",
      "Epoch 74/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.1195e-04 - val_loss: 0.0012\n",
      "Epoch 75/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.1177e-04 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.9759e-04 - val_loss: 0.0012\n",
      "Epoch 77/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.9704e-04 - val_loss: 0.0011\n",
      "Epoch 78/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.9320e-04 - val_loss: 0.0011\n",
      "Epoch 79/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.8656e-04 - val_loss: 0.0011\n",
      "Epoch 80/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.9884e-04 - val_loss: 0.0011\n",
      "Epoch 81/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.8247e-04 - val_loss: 0.0011\n",
      "Epoch 82/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.7829e-04 - val_loss: 0.0011\n",
      "Epoch 83/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.8262e-04 - val_loss: 0.0011\n",
      "Epoch 84/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.7442e-04 - val_loss: 0.0011\n",
      "Epoch 85/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.7235e-04 - val_loss: 0.0011\n",
      "Epoch 86/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.7514e-04 - val_loss: 0.0011\n",
      "Epoch 87/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.6512e-04 - val_loss: 0.0011\n",
      "Epoch 88/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.6663e-04 - val_loss: 0.0011\n",
      "Epoch 89/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.6244e-04 - val_loss: 0.0011\n",
      "Epoch 90/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.6314e-04 - val_loss: 0.0011\n",
      "Epoch 91/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.5402e-04 - val_loss: 0.0011\n",
      "Epoch 92/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.5000e-04 - val_loss: 0.0011\n",
      "Epoch 93/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.5697e-04 - val_loss: 0.0011\n",
      "Epoch 94/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.4833e-04 - val_loss: 0.0010\n",
      "Epoch 95/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.4637e-04 - val_loss: 0.0010\n",
      "Epoch 96/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.5222e-04 - val_loss: 0.0011\n",
      "Epoch 97/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.4300e-04 - val_loss: 0.0011\n",
      "Epoch 98/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.5784e-04 - val_loss: 0.0010\n",
      "Epoch 99/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.3764e-04 - val_loss: 0.0010\n",
      "Epoch 100/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.4199e-04 - val_loss: 0.0010\n",
      "Epoch 101/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2954e-04 - val_loss: 0.0010\n",
      "Epoch 102/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.4278e-04 - val_loss: 0.0010\n",
      "Epoch 103/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.3817e-04 - val_loss: 0.0010\n",
      "Epoch 104/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2342e-04 - val_loss: 0.0010\n",
      "Epoch 105/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2685e-04 - val_loss: 9.9169e-04\n",
      "Epoch 106/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2611e-04 - val_loss: 0.0010\n",
      "Epoch 107/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2174e-04 - val_loss: 9.7891e-04\n",
      "Epoch 108/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2280e-04 - val_loss: 9.8186e-04\n",
      "Epoch 109/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2249e-04 - val_loss: 9.6952e-04\n",
      "Epoch 110/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2391e-04 - val_loss: 9.6682e-04\n",
      "Epoch 111/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2017e-04 - val_loss: 9.9090e-04\n",
      "Epoch 112/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.0664e-04 - val_loss: 9.7068e-04\n",
      "Epoch 113/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.0393e-04 - val_loss: 9.7679e-04\n",
      "Epoch 114/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2032e-04 - val_loss: 9.4386e-04\n",
      "Epoch 115/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.9853e-04 - val_loss: 9.4490e-04\n",
      "Epoch 116/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.0312e-04 - val_loss: 9.4026e-04\n",
      "Epoch 117/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.0341e-04 - val_loss: 9.3266e-04\n",
      "Epoch 118/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.9743e-04 - val_loss: 9.4285e-04\n",
      "Epoch 119/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.0338e-04 - val_loss: 9.7494e-04\n",
      "Epoch 120/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.0973e-04 - val_loss: 9.2651e-04\n",
      "Epoch 121/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.9635e-04 - val_loss: 9.5159e-04\n",
      "Epoch 122/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.8882e-04 - val_loss: 9.1231e-04\n",
      "Epoch 123/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.8085e-04 - val_loss: 9.1208e-04\n",
      "Epoch 124/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.8187e-04 - val_loss: 9.1244e-04\n",
      "Epoch 125/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.8225e-04 - val_loss: 9.0744e-04\n",
      "Epoch 126/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.8058e-04 - val_loss: 9.0388e-04\n",
      "Epoch 127/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.7368e-04 - val_loss: 9.1168e-04\n",
      "Epoch 128/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.7274e-04 - val_loss: 9.2376e-04\n",
      "Epoch 129/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.7564e-04 - val_loss: 8.8894e-04\n",
      "Epoch 130/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.7131e-04 - val_loss: 8.8770e-04\n",
      "Epoch 131/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.7410e-04 - val_loss: 8.8073e-04\n",
      "Epoch 132/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.6691e-04 - val_loss: 8.7209e-04\n",
      "Epoch 133/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.6639e-04 - val_loss: 8.9929e-04\n",
      "Epoch 134/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.7764e-04 - val_loss: 8.6542e-04\n",
      "Epoch 135/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.6797e-04 - val_loss: 8.6427e-04\n",
      "Epoch 136/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.6019e-04 - val_loss: 8.5945e-04\n",
      "Epoch 137/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.5758e-04 - val_loss: 8.6457e-04\n",
      "Epoch 138/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.5658e-04 - val_loss: 8.5216e-04\n",
      "Epoch 139/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.5468e-04 - val_loss: 8.4844e-04\n",
      "Epoch 140/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.6139e-04 - val_loss: 8.4561e-04\n",
      "Epoch 141/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.6068e-04 - val_loss: 8.5741e-04\n",
      "Epoch 142/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.6401e-04 - val_loss: 8.3876e-04\n",
      "Epoch 143/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.5960e-04 - val_loss: 8.4357e-04\n",
      "Epoch 144/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.4907e-04 - val_loss: 8.4675e-04\n",
      "Epoch 145/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.4223e-04 - val_loss: 8.3368e-04\n",
      "Epoch 146/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.4068e-04 - val_loss: 8.2529e-04\n",
      "Epoch 147/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.6252e-04 - val_loss: 8.2652e-04\n",
      "Epoch 148/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.4818e-04 - val_loss: 8.1834e-04\n",
      "Epoch 149/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.4524e-04 - val_loss: 8.4498e-04\n",
      "Epoch 150/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.4038e-04 - val_loss: 8.1482e-04\n",
      "Epoch 151/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.3759e-04 - val_loss: 8.0977e-04\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 6ms/step - loss: 5.5776e-04 - val_loss: 8.1257e-04\n",
      "Epoch 153/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.3919e-04 - val_loss: 8.0331e-04\n",
      "Epoch 154/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.3488e-04 - val_loss: 8.0423e-04\n",
      "Epoch 155/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.3021e-04 - val_loss: 8.1065e-04\n",
      "Epoch 156/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.2898e-04 - val_loss: 7.9633e-04\n",
      "Epoch 157/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.4205e-04 - val_loss: 8.3166e-04\n",
      "Epoch 158/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.4339e-04 - val_loss: 7.9612e-04\n",
      "Epoch 159/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.3782e-04 - val_loss: 7.8790e-04\n",
      "Epoch 160/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.2676e-04 - val_loss: 7.8311e-04\n",
      "Epoch 161/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.2682e-04 - val_loss: 7.8505e-04\n",
      "Epoch 162/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.2253e-04 - val_loss: 7.8098e-04\n",
      "Epoch 163/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.2319e-04 - val_loss: 7.7637e-04\n",
      "Epoch 164/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.2447e-04 - val_loss: 7.8999e-04\n",
      "Epoch 165/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.2177e-04 - val_loss: 7.7213e-04\n",
      "Epoch 166/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.2036e-04 - val_loss: 7.7199e-04\n",
      "Epoch 167/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.3362e-04 - val_loss: 7.8898e-04\n",
      "Epoch 168/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.7400e-04 - val_loss: 7.6214e-04\n",
      "Epoch 169/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 5.2834e-04 - val_loss: 7.6518e-04\n",
      "Epoch 170/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.2139e-04 - val_loss: 7.5951e-04\n",
      "Epoch 171/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.2190e-04 - val_loss: 7.8309e-04\n",
      "Epoch 172/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.1370e-04 - val_loss: 7.8046e-04\n",
      "Epoch 173/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.0670e-04 - val_loss: 7.5229e-04\n",
      "Epoch 174/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.0960e-04 - val_loss: 7.6697e-04\n",
      "Epoch 175/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.1230e-04 - val_loss: 7.4643e-04\n",
      "Epoch 176/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.1001e-04 - val_loss: 7.8417e-04\n",
      "Epoch 177/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.0390e-04 - val_loss: 7.4184e-04\n",
      "Epoch 178/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.0665e-04 - val_loss: 7.4163e-04\n",
      "Epoch 179/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.0439e-04 - val_loss: 7.6353e-04\n",
      "Epoch 180/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.0948e-04 - val_loss: 7.4563e-04\n",
      "Epoch 181/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.0627e-04 - val_loss: 7.6187e-04\n",
      "Epoch 182/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.0663e-04 - val_loss: 7.8473e-04\n",
      "Epoch 183/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.0936e-04 - val_loss: 7.7185e-04\n",
      "Epoch 184/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.4101e-04 - val_loss: 7.5617e-04\n",
      "Epoch 185/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.3773e-04 - val_loss: 7.4285e-04\n",
      "Epoch 186/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.2117e-04 - val_loss: 7.2343e-04\n",
      "Epoch 187/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.1556e-04 - val_loss: 7.2559e-04\n",
      "Epoch 188/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.9667e-04 - val_loss: 7.3961e-04\n",
      "Epoch 189/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.9967e-04 - val_loss: 7.3407e-04\n",
      "Epoch 190/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.9869e-04 - val_loss: 7.1530e-04\n",
      "Epoch 191/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.9300e-04 - val_loss: 7.1345e-04\n",
      "Epoch 192/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.9459e-04 - val_loss: 7.1725e-04\n",
      "Epoch 193/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.9755e-04 - val_loss: 7.1050e-04\n",
      "Epoch 194/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.8871e-04 - val_loss: 7.3071e-04\n",
      "Epoch 195/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.0017e-04 - val_loss: 7.0338e-04\n",
      "Epoch 196/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.9322e-04 - val_loss: 7.4176e-04\n",
      "Epoch 197/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.9362e-04 - val_loss: 7.1504e-04\n",
      "Epoch 198/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.8425e-04 - val_loss: 7.0107e-04\n",
      "Epoch 199/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.9838e-04 - val_loss: 7.1131e-04\n",
      "Epoch 200/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.8684e-04 - val_loss: 6.9650e-04\n",
      "Thời gian huấn luyện:  35.96290373802185\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_6 (GRU)                 (None, 10, 89)            24564     \n",
      "                                                                 \n",
      " flatten_27 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,455\n",
      "Trainable params: 25,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "30/30 [==============================] - 0s 931us/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 24/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 29/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 32/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 42/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 44/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 49/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 50/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 51/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 52/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 53/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 54/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 55/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 56/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 57/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 58/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 59/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 60/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 61/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 62/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 63/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 64/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 65/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 66/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 67/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 68/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 69/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 70/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 71/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 72/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 73/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 74/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 75/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 76/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 77/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 78/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 79/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 80/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 81/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 82/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 83/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 84/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 85/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 86/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 87/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 88/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 89/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 90/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 91/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 92/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 93/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 94/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 95/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 96/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 97/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 98/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 100/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 101/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 102/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 103/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 104/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 105/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 106/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 107/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 108/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 109/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 110/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 111/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 112/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 113/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 114/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 115/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 116/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 117/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 118/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 119/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 120/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 121/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 122/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 123/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 124/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 125/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 126/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 127/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 128/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 129/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 130/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 131/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 132/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 133/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 134/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 135/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 136/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 137/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 138/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 139/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 140/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 141/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 142/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 143/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 144/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 145/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 146/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 147/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 148/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 149/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 150/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 151/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 152/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 153/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 154/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 155/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 156/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 157/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 158/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 159/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 160/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 161/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 162/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 163/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 164/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 165/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 166/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 167/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 168/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 169/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 170/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 171/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 172/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 173/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 174/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 175/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 176/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 177/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 178/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 179/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 180/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 181/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 182/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 183/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 184/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 185/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 186/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 187/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 188/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 189/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 190/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 191/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 192/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 193/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 194/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 195/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 196/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 197/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 198/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 199/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 200/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Thời gian huấn luyện:  12.718680381774902\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_35 (Dense)            (None, 10, 89)            178       \n",
      "                                                                 \n",
      " flatten_28 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069\n",
      "Trainable params: 1,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "26/26 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.0062\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.6260e-04 - val_loss: 0.0016\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.3805e-04 - val_loss: 0.0015\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 9.6674e-04 - val_loss: 0.0014\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 8.8455e-04 - val_loss: 0.0014\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.6465e-04 - val_loss: 0.0014\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 8.4996e-04 - val_loss: 0.0013\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 8.4174e-04 - val_loss: 0.0014\n",
      "Epoch 17/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 8.4676e-04 - val_loss: 0.0012\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.1168e-04 - val_loss: 0.0012\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.0377e-04 - val_loss: 0.0012\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 8.1760e-04 - val_loss: 0.0012\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 8.0519e-04 - val_loss: 0.0012\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.8563e-04 - val_loss: 0.0012\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.8413e-04 - val_loss: 0.0011\n",
      "Epoch 24/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.0141e-04 - val_loss: 0.0012\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.7508e-04 - val_loss: 0.0012\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.5288e-04 - val_loss: 0.0011\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.5382e-04 - val_loss: 0.0011\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.4755e-04 - val_loss: 0.0011\n",
      "Epoch 29/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.4360e-04 - val_loss: 0.0011\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.4675e-04 - val_loss: 0.0011\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.3909e-04 - val_loss: 0.0010\n",
      "Epoch 32/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.2650e-04 - val_loss: 0.0010\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.1320e-04 - val_loss: 0.0010\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 7.1432e-04 - val_loss: 0.0010\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.0451e-04 - val_loss: 0.0010\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.9841e-04 - val_loss: 9.9877e-04\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9575e-04 - val_loss: 9.8369e-04\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.9329e-04 - val_loss: 9.7693e-04\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.9772e-04 - val_loss: 0.0010\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8516e-04 - val_loss: 9.6641e-04\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8147e-04 - val_loss: 9.5222e-04\n",
      "Epoch 42/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8556e-04 - val_loss: 9.8572e-04\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8734e-04 - val_loss: 0.0010\n",
      "Epoch 44/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.9518e-04 - val_loss: 9.6939e-04\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8261e-04 - val_loss: 9.7239e-04\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9580e-04 - val_loss: 9.7402e-04\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.6887e-04 - val_loss: 9.1912e-04\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.6274e-04 - val_loss: 9.8932e-04\n",
      "Epoch 49/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1931e-04 - val_loss: 9.5197e-04\n",
      "Epoch 50/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6695e-04 - val_loss: 9.0902e-04\n",
      "Epoch 51/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 4ms/step - loss: 7.3908e-04 - val_loss: 9.2478e-04\n",
      "Epoch 52/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.6858e-04 - val_loss: 9.1006e-04\n",
      "Epoch 53/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4115e-04 - val_loss: 8.9313e-04\n",
      "Epoch 54/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3589e-04 - val_loss: 8.9081e-04\n",
      "Epoch 55/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4544e-04 - val_loss: 8.8478e-04\n",
      "Epoch 56/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3664e-04 - val_loss: 9.5064e-04\n",
      "Epoch 57/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.7962e-04 - val_loss: 8.8050e-04\n",
      "Epoch 58/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.6345e-04 - val_loss: 8.6535e-04\n",
      "Epoch 59/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.2958e-04 - val_loss: 8.7547e-04\n",
      "Epoch 60/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.2622e-04 - val_loss: 8.7004e-04\n",
      "Epoch 61/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.3477e-04 - val_loss: 8.5393e-04\n",
      "Epoch 62/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6590e-04 - val_loss: 8.5216e-04\n",
      "Epoch 63/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.2286e-04 - val_loss: 9.0474e-04\n",
      "Epoch 64/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.3223e-04 - val_loss: 8.5383e-04\n",
      "Epoch 65/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2341e-04 - val_loss: 8.6658e-04\n",
      "Epoch 66/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.1613e-04 - val_loss: 8.4142e-04\n",
      "Epoch 67/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1281e-04 - val_loss: 9.2952e-04\n",
      "Epoch 68/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3306e-04 - val_loss: 8.2741e-04\n",
      "Epoch 69/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.1971e-04 - val_loss: 8.4170e-04\n",
      "Epoch 70/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.1542e-04 - val_loss: 8.8444e-04\n",
      "Epoch 71/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3299e-04 - val_loss: 8.2604e-04\n",
      "Epoch 72/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.0832e-04 - val_loss: 8.1085e-04\n",
      "Epoch 73/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.9786e-04 - val_loss: 8.0978e-04\n",
      "Epoch 74/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.9366e-04 - val_loss: 8.0916e-04\n",
      "Epoch 75/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3326e-04 - val_loss: 8.0234e-04\n",
      "Epoch 76/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9356e-04 - val_loss: 8.6991e-04\n",
      "Epoch 77/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.0841e-04 - val_loss: 8.0416e-04\n",
      "Epoch 78/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8788e-04 - val_loss: 7.9693e-04\n",
      "Epoch 79/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.8930e-04 - val_loss: 8.2279e-04\n",
      "Epoch 80/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.9233e-04 - val_loss: 8.3388e-04\n",
      "Epoch 81/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2543e-04 - val_loss: 9.5202e-04\n",
      "Epoch 82/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.0532e-04 - val_loss: 8.3759e-04\n",
      "Epoch 83/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.9989e-04 - val_loss: 8.5460e-04\n",
      "Epoch 84/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9312e-04 - val_loss: 7.9545e-04\n",
      "Epoch 85/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1688e-04 - val_loss: 8.0539e-04\n",
      "Epoch 86/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.8809e-04 - val_loss: 8.9561e-04\n",
      "Epoch 87/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9428e-04 - val_loss: 8.3965e-04\n",
      "Epoch 88/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.7819e-04 - val_loss: 8.4056e-04\n",
      "Epoch 89/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8840e-04 - val_loss: 7.6197e-04\n",
      "Epoch 90/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.7326e-04 - val_loss: 7.6084e-04\n",
      "Epoch 91/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.5480e-04 - val_loss: 7.6035e-04\n",
      "Epoch 92/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.6591e-04 - val_loss: 8.7275e-04\n",
      "Epoch 93/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9442e-04 - val_loss: 8.2830e-04\n",
      "Epoch 94/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.6729e-04 - val_loss: 8.3499e-04\n",
      "Epoch 95/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8181e-04 - val_loss: 9.0589e-04\n",
      "Epoch 96/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8149e-04 - val_loss: 7.4017e-04\n",
      "Epoch 97/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.6095e-04 - val_loss: 7.9730e-04\n",
      "Epoch 98/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3740e-04 - val_loss: 7.3996e-04\n",
      "Epoch 99/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.6654e-04 - val_loss: 7.4171e-04\n",
      "Epoch 100/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.5363e-04 - val_loss: 7.7451e-04\n",
      "Epoch 101/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.7897e-04 - val_loss: 7.5864e-04\n",
      "Epoch 102/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.5678e-04 - val_loss: 7.5051e-04\n",
      "Epoch 103/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.7413e-04 - val_loss: 7.8776e-04\n",
      "Epoch 104/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.5166e-04 - val_loss: 8.0252e-04\n",
      "Epoch 105/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.8881e-04 - val_loss: 8.7707e-04\n",
      "Epoch 106/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.6212e-04 - val_loss: 7.1681e-04\n",
      "Epoch 107/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.4558e-04 - val_loss: 7.2349e-04\n",
      "Epoch 108/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.3755e-04 - val_loss: 7.1142e-04\n",
      "Epoch 109/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.4350e-04 - val_loss: 7.1626e-04\n",
      "Epoch 110/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8738e-04 - val_loss: 7.1097e-04\n",
      "Epoch 111/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.5414e-04 - val_loss: 7.0670e-04\n",
      "Epoch 112/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.3402e-04 - val_loss: 7.4188e-04\n",
      "Epoch 113/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.3738e-04 - val_loss: 7.0051e-04\n",
      "Epoch 114/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8092e-04 - val_loss: 7.4544e-04\n",
      "Epoch 115/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1881e-04 - val_loss: 7.0721e-04\n",
      "Epoch 116/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.3433e-04 - val_loss: 6.9516e-04\n",
      "Epoch 117/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.3524e-04 - val_loss: 6.9527e-04\n",
      "Epoch 118/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.3680e-04 - val_loss: 7.0036e-04\n",
      "Epoch 119/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.4340e-04 - val_loss: 7.7476e-04\n",
      "Epoch 120/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.4554e-04 - val_loss: 6.9300e-04\n",
      "Epoch 121/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.5249e-04 - val_loss: 6.8666e-04\n",
      "Epoch 122/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.2323e-04 - val_loss: 6.9047e-04\n",
      "Epoch 123/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.2194e-04 - val_loss: 7.1642e-04\n",
      "Epoch 124/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.6817e-04 - val_loss: 6.8568e-04\n",
      "Epoch 125/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.2382e-04 - val_loss: 6.9975e-04\n",
      "Epoch 126/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 4ms/step - loss: 5.2381e-04 - val_loss: 7.2389e-04\n",
      "Epoch 127/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.4974e-04 - val_loss: 6.9482e-04\n",
      "Epoch 128/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.4557e-04 - val_loss: 7.2914e-04\n",
      "Epoch 129/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.3179e-04 - val_loss: 6.9214e-04\n",
      "Epoch 130/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.1822e-04 - val_loss: 7.2393e-04\n",
      "Epoch 131/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.1770e-04 - val_loss: 6.7983e-04\n",
      "Epoch 132/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.2013e-04 - val_loss: 6.6581e-04\n",
      "Epoch 133/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.3123e-04 - val_loss: 6.6200e-04\n",
      "Epoch 134/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.3519e-04 - val_loss: 6.6886e-04\n",
      "Epoch 135/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.5607e-04 - val_loss: 6.9961e-04\n",
      "Epoch 136/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.3711e-04 - val_loss: 6.5574e-04\n",
      "Epoch 137/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.5233e-04 - val_loss: 6.5658e-04\n",
      "Epoch 138/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.5192e-04 - val_loss: 6.8320e-04\n",
      "Epoch 139/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.3152e-04 - val_loss: 7.7007e-04\n",
      "Epoch 140/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.2579e-04 - val_loss: 6.9060e-04\n",
      "Epoch 141/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.2502e-04 - val_loss: 7.2492e-04\n",
      "Epoch 142/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.6292e-04 - val_loss: 6.7956e-04\n",
      "Epoch 143/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.3258e-04 - val_loss: 6.4514e-04\n",
      "Epoch 144/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.0606e-04 - val_loss: 6.9417e-04\n",
      "Epoch 145/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.1493e-04 - val_loss: 7.3101e-04\n",
      "Epoch 146/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.1782e-04 - val_loss: 6.5609e-04\n",
      "Epoch 147/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.1872e-04 - val_loss: 6.3640e-04\n",
      "Epoch 148/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.2496e-04 - val_loss: 6.3971e-04\n",
      "Epoch 149/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.0845e-04 - val_loss: 6.7181e-04\n",
      "Epoch 150/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.9593e-04 - val_loss: 6.4721e-04\n",
      "Epoch 151/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.0333e-04 - val_loss: 6.3256e-04\n",
      "Epoch 152/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.9895e-04 - val_loss: 6.4238e-04\n",
      "Epoch 153/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.0916e-04 - val_loss: 6.7686e-04\n",
      "Epoch 154/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.9643e-04 - val_loss: 6.3425e-04\n",
      "Epoch 155/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.9877e-04 - val_loss: 6.2841e-04\n",
      "Epoch 156/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.0400e-04 - val_loss: 6.3341e-04\n",
      "Epoch 157/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.0151e-04 - val_loss: 6.1903e-04\n",
      "Epoch 158/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.0180e-04 - val_loss: 7.4340e-04\n",
      "Epoch 159/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.9986e-04 - val_loss: 6.9590e-04\n",
      "Epoch 160/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.3588e-04 - val_loss: 7.0413e-04\n",
      "Epoch 161/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.9959e-04 - val_loss: 8.7849e-04\n",
      "Epoch 162/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.3393e-04 - val_loss: 7.8543e-04\n",
      "Epoch 163/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.2804e-04 - val_loss: 6.1499e-04\n",
      "Epoch 164/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.8986e-04 - val_loss: 6.1827e-04\n",
      "Epoch 165/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.0360e-04 - val_loss: 6.4125e-04\n",
      "Epoch 166/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.0932e-04 - val_loss: 6.4508e-04\n",
      "Epoch 167/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.9389e-04 - val_loss: 6.0825e-04\n",
      "Epoch 168/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.9099e-04 - val_loss: 6.0445e-04\n",
      "Epoch 169/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.1213e-04 - val_loss: 6.5157e-04\n",
      "Epoch 170/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.9329e-04 - val_loss: 6.0220e-04\n",
      "Epoch 171/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.8169e-04 - val_loss: 6.0269e-04\n",
      "Epoch 172/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.8385e-04 - val_loss: 6.4793e-04\n",
      "Epoch 173/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.8242e-04 - val_loss: 6.2362e-04\n",
      "Epoch 174/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.7567e-04 - val_loss: 6.0615e-04\n",
      "Epoch 175/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.8139e-04 - val_loss: 6.0110e-04\n",
      "Epoch 176/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.8201e-04 - val_loss: 6.3336e-04\n",
      "Epoch 177/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.9584e-04 - val_loss: 6.0676e-04\n",
      "Epoch 178/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.3918e-04 - val_loss: 6.9622e-04\n",
      "Epoch 179/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.9008e-04 - val_loss: 6.3196e-04\n",
      "Epoch 180/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.7350e-04 - val_loss: 5.9061e-04\n",
      "Epoch 181/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.7312e-04 - val_loss: 5.9437e-04\n",
      "Epoch 182/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.1832e-04 - val_loss: 5.8885e-04\n",
      "Epoch 183/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.9768e-04 - val_loss: 6.1593e-04\n",
      "Epoch 184/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.9418e-04 - val_loss: 6.3299e-04\n",
      "Epoch 185/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.7806e-04 - val_loss: 8.0223e-04\n",
      "Epoch 186/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.3678e-04 - val_loss: 6.6533e-04\n",
      "Epoch 187/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.9386e-04 - val_loss: 6.0460e-04\n",
      "Epoch 188/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.7557e-04 - val_loss: 5.8131e-04\n",
      "Epoch 189/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.6601e-04 - val_loss: 5.8856e-04\n",
      "Epoch 190/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.7584e-04 - val_loss: 6.3688e-04\n",
      "Epoch 191/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.6875e-04 - val_loss: 5.9942e-04\n",
      "Epoch 192/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.8279e-04 - val_loss: 5.8155e-04\n",
      "Epoch 193/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.7067e-04 - val_loss: 5.7329e-04\n",
      "Epoch 194/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.7283e-04 - val_loss: 5.8816e-04\n",
      "Epoch 195/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.6630e-04 - val_loss: 5.8072e-04\n",
      "Epoch 196/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.6924e-04 - val_loss: 6.1646e-04\n",
      "Epoch 197/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.6504e-04 - val_loss: 5.8366e-04\n",
      "Epoch 198/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.7770e-04 - val_loss: 5.8463e-04\n",
      "Epoch 199/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.8673e-04 - val_loss: 5.6886e-04\n",
      "Epoch 200/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.7152e-04 - val_loss: 5.6660e-04\n",
      "Thời gian huấn luyện:  19.293518781661987\n",
      "Model: \"sequential_29\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_7 (SimpleRNN)    (None, 10, 89)            8099      \n",
      "                                                                 \n",
      " flatten_29 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,990\n",
      "Trainable params: 8,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "26/26 [==============================] - 2s 20ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 17/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 24/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 29/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 32/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 42/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 44/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 49/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 50/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 51/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 52/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 53/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 54/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 55/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 56/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 57/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 58/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 59/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 60/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 61/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 62/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 63/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 64/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 65/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 66/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 67/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 68/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 69/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 70/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 71/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 72/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 73/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 74/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 75/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 76/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 77/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 78/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 79/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 80/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 81/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 82/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 83/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 84/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 85/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 86/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 87/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 88/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 89/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 90/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 91/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 92/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 93/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 94/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 95/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 96/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 97/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 98/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 99/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 100/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 101/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 102/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 103/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 104/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 105/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 106/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 107/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 108/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 109/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 110/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 111/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 112/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 113/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 114/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 115/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 116/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 117/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 118/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 119/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 120/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 121/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 122/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 123/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 124/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 125/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 126/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 127/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 128/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 129/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 130/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 131/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 132/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 133/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 134/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 135/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 136/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 137/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 138/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 139/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 140/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 141/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 142/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 143/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 144/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 145/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 146/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 147/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 148/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 149/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 150/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 151/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 152/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 153/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 154/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 155/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 157/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 158/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 159/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 160/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 161/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 162/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 163/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 164/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 165/200\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 166/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 167/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 168/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 169/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 170/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 171/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 172/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 173/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 174/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 175/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 176/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 177/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 178/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 179/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 180/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 181/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 182/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 183/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 184/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 185/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 186/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 187/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 188/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 189/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 190/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 191/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 192/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 193/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 194/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 195/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 196/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 197/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 198/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 199/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 200/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Thời gian huấn luyện:  39.17798829078674\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_7 (LSTM)               (None, 10, 89)            32396     \n",
      "                                                                 \n",
      " flatten_30 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,287\n",
      "Trainable params: 33,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "26/26 [==============================] - 2s 18ms/step - loss: 0.0191 - val_loss: 0.0032\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 17/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 24/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 32/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.9533e-04 - val_loss: 0.0017\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.7962e-04 - val_loss: 0.0016\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.6770e-04 - val_loss: 0.0017\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.4968e-04 - val_loss: 0.0017\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.6102e-04 - val_loss: 0.0016\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.3356e-04 - val_loss: 0.0015\n",
      "Epoch 42/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.2744e-04 - val_loss: 0.0015\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.0753e-04 - val_loss: 0.0015\n",
      "Epoch 44/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 8.9948e-04 - val_loss: 0.0015\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.9264e-04 - val_loss: 0.0014\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.7890e-04 - val_loss: 0.0014\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.7208e-04 - val_loss: 0.0015\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.6394e-04 - val_loss: 0.0014\n",
      "Epoch 49/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.5255e-04 - val_loss: 0.0013\n",
      "Epoch 50/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.6722e-04 - val_loss: 0.0013\n",
      "Epoch 51/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.3861e-04 - val_loss: 0.0013\n",
      "Epoch 52/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.3276e-04 - val_loss: 0.0013\n",
      "Epoch 53/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.3124e-04 - val_loss: 0.0013\n",
      "Epoch 54/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.1529e-04 - val_loss: 0.0013\n",
      "Epoch 55/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.1006e-04 - val_loss: 0.0012\n",
      "Epoch 56/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.9837e-04 - val_loss: 0.0014\n",
      "Epoch 57/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.1620e-04 - val_loss: 0.0013\n",
      "Epoch 58/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.0317e-04 - val_loss: 0.0012\n",
      "Epoch 59/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.9066e-04 - val_loss: 0.0012\n",
      "Epoch 60/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.7771e-04 - val_loss: 0.0013\n",
      "Epoch 61/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.7496e-04 - val_loss: 0.0012\n",
      "Epoch 62/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.7927e-04 - val_loss: 0.0012\n",
      "Epoch 63/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.7417e-04 - val_loss: 0.0012\n",
      "Epoch 64/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.6690e-04 - val_loss: 0.0012\n",
      "Epoch 65/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.7070e-04 - val_loss: 0.0012\n",
      "Epoch 66/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.5589e-04 - val_loss: 0.0011\n",
      "Epoch 67/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.6040e-04 - val_loss: 0.0011\n",
      "Epoch 68/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.5674e-04 - val_loss: 0.0011\n",
      "Epoch 69/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 7.8259e-04 - val_loss: 0.0011\n",
      "Epoch 70/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.6390e-04 - val_loss: 0.0012\n",
      "Epoch 71/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.4966e-04 - val_loss: 0.0011\n",
      "Epoch 72/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.4314e-04 - val_loss: 0.0011\n",
      "Epoch 73/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 7.2906e-04 - val_loss: 0.0011\n",
      "Epoch 74/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.2709e-04 - val_loss: 0.0011\n",
      "Epoch 75/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 7.2220e-04 - val_loss: 0.0011\n",
      "Epoch 76/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 7.3601e-04 - val_loss: 0.0011\n",
      "Epoch 77/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.2226e-04 - val_loss: 0.0011\n",
      "Epoch 78/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 7.1792e-04 - val_loss: 0.0011\n",
      "Epoch 79/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.2210e-04 - val_loss: 0.0011\n",
      "Epoch 80/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.0577e-04 - val_loss: 0.0011\n",
      "Epoch 81/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.1807e-04 - val_loss: 0.0011\n",
      "Epoch 82/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.1059e-04 - val_loss: 0.0010\n",
      "Epoch 83/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.9803e-04 - val_loss: 0.0010\n",
      "Epoch 84/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.9820e-04 - val_loss: 0.0010\n",
      "Epoch 85/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.9151e-04 - val_loss: 0.0010\n",
      "Epoch 86/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.8698e-04 - val_loss: 0.0011\n",
      "Epoch 87/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.8575e-04 - val_loss: 0.0011\n",
      "Epoch 88/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.8866e-04 - val_loss: 0.0010\n",
      "Epoch 89/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.8111e-04 - val_loss: 9.9715e-04\n",
      "Epoch 90/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.7656e-04 - val_loss: 0.0010\n",
      "Epoch 91/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.6987e-04 - val_loss: 0.0010\n",
      "Epoch 92/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.7331e-04 - val_loss: 9.8283e-04\n",
      "Epoch 93/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.6853e-04 - val_loss: 9.8139e-04\n",
      "Epoch 94/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.7980e-04 - val_loss: 9.7249e-04\n",
      "Epoch 95/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.8612e-04 - val_loss: 0.0010\n",
      "Epoch 96/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 6.7001e-04 - val_loss: 9.8740e-04\n",
      "Epoch 97/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.5651e-04 - val_loss: 9.6555e-04\n",
      "Epoch 98/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 6.6176e-04 - val_loss: 9.7716e-04\n",
      "Epoch 99/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.5320e-04 - val_loss: 9.8489e-04\n",
      "Epoch 100/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.4669e-04 - val_loss: 0.0010\n",
      "Epoch 101/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.7252e-04 - val_loss: 9.8938e-04\n",
      "Epoch 102/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.5114e-04 - val_loss: 9.6407e-04\n",
      "Epoch 103/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.4310e-04 - val_loss: 9.8390e-04\n",
      "Epoch 104/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.6076e-04 - val_loss: 9.2832e-04\n",
      "Epoch 105/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.5070e-04 - val_loss: 9.4136e-04\n",
      "Epoch 106/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 6.4006e-04 - val_loss: 9.2194e-04\n",
      "Epoch 107/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 6ms/step - loss: 6.3239e-04 - val_loss: 9.1578e-04\n",
      "Epoch 108/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.3867e-04 - val_loss: 9.2806e-04\n",
      "Epoch 109/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.2996e-04 - val_loss: 9.0575e-04\n",
      "Epoch 110/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.3263e-04 - val_loss: 9.1873e-04\n",
      "Epoch 111/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.2525e-04 - val_loss: 9.2269e-04\n",
      "Epoch 112/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.2638e-04 - val_loss: 9.5398e-04\n",
      "Epoch 113/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.2256e-04 - val_loss: 8.8411e-04\n",
      "Epoch 114/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.1750e-04 - val_loss: 8.9118e-04\n",
      "Epoch 115/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.2045e-04 - val_loss: 9.3150e-04\n",
      "Epoch 116/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.1230e-04 - val_loss: 8.7591e-04\n",
      "Epoch 117/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.2520e-04 - val_loss: 8.7068e-04\n",
      "Epoch 118/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.0789e-04 - val_loss: 8.9347e-04\n",
      "Epoch 119/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.1022e-04 - val_loss: 8.6455e-04\n",
      "Epoch 120/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.1265e-04 - val_loss: 9.0015e-04\n",
      "Epoch 121/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 6.0579e-04 - val_loss: 8.5722e-04\n",
      "Epoch 122/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.0507e-04 - val_loss: 8.7134e-04\n",
      "Epoch 123/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.1292e-04 - val_loss: 8.4451e-04\n",
      "Epoch 124/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.0070e-04 - val_loss: 8.4826e-04\n",
      "Epoch 125/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.9594e-04 - val_loss: 8.3641e-04\n",
      "Epoch 126/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.1126e-04 - val_loss: 8.3182e-04\n",
      "Epoch 127/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.0819e-04 - val_loss: 8.3901e-04\n",
      "Epoch 128/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.9074e-04 - val_loss: 8.2610e-04\n",
      "Epoch 129/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.9685e-04 - val_loss: 8.4481e-04\n",
      "Epoch 130/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 5.9418e-04 - val_loss: 8.3941e-04\n",
      "Epoch 131/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.8810e-04 - val_loss: 8.5240e-04\n",
      "Epoch 132/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.8216e-04 - val_loss: 8.1144e-04\n",
      "Epoch 133/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.7817e-04 - val_loss: 8.2143e-04\n",
      "Epoch 134/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.8055e-04 - val_loss: 8.1771e-04\n",
      "Epoch 135/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.8198e-04 - val_loss: 8.1281e-04\n",
      "Epoch 136/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.7735e-04 - val_loss: 7.9893e-04\n",
      "Epoch 137/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.8635e-04 - val_loss: 8.2402e-04\n",
      "Epoch 138/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 5.7321e-04 - val_loss: 7.9262e-04\n",
      "Epoch 139/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.7543e-04 - val_loss: 8.7328e-04\n",
      "Epoch 140/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.8689e-04 - val_loss: 8.1784e-04\n",
      "Epoch 141/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.6887e-04 - val_loss: 7.8728e-04\n",
      "Epoch 142/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.7135e-04 - val_loss: 8.1080e-04\n",
      "Epoch 143/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.6840e-04 - val_loss: 7.7736e-04\n",
      "Epoch 144/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.6790e-04 - val_loss: 7.7463e-04\n",
      "Epoch 145/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.6810e-04 - val_loss: 7.7134e-04\n",
      "Epoch 146/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.6402e-04 - val_loss: 8.4807e-04\n",
      "Epoch 147/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.7299e-04 - val_loss: 7.6606e-04\n",
      "Epoch 148/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.6360e-04 - val_loss: 8.5783e-04\n",
      "Epoch 149/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.6541e-04 - val_loss: 7.6442e-04\n",
      "Epoch 150/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.5895e-04 - val_loss: 7.6396e-04\n",
      "Epoch 151/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.5663e-04 - val_loss: 7.6508e-04\n",
      "Epoch 152/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.4738e-04 - val_loss: 7.5320e-04\n",
      "Epoch 153/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.5387e-04 - val_loss: 7.6708e-04\n",
      "Epoch 154/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.4367e-04 - val_loss: 7.4412e-04\n",
      "Epoch 155/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.4877e-04 - val_loss: 7.4600e-04\n",
      "Epoch 156/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.4953e-04 - val_loss: 8.4311e-04\n",
      "Epoch 157/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 5.5920e-04 - val_loss: 7.4172e-04\n",
      "Epoch 158/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3965e-04 - val_loss: 7.4296e-04\n",
      "Epoch 159/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 5.4886e-04 - val_loss: 7.3842e-04\n",
      "Epoch 160/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3846e-04 - val_loss: 7.3379e-04\n",
      "Epoch 161/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3648e-04 - val_loss: 7.2933e-04\n",
      "Epoch 162/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3972e-04 - val_loss: 7.7184e-04\n",
      "Epoch 163/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3944e-04 - val_loss: 7.4633e-04\n",
      "Epoch 164/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3838e-04 - val_loss: 7.2037e-04\n",
      "Epoch 165/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3910e-04 - val_loss: 7.2966e-04\n",
      "Epoch 166/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.4565e-04 - val_loss: 7.2429e-04\n",
      "Epoch 167/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.2922e-04 - val_loss: 7.2933e-04\n",
      "Epoch 168/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3632e-04 - val_loss: 7.3323e-04\n",
      "Epoch 169/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.2972e-04 - val_loss: 7.0755e-04\n",
      "Epoch 170/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3059e-04 - val_loss: 7.5034e-04\n",
      "Epoch 171/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3058e-04 - val_loss: 7.3310e-04\n",
      "Epoch 172/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.2429e-04 - val_loss: 7.0851e-04\n",
      "Epoch 173/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.2079e-04 - val_loss: 7.0643e-04\n",
      "Epoch 174/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.2146e-04 - val_loss: 7.1847e-04\n",
      "Epoch 175/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3384e-04 - val_loss: 6.9508e-04\n",
      "Epoch 176/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.1718e-04 - val_loss: 7.1577e-04\n",
      "Epoch 177/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3452e-04 - val_loss: 6.9110e-04\n",
      "Epoch 178/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.1917e-04 - val_loss: 6.9246e-04\n",
      "Epoch 179/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.1895e-04 - val_loss: 6.8598e-04\n",
      "Epoch 180/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.1915e-04 - val_loss: 7.2033e-04\n",
      "Epoch 181/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.1665e-04 - val_loss: 6.8462e-04\n",
      "Epoch 182/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 6ms/step - loss: 5.1031e-04 - val_loss: 7.1422e-04\n",
      "Epoch 183/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.1647e-04 - val_loss: 6.7911e-04\n",
      "Epoch 184/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3035e-04 - val_loss: 6.7582e-04\n",
      "Epoch 185/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.0836e-04 - val_loss: 6.9552e-04\n",
      "Epoch 186/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.1500e-04 - val_loss: 6.7613e-04\n",
      "Epoch 187/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.0792e-04 - val_loss: 6.7124e-04\n",
      "Epoch 188/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.0544e-04 - val_loss: 6.7021e-04\n",
      "Epoch 189/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.0288e-04 - val_loss: 6.8472e-04\n",
      "Epoch 190/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.0426e-04 - val_loss: 6.7035e-04\n",
      "Epoch 191/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.0163e-04 - val_loss: 6.7436e-04\n",
      "Epoch 192/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.0654e-04 - val_loss: 6.6447e-04\n",
      "Epoch 193/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.1442e-04 - val_loss: 6.6206e-04\n",
      "Epoch 194/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.0050e-04 - val_loss: 6.7088e-04\n",
      "Epoch 195/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 4.9889e-04 - val_loss: 6.6226e-04\n",
      "Epoch 196/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.0007e-04 - val_loss: 6.5817e-04\n",
      "Epoch 197/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.0746e-04 - val_loss: 6.5677e-04\n",
      "Epoch 198/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.0336e-04 - val_loss: 6.6301e-04\n",
      "Epoch 199/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 4.9739e-04 - val_loss: 6.4667e-04\n",
      "Epoch 200/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 4.9427e-04 - val_loss: 6.5678e-04\n",
      "Thời gian huấn luyện:  35.321553468704224\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_7 (GRU)                 (None, 10, 89)            24564     \n",
      "                                                                 \n",
      " flatten_31 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,455\n",
      "Trainable params: 25,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 1s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0559 - val_loss: 0.0212\n",
      "Epoch 2/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0065\n",
      "Epoch 3/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 4/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 5/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 6/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 7/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 8/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 9/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 10/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 11/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 12/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 13/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 14/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 15/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 16/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 17/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 18/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 19/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 20/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 21/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 22/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 23/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 24/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 25/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 26/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 27/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 28/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 29/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 30/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 31/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 32/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 33/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 34/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 35/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 36/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 37/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 38/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 39/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 40/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 41/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 42/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 43/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 44/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 45/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 46/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 47/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 48/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 50/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 51/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 52/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 53/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 54/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 55/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 56/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 57/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 58/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 59/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 60/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 61/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 62/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 63/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 64/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 65/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 66/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 67/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 68/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 69/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 70/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 71/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.9276e-04 - val_loss: 0.0013\n",
      "Epoch 72/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.8931e-04 - val_loss: 0.0013\n",
      "Epoch 73/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.8514e-04 - val_loss: 0.0013\n",
      "Epoch 74/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.7826e-04 - val_loss: 0.0013\n",
      "Epoch 75/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.7763e-04 - val_loss: 0.0013\n",
      "Epoch 76/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.6918e-04 - val_loss: 0.0013\n",
      "Epoch 77/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.6571e-04 - val_loss: 0.0013\n",
      "Epoch 78/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.5925e-04 - val_loss: 0.0012\n",
      "Epoch 79/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.5884e-04 - val_loss: 0.0012\n",
      "Epoch 80/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.4764e-04 - val_loss: 0.0012\n",
      "Epoch 81/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.4196e-04 - val_loss: 0.0012\n",
      "Epoch 82/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.3992e-04 - val_loss: 0.0012\n",
      "Epoch 83/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.4644e-04 - val_loss: 0.0012\n",
      "Epoch 84/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.3065e-04 - val_loss: 0.0012\n",
      "Epoch 85/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 9.3009e-04 - val_loss: 0.0012\n",
      "Epoch 86/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.2896e-04 - val_loss: 0.0012\n",
      "Epoch 87/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.1298e-04 - val_loss: 0.0012\n",
      "Epoch 88/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.1066e-04 - val_loss: 0.0012\n",
      "Epoch 89/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 9.0459e-04 - val_loss: 0.0012\n",
      "Epoch 90/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.9952e-04 - val_loss: 0.0012\n",
      "Epoch 91/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.9735e-04 - val_loss: 0.0012\n",
      "Epoch 92/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.9043e-04 - val_loss: 0.0012\n",
      "Epoch 93/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.8633e-04 - val_loss: 0.0011\n",
      "Epoch 94/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.8242e-04 - val_loss: 0.0011\n",
      "Epoch 95/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.7929e-04 - val_loss: 0.0011\n",
      "Epoch 96/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.7265e-04 - val_loss: 0.0011\n",
      "Epoch 97/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.6688e-04 - val_loss: 0.0011\n",
      "Epoch 98/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.6569e-04 - val_loss: 0.0011\n",
      "Epoch 99/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.6072e-04 - val_loss: 0.0011\n",
      "Epoch 100/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.5443e-04 - val_loss: 0.0011\n",
      "Epoch 101/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.4802e-04 - val_loss: 0.0011\n",
      "Epoch 102/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.4302e-04 - val_loss: 0.0011\n",
      "Epoch 103/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.3842e-04 - val_loss: 0.0011\n",
      "Epoch 104/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.3589e-04 - val_loss: 0.0011\n",
      "Epoch 105/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.3144e-04 - val_loss: 0.0011\n",
      "Epoch 106/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.2599e-04 - val_loss: 0.0011\n",
      "Epoch 107/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.2263e-04 - val_loss: 0.0010\n",
      "Epoch 108/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.1689e-04 - val_loss: 0.0011\n",
      "Epoch 109/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.1503e-04 - val_loss: 0.0010\n",
      "Epoch 110/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.1108e-04 - val_loss: 0.0010\n",
      "Epoch 111/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.1074e-04 - val_loss: 0.0010\n",
      "Epoch 112/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.0121e-04 - val_loss: 0.0010\n",
      "Epoch 113/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.9854e-04 - val_loss: 0.0010\n",
      "Epoch 114/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.9271e-04 - val_loss: 0.0010\n",
      "Epoch 115/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.9522e-04 - val_loss: 9.9522e-04\n",
      "Epoch 116/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.9181e-04 - val_loss: 9.8670e-04\n",
      "Epoch 117/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.8309e-04 - val_loss: 9.8059e-04\n",
      "Epoch 118/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.7928e-04 - val_loss: 9.7638e-04\n",
      "Epoch 119/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.7219e-04 - val_loss: 9.6806e-04\n",
      "Epoch 120/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.6843e-04 - val_loss: 9.6309e-04\n",
      "Epoch 121/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.6547e-04 - val_loss: 9.5914e-04\n",
      "Epoch 122/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.6105e-04 - val_loss: 9.6743e-04\n",
      "Epoch 123/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.6119e-04 - val_loss: 9.4956e-04\n",
      "Epoch 124/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.5244e-04 - val_loss: 9.4246e-04\n",
      "Epoch 125/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.4868e-04 - val_loss: 9.3488e-04\n",
      "Epoch 126/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.4604e-04 - val_loss: 9.2782e-04\n",
      "Epoch 127/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.4523e-04 - val_loss: 9.2248e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.3917e-04 - val_loss: 9.2022e-04\n",
      "Epoch 129/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.4454e-04 - val_loss: 9.6728e-04\n",
      "Epoch 130/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.4223e-04 - val_loss: 9.0633e-04\n",
      "Epoch 131/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.3091e-04 - val_loss: 9.0062e-04\n",
      "Epoch 132/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.3323e-04 - val_loss: 9.0288e-04\n",
      "Epoch 133/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.3411e-04 - val_loss: 9.0019e-04\n",
      "Epoch 134/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.2327e-04 - val_loss: 9.0022e-04\n",
      "Epoch 135/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.1342e-04 - val_loss: 8.8171e-04\n",
      "Epoch 136/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.1147e-04 - val_loss: 8.7881e-04\n",
      "Epoch 137/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.1256e-04 - val_loss: 8.7053e-04\n",
      "Epoch 138/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.0375e-04 - val_loss: 8.6511e-04\n",
      "Epoch 139/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.0264e-04 - val_loss: 8.7629e-04\n",
      "Epoch 140/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.9919e-04 - val_loss: 8.5619e-04\n",
      "Epoch 141/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.9955e-04 - val_loss: 8.6408e-04\n",
      "Epoch 142/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.0074e-04 - val_loss: 8.4671e-04\n",
      "Epoch 143/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.9012e-04 - val_loss: 8.4205e-04\n",
      "Epoch 144/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.8636e-04 - val_loss: 8.4668e-04\n",
      "Epoch 145/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.8280e-04 - val_loss: 8.3310e-04\n",
      "Epoch 146/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.8076e-04 - val_loss: 8.3129e-04\n",
      "Epoch 147/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.8112e-04 - val_loss: 8.2407e-04\n",
      "Epoch 148/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.7723e-04 - val_loss: 8.1991e-04\n",
      "Epoch 149/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.7102e-04 - val_loss: 8.2407e-04\n",
      "Epoch 150/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.7191e-04 - val_loss: 8.1247e-04\n",
      "Epoch 151/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.6645e-04 - val_loss: 8.1593e-04\n",
      "Epoch 152/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.6327e-04 - val_loss: 8.0659e-04\n",
      "Epoch 153/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.6567e-04 - val_loss: 8.0741e-04\n",
      "Epoch 154/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.6996e-04 - val_loss: 8.1233e-04\n",
      "Epoch 155/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.6284e-04 - val_loss: 7.9788e-04\n",
      "Epoch 156/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.5285e-04 - val_loss: 7.8943e-04\n",
      "Epoch 157/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.5033e-04 - val_loss: 7.8446e-04\n",
      "Epoch 158/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.5599e-04 - val_loss: 7.8056e-04\n",
      "Epoch 159/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.4967e-04 - val_loss: 7.7575e-04\n",
      "Epoch 160/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.4683e-04 - val_loss: 7.8204e-04\n",
      "Epoch 161/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.4249e-04 - val_loss: 7.6889e-04\n",
      "Epoch 162/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.4399e-04 - val_loss: 7.6529e-04\n",
      "Epoch 163/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.3702e-04 - val_loss: 7.6319e-04\n",
      "Epoch 164/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.3280e-04 - val_loss: 7.5821e-04\n",
      "Epoch 165/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.3271e-04 - val_loss: 7.6029e-04\n",
      "Epoch 166/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.3465e-04 - val_loss: 7.5802e-04\n",
      "Epoch 167/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.2846e-04 - val_loss: 7.4855e-04\n",
      "Epoch 168/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.2363e-04 - val_loss: 7.5249e-04\n",
      "Epoch 169/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.3655e-04 - val_loss: 7.8465e-04\n",
      "Epoch 170/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.3027e-04 - val_loss: 7.3815e-04\n",
      "Epoch 171/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.2127e-04 - val_loss: 7.4769e-04\n",
      "Epoch 172/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.1578e-04 - val_loss: 7.3644e-04\n",
      "Epoch 173/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.1910e-04 - val_loss: 7.2937e-04\n",
      "Epoch 174/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.1919e-04 - val_loss: 7.3280e-04\n",
      "Epoch 175/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.2103e-04 - val_loss: 7.5220e-04\n",
      "Epoch 176/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.1106e-04 - val_loss: 7.2061e-04\n",
      "Epoch 177/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.0866e-04 - val_loss: 7.1894e-04\n",
      "Epoch 178/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.0685e-04 - val_loss: 7.1738e-04\n",
      "Epoch 179/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.0454e-04 - val_loss: 7.1226e-04\n",
      "Epoch 180/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.0468e-04 - val_loss: 7.1290e-04\n",
      "Epoch 181/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.0401e-04 - val_loss: 7.1471e-04\n",
      "Epoch 182/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.0155e-04 - val_loss: 7.0430e-04\n",
      "Epoch 183/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.9885e-04 - val_loss: 7.0162e-04\n",
      "Epoch 184/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.9951e-04 - val_loss: 7.0002e-04\n",
      "Epoch 185/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.9751e-04 - val_loss: 6.9783e-04\n",
      "Epoch 186/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.9399e-04 - val_loss: 6.9784e-04\n",
      "Epoch 187/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.9328e-04 - val_loss: 6.9924e-04\n",
      "Epoch 188/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.9829e-04 - val_loss: 6.8947e-04\n",
      "Epoch 189/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.9180e-04 - val_loss: 6.9125e-04\n",
      "Epoch 190/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.9228e-04 - val_loss: 6.9785e-04\n",
      "Epoch 191/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.8545e-04 - val_loss: 6.8237e-04\n",
      "Epoch 192/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.8462e-04 - val_loss: 6.7998e-04\n",
      "Epoch 193/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.8357e-04 - val_loss: 6.8246e-04\n",
      "Epoch 194/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.8168e-04 - val_loss: 6.7997e-04\n",
      "Epoch 195/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.8137e-04 - val_loss: 6.7339e-04\n",
      "Epoch 196/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.7647e-04 - val_loss: 6.7230e-04\n",
      "Epoch 197/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.7809e-04 - val_loss: 6.6918e-04\n",
      "Epoch 198/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.7815e-04 - val_loss: 6.6738e-04\n",
      "Epoch 199/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.7379e-04 - val_loss: 6.6651e-04\n",
      "Epoch 200/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.7683e-04 - val_loss: 6.6312e-04\n",
      "Thời gian huấn luyện:  12.227001428604126\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_40 (Dense)            (None, 10, 89)            178       \n",
      "                                                                 \n",
      " flatten_32 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069\n",
      "Trainable params: 1,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "24/24 [==============================] - 1s 10ms/step - loss: 0.0189 - val_loss: 0.0025\n",
      "Epoch 2/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 3/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 4/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 5/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 6/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 7/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 8/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 9/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 10/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 11/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 12/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 13/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 14/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 15/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 16/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 17/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 18/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 19/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 20/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 21/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 22/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 23/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 24/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.9138e-04 - val_loss: 0.0012\n",
      "Epoch 25/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 26/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.7989e-04 - val_loss: 0.0012\n",
      "Epoch 27/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.9268e-04 - val_loss: 0.0012\n",
      "Epoch 28/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.5718e-04 - val_loss: 0.0012\n",
      "Epoch 29/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.4589e-04 - val_loss: 0.0012\n",
      "Epoch 30/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.4670e-04 - val_loss: 0.0012\n",
      "Epoch 31/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.3197e-04 - val_loss: 0.0012\n",
      "Epoch 32/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.7293e-04 - val_loss: 0.0012\n",
      "Epoch 33/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.5719e-04 - val_loss: 0.0011\n",
      "Epoch 34/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.2597e-04 - val_loss: 0.0011\n",
      "Epoch 35/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.9993e-04 - val_loss: 0.0011\n",
      "Epoch 36/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.0446e-04 - val_loss: 0.0011\n",
      "Epoch 37/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.0263e-04 - val_loss: 0.0012\n",
      "Epoch 38/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.0013e-04 - val_loss: 0.0011\n",
      "Epoch 39/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.7617e-04 - val_loss: 0.0011\n",
      "Epoch 40/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.7212e-04 - val_loss: 0.0011\n",
      "Epoch 41/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.5782e-04 - val_loss: 0.0011\n",
      "Epoch 42/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.6651e-04 - val_loss: 0.0010\n",
      "Epoch 43/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.5131e-04 - val_loss: 0.0010\n",
      "Epoch 44/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.4666e-04 - val_loss: 0.0010\n",
      "Epoch 45/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.4082e-04 - val_loss: 0.0010\n",
      "Epoch 46/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.3799e-04 - val_loss: 0.0010\n",
      "Epoch 47/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.4374e-04 - val_loss: 0.0010\n",
      "Epoch 48/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.4089e-04 - val_loss: 9.9612e-04\n",
      "Epoch 49/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.1647e-04 - val_loss: 9.8878e-04\n",
      "Epoch 50/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.0848e-04 - val_loss: 9.9870e-04\n",
      "Epoch 51/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.0786e-04 - val_loss: 9.9302e-04\n",
      "Epoch 52/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.5547e-04 - val_loss: 9.7122e-04\n",
      "Epoch 53/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.9854e-04 - val_loss: 9.6123e-04\n",
      "Epoch 54/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.8835e-04 - val_loss: 9.6561e-04\n",
      "Epoch 55/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.9528e-04 - val_loss: 9.4864e-04\n",
      "Epoch 56/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.8434e-04 - val_loss: 9.5278e-04\n",
      "Epoch 57/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.8591e-04 - val_loss: 9.4172e-04\n",
      "Epoch 58/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.7401e-04 - val_loss: 9.3893e-04\n",
      "Epoch 59/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.1763e-04 - val_loss: 9.2159e-04\n",
      "Epoch 60/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.7194e-04 - val_loss: 9.7698e-04\n",
      "Epoch 61/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.8352e-04 - val_loss: 9.3099e-04\n",
      "Epoch 62/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.6406e-04 - val_loss: 9.0377e-04\n",
      "Epoch 63/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.5726e-04 - val_loss: 8.9945e-04\n",
      "Epoch 64/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.6217e-04 - val_loss: 8.9335e-04\n",
      "Epoch 65/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.5317e-04 - val_loss: 9.0667e-04\n",
      "Epoch 66/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.6621e-04 - val_loss: 9.6184e-04\n",
      "Epoch 67/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.3824e-04 - val_loss: 8.8024e-04\n",
      "Epoch 68/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.5032e-04 - val_loss: 9.0449e-04\n",
      "Epoch 69/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.2742e-04 - val_loss: 9.0020e-04\n",
      "Epoch 70/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.2499e-04 - val_loss: 8.6516e-04\n",
      "Epoch 71/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.2242e-04 - val_loss: 8.6537e-04\n",
      "Epoch 72/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.1926e-04 - val_loss: 8.5631e-04\n",
      "Epoch 73/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.1719e-04 - val_loss: 8.4660e-04\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step - loss: 7.1219e-04 - val_loss: 8.4313e-04\n",
      "Epoch 75/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.3176e-04 - val_loss: 9.1186e-04\n",
      "Epoch 76/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.0956e-04 - val_loss: 8.4302e-04\n",
      "Epoch 77/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.0806e-04 - val_loss: 8.2831e-04\n",
      "Epoch 78/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.0376e-04 - val_loss: 8.3252e-04\n",
      "Epoch 79/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.9804e-04 - val_loss: 8.1825e-04\n",
      "Epoch 80/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.9020e-04 - val_loss: 8.1850e-04\n",
      "Epoch 81/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.0111e-04 - val_loss: 8.2369e-04\n",
      "Epoch 82/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7873e-04 - val_loss: 8.3295e-04\n",
      "Epoch 83/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.8774e-04 - val_loss: 8.1378e-04\n",
      "Epoch 84/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7436e-04 - val_loss: 8.0679e-04\n",
      "Epoch 85/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7507e-04 - val_loss: 7.8946e-04\n",
      "Epoch 86/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7921e-04 - val_loss: 7.9813e-04\n",
      "Epoch 87/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7778e-04 - val_loss: 8.5950e-04\n",
      "Epoch 88/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.4751e-04 - val_loss: 7.8965e-04\n",
      "Epoch 89/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7750e-04 - val_loss: 7.7876e-04\n",
      "Epoch 90/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7507e-04 - val_loss: 8.3886e-04\n",
      "Epoch 91/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.8358e-04 - val_loss: 7.6838e-04\n",
      "Epoch 92/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.5140e-04 - val_loss: 7.6297e-04\n",
      "Epoch 93/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.6110e-04 - val_loss: 7.6942e-04\n",
      "Epoch 94/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.6661e-04 - val_loss: 7.7050e-04\n",
      "Epoch 95/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.6921e-04 - val_loss: 7.5490e-04\n",
      "Epoch 96/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.4822e-04 - val_loss: 7.4794e-04\n",
      "Epoch 97/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.4144e-04 - val_loss: 7.6419e-04\n",
      "Epoch 98/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3527e-04 - val_loss: 7.3999e-04\n",
      "Epoch 99/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3592e-04 - val_loss: 7.3827e-04\n",
      "Epoch 100/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3351e-04 - val_loss: 7.3438e-04\n",
      "Epoch 101/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3067e-04 - val_loss: 7.9930e-04\n",
      "Epoch 102/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3873e-04 - val_loss: 7.3160e-04\n",
      "Epoch 103/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.5363e-04 - val_loss: 7.2655e-04\n",
      "Epoch 104/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.4068e-04 - val_loss: 7.3254e-04\n",
      "Epoch 105/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3195e-04 - val_loss: 7.1615e-04\n",
      "Epoch 106/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.2424e-04 - val_loss: 8.1374e-04\n",
      "Epoch 107/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3637e-04 - val_loss: 7.4509e-04\n",
      "Epoch 108/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.0539e-04 - val_loss: 7.2183e-04\n",
      "Epoch 109/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.1304e-04 - val_loss: 7.0915e-04\n",
      "Epoch 110/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.1196e-04 - val_loss: 7.0064e-04\n",
      "Epoch 111/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.6135e-04 - val_loss: 7.0791e-04\n",
      "Epoch 112/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.1175e-04 - val_loss: 6.9521e-04\n",
      "Epoch 113/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.0521e-04 - val_loss: 7.2686e-04\n",
      "Epoch 114/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3591e-04 - val_loss: 7.3640e-04\n",
      "Epoch 115/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.9694e-04 - val_loss: 6.9719e-04\n",
      "Epoch 116/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.9912e-04 - val_loss: 6.8203e-04\n",
      "Epoch 117/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.9482e-04 - val_loss: 6.8390e-04\n",
      "Epoch 118/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.8390e-04 - val_loss: 7.7385e-04\n",
      "Epoch 119/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.2693e-04 - val_loss: 6.7329e-04\n",
      "Epoch 120/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.9974e-04 - val_loss: 7.1759e-04\n",
      "Epoch 121/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.0886e-04 - val_loss: 6.7460e-04\n",
      "Epoch 122/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.8257e-04 - val_loss: 6.6971e-04\n",
      "Epoch 123/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.8666e-04 - val_loss: 6.6979e-04\n",
      "Epoch 124/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.8290e-04 - val_loss: 7.0372e-04\n",
      "Epoch 125/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.1188e-04 - val_loss: 7.3130e-04\n",
      "Epoch 126/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.4819e-04 - val_loss: 7.8840e-04\n",
      "Epoch 127/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.8919e-04 - val_loss: 6.5343e-04\n",
      "Epoch 128/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.6978e-04 - val_loss: 6.5207e-04\n",
      "Epoch 129/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.7903e-04 - val_loss: 7.2006e-04\n",
      "Epoch 130/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.8130e-04 - val_loss: 6.6979e-04\n",
      "Epoch 131/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.7117e-04 - val_loss: 6.5206e-04\n",
      "Epoch 132/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.8023e-04 - val_loss: 6.5550e-04\n",
      "Epoch 133/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.7362e-04 - val_loss: 6.3984e-04\n",
      "Epoch 134/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.6487e-04 - val_loss: 6.4404e-04\n",
      "Epoch 135/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.6865e-04 - val_loss: 6.4042e-04\n",
      "Epoch 136/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.8911e-04 - val_loss: 6.3734e-04\n",
      "Epoch 137/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.6228e-04 - val_loss: 6.6973e-04\n",
      "Epoch 138/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.7569e-04 - val_loss: 7.8170e-04\n",
      "Epoch 139/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.1604e-04 - val_loss: 6.3235e-04\n",
      "Epoch 140/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.5571e-04 - val_loss: 6.2192e-04\n",
      "Epoch 141/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.4772e-04 - val_loss: 6.2152e-04\n",
      "Epoch 142/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.5918e-04 - val_loss: 6.2426e-04\n",
      "Epoch 143/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.5511e-04 - val_loss: 6.1778e-04\n",
      "Epoch 144/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.5006e-04 - val_loss: 6.2903e-04\n",
      "Epoch 145/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.5537e-04 - val_loss: 6.2694e-04\n",
      "Epoch 146/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.4626e-04 - val_loss: 6.6988e-04\n",
      "Epoch 147/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.4603e-04 - val_loss: 6.2484e-04\n",
      "Epoch 148/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.6469e-04 - val_loss: 6.3010e-04\n",
      "Epoch 149/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step - loss: 5.4214e-04 - val_loss: 6.3820e-04\n",
      "Epoch 150/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.7625e-04 - val_loss: 6.1464e-04\n",
      "Epoch 151/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.5827e-04 - val_loss: 6.2751e-04\n",
      "Epoch 152/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.4643e-04 - val_loss: 7.0839e-04\n",
      "Epoch 153/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.3890e-04 - val_loss: 5.9546e-04\n",
      "Epoch 154/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.4611e-04 - val_loss: 6.3842e-04\n",
      "Epoch 155/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.3431e-04 - val_loss: 5.9140e-04\n",
      "Epoch 156/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.3835e-04 - val_loss: 6.0587e-04\n",
      "Epoch 157/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.2950e-04 - val_loss: 6.1282e-04\n",
      "Epoch 158/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.4052e-04 - val_loss: 5.8959e-04\n",
      "Epoch 159/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.2437e-04 - val_loss: 5.8352e-04\n",
      "Epoch 160/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.2213e-04 - val_loss: 5.8138e-04\n",
      "Epoch 161/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.3000e-04 - val_loss: 5.9621e-04\n",
      "Epoch 162/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.2865e-04 - val_loss: 5.8608e-04\n",
      "Epoch 163/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.2984e-04 - val_loss: 6.0158e-04\n",
      "Epoch 164/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.4562e-04 - val_loss: 5.8543e-04\n",
      "Epoch 165/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.3106e-04 - val_loss: 5.9336e-04\n",
      "Epoch 166/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.3619e-04 - val_loss: 6.5123e-04\n",
      "Epoch 167/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.1501e-04 - val_loss: 5.7009e-04\n",
      "Epoch 168/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.2395e-04 - val_loss: 5.6770e-04\n",
      "Epoch 169/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.2025e-04 - val_loss: 6.0318e-04\n",
      "Epoch 170/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.1534e-04 - val_loss: 5.7509e-04\n",
      "Epoch 171/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.1545e-04 - val_loss: 5.6504e-04\n",
      "Epoch 172/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.1974e-04 - val_loss: 5.6138e-04\n",
      "Epoch 173/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.5537e-04 - val_loss: 5.6317e-04\n",
      "Epoch 174/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.2027e-04 - val_loss: 5.6184e-04\n",
      "Epoch 175/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.2740e-04 - val_loss: 5.7645e-04\n",
      "Epoch 176/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.3004e-04 - val_loss: 5.6831e-04\n",
      "Epoch 177/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.0123e-04 - val_loss: 5.7223e-04\n",
      "Epoch 178/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.2066e-04 - val_loss: 5.5598e-04\n",
      "Epoch 179/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.0023e-04 - val_loss: 5.7922e-04\n",
      "Epoch 180/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.0359e-04 - val_loss: 5.5795e-04\n",
      "Epoch 181/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.2004e-04 - val_loss: 7.2620e-04\n",
      "Epoch 182/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.4698e-04 - val_loss: 5.4945e-04\n",
      "Epoch 183/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.9684e-04 - val_loss: 5.8077e-04\n",
      "Epoch 184/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.1613e-04 - val_loss: 5.8080e-04\n",
      "Epoch 185/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.9560e-04 - val_loss: 5.4388e-04\n",
      "Epoch 186/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.1312e-04 - val_loss: 5.4294e-04\n",
      "Epoch 187/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.9831e-04 - val_loss: 5.4487e-04\n",
      "Epoch 188/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.9994e-04 - val_loss: 5.5135e-04\n",
      "Epoch 189/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.0032e-04 - val_loss: 5.3906e-04\n",
      "Epoch 190/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.9824e-04 - val_loss: 5.3486e-04\n",
      "Epoch 191/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.9313e-04 - val_loss: 5.3325e-04\n",
      "Epoch 192/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.9497e-04 - val_loss: 5.4150e-04\n",
      "Epoch 193/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.0681e-04 - val_loss: 5.3424e-04\n",
      "Epoch 194/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.0388e-04 - val_loss: 5.3038e-04\n",
      "Epoch 195/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.0012e-04 - val_loss: 5.5218e-04\n",
      "Epoch 196/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.0155e-04 - val_loss: 5.2871e-04\n",
      "Epoch 197/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.9162e-04 - val_loss: 5.2615e-04\n",
      "Epoch 198/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.8704e-04 - val_loss: 5.2745e-04\n",
      "Epoch 199/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.9331e-04 - val_loss: 5.2567e-04\n",
      "Epoch 200/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.8881e-04 - val_loss: 5.2498e-04\n",
      "Thời gian huấn luyện:  18.64842462539673\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_8 (SimpleRNN)    (None, 10, 89)            8099      \n",
      "                                                                 \n",
      " flatten_33 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,990\n",
      "Trainable params: 8,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "24/24 [==============================] - 2s 22ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 2/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 3/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 4/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 5/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 6/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 7/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 8/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 9/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 10/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 11/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 12/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 13/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 14/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 15/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 16/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 17/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 19/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 20/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 21/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 22/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 23/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 24/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 25/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 26/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 27/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 28/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 29/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 30/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 31/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 32/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 33/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 34/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 35/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 36/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 37/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 38/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 39/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 40/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 41/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 42/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 43/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 44/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 45/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 46/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 47/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 48/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 49/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 50/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 51/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 52/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 53/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 54/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 55/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 56/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 57/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 58/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 59/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 60/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 61/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 62/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 63/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 64/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 65/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 66/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 67/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 68/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 69/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 70/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 71/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 72/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 73/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 74/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 75/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 76/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 77/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 78/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 79/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 80/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 81/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 82/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 83/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 84/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 85/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 86/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 87/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 88/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 89/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 90/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 91/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 92/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 93/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 94/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 95/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 96/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 97/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 98/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 99/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 101/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 102/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 103/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 104/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 105/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 106/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 107/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 108/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 109/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 110/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 111/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 112/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 113/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 114/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 115/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 116/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 117/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 118/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 119/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 120/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 121/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 122/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 123/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 124/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 125/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 126/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 127/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 128/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 129/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 130/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 131/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 132/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 133/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 134/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 135/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 136/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 137/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 138/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 139/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 140/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 141/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 142/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 143/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 144/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 145/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 146/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 147/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 148/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 149/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 150/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 151/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 152/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 153/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 154/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 155/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 156/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 157/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 158/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 159/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 160/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 161/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 162/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 163/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 164/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 165/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 166/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 167/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 168/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 169/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 170/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 171/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 172/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 173/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 174/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 175/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 176/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 177/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 178/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 179/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 180/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 182/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 183/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 184/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 185/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 186/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 187/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 188/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 189/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 190/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 191/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 192/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 193/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 194/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 195/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 196/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 197/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 198/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 199/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 200/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Thời gian huấn luyện:  37.9913535118103\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 10, 89)            32396     \n",
      "                                                                 \n",
      " flatten_34 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,287\n",
      "Trainable params: 33,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "24/24 [==============================] - 2s 20ms/step - loss: 0.0208 - val_loss: 0.0030\n",
      "Epoch 2/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 3/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 4/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 5/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 6/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 7/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 8/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 9/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 10/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 11/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 12/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 13/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 14/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 15/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 16/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 17/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 18/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 19/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 20/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 21/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 22/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 23/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 24/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 25/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 26/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 27/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 28/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 29/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 30/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 31/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 32/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 33/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 34/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 35/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 36/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 37/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 38/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 39/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 40/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 9.9778e-04 - val_loss: 0.0013\n",
      "Epoch 41/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 9.8212e-04 - val_loss: 0.0013\n",
      "Epoch 42/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 9.7278e-04 - val_loss: 0.0013\n",
      "Epoch 43/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 9.5875e-04 - val_loss: 0.0012\n",
      "Epoch 44/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 9.4974e-04 - val_loss: 0.0012\n",
      "Epoch 45/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 9.5316e-04 - val_loss: 0.0012\n",
      "Epoch 46/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 9.2035e-04 - val_loss: 0.0012\n",
      "Epoch 47/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 9.1577e-04 - val_loss: 0.0012\n",
      "Epoch 48/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.9880e-04 - val_loss: 0.0012\n",
      "Epoch 49/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.8737e-04 - val_loss: 0.0011\n",
      "Epoch 50/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.7694e-04 - val_loss: 0.0011\n",
      "Epoch 51/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.7325e-04 - val_loss: 0.0011\n",
      "Epoch 52/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.6025e-04 - val_loss: 0.0011\n",
      "Epoch 53/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.5035e-04 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.5210e-04 - val_loss: 0.0011\n",
      "Epoch 55/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.4331e-04 - val_loss: 0.0011\n",
      "Epoch 56/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.2550e-04 - val_loss: 0.0011\n",
      "Epoch 57/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.3956e-04 - val_loss: 0.0011\n",
      "Epoch 58/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.2551e-04 - val_loss: 0.0010\n",
      "Epoch 59/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.0509e-04 - val_loss: 0.0010\n",
      "Epoch 60/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.0233e-04 - val_loss: 0.0010\n",
      "Epoch 61/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.9217e-04 - val_loss: 9.9407e-04\n",
      "Epoch 62/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.9420e-04 - val_loss: 9.8685e-04\n",
      "Epoch 63/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.0664e-04 - val_loss: 9.7785e-04\n",
      "Epoch 64/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.7551e-04 - val_loss: 9.6755e-04\n",
      "Epoch 65/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.7089e-04 - val_loss: 9.9353e-04\n",
      "Epoch 66/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.0213e-04 - val_loss: 9.8395e-04\n",
      "Epoch 67/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.7967e-04 - val_loss: 9.5178e-04\n",
      "Epoch 68/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.5800e-04 - val_loss: 9.4177e-04\n",
      "Epoch 69/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.4968e-04 - val_loss: 9.3102e-04\n",
      "Epoch 70/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.4176e-04 - val_loss: 9.2459e-04\n",
      "Epoch 71/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.4508e-04 - val_loss: 9.3843e-04\n",
      "Epoch 72/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.5557e-04 - val_loss: 9.3839e-04\n",
      "Epoch 73/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.3114e-04 - val_loss: 9.1746e-04\n",
      "Epoch 74/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.2285e-04 - val_loss: 9.0322e-04\n",
      "Epoch 75/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.2338e-04 - val_loss: 9.0541e-04\n",
      "Epoch 76/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.1959e-04 - val_loss: 8.8860e-04\n",
      "Epoch 77/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.2179e-04 - val_loss: 9.0350e-04\n",
      "Epoch 78/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.1350e-04 - val_loss: 8.8816e-04\n",
      "Epoch 79/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.1967e-04 - val_loss: 8.8468e-04\n",
      "Epoch 80/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.0652e-04 - val_loss: 8.6749e-04\n",
      "Epoch 81/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.9759e-04 - val_loss: 8.6552e-04\n",
      "Epoch 82/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.9594e-04 - val_loss: 8.5859e-04\n",
      "Epoch 83/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.9572e-04 - val_loss: 8.5399e-04\n",
      "Epoch 84/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.9457e-04 - val_loss: 8.5313e-04\n",
      "Epoch 85/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.8902e-04 - val_loss: 8.4437e-04\n",
      "Epoch 86/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.9013e-04 - val_loss: 8.4714e-04\n",
      "Epoch 87/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.8546e-04 - val_loss: 8.6708e-04\n",
      "Epoch 88/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.8247e-04 - val_loss: 8.3177e-04\n",
      "Epoch 89/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.8082e-04 - val_loss: 8.5382e-04\n",
      "Epoch 90/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.7155e-04 - val_loss: 8.2108e-04\n",
      "Epoch 91/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.6825e-04 - val_loss: 8.1872e-04\n",
      "Epoch 92/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.6720e-04 - val_loss: 8.2839e-04\n",
      "Epoch 93/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.6778e-04 - val_loss: 8.2613e-04\n",
      "Epoch 94/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.7040e-04 - val_loss: 8.6436e-04\n",
      "Epoch 95/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.7168e-04 - val_loss: 8.0072e-04\n",
      "Epoch 96/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.5940e-04 - val_loss: 7.9605e-04\n",
      "Epoch 97/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.5050e-04 - val_loss: 8.0385e-04\n",
      "Epoch 98/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.4756e-04 - val_loss: 7.8847e-04\n",
      "Epoch 99/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.4786e-04 - val_loss: 7.9522e-04\n",
      "Epoch 100/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.4946e-04 - val_loss: 7.8203e-04\n",
      "Epoch 101/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.4433e-04 - val_loss: 7.8427e-04\n",
      "Epoch 102/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.5316e-04 - val_loss: 7.7427e-04\n",
      "Epoch 103/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.3533e-04 - val_loss: 7.7639e-04\n",
      "Epoch 104/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.4168e-04 - val_loss: 7.8203e-04\n",
      "Epoch 105/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.5481e-04 - val_loss: 7.6304e-04\n",
      "Epoch 106/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.4709e-04 - val_loss: 8.2074e-04\n",
      "Epoch 107/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.3458e-04 - val_loss: 7.5972e-04\n",
      "Epoch 108/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.2282e-04 - val_loss: 7.5520e-04\n",
      "Epoch 109/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.2253e-04 - val_loss: 7.5784e-04\n",
      "Epoch 110/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.2227e-04 - val_loss: 7.6281e-04\n",
      "Epoch 111/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.2216e-04 - val_loss: 7.4300e-04\n",
      "Epoch 112/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.1523e-04 - val_loss: 7.3921e-04\n",
      "Epoch 113/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.1013e-04 - val_loss: 7.3634e-04\n",
      "Epoch 114/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.0618e-04 - val_loss: 7.3652e-04\n",
      "Epoch 115/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.1506e-04 - val_loss: 7.3306e-04\n",
      "Epoch 116/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.0568e-04 - val_loss: 7.2641e-04\n",
      "Epoch 117/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.0234e-04 - val_loss: 7.2637e-04\n",
      "Epoch 118/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.9989e-04 - val_loss: 7.2285e-04\n",
      "Epoch 119/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.9685e-04 - val_loss: 7.2123e-04\n",
      "Epoch 120/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.9432e-04 - val_loss: 7.1445e-04\n",
      "Epoch 121/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.9518e-04 - val_loss: 7.1143e-04\n",
      "Epoch 122/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.0346e-04 - val_loss: 7.1183e-04\n",
      "Epoch 123/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.9069e-04 - val_loss: 7.6118e-04\n",
      "Epoch 124/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.9621e-04 - val_loss: 7.1271e-04\n",
      "Epoch 125/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.9921e-04 - val_loss: 7.0384e-04\n",
      "Epoch 126/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.8845e-04 - val_loss: 6.9851e-04\n",
      "Epoch 127/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.7965e-04 - val_loss: 6.9772e-04\n",
      "Epoch 128/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.7770e-04 - val_loss: 7.0154e-04\n",
      "Epoch 129/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.8045e-04 - val_loss: 6.8933e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.7787e-04 - val_loss: 6.9163e-04\n",
      "Epoch 131/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.7502e-04 - val_loss: 6.8434e-04\n",
      "Epoch 132/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6937e-04 - val_loss: 6.9974e-04\n",
      "Epoch 133/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.7753e-04 - val_loss: 6.7835e-04\n",
      "Epoch 134/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6990e-04 - val_loss: 6.8079e-04\n",
      "Epoch 135/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6741e-04 - val_loss: 6.7711e-04\n",
      "Epoch 136/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6694e-04 - val_loss: 6.7644e-04\n",
      "Epoch 137/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6687e-04 - val_loss: 6.6897e-04\n",
      "Epoch 138/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6485e-04 - val_loss: 6.6611e-04\n",
      "Epoch 139/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6459e-04 - val_loss: 6.6449e-04\n",
      "Epoch 140/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6078e-04 - val_loss: 6.6810e-04\n",
      "Epoch 141/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6898e-04 - val_loss: 6.6036e-04\n",
      "Epoch 142/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6023e-04 - val_loss: 6.6318e-04\n",
      "Epoch 143/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6117e-04 - val_loss: 6.6489e-04\n",
      "Epoch 144/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.5793e-04 - val_loss: 6.5899e-04\n",
      "Epoch 145/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.5328e-04 - val_loss: 6.8688e-04\n",
      "Epoch 146/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.5465e-04 - val_loss: 6.4856e-04\n",
      "Epoch 147/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6101e-04 - val_loss: 6.5068e-04\n",
      "Epoch 148/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4996e-04 - val_loss: 6.4545e-04\n",
      "Epoch 149/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4512e-04 - val_loss: 6.4166e-04\n",
      "Epoch 150/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4894e-04 - val_loss: 6.5859e-04\n",
      "Epoch 151/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.9161e-04 - val_loss: 6.6295e-04\n",
      "Epoch 152/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6600e-04 - val_loss: 6.5156e-04\n",
      "Epoch 153/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4290e-04 - val_loss: 6.3630e-04\n",
      "Epoch 154/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.5380e-04 - val_loss: 6.4703e-04\n",
      "Epoch 155/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4164e-04 - val_loss: 6.3703e-04\n",
      "Epoch 156/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4410e-04 - val_loss: 6.2948e-04\n",
      "Epoch 157/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4328e-04 - val_loss: 6.3081e-04\n",
      "Epoch 158/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.3674e-04 - val_loss: 6.2533e-04\n",
      "Epoch 159/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.5116e-04 - val_loss: 6.2393e-04\n",
      "Epoch 160/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4793e-04 - val_loss: 6.6404e-04\n",
      "Epoch 161/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.3218e-04 - val_loss: 6.2123e-04\n",
      "Epoch 162/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4660e-04 - val_loss: 6.2777e-04\n",
      "Epoch 163/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.3587e-04 - val_loss: 6.1907e-04\n",
      "Epoch 164/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.2759e-04 - val_loss: 6.1881e-04\n",
      "Epoch 165/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.3086e-04 - val_loss: 6.3024e-04\n",
      "Epoch 166/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4118e-04 - val_loss: 6.9996e-04\n",
      "Epoch 167/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4474e-04 - val_loss: 6.1041e-04\n",
      "Epoch 168/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.2257e-04 - val_loss: 6.0800e-04\n",
      "Epoch 169/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.2512e-04 - val_loss: 6.0844e-04\n",
      "Epoch 170/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1953e-04 - val_loss: 6.1006e-04\n",
      "Epoch 171/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.2391e-04 - val_loss: 6.0737e-04\n",
      "Epoch 172/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1883e-04 - val_loss: 6.0127e-04\n",
      "Epoch 173/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.2306e-04 - val_loss: 6.0025e-04\n",
      "Epoch 174/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1992e-04 - val_loss: 5.9886e-04\n",
      "Epoch 175/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.3945e-04 - val_loss: 6.1436e-04\n",
      "Epoch 176/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.2013e-04 - val_loss: 6.1639e-04\n",
      "Epoch 177/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4657e-04 - val_loss: 7.2605e-04\n",
      "Epoch 178/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6219e-04 - val_loss: 5.9598e-04\n",
      "Epoch 179/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1363e-04 - val_loss: 6.0206e-04\n",
      "Epoch 180/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1679e-04 - val_loss: 6.5860e-04\n",
      "Epoch 181/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.3768e-04 - val_loss: 5.8861e-04\n",
      "Epoch 182/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1219e-04 - val_loss: 5.8976e-04\n",
      "Epoch 183/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.2014e-04 - val_loss: 5.8747e-04\n",
      "Epoch 184/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.0886e-04 - val_loss: 5.9142e-04\n",
      "Epoch 185/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.0674e-04 - val_loss: 5.8470e-04\n",
      "Epoch 186/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1678e-04 - val_loss: 5.8514e-04\n",
      "Epoch 187/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1682e-04 - val_loss: 5.8072e-04\n",
      "Epoch 188/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.0983e-04 - val_loss: 5.8002e-04\n",
      "Epoch 189/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1008e-04 - val_loss: 6.2202e-04\n",
      "Epoch 190/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1474e-04 - val_loss: 5.7609e-04\n",
      "Epoch 191/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.0837e-04 - val_loss: 5.7889e-04\n",
      "Epoch 192/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.0668e-04 - val_loss: 5.8453e-04\n",
      "Epoch 193/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.0774e-04 - val_loss: 5.7182e-04\n",
      "Epoch 194/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1771e-04 - val_loss: 6.1387e-04\n",
      "Epoch 195/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1771e-04 - val_loss: 5.7618e-04\n",
      "Epoch 196/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 4.9479e-04 - val_loss: 5.7293e-04\n",
      "Epoch 197/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 4.9702e-04 - val_loss: 5.6753e-04\n",
      "Epoch 198/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 4.9585e-04 - val_loss: 5.7261e-04\n",
      "Epoch 199/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 4.9840e-04 - val_loss: 5.6588e-04\n",
      "Epoch 200/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 4.9657e-04 - val_loss: 5.6499e-04\n",
      "Thời gian huấn luyện:  34.16022968292236\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_8 (GRU)                 (None, 10, 89)            24564     \n",
      "                                                                 \n",
      " flatten_35 (Flatten)        (None, 890)               0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,455\n",
      "Trainable params: 25,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0525 - val_loss: 0.0027\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0032\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0025\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 9.4395e-04\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 9.6398e-04\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 9.2435e-04\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 8.7858e-04\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 8.7916e-04\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 8.3303e-04\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.0231e-04\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.7518e-04\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.2493e-04\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.1013e-04\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.6861e-04\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.3363e-04\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.2766e-04\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.1383e-04\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.1845e-04\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.0398e-04\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.6750e-04\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.4158e-04\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.9549e-04\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.8898e-04\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.9204e-04\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.1014e-04\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.0496e-04\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.7311e-04\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.7958e-04\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.6749e-04\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.7255e-04\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.5577e-04\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.6337e-04\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.3817e-04\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.8437e-04\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.2312e-04\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.4007e-04\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.2664e-04\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.2281e-04\n",
      "Thời gian huấn luyện:  3.7412447929382324\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_45 (Dense)            (None, 10, 96)            192       \n",
      "                                                                 \n",
      " flatten_36 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,153\n",
      "Trainable params: 1,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 1s 8ms/step - loss: 0.0225 - val_loss: 0.0038\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 9.0934e-04\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 8.4271e-04\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 7.7946e-04\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 7.7605e-04\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 7.0914e-04\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.5566e-04\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.8866e-04\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.3729e-04\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.0480e-04\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.2153e-04\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.3669e-04\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.6381e-04\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.7126e-04\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.8776e-04 - val_loss: 5.8172e-04\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.8948e-04 - val_loss: 7.4749e-04\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.6422e-04 - val_loss: 5.9866e-04\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.3719e-04 - val_loss: 5.1756e-04\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.3645e-04 - val_loss: 5.0434e-04\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.2163e-04 - val_loss: 5.0291e-04\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.9737e-04 - val_loss: 5.4059e-04\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.8536e-04 - val_loss: 5.0310e-04\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.8540e-04 - val_loss: 5.0573e-04\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.6001e-04 - val_loss: 4.8976e-04\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.9151e-04 - val_loss: 4.6843e-04\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.3798e-04 - val_loss: 4.7093e-04\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.3498e-04 - val_loss: 4.7774e-04\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.1376e-04 - val_loss: 4.5431e-04\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.4452e-04 - val_loss: 4.4845e-04\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.1087e-04 - val_loss: 4.4449e-04\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.1178e-04 - val_loss: 4.3874e-04\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.9462e-04 - val_loss: 4.3496e-04\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.9186e-04 - val_loss: 4.3795e-04\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.7276e-04 - val_loss: 4.3558e-04\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.0654e-04 - val_loss: 4.2224e-04\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.0522e-04 - val_loss: 4.4255e-04\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.5808e-04 - val_loss: 4.1974e-04\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.6719e-04 - val_loss: 4.1486e-04\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.4336e-04 - val_loss: 4.0880e-04\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.3939e-04 - val_loss: 4.0304e-04\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.4133e-04 - val_loss: 4.5614e-04\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2445e-04 - val_loss: 3.9917e-04\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1902e-04 - val_loss: 3.9323e-04\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.1563e-04 - val_loss: 4.3718e-04\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.0796e-04 - val_loss: 3.8804e-04\n",
      "Thời gian huấn luyện:  6.031972408294678\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_9 (SimpleRNN)    (None, 10, 96)            9408      \n",
      "                                                                 \n",
      " flatten_37 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,369\n",
      "Trainable params: 10,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 2s 18ms/step - loss: 0.0186 - val_loss: 0.0015\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 9.9844e-04\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 9.7138e-04\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 9.3383e-04\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 9.3350e-04\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 9.6860e-04\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 9.6303e-04\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.9959e-04\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 9.9979e-04\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 8.8254e-04\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 9.2480e-04\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 8.7495e-04\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 8.2800e-04\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 8.4547e-04\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.1591e-04\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.1841e-04\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 8.3998e-04\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.0195e-04\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.2581e-04\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.7356e-04\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 8.3645e-04\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.6223e-04\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.4879e-04\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 7.9167e-04\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 7.5673e-04\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.6821e-04\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.5769e-04\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 7.3128e-04\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 7.0667e-04\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.9462e-04\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 7.1415e-04\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 7.2299e-04\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 7.3406e-04\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.7512e-04\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.8911e-04\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.6622e-04\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 6.8729e-04\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 7.2882e-04\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.3345e-04\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.2711e-04\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 6.6163e-04\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 6.2085e-04\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 6.2338e-04\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 6.6088e-04\n",
      "Thời gian huấn luyện:  12.855132341384888\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_9 (LSTM)               (None, 10, 96)            37632     \n",
      "                                                                 \n",
      " flatten_38 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,593\n",
      "Trainable params: 38,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 2s 16ms/step - loss: 0.0184 - val_loss: 0.0016\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 9.3136e-04\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 9.0136e-04\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.6503e-04\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.3063e-04\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.1289e-04\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.2968e-04\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 7.8035e-04\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 7.7657e-04\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.4416e-04\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.2759e-04\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 7.2143e-04\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 7.2357e-04\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.9220e-04\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.8537e-04\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.9890e-04\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 7.1836e-04\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.9630e-04\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.7190e-04\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.3039e-04\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.5159e-04\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.0394e-04\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.1972e-04\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.1613e-04\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.7069e-04\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.7810e-04\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 6.1088e-04\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 6.3302e-04\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.9424e-04 - val_loss: 5.7998e-04\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.6535e-04 - val_loss: 5.3302e-04\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.4288e-04 - val_loss: 5.2033e-04\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.2888e-04 - val_loss: 5.0001e-04\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.2021e-04 - val_loss: 4.9460e-04\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.9620e-04 - val_loss: 5.4022e-04\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.9331e-04 - val_loss: 4.7988e-04\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.9406e-04 - val_loss: 4.7336e-04\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.5869e-04 - val_loss: 4.6674e-04\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.5802e-04 - val_loss: 5.1198e-04\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.4457e-04 - val_loss: 4.7832e-04\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.2989e-04 - val_loss: 4.7327e-04\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.2164e-04 - val_loss: 4.6680e-04\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.0494e-04 - val_loss: 5.1233e-04\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.2376e-04 - val_loss: 4.3702e-04\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.9112e-04 - val_loss: 4.5930e-04\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.8792e-04 - val_loss: 4.8361e-04\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.7799e-04 - val_loss: 4.2451e-04\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.8096e-04 - val_loss: 4.7428e-04\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.6356e-04 - val_loss: 4.2159e-04\n",
      "Thời gian huấn luyện:  12.046826839447021\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_9 (GRU)                 (None, 10, 96)            28512     \n",
      "                                                                 \n",
      " flatten_39 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_49 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,473\n",
      "Trainable params: 29,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.0565 - val_loss: 0.0062\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0034\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0018\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0020\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0018\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0016\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 9.2051e-04\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 8.0783e-04\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 8.3363e-04\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 7.7062e-04\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 7.8502e-04\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 7.3707e-04\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.0177e-04\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 6.9923e-04\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 6.9459e-04\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.8912e-04\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.3647e-04\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.1821e-04\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.6125e-04\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.5689e-04\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.4527e-04\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.9785e-04\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.4987e-04\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.1157e-04\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.1570e-04\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.8130e-04\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.0835e-04\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.7157e-04\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.7187e-04\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.8057e-04\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.7298e-04\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.7120e-04\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.6194e-04\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.4346e-04\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.5350e-04\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.5617e-04\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.4976e-04\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.3969e-04\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.4086e-04\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.3663e-04\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.2342e-04\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.3744e-04\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.1366e-04\n",
      "Thời gian huấn luyện:  3.7267298698425293\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_50 (Dense)            (None, 10, 96)            192       \n",
      "                                                                 \n",
      " flatten_40 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,153\n",
      "Trainable params: 1,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "30/30 [==============================] - 1s 8ms/step - loss: 0.0374 - val_loss: 0.0031\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0014\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 9.8916e-04\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 9.5495e-04\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 8.8152e-04\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 8.5692e-04\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 7.5870e-04\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 7.6105e-04\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 7.0218e-04\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 7.2408e-04\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 7.1938e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 6.9328e-04\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 7.7918e-04\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 6.4399e-04\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 7.4058e-04\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.0324e-04\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.1903e-04\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.6984e-04\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 5.6890e-04\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.9748e-04\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.5061e-04\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.2218e-04\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.7660e-04\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.4737e-04\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 5.3762e-04\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.2392e-04\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 6.4799e-04\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.4533e-04\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.0818e-04\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.9598e-04 - val_loss: 5.0864e-04\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.8123e-04 - val_loss: 5.1491e-04\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.8892e-04 - val_loss: 5.4320e-04\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.9553e-04 - val_loss: 5.1424e-04\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.5000e-04 - val_loss: 4.9476e-04\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.4059e-04 - val_loss: 5.1590e-04\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.4666e-04 - val_loss: 4.9741e-04\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.3853e-04 - val_loss: 4.9963e-04\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.1595e-04 - val_loss: 5.2152e-04\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.0886e-04 - val_loss: 4.6897e-04\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.4277e-04 - val_loss: 5.1645e-04\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.8582e-04 - val_loss: 4.8833e-04\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.8637e-04 - val_loss: 4.9495e-04\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.8096e-04 - val_loss: 4.6348e-04\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.8576e-04 - val_loss: 4.5756e-04\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.6078e-04 - val_loss: 4.7347e-04\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.5371e-04 - val_loss: 4.4891e-04\n",
      "Thời gian huấn luyện:  5.902420282363892\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_10 (SimpleRNN)   (None, 10, 96)            9408      \n",
      "                                                                 \n",
      " flatten_41 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,369\n",
      "Trainable params: 10,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "30/30 [==============================] - 2s 18ms/step - loss: 0.0202 - val_loss: 0.0012\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 9.4658e-04\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 9.8314e-04\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 9.5979e-04\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 9.3326e-04\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 9.4289e-04\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 9.3458e-04\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 9.3363e-04\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 9.0619e-04\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 9.0690e-04\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 9.5601e-04\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 8.6832e-04\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 8.4208e-04\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 8.5063e-04\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 8.2993e-04\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 8.2622e-04\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.2789e-04\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.3883e-04\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 9.0720e-04\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 8.5033e-04\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 7.9262e-04\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.1921e-04\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 8.0151e-04\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.6260e-04\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.4516e-04\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.9147e-04\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.6236e-04\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.4117e-04\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.9896e-04\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.7998e-04\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.4442e-04\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 6.8644e-04\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.5786e-04\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.8883e-04\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 6.5807e-04\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 6.8463e-04\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 6.5857e-04\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 6.5351e-04\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.5559e-04\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.3202e-04\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.7990e-04\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.3073e-04\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.8959e-04\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 6.6740e-04\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 5.7436e-04\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.7095e-04\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.6109e-04\n",
      "Thời gian huấn luyện:  11.96903133392334\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 10, 96)            37632     \n",
      "                                                                 \n",
      " flatten_42 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,593\n",
      "Trainable params: 38,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "30/30 [==============================] - 2s 17ms/step - loss: 0.0159 - val_loss: 0.0015\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 9.2499e-04\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 8.3093e-04\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 8.3462e-04\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 8.0131e-04\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 7.3582e-04\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 7.7979e-04\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 7.6560e-04\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 7.3280e-04\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 7.2271e-04\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 6.8815e-04\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 7.6766e-04\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 7.7482e-04\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 6.5746e-04\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 6.6624e-04\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.5950e-04\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.7781e-04\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.4419e-04\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.7426e-04\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.6717e-04\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.2913e-04\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 5.9178e-04\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.2635e-04\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.1809e-04\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 5.8452e-04\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.6622e-04\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.6869e-04\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.4279e-04\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.3597e-04\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.4974e-04\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.2398e-04\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.2271e-04\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.1156e-04\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.2255e-04\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.0981e-04\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 4.9789e-04\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.2338e-04\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.7899e-04 - val_loss: 4.9160e-04\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.6793e-04 - val_loss: 4.8445e-04\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.5776e-04 - val_loss: 4.8328e-04\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.4912e-04 - val_loss: 5.0870e-04\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.6632e-04 - val_loss: 5.4066e-04\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.2640e-04 - val_loss: 5.1905e-04\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.1736e-04 - val_loss: 4.6324e-04\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.1852e-04 - val_loss: 4.6051e-04\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.0326e-04 - val_loss: 4.5266e-04\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.0598e-04 - val_loss: 5.0832e-04\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.0111e-04 - val_loss: 4.7692e-04\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.8229e-04 - val_loss: 4.4302e-04\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.7646e-04 - val_loss: 4.8965e-04\n",
      "Thời gian huấn luyện:  11.284602642059326\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_10 (GRU)                (None, 10, 96)            28512     \n",
      "                                                                 \n",
      " flatten_43 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Total params: 29,473\n",
      "Trainable params: 29,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "35/35 [==============================] - 0s 971us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 1s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0693 - val_loss: 0.0133\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0059\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0032\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 19/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 31/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 32/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 33/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 34/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 35/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 36/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 37/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 38/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 39/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 40/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 41/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 42/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 43/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 44/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 45/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 46/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 47/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 48/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 49/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 50/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Thời gian huấn luyện:  3.6277551651000977\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_55 (Dense)            (None, 10, 96)            192       \n",
      "                                                                 \n",
      " flatten_44 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,153\n",
      "Trainable params: 1,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "28/28 [==============================] - 1s 9ms/step - loss: 0.0168 - val_loss: 0.0025\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 9.8564e-04\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 9.3323e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 9.5157e-04\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 8.9796e-04\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 9.9242e-04 - val_loss: 9.5735e-04\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 9.8025e-04 - val_loss: 8.9322e-04\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 9.5884e-04 - val_loss: 9.6199e-04\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.5191e-04 - val_loss: 8.3681e-04\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 9.0941e-04 - val_loss: 8.7678e-04\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 9.4801e-04 - val_loss: 9.0772e-04\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.6897e-04 - val_loss: 8.1455e-04\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.8830e-04 - val_loss: 7.8927e-04\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.7119e-04 - val_loss: 7.8307e-04\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.9255e-04 - val_loss: 8.2616e-04\n",
      "Epoch 31/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 8.4619e-04 - val_loss: 7.9994e-04\n",
      "Epoch 32/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 8.3797e-04 - val_loss: 7.4638e-04\n",
      "Epoch 33/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.1477e-04 - val_loss: 7.4001e-04\n",
      "Epoch 34/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.3553e-04 - val_loss: 7.2944e-04\n",
      "Epoch 35/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.2442e-04 - val_loss: 7.5384e-04\n",
      "Epoch 36/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.9871e-04 - val_loss: 7.1800e-04\n",
      "Epoch 37/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.6737e-04 - val_loss: 7.2073e-04\n",
      "Epoch 38/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.2664e-04 - val_loss: 7.1002e-04\n",
      "Epoch 39/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.9012e-04 - val_loss: 7.7189e-04\n",
      "Epoch 40/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.7005e-04 - val_loss: 6.8375e-04\n",
      "Epoch 41/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.7183e-04 - val_loss: 6.8107e-04\n",
      "Epoch 42/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.7721e-04 - val_loss: 6.7187e-04\n",
      "Epoch 43/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.6670e-04 - val_loss: 6.6782e-04\n",
      "Epoch 44/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.3855e-04 - val_loss: 6.9846e-04\n",
      "Epoch 45/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.3575e-04 - val_loss: 6.7652e-04\n",
      "Epoch 46/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.5761e-04 - val_loss: 7.1796e-04\n",
      "Epoch 47/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.3931e-04 - val_loss: 6.5012e-04\n",
      "Epoch 48/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.5509e-04 - val_loss: 6.4278e-04\n",
      "Epoch 49/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.3324e-04 - val_loss: 6.3844e-04\n",
      "Epoch 50/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.0483e-04 - val_loss: 6.3226e-04\n",
      "Thời gian huấn luyện:  5.750639915466309\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_11 (SimpleRNN)   (None, 10, 96)            9408      \n",
      "                                                                 \n",
      " flatten_45 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,369\n",
      "Trainable params: 10,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "28/28 [==============================] - 2s 19ms/step - loss: 0.0211 - val_loss: 0.0018\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 19/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 31/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 32/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 33/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 34/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 35/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 38/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 39/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 41/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 42/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 43/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 44/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 45/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 46/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 47/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 48/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 49/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 50/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Thời gian huấn luyện:  11.949188709259033\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_11 (LSTM)              (None, 10, 96)            37632     \n",
      "                                                                 \n",
      " flatten_46 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,593\n",
      "Trainable params: 38,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "28/28 [==============================] - 2s 18ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 19/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 31/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 32/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 33/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 34/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 35/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 36/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 37/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 38/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 39/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 40/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 41/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 42/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 43/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 44/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 45/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 46/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 47/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 48/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 49/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 50/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Thời gian huấn luyện:  11.289196252822876\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_11 (GRU)                (None, 10, 96)            28512     \n",
      "                                                                 \n",
      " flatten_47 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,473\n",
      "Trainable params: 29,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0505 - val_loss: 0.0024\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 9.6152e-04\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 9.4355e-04\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 8.6026e-04\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 8.1862e-04\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 8.5891e-04\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 8.1884e-04\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.7337e-04\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.6389e-04\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.0452e-04\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.5587e-04\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.6438e-04\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.6414e-04\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.4678e-04\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.2944e-04\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.0727e-04\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.1661e-04\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.2116e-04\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.0888e-04\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.8999e-04\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.8486e-04\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.9901e-04\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.9215e-04\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.6879e-04\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.5169e-04\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.6126e-04\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.3872e-04\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.6847e-04\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.4129e-04\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.5695e-04\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.2086e-04\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.5069e-04\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.1847e-04\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.0054e-04\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.0535e-04\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.2590e-04\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.8817e-04\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.7798e-04\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.1527e-04\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.9608e-04\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.6198e-04\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.6131e-04\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.5043e-04\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.8200e-04\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.9415e-04\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.9141e-04 - val_loss: 5.3843e-04\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.7933e-04 - val_loss: 5.4937e-04\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.6974e-04 - val_loss: 5.2955e-04\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.5933e-04 - val_loss: 5.4407e-04\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.5595e-04 - val_loss: 5.4762e-04\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.3949e-04 - val_loss: 5.1286e-04\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.2976e-04 - val_loss: 5.5665e-04\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.2910e-04 - val_loss: 5.3216e-04\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.1406e-04 - val_loss: 4.9678e-04\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.1247e-04 - val_loss: 4.8827e-04\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.9832e-04 - val_loss: 4.8539e-04\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.8701e-04 - val_loss: 4.9064e-04\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.7837e-04 - val_loss: 4.7740e-04\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.6782e-04 - val_loss: 4.7208e-04\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.6023e-04 - val_loss: 4.7447e-04\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.5341e-04 - val_loss: 4.6261e-04\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.4393e-04 - val_loss: 4.5746e-04\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.3331e-04 - val_loss: 4.8139e-04\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.2814e-04 - val_loss: 4.7029e-04\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.2570e-04 - val_loss: 4.4942e-04\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.1214e-04 - val_loss: 4.4305e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.0185e-04 - val_loss: 4.4479e-04\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.0368e-04 - val_loss: 4.3858e-04\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.8486e-04 - val_loss: 4.5424e-04\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.8812e-04 - val_loss: 4.3239e-04\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.7875e-04 - val_loss: 4.1583e-04\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.6461e-04 - val_loss: 4.1918e-04\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.5913e-04 - val_loss: 4.1813e-04\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.5105e-04 - val_loss: 4.0576e-04\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.4678e-04 - val_loss: 3.9986e-04\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.4240e-04 - val_loss: 3.9608e-04\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.3186e-04 - val_loss: 3.9684e-04\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.2497e-04 - val_loss: 4.0016e-04\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.1757e-04 - val_loss: 3.9584e-04\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.1253e-04 - val_loss: 4.1490e-04\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.0755e-04 - val_loss: 3.8447e-04\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.0051e-04 - val_loss: 3.7602e-04\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.0228e-04 - val_loss: 3.7215e-04\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.9170e-04 - val_loss: 3.7024e-04\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.8145e-04 - val_loss: 3.7747e-04\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.7801e-04 - val_loss: 3.6496e-04\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.7362e-04 - val_loss: 3.6029e-04\n",
      "Thời gian huấn luyện:  6.997787952423096\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_60 (Dense)            (None, 10, 96)            192       \n",
      "                                                                 \n",
      " flatten_48 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,153\n",
      "Trainable params: 1,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 1s 8ms/step - loss: 0.0126 - val_loss: 0.0011\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 9.0352e-04\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 8.0942e-04\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 8.0306e-04\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 7.3732e-04\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 7.8746e-04\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 7.6488e-04\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 6.9143e-04\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 7.0739e-04\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.3021e-04\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.3247e-04\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.4358e-04\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.1913e-04\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.7998e-04\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.9551e-04\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.5689e-04\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 6.0170e-04\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 6.3731e-04\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.9326e-04\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.6791e-04 - val_loss: 5.2930e-04\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.5560e-04 - val_loss: 5.1639e-04\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.3441e-04 - val_loss: 5.4740e-04\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.2191e-04 - val_loss: 5.0422e-04\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.9932e-04 - val_loss: 5.4451e-04\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.9293e-04 - val_loss: 5.1133e-04\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.8388e-04 - val_loss: 4.9875e-04\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.8554e-04 - val_loss: 4.7572e-04\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.8002e-04 - val_loss: 4.9279e-04\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.9422e-04 - val_loss: 4.6711e-04\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.0108e-04 - val_loss: 4.6681e-04\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.9372e-04 - val_loss: 4.8955e-04\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.3422e-04 - val_loss: 4.5066e-04\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.3591e-04 - val_loss: 4.4981e-04\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.2253e-04 - val_loss: 4.4491e-04\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.0086e-04 - val_loss: 4.8426e-04\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.0925e-04 - val_loss: 4.8246e-04\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.0300e-04 - val_loss: 4.5423e-04\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.7376e-04 - val_loss: 4.6512e-04\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.6082e-04 - val_loss: 5.1664e-04\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.6923e-04 - val_loss: 4.1723e-04\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.5653e-04 - val_loss: 4.6992e-04\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.7914e-04 - val_loss: 4.4677e-04\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.5280e-04 - val_loss: 4.1148e-04\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2814e-04 - val_loss: 4.4076e-04\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.3939e-04 - val_loss: 4.4755e-04\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.5667e-04 - val_loss: 3.9660e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.3398e-04 - val_loss: 3.9369e-04\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.0773e-04 - val_loss: 3.9476e-04\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.0214e-04 - val_loss: 3.8910e-04\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.0831e-04 - val_loss: 4.3773e-04\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.9470e-04 - val_loss: 3.8260e-04\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8829e-04 - val_loss: 4.5788e-04\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.9485e-04 - val_loss: 4.0063e-04\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8262e-04 - val_loss: 3.7473e-04\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.7335e-04 - val_loss: 3.9315e-04\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.9785e-04 - val_loss: 3.7967e-04\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8361e-04 - val_loss: 4.0477e-04\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5800e-04 - val_loss: 3.6406e-04\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6448e-04 - val_loss: 3.6359e-04\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6199e-04 - val_loss: 3.7054e-04\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6253e-04 - val_loss: 3.7382e-04\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5226e-04 - val_loss: 3.5617e-04\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5577e-04 - val_loss: 4.1705e-04\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3555e-04 - val_loss: 3.7757e-04\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4174e-04 - val_loss: 4.2970e-04\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4710e-04 - val_loss: 3.4754e-04\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4099e-04 - val_loss: 3.9510e-04\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5043e-04 - val_loss: 3.4707e-04\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2877e-04 - val_loss: 3.6013e-04\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1498e-04 - val_loss: 3.5602e-04\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1466e-04 - val_loss: 3.8218e-04\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2525e-04 - val_loss: 3.5672e-04\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6768e-04 - val_loss: 3.8527e-04\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0435e-04 - val_loss: 3.4222e-04\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9858e-04 - val_loss: 3.4547e-04\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2821e-04 - val_loss: 4.6466e-04\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5791e-04 - val_loss: 3.2742e-04\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9408e-04 - val_loss: 3.5073e-04\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0377e-04 - val_loss: 3.2859e-04\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0261e-04 - val_loss: 3.2117e-04\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9706e-04 - val_loss: 3.3224e-04\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9020e-04 - val_loss: 3.2271e-04\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8305e-04 - val_loss: 3.4259e-04\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9014e-04 - val_loss: 3.3203e-04\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0272e-04 - val_loss: 3.3898e-04\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7337e-04 - val_loss: 3.1716e-04\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7761e-04 - val_loss: 3.0996e-04\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6780e-04 - val_loss: 3.0890e-04\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6534e-04 - val_loss: 3.1291e-04\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5764e-04 - val_loss: 3.0583e-04\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5900e-04 - val_loss: 3.3294e-04\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7152e-04 - val_loss: 3.0602e-04\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6229e-04 - val_loss: 3.0355e-04\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6271e-04 - val_loss: 3.2407e-04\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4951e-04 - val_loss: 3.4842e-04\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5138e-04 - val_loss: 3.0872e-04\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4579e-04 - val_loss: 2.9636e-04\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6696e-04 - val_loss: 2.9543e-04\n",
      "Thời gian huấn luyện:  11.238847970962524\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_12 (SimpleRNN)   (None, 10, 96)            9408      \n",
      "                                                                 \n",
      " flatten_49 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,369\n",
      "Trainable params: 10,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 2s 30ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Thời gian huấn luyện:  24.05993628501892\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 10, 96)            37632     \n",
      "                                                                 \n",
      " flatten_50 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,593\n",
      "Trainable params: 38,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 2s 16ms/step - loss: 0.0152 - val_loss: 0.0013\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 9.1411e-04\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 8.8378e-04\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.5471e-04\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 8.7168e-04\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.7447e-04\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 8.1964e-04\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 7.8798e-04\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 7.2910e-04\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 7.1024e-04\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.9264e-04\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 7.1616e-04\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.8094e-04\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 7.2186e-04\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.5383e-04\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.3426e-04\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.4417e-04\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.0629e-04\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.3951e-04\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.0890e-04\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.8397e-04\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.7586e-04\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 5.9003e-04\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.5111e-04\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.9847e-04 - val_loss: 5.4649e-04\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.8325e-04 - val_loss: 5.4447e-04\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.6767e-04 - val_loss: 5.6160e-04\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.5348e-04 - val_loss: 5.6719e-04\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.5604e-04 - val_loss: 5.6711e-04\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.3970e-04 - val_loss: 5.0608e-04\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.1630e-04 - val_loss: 4.9991e-04\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.1123e-04 - val_loss: 5.2941e-04\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.9639e-04 - val_loss: 4.9404e-04\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.8072e-04 - val_loss: 5.2615e-04\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.7757e-04 - val_loss: 5.3880e-04\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.7669e-04 - val_loss: 4.8043e-04\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.6371e-04 - val_loss: 4.7978e-04\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.4498e-04 - val_loss: 4.9309e-04\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.5015e-04 - val_loss: 5.2235e-04\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.3457e-04 - val_loss: 4.6067e-04\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.2514e-04 - val_loss: 4.6199e-04\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.1587e-04 - val_loss: 4.6832e-04\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.1392e-04 - val_loss: 4.4224e-04\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.1034e-04 - val_loss: 4.7592e-04\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.9559e-04 - val_loss: 4.5389e-04\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.8760e-04 - val_loss: 4.3223e-04\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.8374e-04 - val_loss: 4.3593e-04\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.9011e-04 - val_loss: 4.3102e-04\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.9878e-04 - val_loss: 4.3870e-04\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.7799e-04 - val_loss: 4.2131e-04\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.7993e-04 - val_loss: 4.2232e-04\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.6844e-04 - val_loss: 4.2482e-04\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.5626e-04 - val_loss: 4.6047e-04\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.4331e-04 - val_loss: 4.1319e-04\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.4033e-04 - val_loss: 4.2984e-04\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.3753e-04 - val_loss: 4.2828e-04\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.3532e-04 - val_loss: 4.2562e-04\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.2778e-04 - val_loss: 4.4830e-04\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.2162e-04 - val_loss: 4.2299e-04\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.2482e-04 - val_loss: 3.9620e-04\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.1624e-04 - val_loss: 4.3669e-04\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.0859e-04 - val_loss: 3.9848e-04\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.0635e-04 - val_loss: 4.0124e-04\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.9564e-04 - val_loss: 4.2646e-04\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.9807e-04 - val_loss: 3.9428e-04\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.9871e-04 - val_loss: 4.2599e-04\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.9663e-04 - val_loss: 4.0156e-04\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.8278e-04 - val_loss: 3.9527e-04\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 6.8381e-04 - val_loss: 4.0379e-04\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.7596e-04 - val_loss: 4.2889e-04\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.7753e-04 - val_loss: 3.9154e-04\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.6929e-04 - val_loss: 3.8039e-04\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.7630e-04 - val_loss: 3.6870e-04\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.6152e-04 - val_loss: 3.6983e-04\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.5696e-04 - val_loss: 3.8084e-04\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.6150e-04 - val_loss: 3.8093e-04\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.5273e-04 - val_loss: 3.7870e-04\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.3816e-04 - val_loss: 4.9388e-04\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.5892e-04 - val_loss: 3.5780e-04\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.4644e-04 - val_loss: 4.0846e-04\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.3842e-04 - val_loss: 3.5916e-04\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.3245e-04 - val_loss: 3.8906e-04\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.3171e-04 - val_loss: 3.6545e-04\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.2789e-04 - val_loss: 3.7520e-04\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.2216e-04 - val_loss: 3.4768e-04\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.3248e-04 - val_loss: 3.8154e-04\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.1231e-04 - val_loss: 3.5338e-04\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.0992e-04 - val_loss: 4.0878e-04\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.1114e-04 - val_loss: 3.5010e-04\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.1043e-04 - val_loss: 3.5503e-04\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.0568e-04 - val_loss: 3.4157e-04\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.1253e-04 - val_loss: 3.4357e-04\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.9848e-04 - val_loss: 3.4692e-04\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.1670e-04 - val_loss: 3.3494e-04\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.9405e-04 - val_loss: 3.5171e-04\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.0145e-04 - val_loss: 3.3432e-04\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.9032e-04 - val_loss: 3.6414e-04\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.8675e-04 - val_loss: 3.2794e-04\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.8431e-04 - val_loss: 3.4628e-04\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.8665e-04 - val_loss: 3.6377e-04\n",
      "Thời gian huấn luyện:  22.47052812576294\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_12 (GRU)                (None, 10, 96)            28512     \n",
      "                                                                 \n",
      " flatten_51 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,473\n",
      "Trainable params: 29,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.0509 - val_loss: 0.0029\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0029\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0018\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0018\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0016\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 9.2993e-04\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 8.6738e-04\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 8.2345e-04\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 8.0500e-04\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 7.9507e-04\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 7.5137e-04\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 7.3831e-04\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 7.5771e-04\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.0603e-04\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 6.9689e-04\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 6.8434e-04\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.0720e-04\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 6.5964e-04\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 6.9027e-04\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.5502e-04\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.3913e-04\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.6773e-04\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.3135e-04\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.7406e-04\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.4731e-04\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.4761e-04\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.1245e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.5909e-04\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.1176e-04\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.9189e-04\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.1592e-04\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.8978e-04\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.8573e-04\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.9891e-04\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.8410e-04\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.7237e-04\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.6991e-04\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.6459e-04\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.9227e-04\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.5136e-04\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.7765e-04\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.4861e-04\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.4353e-04\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.5628e-04\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.4380e-04\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.3156e-04\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.2369e-04\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.3634e-04\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.2614e-04\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.5567e-04\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.1479e-04\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.1540e-04\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.0526e-04\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.2344e-04\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.9392e-04 - val_loss: 4.9855e-04\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.8962e-04 - val_loss: 4.8630e-04\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.7624e-04 - val_loss: 5.5060e-04\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.6952e-04 - val_loss: 4.7310e-04\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.6351e-04 - val_loss: 4.8326e-04\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.5321e-04 - val_loss: 5.0244e-04\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.4162e-04 - val_loss: 4.6871e-04\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.3590e-04 - val_loss: 4.6515e-04\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.2467e-04 - val_loss: 4.7510e-04\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.1896e-04 - val_loss: 4.5042e-04\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.0940e-04 - val_loss: 4.7332e-04\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.0229e-04 - val_loss: 4.4734e-04\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.9249e-04 - val_loss: 4.6569e-04\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.9840e-04 - val_loss: 4.3640e-04\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.8920e-04 - val_loss: 4.3189e-04\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.7632e-04 - val_loss: 4.3198e-04\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.6613e-04 - val_loss: 4.4371e-04\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.5448e-04 - val_loss: 4.2879e-04\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.4867e-04 - val_loss: 4.2240e-04\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.3953e-04 - val_loss: 4.2774e-04\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.4166e-04 - val_loss: 4.2193e-04\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.2771e-04 - val_loss: 4.3164e-04\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.3146e-04 - val_loss: 4.0825e-04\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.1468e-04 - val_loss: 4.1864e-04\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.0588e-04 - val_loss: 4.0394e-04\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.0405e-04 - val_loss: 4.1733e-04\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.9411e-04 - val_loss: 4.1494e-04\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.8714e-04 - val_loss: 4.1126e-04\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.8135e-04 - val_loss: 4.0254e-04\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.7779e-04 - val_loss: 4.0014e-04\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.6955e-04 - val_loss: 4.1766e-04\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.6254e-04 - val_loss: 3.9160e-04\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.5966e-04 - val_loss: 4.2955e-04\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.5961e-04 - val_loss: 4.0329e-04\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.4550e-04 - val_loss: 3.8982e-04\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.3789e-04 - val_loss: 3.7790e-04\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.3449e-04 - val_loss: 3.7310e-04\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.2837e-04 - val_loss: 3.7442e-04\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.2413e-04 - val_loss: 3.6509e-04\n",
      "Thời gian huấn luyện:  7.043416976928711\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_65 (Dense)            (None, 10, 96)            192       \n",
      "                                                                 \n",
      " flatten_52 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,153\n",
      "Trainable params: 1,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "30/30 [==============================] - 1s 8ms/step - loss: 0.0163 - val_loss: 0.0020\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 8.3034e-04\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 7.7959e-04\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 6.9951e-04\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 6.7737e-04\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 6.7248e-04\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 5.8994e-04\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.8151e-04\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.5192e-04\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.4363e-04\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.1838e-04\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.6563e-04\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.3945e-04\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.7941e-04 - val_loss: 5.0833e-04\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.4318e-04 - val_loss: 4.9322e-04\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.2195e-04 - val_loss: 4.7709e-04\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.0475e-04 - val_loss: 4.6721e-04\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.9517e-04 - val_loss: 4.7025e-04\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.7183e-04 - val_loss: 4.4555e-04\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.5334e-04 - val_loss: 4.5612e-04\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.5308e-04 - val_loss: 4.6015e-04\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.5612e-04 - val_loss: 4.1759e-04\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.1412e-04 - val_loss: 4.8020e-04\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.0806e-04 - val_loss: 4.5518e-04\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.1090e-04 - val_loss: 4.1471e-04\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.8334e-04 - val_loss: 4.0294e-04\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.8694e-04 - val_loss: 4.3359e-04\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.9148e-04 - val_loss: 4.7317e-04\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.7168e-04 - val_loss: 3.9730e-04\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.5379e-04 - val_loss: 4.0160e-04\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.4262e-04 - val_loss: 3.8280e-04\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.4941e-04 - val_loss: 3.8345e-04\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.5755e-04 - val_loss: 3.8561e-04\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.2543e-04 - val_loss: 3.8145e-04\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.2048e-04 - val_loss: 3.7763e-04\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.9945e-04 - val_loss: 5.1050e-04\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.0358e-04 - val_loss: 3.6517e-04\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.1328e-04 - val_loss: 5.5404e-04\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.0184e-04 - val_loss: 3.6500e-04\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.9899e-04 - val_loss: 4.0994e-04\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.7917e-04 - val_loss: 3.5810e-04\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.7130e-04 - val_loss: 3.5522e-04\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.6499e-04 - val_loss: 3.6619e-04\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.5832e-04 - val_loss: 3.7240e-04\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.5294e-04 - val_loss: 3.5389e-04\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.9192e-04 - val_loss: 3.4451e-04\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.5624e-04 - val_loss: 3.7315e-04\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.4932e-04 - val_loss: 3.4930e-04\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.3977e-04 - val_loss: 3.3683e-04\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.3776e-04 - val_loss: 4.1818e-04\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.2768e-04 - val_loss: 3.8556e-04\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.3159e-04 - val_loss: 3.6282e-04\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.2351e-04 - val_loss: 3.4715e-04\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.1635e-04 - val_loss: 3.3118e-04\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.2516e-04 - val_loss: 3.2653e-04\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.1603e-04 - val_loss: 3.7023e-04\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.1653e-04 - val_loss: 3.5065e-04\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.0333e-04 - val_loss: 3.5397e-04\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.9635e-04 - val_loss: 4.3784e-04\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.1139e-04 - val_loss: 5.2166e-04\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.2641e-04 - val_loss: 3.2350e-04\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 6.0631e-04 - val_loss: 3.6620e-04\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 5.9951e-04 - val_loss: 3.5287e-04\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.8906e-04 - val_loss: 4.1868e-04\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.8717e-04 - val_loss: 3.1412e-04\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.7775e-04 - val_loss: 3.3784e-04\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.7860e-04 - val_loss: 3.1758e-04\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 5.9876e-04 - val_loss: 3.3358e-04\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.7126e-04 - val_loss: 3.5471e-04\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.7447e-04 - val_loss: 3.1273e-04\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.8399e-04 - val_loss: 3.0373e-04\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.7485e-04 - val_loss: 3.1218e-04\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 5.6757e-04 - val_loss: 3.1250e-04\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.5676e-04 - val_loss: 3.0112e-04\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.6815e-04 - val_loss: 3.0327e-04\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.5415e-04 - val_loss: 3.0081e-04\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.5390e-04 - val_loss: 3.4127e-04\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.8622e-04 - val_loss: 4.8419e-04\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.8999e-04 - val_loss: 3.4409e-04\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 3ms/step - loss: 5.4780e-04 - val_loss: 3.3832e-04\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.4537e-04 - val_loss: 3.0317e-04\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.5819e-04 - val_loss: 2.9033e-04\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.4261e-04 - val_loss: 2.8996e-04\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.6210e-04 - val_loss: 3.6191e-04\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.7823e-04 - val_loss: 2.9996e-04\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.4120e-04 - val_loss: 2.8695e-04\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.0806e-04 - val_loss: 3.6751e-04\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.5247e-04 - val_loss: 2.8473e-04\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.2666e-04 - val_loss: 2.8952e-04\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.3144e-04 - val_loss: 2.8647e-04\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.3103e-04 - val_loss: 2.8287e-04\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.3016e-04 - val_loss: 3.3413e-04\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.2781e-04 - val_loss: 2.8582e-04\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.2704e-04 - val_loss: 3.0289e-04\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.3703e-04 - val_loss: 3.1686e-04\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.3472e-04 - val_loss: 2.8326e-04\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.3980e-04 - val_loss: 2.8022e-04\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.1875e-04 - val_loss: 2.9179e-04\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 5.2632e-04 - val_loss: 2.9117e-04\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.1389e-04 - val_loss: 2.7528e-04\n",
      "Thời gian huấn luyện:  10.990137338638306\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_13 (SimpleRNN)   (None, 10, 96)            9408      \n",
      "                                                                 \n",
      " flatten_53 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,369\n",
      "Trainable params: 10,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "30/30 [==============================] - 2s 18ms/step - loss: 0.0232 - val_loss: 0.0011\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 9.5392e-04\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 9.7008e-04\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 9.7099e-04\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 9.8123e-04\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 9.0156e-04\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 9.1991e-04\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 9.1200e-04\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 9.2123e-04\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 8.6696e-04\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 8.8307e-04\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 8.6901e-04\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.7301e-04\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.5500e-04\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.1642e-04\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.9297e-04\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.6645e-04\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.4149e-04\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.0800e-04\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 7.8647e-04\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 8.3260e-04\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.6888e-04\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.6574e-04\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.9288e-04\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.6497e-04\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.3365e-04\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.4954e-04\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.3957e-04\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.3710e-04\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.0828e-04\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.0310e-04\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 6.9405e-04\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.0278e-04\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.1926e-04\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.2730e-04\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 6.7685e-04\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 7.0064e-04\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 7.0671e-04\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 6.7718e-04\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 6.6792e-04\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 7.0757e-04\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.3092e-04\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 7.2211e-04\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.2483e-04\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.4786e-04\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 7.5051e-04\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.1126e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.3398e-04\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 6.5114e-04\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 6.3551e-04\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 6.2571e-04\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 6.5474e-04\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 6.8103e-04\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.7705e-04\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.5994e-04\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 6.3606e-04\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.4906e-04\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.5174e-04\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.5346e-04\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.6647e-04\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 6.1537e-04\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.3003e-04\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.3462e-04\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.5125e-04\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.4563e-04\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.2790e-04\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 5.2275e-04\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 5.2424e-04\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 6.3100e-04\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.1862e-04\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 5.7187e-04\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 5.0406e-04\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 6.7747e-04\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 5.3315e-04\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 9.9752e-04 - val_loss: 5.7851e-04\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 9.9420e-04 - val_loss: 5.2461e-04\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 6.6662e-04\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 5.0296e-04\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.8191e-04 - val_loss: 5.6312e-04\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 5.1920e-04\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.9642e-04 - val_loss: 5.3391e-04\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.8032e-04 - val_loss: 6.2891e-04\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.7402e-04 - val_loss: 5.1412e-04\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 9.6354e-04 - val_loss: 5.4611e-04\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.8408e-04 - val_loss: 5.1675e-04\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.6720e-04 - val_loss: 4.9383e-04\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 9.6849e-04 - val_loss: 5.8053e-04\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.4690e-04 - val_loss: 5.0933e-04\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.5180e-04 - val_loss: 4.8184e-04\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.5043e-04 - val_loss: 5.3062e-04\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.4256e-04 - val_loss: 5.5193e-04\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.5184e-04 - val_loss: 4.7685e-04\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.4289e-04 - val_loss: 4.7391e-04\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.5612e-04 - val_loss: 5.1477e-04\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.2409e-04 - val_loss: 4.8808e-04\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.2114e-04 - val_loss: 5.1194e-04\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.1778e-04 - val_loss: 5.1858e-04\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.0574e-04 - val_loss: 4.7942e-04\n",
      "Thời gian huấn luyện:  23.246170043945312\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_13 (LSTM)              (None, 10, 96)            37632     \n",
      "                                                                 \n",
      " flatten_54 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,593\n",
      "Trainable params: 38,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "30/30 [==============================] - 2s 17ms/step - loss: 0.0206 - val_loss: 0.0017\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 8.0687e-04\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 8.2083e-04\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 7.5676e-04\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 7.8632e-04\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 7.1664e-04\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 7.3885e-04\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 7.4806e-04\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 7.1348e-04\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 6.8583e-04\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 6.6653e-04\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 6.9655e-04\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 7.1017e-04\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.8038e-04\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.6211e-04\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.5689e-04\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.7130e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.0267e-04\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 5.9390e-04\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 5.8980e-04\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.3456e-04\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 5.7024e-04\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 5.7723e-04\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 5.5510e-04\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.5276e-04\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.2280e-04\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.0195e-04\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.3478e-04\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.2259e-04\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.1581e-04\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.3696e-04\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 5.0868e-04\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.1515e-04\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.1294e-04\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.9056e-04 - val_loss: 5.2421e-04\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.7682e-04 - val_loss: 4.9154e-04\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.6355e-04 - val_loss: 5.4601e-04\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.6530e-04 - val_loss: 4.7546e-04\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.9402e-04 - val_loss: 4.7110e-04\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.4654e-04 - val_loss: 4.9735e-04\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.2597e-04 - val_loss: 5.4115e-04\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.1355e-04 - val_loss: 4.6199e-04\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.0347e-04 - val_loss: 5.0625e-04\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.0265e-04 - val_loss: 4.8405e-04\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.9444e-04 - val_loss: 4.4748e-04\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.8291e-04 - val_loss: 4.4490e-04\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.8161e-04 - val_loss: 4.4565e-04\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.7538e-04 - val_loss: 4.7131e-04\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.6733e-04 - val_loss: 4.6859e-04\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.5608e-04 - val_loss: 4.9397e-04\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.5732e-04 - val_loss: 4.3427e-04\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.7610e-04 - val_loss: 4.6341e-04\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.3429e-04 - val_loss: 4.7144e-04\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.3019e-04 - val_loss: 4.3054e-04\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.3675e-04 - val_loss: 4.2058e-04\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.1807e-04 - val_loss: 4.1755e-04\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.1719e-04 - val_loss: 4.1771e-04\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.0776e-04 - val_loss: 4.1962e-04\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.0121e-04 - val_loss: 4.2764e-04\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.0112e-04 - val_loss: 4.3165e-04\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.9482e-04 - val_loss: 4.0756e-04\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.8733e-04 - val_loss: 4.0897e-04\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.8416e-04 - val_loss: 4.0971e-04\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.7799e-04 - val_loss: 4.0482e-04\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.8230e-04 - val_loss: 4.1883e-04\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.8451e-04 - val_loss: 4.1923e-04\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.8918e-04 - val_loss: 4.2233e-04\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.6619e-04 - val_loss: 4.5273e-04\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.5789e-04 - val_loss: 4.4469e-04\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.5108e-04 - val_loss: 4.3425e-04\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.5077e-04 - val_loss: 3.8914e-04\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.4156e-04 - val_loss: 4.0416e-04\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.4048e-04 - val_loss: 4.2652e-04\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.4343e-04 - val_loss: 4.0244e-04\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.3488e-04 - val_loss: 4.7767e-04\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.3877e-04 - val_loss: 3.9148e-04\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 7.2457e-04 - val_loss: 3.8466e-04\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.2603e-04 - val_loss: 4.1734e-04\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.1513e-04 - val_loss: 3.7653e-04\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.1897e-04 - val_loss: 4.0165e-04\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 7.0680e-04 - val_loss: 4.0487e-04\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.0751e-04 - val_loss: 3.7130e-04\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.9621e-04 - val_loss: 4.0770e-04\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.9811e-04 - val_loss: 3.7800e-04\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.9749e-04 - val_loss: 3.6742e-04\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.9452e-04 - val_loss: 4.2538e-04\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.8941e-04 - val_loss: 3.6373e-04\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.8676e-04 - val_loss: 5.0635e-04\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.8122e-04 - val_loss: 3.6425e-04\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.8990e-04 - val_loss: 4.1942e-04\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.7288e-04 - val_loss: 3.7266e-04\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.6574e-04 - val_loss: 4.0170e-04\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.6452e-04 - val_loss: 4.0751e-04\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 6ms/step - loss: 6.7516e-04 - val_loss: 3.6622e-04\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.8564e-04 - val_loss: 3.5712e-04\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.5863e-04 - val_loss: 4.8090e-04\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.7867e-04 - val_loss: 3.7763e-04\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.4787e-04 - val_loss: 3.5093e-04\n",
      "Thời gian huấn luyện:  20.92561912536621\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_13 (GRU)                (None, 10, 96)            28512     \n",
      "                                                                 \n",
      " flatten_55 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,473\n",
      "Trainable params: 29,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "35/35 [==============================] - 0s 941us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 1s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0442 - val_loss: 0.0029\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 9.9587e-04\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 9.8964e-04\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 9.8921e-04\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 9.7177e-04\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 9.6849e-04\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 9.5574e-04\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 9.5720e-04\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 9.4218e-04\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 3ms/step - loss: 9.9642e-04 - val_loss: 9.3718e-04\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 9.3195e-04\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.9025e-04 - val_loss: 9.2200e-04\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.7805e-04 - val_loss: 9.1194e-04\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.6751e-04 - val_loss: 9.0403e-04\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.6595e-04 - val_loss: 8.9795e-04\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.5768e-04 - val_loss: 8.9044e-04\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.5811e-04 - val_loss: 8.9802e-04\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.4168e-04 - val_loss: 8.7854e-04\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.3414e-04 - val_loss: 8.6805e-04\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.2615e-04 - val_loss: 8.6034e-04\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.1976e-04 - val_loss: 8.5463e-04\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.1560e-04 - val_loss: 8.4670e-04\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.0831e-04 - val_loss: 8.3943e-04\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.0044e-04 - val_loss: 8.3258e-04\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.9783e-04 - val_loss: 8.2619e-04\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.9912e-04 - val_loss: 8.4133e-04\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 8.8317e-04 - val_loss: 8.1158e-04\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.7476e-04 - val_loss: 8.0850e-04\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.6839e-04 - val_loss: 7.9890e-04\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.6248e-04 - val_loss: 7.9973e-04\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.5658e-04 - val_loss: 7.8574e-04\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.5398e-04 - val_loss: 7.8538e-04\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.4658e-04 - val_loss: 7.7330e-04\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.3773e-04 - val_loss: 7.6468e-04\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.2987e-04 - val_loss: 7.6068e-04\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.2383e-04 - val_loss: 7.5225e-04\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.2588e-04 - val_loss: 7.4886e-04\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.1499e-04 - val_loss: 7.3942e-04\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.0543e-04 - val_loss: 7.3522e-04\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.0314e-04 - val_loss: 7.2766e-04\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.9346e-04 - val_loss: 7.2158e-04\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.8772e-04 - val_loss: 7.1483e-04\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.8208e-04 - val_loss: 7.1958e-04\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.8150e-04 - val_loss: 7.0364e-04\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.7008e-04 - val_loss: 6.9751e-04\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.6332e-04 - val_loss: 6.9700e-04\n",
      "Thời gian huấn luyện:  7.110063552856445\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_70 (Dense)            (None, 10, 96)            192       \n",
      "                                                                 \n",
      " flatten_56 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,153\n",
      "Trainable params: 1,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 1s 9ms/step - loss: 0.0063 - val_loss: 0.0021\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 9.6307e-04\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 9.3373e-04\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 8.2123e-04\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 9.4457e-04 - val_loss: 7.6896e-04\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.6702e-04 - val_loss: 7.3567e-04\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.3189e-04 - val_loss: 7.1114e-04\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.1229e-04 - val_loss: 6.9456e-04\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.0000e-04 - val_loss: 6.8691e-04\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.5956e-04 - val_loss: 6.5969e-04\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.2838e-04 - val_loss: 7.8135e-04\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.0108e-04 - val_loss: 6.2759e-04\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.1821e-04 - val_loss: 6.4840e-04\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.2337e-04 - val_loss: 6.6685e-04\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.2308e-04 - val_loss: 6.6877e-04\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.9111e-04 - val_loss: 5.8401e-04\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.1429e-04 - val_loss: 6.1341e-04\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.7305e-04 - val_loss: 5.6396e-04\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.7545e-04 - val_loss: 5.6783e-04\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.9012e-04 - val_loss: 5.8287e-04\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.9123e-04 - val_loss: 5.4878e-04\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.5618e-04 - val_loss: 5.3987e-04\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.9099e-04 - val_loss: 5.4902e-04\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.4388e-04 - val_loss: 6.0606e-04\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.3095e-04 - val_loss: 5.2876e-04\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.4752e-04 - val_loss: 5.9347e-04\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.2418e-04 - val_loss: 5.3637e-04\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.0867e-04 - val_loss: 5.1410e-04\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 4ms/step - loss: 6.0116e-04 - val_loss: 5.1270e-04\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.9634e-04 - val_loss: 5.1187e-04\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.1092e-04 - val_loss: 5.3798e-04\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.3330e-04 - val_loss: 5.0403e-04\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.9498e-04 - val_loss: 4.9665e-04\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.1673e-04 - val_loss: 5.6227e-04\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.9279e-04 - val_loss: 4.9126e-04\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.7705e-04 - val_loss: 4.8616e-04\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.0747e-04 - val_loss: 4.9866e-04\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.7621e-04 - val_loss: 4.9777e-04\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.7216e-04 - val_loss: 4.9129e-04\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.6293e-04 - val_loss: 5.3204e-04\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.8588e-04 - val_loss: 4.7768e-04\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.7771e-04 - val_loss: 4.7298e-04\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.5481e-04 - val_loss: 4.6727e-04\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.6723e-04 - val_loss: 4.6903e-04\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.5340e-04 - val_loss: 4.7715e-04\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.4493e-04 - val_loss: 4.6915e-04\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.6168e-04 - val_loss: 4.6545e-04\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.4965e-04 - val_loss: 4.5645e-04\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.5778e-04 - val_loss: 4.7483e-04\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.4835e-04 - val_loss: 4.7140e-04\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.4665e-04 - val_loss: 4.6539e-04\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.7229e-04 - val_loss: 4.5124e-04\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.8779e-04 - val_loss: 4.5282e-04\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.4941e-04 - val_loss: 4.4645e-04\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.2641e-04 - val_loss: 4.5290e-04\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.3030e-04 - val_loss: 4.4571e-04\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.6167e-04 - val_loss: 4.5458e-04\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.5226e-04 - val_loss: 5.4686e-04\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.2519e-04 - val_loss: 4.4031e-04\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.2185e-04 - val_loss: 4.3759e-04\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.3904e-04 - val_loss: 5.3552e-04\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.3940e-04 - val_loss: 4.9723e-04\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.2384e-04 - val_loss: 4.3045e-04\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.1272e-04 - val_loss: 4.4517e-04\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.1856e-04 - val_loss: 4.2808e-04\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.1488e-04 - val_loss: 4.2793e-04\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.5722e-04 - val_loss: 4.3072e-04\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.2099e-04 - val_loss: 4.5849e-04\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.3066e-04 - val_loss: 4.2611e-04\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.1167e-04 - val_loss: 4.2367e-04\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.2775e-04 - val_loss: 4.2434e-04\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.1320e-04 - val_loss: 4.3063e-04\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.9861e-04 - val_loss: 4.3608e-04\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.2384e-04 - val_loss: 4.2155e-04\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.1886e-04 - val_loss: 4.1656e-04\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.0993e-04 - val_loss: 4.4440e-04\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.4211e-04 - val_loss: 4.2040e-04\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.0133e-04 - val_loss: 4.1123e-04\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.5799e-04 - val_loss: 4.2780e-04\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.9405e-04 - val_loss: 4.0870e-04\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.0251e-04 - val_loss: 4.1890e-04\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.9136e-04 - val_loss: 4.0524e-04\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.9149e-04 - val_loss: 4.0794e-04\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.0010e-04 - val_loss: 4.0476e-04\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.8424e-04 - val_loss: 4.1252e-04\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.2400e-04 - val_loss: 5.1962e-04\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.1174e-04 - val_loss: 4.0577e-04\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4.9365e-04 - val_loss: 4.0807e-04\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.0373e-04 - val_loss: 4.2611e-04\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.1018e-04 - val_loss: 4.0425e-04\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.9740e-04 - val_loss: 3.9703e-04\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.1439e-04 - val_loss: 4.7460e-04\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.1334e-04 - val_loss: 3.9730e-04\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4.8209e-04 - val_loss: 3.9337e-04\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4.7748e-04 - val_loss: 3.9332e-04\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4.9764e-04 - val_loss: 4.3691e-04\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.0230e-04 - val_loss: 3.9205e-04\n",
      "Thời gian huấn luyện:  10.797170877456665\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_14 (SimpleRNN)   (None, 10, 96)            9408      \n",
      "                                                                 \n",
      " flatten_57 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,369\n",
      "Trainable params: 10,369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 2s 19ms/step - loss: 0.0223 - val_loss: 0.0018\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 9.7832e-04\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 9.7377e-04\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 9.6439e-04\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 9.5244e-04\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 9.5786e-04\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 9.4906e-04\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 9.8964e-04\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.9880e-04 - val_loss: 9.3634e-04\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.9212e-04 - val_loss: 9.5150e-04\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.7618e-04 - val_loss: 9.1127e-04\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.8333e-04 - val_loss: 9.1073e-04\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.7753e-04 - val_loss: 9.6007e-04\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.6060e-04 - val_loss: 9.0476e-04\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.7837e-04 - val_loss: 8.9169e-04\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.5231e-04 - val_loss: 8.9496e-04\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.5143e-04 - val_loss: 8.9799e-04\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 7ms/step - loss: 9.7972e-04 - val_loss: 9.4088e-04\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.4610e-04 - val_loss: 8.9199e-04\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.3512e-04 - val_loss: 8.8639e-04\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.3407e-04 - val_loss: 8.7752e-04\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.5100e-04 - val_loss: 8.7084e-04\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.3950e-04 - val_loss: 8.8078e-04\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.3859e-04 - val_loss: 9.0629e-04\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.1351e-04 - val_loss: 8.6037e-04\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.1884e-04 - val_loss: 8.6951e-04\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.1530e-04 - val_loss: 8.5348e-04\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.1565e-04 - val_loss: 8.7259e-04\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.1154e-04 - val_loss: 8.6034e-04\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.0239e-04 - val_loss: 8.7348e-04\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.9913e-04 - val_loss: 8.8358e-04\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.9436e-04 - val_loss: 9.4035e-04\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.8356e-04 - val_loss: 9.2602e-04\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.9941e-04 - val_loss: 8.7044e-04\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.8255e-04 - val_loss: 8.5237e-04\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.9803e-04 - val_loss: 8.4003e-04\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7760e-04 - val_loss: 8.3297e-04\n",
      "Thời gian huấn luyện:  21.741520404815674\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_14 (LSTM)              (None, 10, 96)            37632     \n",
      "                                                                 \n",
      " flatten_58 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,593\n",
      "Trainable params: 38,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 2s 18ms/step - loss: 0.0125 - val_loss: 0.0025\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 9.8572e-04\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 9.4919e-04\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 9.4395e-04\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.9788e-04 - val_loss: 9.1163e-04\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.7202e-04 - val_loss: 8.9745e-04\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.4995e-04 - val_loss: 9.1225e-04\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.4578e-04 - val_loss: 8.6540e-04\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.2519e-04 - val_loss: 8.4842e-04\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.1587e-04 - val_loss: 8.3901e-04\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.0103e-04 - val_loss: 8.3850e-04\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.0003e-04 - val_loss: 8.1388e-04\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.8169e-04 - val_loss: 8.3615e-04\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.7232e-04 - val_loss: 7.9978e-04\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.6028e-04 - val_loss: 7.8019e-04\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.5479e-04 - val_loss: 7.7392e-04\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.3646e-04 - val_loss: 7.6318e-04\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.3328e-04 - val_loss: 7.7684e-04\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.2740e-04 - val_loss: 7.4992e-04\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.1597e-04 - val_loss: 7.4963e-04\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.2167e-04 - val_loss: 7.3645e-04\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.0343e-04 - val_loss: 7.3085e-04\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.9300e-04 - val_loss: 7.4366e-04\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.9494e-04 - val_loss: 7.1722e-04\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.8329e-04 - val_loss: 7.4911e-04\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.1244e-04 - val_loss: 7.3003e-04\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 7ms/step - loss: 7.9449e-04 - val_loss: 7.1759e-04\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.9249e-04 - val_loss: 6.9487e-04\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.7417e-04 - val_loss: 7.0849e-04\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.5979e-04 - val_loss: 7.2677e-04\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.5388e-04 - val_loss: 7.1793e-04\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.5353e-04 - val_loss: 6.7609e-04\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.4030e-04 - val_loss: 6.7350e-04\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.3604e-04 - val_loss: 6.8028e-04\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.3207e-04 - val_loss: 6.6489e-04\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.4204e-04 - val_loss: 6.8095e-04\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.2894e-04 - val_loss: 6.6813e-04\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.1978e-04 - val_loss: 6.6011e-04\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.1888e-04 - val_loss: 6.6032e-04\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.1414e-04 - val_loss: 6.5557e-04\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.1152e-04 - val_loss: 6.4818e-04\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.1124e-04 - val_loss: 6.4108e-04\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.0014e-04 - val_loss: 6.3905e-04\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 6.9988e-04 - val_loss: 6.8270e-04\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.1064e-04 - val_loss: 6.2993e-04\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.0359e-04 - val_loss: 6.2906e-04\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.9563e-04 - val_loss: 6.2095e-04\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.8205e-04 - val_loss: 6.2813e-04\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.8192e-04 - val_loss: 6.4057e-04\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.7557e-04 - val_loss: 6.1639e-04\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.7496e-04 - val_loss: 6.1125e-04\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.6963e-04 - val_loss: 6.2285e-04\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.8435e-04 - val_loss: 6.0379e-04\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 6.6096e-04 - val_loss: 5.9914e-04\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.7754e-04 - val_loss: 6.2900e-04\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.6104e-04 - val_loss: 6.0345e-04\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.5703e-04 - val_loss: 6.5694e-04\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.5505e-04 - val_loss: 6.0231e-04\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.5527e-04 - val_loss: 5.9479e-04\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.4300e-04 - val_loss: 5.8477e-04\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.4440e-04 - val_loss: 5.7879e-04\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.4265e-04 - val_loss: 5.7921e-04\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.3788e-04 - val_loss: 5.8579e-04\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.3168e-04 - val_loss: 6.1778e-04\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.3316e-04 - val_loss: 5.8396e-04\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 6.3683e-04 - val_loss: 5.7034e-04\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.5043e-04 - val_loss: 5.7822e-04\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.4139e-04 - val_loss: 5.7978e-04\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.2416e-04 - val_loss: 5.6542e-04\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 6.2847e-04 - val_loss: 5.5687e-04\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.1626e-04 - val_loss: 6.0123e-04\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.1817e-04 - val_loss: 5.6102e-04\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.0960e-04 - val_loss: 5.5174e-04\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.1101e-04 - val_loss: 5.5701e-04\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.1018e-04 - val_loss: 5.4973e-04\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.0234e-04 - val_loss: 5.9196e-04\n",
      "Thời gian huấn luyện:  20.769975900650024\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_14 (GRU)                (None, 10, 96)            28512     \n",
      "                                                                 \n",
      " flatten_59 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,473\n",
      "Trainable params: 29,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1000us/step\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0448 - val_loss: 0.0020\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 9.4698e-04\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 9.4817e-04\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 9.3916e-04\n",
      "Epoch 16/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 8.4576e-04\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 8.4593e-04\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.8025e-04\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.3757e-04\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.9402e-04\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.5841e-04\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.1215e-04\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.2778e-04\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.8319e-04\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.0780e-04\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.8928e-04\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.0262e-04\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.7367e-04\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.6509e-04\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.7383e-04\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.8704e-04\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.3826e-04\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.6813e-04\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.2698e-04\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.4935e-04\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.2841e-04\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.1464e-04\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.2569e-04\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.2702e-04\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.0406e-04\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.9590e-04\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.1767e-04\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.9479e-04\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.0261e-04\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.9728e-04\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.7340e-04\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.8307e-04\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.7216e-04\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.5367e-04\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.6232e-04\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.4193e-04\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.4559e-04\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.8593e-04 - val_loss: 5.3598e-04\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.8092e-04 - val_loss: 5.6851e-04\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.6607e-04 - val_loss: 5.2022e-04\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.6216e-04 - val_loss: 5.1193e-04\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.6702e-04 - val_loss: 5.1426e-04\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.3978e-04 - val_loss: 5.4533e-04\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.3934e-04 - val_loss: 5.2481e-04\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.3038e-04 - val_loss: 4.9435e-04\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.2370e-04 - val_loss: 5.3730e-04\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.0610e-04 - val_loss: 5.0487e-04\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.0523e-04 - val_loss: 5.0398e-04\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.9267e-04 - val_loss: 4.7243e-04\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.7743e-04 - val_loss: 4.7784e-04\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.7083e-04 - val_loss: 4.7206e-04\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.6702e-04 - val_loss: 4.6895e-04\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.5471e-04 - val_loss: 4.5304e-04\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.4840e-04 - val_loss: 4.5515e-04\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.3882e-04 - val_loss: 4.6216e-04\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.2934e-04 - val_loss: 4.4588e-04\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.2119e-04 - val_loss: 4.4661e-04\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.1201e-04 - val_loss: 4.4870e-04\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.0707e-04 - val_loss: 4.3262e-04\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.9797e-04 - val_loss: 4.3611e-04\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.9006e-04 - val_loss: 4.3804e-04\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.8504e-04 - val_loss: 4.2215e-04\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.7530e-04 - val_loss: 4.2074e-04\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.6973e-04 - val_loss: 4.1124e-04\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.6587e-04 - val_loss: 4.2705e-04\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.5782e-04 - val_loss: 4.0649e-04\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.6055e-04 - val_loss: 4.4684e-04\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.4357e-04 - val_loss: 3.9101e-04\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.4347e-04 - val_loss: 3.9040e-04\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.2692e-04 - val_loss: 3.9850e-04\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.2095e-04 - val_loss: 3.8005e-04\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.1810e-04 - val_loss: 3.8518e-04\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.0914e-04 - val_loss: 3.8912e-04\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.0398e-04 - val_loss: 3.7241e-04\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.9949e-04 - val_loss: 3.7102e-04\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.9344e-04 - val_loss: 3.7421e-04\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.8486e-04 - val_loss: 3.6127e-04\n",
      "Epoch 93/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 6.8216e-04 - val_loss: 3.7533e-04\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.7643e-04 - val_loss: 3.6359e-04\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.7314e-04 - val_loss: 3.5532e-04\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.6546e-04 - val_loss: 3.5368e-04\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.6001e-04 - val_loss: 3.4713e-04\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.5728e-04 - val_loss: 3.5344e-04\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.5042e-04 - val_loss: 3.6218e-04\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.5038e-04 - val_loss: 3.6534e-04\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.4410e-04 - val_loss: 3.4840e-04\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.3788e-04 - val_loss: 3.5163e-04\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.3306e-04 - val_loss: 3.3237e-04\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.2941e-04 - val_loss: 3.3794e-04\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.2892e-04 - val_loss: 3.3417e-04\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.2814e-04 - val_loss: 3.4396e-04\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.1779e-04 - val_loss: 3.3055e-04\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.1451e-04 - val_loss: 3.2991e-04\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.1489e-04 - val_loss: 3.3671e-04\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.2260e-04 - val_loss: 3.2598e-04\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0023e-04 - val_loss: 3.7204e-04\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0720e-04 - val_loss: 3.2792e-04\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0273e-04 - val_loss: 3.1794e-04\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9396e-04 - val_loss: 3.1106e-04\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9205e-04 - val_loss: 3.0909e-04\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9926e-04 - val_loss: 3.1145e-04\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8793e-04 - val_loss: 3.1446e-04\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8824e-04 - val_loss: 3.3734e-04\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8379e-04 - val_loss: 3.1149e-04\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7942e-04 - val_loss: 3.0602e-04\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8523e-04 - val_loss: 3.0052e-04\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7385e-04 - val_loss: 3.0362e-04\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6964e-04 - val_loss: 3.3678e-04\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7702e-04 - val_loss: 3.2009e-04\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7063e-04 - val_loss: 2.9571e-04\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6802e-04 - val_loss: 2.9783e-04\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6118e-04 - val_loss: 2.9417e-04\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6146e-04 - val_loss: 2.9454e-04\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6013e-04 - val_loss: 2.9933e-04\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5944e-04 - val_loss: 2.9201e-04\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5572e-04 - val_loss: 2.8922e-04\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5474e-04 - val_loss: 2.9342e-04\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5332e-04 - val_loss: 2.8761e-04\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4721e-04 - val_loss: 3.0653e-04\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5593e-04 - val_loss: 3.0218e-04\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4949e-04 - val_loss: 2.9529e-04\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4855e-04 - val_loss: 2.9445e-04\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4338e-04 - val_loss: 2.8350e-04\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4173e-04 - val_loss: 2.8318e-04\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4011e-04 - val_loss: 2.8880e-04\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4060e-04 - val_loss: 2.8029e-04\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3374e-04 - val_loss: 2.8939e-04\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3863e-04 - val_loss: 2.7865e-04\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3559e-04 - val_loss: 2.8078e-04\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5037e-04 - val_loss: 3.0926e-04\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3087e-04 - val_loss: 2.8314e-04\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2965e-04 - val_loss: 2.7547e-04\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3179e-04 - val_loss: 2.9065e-04\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2703e-04 - val_loss: 2.8252e-04\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2506e-04 - val_loss: 2.8304e-04\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2351e-04 - val_loss: 2.8301e-04\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2059e-04 - val_loss: 2.8499e-04\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2419e-04 - val_loss: 2.7260e-04\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2171e-04 - val_loss: 2.7005e-04\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1845e-04 - val_loss: 2.7048e-04\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1552e-04 - val_loss: 2.7685e-04\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1428e-04 - val_loss: 2.6792e-04\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1717e-04 - val_loss: 2.7094e-04\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1741e-04 - val_loss: 2.8387e-04\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1135e-04 - val_loss: 2.7462e-04\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1119e-04 - val_loss: 2.6545e-04\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1082e-04 - val_loss: 2.6680e-04\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1168e-04 - val_loss: 2.8935e-04\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0817e-04 - val_loss: 2.6452e-04\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0617e-04 - val_loss: 2.6831e-04\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0457e-04 - val_loss: 2.7042e-04\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0246e-04 - val_loss: 2.7452e-04\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0820e-04 - val_loss: 2.7731e-04\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9912e-04 - val_loss: 2.6125e-04\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0310e-04 - val_loss: 2.6066e-04\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0213e-04 - val_loss: 2.6812e-04\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1348e-04 - val_loss: 2.5936e-04\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0598e-04 - val_loss: 2.8339e-04\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0343e-04 - val_loss: 2.6349e-04\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9556e-04 - val_loss: 2.7145e-04\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9413e-04 - val_loss: 2.5742e-04\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9392e-04 - val_loss: 2.6283e-04\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9114e-04 - val_loss: 2.6283e-04\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9346e-04 - val_loss: 2.8098e-04\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9437e-04 - val_loss: 2.5727e-04\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9038e-04 - val_loss: 2.5551e-04\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8903e-04 - val_loss: 2.5897e-04\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9298e-04 - val_loss: 2.5460e-04\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8886e-04 - val_loss: 2.5440e-04\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8896e-04 - val_loss: 2.5895e-04\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8968e-04 - val_loss: 2.7240e-04\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8680e-04 - val_loss: 2.5678e-04\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8460e-04 - val_loss: 2.5393e-04\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8670e-04 - val_loss: 2.5673e-04\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8196e-04 - val_loss: 2.5174e-04\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8408e-04 - val_loss: 2.5329e-04\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8013e-04 - val_loss: 2.5848e-04\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8155e-04 - val_loss: 2.5630e-04\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.7899e-04 - val_loss: 2.5064e-04\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8277e-04 - val_loss: 2.5238e-04\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.7921e-04 - val_loss: 2.5629e-04\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.7826e-04 - val_loss: 2.5474e-04\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.7737e-04 - val_loss: 2.5537e-04\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8118e-04 - val_loss: 2.4964e-04\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.7629e-04 - val_loss: 2.6165e-04\n",
      "Thời gian huấn luyện:  13.646236181259155\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_75 (Dense)            (None, 10, 96)            192       \n",
      "                                                                 \n",
      " flatten_60 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,153\n",
      "Trainable params: 1,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 1s 8ms/step - loss: 0.0096 - val_loss: 0.0014\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 9.4833e-04\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 7.9748e-04\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 7.5995e-04\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 8.2217e-04\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.6892e-04\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.4171e-04\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.6831e-04\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.7827e-04\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.9070e-04\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 6.2617e-04\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.9111e-04 - val_loss: 5.3320e-04\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.6223e-04 - val_loss: 5.2255e-04\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.1850e-04\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.8257e-04 - val_loss: 5.8079e-04\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.2556e-04 - val_loss: 5.2224e-04\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.1939e-04 - val_loss: 5.6759e-04\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.1607e-04 - val_loss: 4.9693e-04\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.7889e-04 - val_loss: 5.1135e-04\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.7216e-04 - val_loss: 5.0443e-04\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.5329e-04 - val_loss: 4.9599e-04\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.5529e-04 - val_loss: 4.9094e-04\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.4969e-04 - val_loss: 4.6876e-04\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.6249e-04 - val_loss: 4.8616e-04\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.2705e-04 - val_loss: 5.1914e-04\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.3788e-04 - val_loss: 4.7058e-04\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.4741e-04 - val_loss: 4.7016e-04\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.1075e-04 - val_loss: 5.0783e-04\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.8830e-04 - val_loss: 4.9056e-04\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.9864e-04 - val_loss: 4.5158e-04\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.8139e-04 - val_loss: 4.4633e-04\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.8162e-04 - val_loss: 4.3592e-04\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.8763e-04 - val_loss: 5.5718e-04\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.6966e-04 - val_loss: 4.6374e-04\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.5740e-04 - val_loss: 4.3414e-04\n",
      "Epoch 36/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 7.4649e-04 - val_loss: 4.7841e-04\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.5285e-04 - val_loss: 4.1763e-04\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.5092e-04 - val_loss: 4.8526e-04\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.3744e-04 - val_loss: 4.6450e-04\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2409e-04 - val_loss: 4.1650e-04\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2304e-04 - val_loss: 4.1536e-04\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1993e-04 - val_loss: 4.0167e-04\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2593e-04 - val_loss: 3.9754e-04\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.1695e-04 - val_loss: 3.9876e-04\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2350e-04 - val_loss: 3.9864e-04\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.0186e-04 - val_loss: 4.7331e-04\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.9517e-04 - val_loss: 3.8870e-04\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8769e-04 - val_loss: 3.8750e-04\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.1815e-04 - val_loss: 4.1629e-04\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0019e-04 - val_loss: 3.8245e-04\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8224e-04 - val_loss: 4.1911e-04\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8414e-04 - val_loss: 3.8949e-04\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6747e-04 - val_loss: 3.7586e-04\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6700e-04 - val_loss: 3.6886e-04\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.7391e-04 - val_loss: 3.7320e-04\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.9685e-04 - val_loss: 4.8212e-04\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.4122e-04 - val_loss: 4.2121e-04\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5588e-04 - val_loss: 3.9741e-04\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4685e-04 - val_loss: 4.2570e-04\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4986e-04 - val_loss: 4.0418e-04\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4095e-04 - val_loss: 3.5328e-04\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3627e-04 - val_loss: 3.5415e-04\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5341e-04 - val_loss: 3.7533e-04\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8099e-04 - val_loss: 3.5435e-04\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3409e-04 - val_loss: 3.7316e-04\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2534e-04 - val_loss: 3.5643e-04\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2802e-04 - val_loss: 3.4237e-04\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4148e-04 - val_loss: 4.0852e-04\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3634e-04 - val_loss: 5.0361e-04\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4223e-04 - val_loss: 3.5999e-04\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1054e-04 - val_loss: 3.3455e-04\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1271e-04 - val_loss: 3.3358e-04\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1182e-04 - val_loss: 3.6169e-04\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9210e-04 - val_loss: 3.3371e-04\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0967e-04 - val_loss: 3.3751e-04\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0419e-04 - val_loss: 3.4617e-04\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3023e-04 - val_loss: 3.3061e-04\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0441e-04 - val_loss: 3.7363e-04\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9047e-04 - val_loss: 3.4953e-04\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8632e-04 - val_loss: 3.2071e-04\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3398e-04 - val_loss: 3.2080e-04\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8391e-04 - val_loss: 3.4392e-04\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2774e-04 - val_loss: 3.2665e-04\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7878e-04 - val_loss: 3.1588e-04\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6560e-04 - val_loss: 3.3619e-04\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6493e-04 - val_loss: 3.4443e-04\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8518e-04 - val_loss: 3.0810e-04\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6740e-04 - val_loss: 3.0712e-04\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6563e-04 - val_loss: 3.1858e-04\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6401e-04 - val_loss: 5.9180e-04\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0034e-04 - val_loss: 3.0353e-04\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6670e-04 - val_loss: 3.3817e-04\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6689e-04 - val_loss: 3.0528e-04\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6087e-04 - val_loss: 3.2573e-04\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4711e-04 - val_loss: 2.9905e-04\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4767e-04 - val_loss: 3.0698e-04\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5519e-04 - val_loss: 2.9525e-04\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7591e-04 - val_loss: 3.4235e-04\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3487e-04 - val_loss: 3.0073e-04\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4620e-04 - val_loss: 3.0111e-04\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4655e-04 - val_loss: 4.3777e-04\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7906e-04 - val_loss: 2.8843e-04\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2762e-04 - val_loss: 3.0593e-04\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2449e-04 - val_loss: 2.8585e-04\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3008e-04 - val_loss: 3.0684e-04\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3457e-04 - val_loss: 2.8526e-04\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4507e-04 - val_loss: 2.8216e-04\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3338e-04 - val_loss: 2.8029e-04\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2411e-04 - val_loss: 2.9318e-04\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1238e-04 - val_loss: 2.7954e-04\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1394e-04 - val_loss: 2.9270e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2264e-04 - val_loss: 2.7711e-04\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2110e-04 - val_loss: 2.8204e-04\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2723e-04 - val_loss: 3.3373e-04\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0379e-04 - val_loss: 3.3089e-04\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1174e-04 - val_loss: 2.7316e-04\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0610e-04 - val_loss: 2.7149e-04\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2171e-04 - val_loss: 2.8009e-04\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9771e-04 - val_loss: 2.9873e-04\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0255e-04 - val_loss: 2.9942e-04\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1648e-04 - val_loss: 2.6977e-04\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9337e-04 - val_loss: 2.6711e-04\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0251e-04 - val_loss: 2.7931e-04\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9523e-04 - val_loss: 2.7620e-04\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9717e-04 - val_loss: 2.7715e-04\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1562e-04 - val_loss: 2.6193e-04\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9400e-04 - val_loss: 2.6298e-04\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1174e-04 - val_loss: 2.7111e-04\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9877e-04 - val_loss: 2.6480e-04\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8680e-04 - val_loss: 2.6019e-04\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1089e-04 - val_loss: 2.5891e-04\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8539e-04 - val_loss: 3.6658e-04\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2957e-04 - val_loss: 2.6699e-04\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8381e-04 - val_loss: 2.6013e-04\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8122e-04 - val_loss: 2.6687e-04\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7552e-04 - val_loss: 2.5841e-04\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7296e-04 - val_loss: 3.2224e-04\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0143e-04 - val_loss: 2.5149e-04\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8572e-04 - val_loss: 2.8373e-04\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7645e-04 - val_loss: 2.7674e-04\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8357e-04 - val_loss: 2.4973e-04\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7262e-04 - val_loss: 2.5255e-04\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6395e-04 - val_loss: 2.5779e-04\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7461e-04 - val_loss: 2.4743e-04\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7213e-04 - val_loss: 2.4622e-04\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6453e-04 - val_loss: 2.7785e-04\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7822e-04 - val_loss: 2.6397e-04\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7963e-04 - val_loss: 2.5585e-04\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6591e-04 - val_loss: 2.7499e-04\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6634e-04 - val_loss: 2.4391e-04\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7319e-04 - val_loss: 2.7352e-04\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8906e-04 - val_loss: 2.5622e-04\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7990e-04 - val_loss: 2.4278e-04\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7220e-04 - val_loss: 2.6319e-04\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7201e-04 - val_loss: 2.4107e-04\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5275e-04 - val_loss: 2.5763e-04\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6138e-04 - val_loss: 2.5854e-04\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7818e-04 - val_loss: 2.4182e-04\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7377e-04 - val_loss: 2.7437e-04\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6082e-04 - val_loss: 2.4352e-04\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6150e-04 - val_loss: 3.3986e-04\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6420e-04 - val_loss: 2.6480e-04\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6371e-04 - val_loss: 2.3661e-04\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9218e-04 - val_loss: 2.4062e-04\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.5871e-04 - val_loss: 2.3425e-04\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5857e-04 - val_loss: 2.3534e-04\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6162e-04 - val_loss: 2.4347e-04\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4605e-04 - val_loss: 2.4663e-04\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5215e-04 - val_loss: 2.3358e-04\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5575e-04 - val_loss: 2.3466e-04\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5786e-04 - val_loss: 2.3554e-04\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5936e-04 - val_loss: 2.5012e-04\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4502e-04 - val_loss: 2.6878e-04\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4785e-04 - val_loss: 2.4561e-04\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7315e-04 - val_loss: 2.5049e-04\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5412e-04 - val_loss: 2.2976e-04\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5699e-04 - val_loss: 2.3472e-04\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3911e-04 - val_loss: 2.3794e-04\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5842e-04 - val_loss: 2.4014e-04\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4925e-04 - val_loss: 2.3158e-04\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6219e-04 - val_loss: 3.1015e-04\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4154e-04 - val_loss: 2.2645e-04\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3783e-04 - val_loss: 2.2985e-04\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4787e-04 - val_loss: 2.2630e-04\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4436e-04 - val_loss: 2.4026e-04\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4721e-04 - val_loss: 2.4355e-04\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4200e-04 - val_loss: 2.2827e-04\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4348e-04 - val_loss: 2.3863e-04\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4513e-04 - val_loss: 2.2509e-04\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3348e-04 - val_loss: 2.3012e-04\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4094e-04 - val_loss: 2.3278e-04\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4430e-04 - val_loss: 2.4683e-04\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4965e-04 - val_loss: 2.3367e-04\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3612e-04 - val_loss: 2.2276e-04\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5238e-04 - val_loss: 2.5696e-04\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7005e-04 - val_loss: 2.6738e-04\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3945e-04 - val_loss: 2.6066e-04\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4048e-04 - val_loss: 2.3407e-04\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3536e-04 - val_loss: 2.2170e-04\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.2961e-04 - val_loss: 2.2377e-04\n",
      "Thời gian huấn luyện:  21.374991416931152\n",
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_15 (SimpleRNN)   (None, 10, 96)            9408      \n",
      "                                                                 \n",
      " flatten_61 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,369\n",
      "Trainable params: 10,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 2s 29ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 140/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Thời gian huấn luyện:  44.458821296691895\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_15 (LSTM)              (None, 10, 96)            37632     \n",
      "                                                                 \n",
      " flatten_62 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,593\n",
      "Trainable params: 38,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 2s 16ms/step - loss: 0.0108 - val_loss: 0.0012\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 9.6571e-04\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 9.8306e-04\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 9.0140e-04\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 8.8504e-04\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 8.8431e-04\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 8.6763e-04\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.8772e-04\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.4647e-04\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 7.7141e-04\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 8.1612e-04\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 7.4449e-04\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 7.2018e-04\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 8.9244e-04\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 7.3024e-04\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 7.5157e-04\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.7674e-04\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.7380e-04\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.2445e-04\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 7.3603e-04\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.1390e-04\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.9471e-04\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.8453e-04\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.9374e-04\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.4293e-04\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.8895e-04\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.8127e-04 - val_loss: 5.2081e-04\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.8222e-04 - val_loss: 5.6738e-04\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.4656e-04 - val_loss: 5.1081e-04\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.2044e-04 - val_loss: 4.9804e-04\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.2183e-04 - val_loss: 5.2252e-04\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.9824e-04 - val_loss: 5.0779e-04\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.9125e-04 - val_loss: 5.3582e-04\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.8216e-04 - val_loss: 4.9283e-04\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.7077e-04 - val_loss: 5.2446e-04\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.6220e-04 - val_loss: 4.9185e-04\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.5513e-04 - val_loss: 4.7887e-04\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.4858e-04 - val_loss: 4.6301e-04\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.4280e-04 - val_loss: 4.8322e-04\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.3032e-04 - val_loss: 4.6570e-04\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.2015e-04 - val_loss: 4.4670e-04\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.4176e-04 - val_loss: 5.0092e-04\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.1814e-04 - val_loss: 4.5378e-04\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.9923e-04 - val_loss: 4.3622e-04\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.0841e-04 - val_loss: 4.7790e-04\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.9261e-04 - val_loss: 4.4041e-04\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.8327e-04 - val_loss: 5.1675e-04\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.9949e-04 - val_loss: 4.2426e-04\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.9741e-04 - val_loss: 4.6183e-04\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.7049e-04 - val_loss: 4.2836e-04\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.0746e-04 - val_loss: 5.0591e-04\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.8968e-04 - val_loss: 4.2023e-04\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.5002e-04 - val_loss: 4.1227e-04\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.4793e-04 - val_loss: 4.1264e-04\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.4395e-04 - val_loss: 4.1367e-04\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.3505e-04 - val_loss: 4.0366e-04\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.4078e-04 - val_loss: 4.9951e-04\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.3516e-04 - val_loss: 4.0431e-04\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.2111e-04 - val_loss: 3.9799e-04\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.1534e-04 - val_loss: 3.9582e-04\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.3120e-04 - val_loss: 3.9196e-04\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.2151e-04 - val_loss: 4.1223e-04\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.9967e-04 - val_loss: 4.3976e-04\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.0356e-04 - val_loss: 3.8558e-04\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.0850e-04 - val_loss: 3.9650e-04\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.0618e-04 - val_loss: 3.8100e-04\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.0654e-04 - val_loss: 4.2097e-04\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.8197e-04 - val_loss: 4.6496e-04\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.8079e-04 - val_loss: 3.7542e-04\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.7048e-04 - val_loss: 3.9378e-04\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.7702e-04 - val_loss: 4.1250e-04\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.7020e-04 - val_loss: 3.7427e-04\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.6467e-04 - val_loss: 4.2707e-04\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.6680e-04 - val_loss: 3.7468e-04\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.7166e-04 - val_loss: 3.6700e-04\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.6053e-04 - val_loss: 3.8146e-04\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.5627e-04 - val_loss: 4.1136e-04\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.5773e-04 - val_loss: 3.5862e-04\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.4734e-04 - val_loss: 3.9943e-04\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.4660e-04 - val_loss: 3.9814e-04\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.4145e-04 - val_loss: 3.5684e-04\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.2888e-04 - val_loss: 4.1027e-04\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.4107e-04 - val_loss: 3.5425e-04\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.3225e-04 - val_loss: 3.6595e-04\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.3873e-04 - val_loss: 3.4704e-04\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.3178e-04 - val_loss: 3.4792e-04\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.2690e-04 - val_loss: 3.7133e-04\n",
      "Epoch 88/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 6ms/step - loss: 6.2770e-04 - val_loss: 3.4613e-04\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.2407e-04 - val_loss: 3.4777e-04\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.1555e-04 - val_loss: 3.4667e-04\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.1828e-04 - val_loss: 3.5053e-04\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.0655e-04 - val_loss: 3.4115e-04\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.0018e-04 - val_loss: 3.4292e-04\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.0159e-04 - val_loss: 3.4210e-04\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.0425e-04 - val_loss: 4.0199e-04\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.9670e-04 - val_loss: 3.3332e-04\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.9312e-04 - val_loss: 3.3651e-04\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.8852e-04 - val_loss: 3.3251e-04\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.9307e-04 - val_loss: 3.7612e-04\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.9189e-04 - val_loss: 3.2705e-04\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.8208e-04 - val_loss: 3.6620e-04\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.7890e-04 - val_loss: 3.5808e-04\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.7901e-04 - val_loss: 3.2560e-04\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.7747e-04 - val_loss: 3.5525e-04\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.9739e-04 - val_loss: 3.2828e-04\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.8028e-04 - val_loss: 3.3674e-04\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.7413e-04 - val_loss: 3.2340e-04\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.7246e-04 - val_loss: 3.5300e-04\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.6688e-04 - val_loss: 3.4103e-04\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.6447e-04 - val_loss: 3.1519e-04\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.6479e-04 - val_loss: 3.1472e-04\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.6134e-04 - val_loss: 3.3090e-04\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.6208e-04 - val_loss: 3.3337e-04\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.6952e-04 - val_loss: 3.4002e-04\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.5773e-04 - val_loss: 3.3782e-04\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.5408e-04 - val_loss: 3.1095e-04\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.5481e-04 - val_loss: 3.0744e-04\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.6255e-04 - val_loss: 3.1541e-04\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.6354e-04 - val_loss: 3.0866e-04\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.4560e-04 - val_loss: 3.1120e-04\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.8318e-04 - val_loss: 3.5391e-04\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.5389e-04 - val_loss: 3.8279e-04\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.6094e-04 - val_loss: 3.0279e-04\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.4373e-04 - val_loss: 3.3263e-04\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.4761e-04 - val_loss: 2.9825e-04\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.3752e-04 - val_loss: 3.2052e-04\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.3689e-04 - val_loss: 3.1308e-04\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.4259e-04 - val_loss: 3.4162e-04\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.3849e-04 - val_loss: 3.0015e-04\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.3474e-04 - val_loss: 3.5142e-04\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.5650e-04 - val_loss: 3.0039e-04\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.2583e-04 - val_loss: 3.0564e-04\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.2863e-04 - val_loss: 3.2113e-04\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.2115e-04 - val_loss: 3.0179e-04\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.2355e-04 - val_loss: 2.8730e-04\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.2329e-04 - val_loss: 2.9339e-04\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.1950e-04 - val_loss: 2.9772e-04\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.1619e-04 - val_loss: 2.8564e-04\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.1641e-04 - val_loss: 2.8336e-04\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.1503e-04 - val_loss: 2.8197e-04\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.1531e-04 - val_loss: 2.8470e-04\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.1247e-04 - val_loss: 2.7969e-04\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.1109e-04 - val_loss: 2.7877e-04\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.1954e-04 - val_loss: 2.7994e-04\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.0219e-04 - val_loss: 2.8511e-04\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.0365e-04 - val_loss: 2.7618e-04\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.0780e-04 - val_loss: 2.7739e-04\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.3500e-04 - val_loss: 2.9189e-04\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.0094e-04 - val_loss: 2.8411e-04\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.0011e-04 - val_loss: 2.7823e-04\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.9772e-04 - val_loss: 2.7124e-04\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.9196e-04 - val_loss: 2.7132e-04\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.9438e-04 - val_loss: 2.7350e-04\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.9503e-04 - val_loss: 2.7029e-04\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.9670e-04 - val_loss: 2.7556e-04\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.9671e-04 - val_loss: 3.0326e-04\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.0200e-04 - val_loss: 2.6755e-04\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.9202e-04 - val_loss: 2.6595e-04\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.8863e-04 - val_loss: 2.6424e-04\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.1613e-04 - val_loss: 3.6474e-04\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.0650e-04 - val_loss: 2.9116e-04\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.0189e-04 - val_loss: 3.0174e-04\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 4.9726e-04 - val_loss: 2.7765e-04\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.8941e-04 - val_loss: 2.8645e-04\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.9305e-04 - val_loss: 2.7157e-04\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.9483e-04 - val_loss: 2.6457e-04\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.9561e-04 - val_loss: 2.5881e-04\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.8804e-04 - val_loss: 2.6450e-04\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.7265e-04 - val_loss: 2.7101e-04\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.8995e-04 - val_loss: 2.5759e-04\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.7985e-04 - val_loss: 2.9354e-04\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.7848e-04 - val_loss: 3.0298e-04\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.9102e-04 - val_loss: 3.3544e-04\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.0328e-04 - val_loss: 2.5578e-04\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.7474e-04 - val_loss: 2.5742e-04\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.8127e-04 - val_loss: 2.5286e-04\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.7164e-04 - val_loss: 2.7169e-04\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.6630e-04 - val_loss: 2.5662e-04\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.7860e-04 - val_loss: 2.5118e-04\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.7205e-04 - val_loss: 2.5026e-04\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.7241e-04 - val_loss: 2.4984e-04\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.6676e-04 - val_loss: 2.7206e-04\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.6902e-04 - val_loss: 2.6600e-04\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.6163e-04 - val_loss: 2.9895e-04\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.6480e-04 - val_loss: 2.4694e-04\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.6268e-04 - val_loss: 2.4661e-04\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.6035e-04 - val_loss: 2.5626e-04\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.5839e-04 - val_loss: 2.5349e-04\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.6044e-04 - val_loss: 2.5028e-04\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.6221e-04 - val_loss: 2.4498e-04\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.7158e-04 - val_loss: 2.4895e-04\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.7178e-04 - val_loss: 2.4803e-04\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.6033e-04 - val_loss: 2.4495e-04\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.5590e-04 - val_loss: 2.5387e-04\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.5925e-04 - val_loss: 2.5454e-04\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.5932e-04 - val_loss: 2.4584e-04\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.7504e-04 - val_loss: 2.4059e-04\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.5518e-04 - val_loss: 2.7151e-04\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.6659e-04 - val_loss: 2.5419e-04\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.6207e-04 - val_loss: 2.6636e-04\n",
      "Thời gian huấn luyện:  43.007333278656006\n",
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_15 (GRU)                (None, 10, 96)            28512     \n",
      "                                                                 \n",
      " flatten_63 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,473\n",
      "Trainable params: 29,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "35/35 [==============================] - 0s 912us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.0482 - val_loss: 0.0021\n",
      "Epoch 2/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0025\n",
      "Epoch 3/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0019\n",
      "Epoch 4/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0019\n",
      "Epoch 5/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0017\n",
      "Epoch 6/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0016\n",
      "Epoch 7/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 8/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 9/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 10/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 11/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 12/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 9.8776e-04\n",
      "Epoch 13/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 9.0709e-04\n",
      "Epoch 14/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 8.8303e-04\n",
      "Epoch 15/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 8.9343e-04\n",
      "Epoch 16/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 8.4673e-04\n",
      "Epoch 17/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 7.7424e-04\n",
      "Epoch 18/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 7.7179e-04\n",
      "Epoch 19/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 7.3104e-04\n",
      "Epoch 20/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 7.3778e-04\n",
      "Epoch 21/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 6.8693e-04\n",
      "Epoch 22/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.4308e-04\n",
      "Epoch 23/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.0869e-04\n",
      "Epoch 24/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 6.6424e-04\n",
      "Epoch 25/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.2057e-04\n",
      "Epoch 26/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 6.7814e-04\n",
      "Epoch 27/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 6.8043e-04\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.8288e-04\n",
      "Epoch 29/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.5770e-04\n",
      "Epoch 30/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.4244e-04\n",
      "Epoch 31/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.8020e-04\n",
      "Epoch 32/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.6750e-04\n",
      "Epoch 33/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.4755e-04\n",
      "Epoch 34/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.1588e-04\n",
      "Epoch 35/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.3496e-04\n",
      "Epoch 36/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.3580e-04\n",
      "Epoch 37/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.2007e-04\n",
      "Epoch 38/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.6540e-04\n",
      "Epoch 39/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.1117e-04\n",
      "Epoch 40/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.0260e-04\n",
      "Epoch 41/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.0214e-04\n",
      "Epoch 42/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.1834e-04\n",
      "Epoch 43/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.0728e-04\n",
      "Epoch 44/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.8093e-04\n",
      "Epoch 45/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.8764e-04\n",
      "Epoch 46/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.7786e-04\n",
      "Epoch 47/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.9657e-04\n",
      "Epoch 48/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.6348e-04\n",
      "Epoch 49/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.8672e-04\n",
      "Epoch 50/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.6331e-04\n",
      "Epoch 51/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.7509e-04\n",
      "Epoch 52/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.4921e-04\n",
      "Epoch 53/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.4727e-04\n",
      "Epoch 54/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.4984e-04\n",
      "Epoch 55/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.4495e-04\n",
      "Epoch 56/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.3772e-04\n",
      "Epoch 57/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.2651e-04\n",
      "Epoch 58/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.3070e-04\n",
      "Epoch 59/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.5178e-04\n",
      "Epoch 60/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.1770e-04\n",
      "Epoch 61/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.7838e-04\n",
      "Epoch 62/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.0578e-04\n",
      "Epoch 63/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.9894e-04 - val_loss: 4.9155e-04\n",
      "Epoch 64/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 4.8483e-04\n",
      "Epoch 65/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.8854e-04 - val_loss: 4.9260e-04\n",
      "Epoch 66/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.7269e-04 - val_loss: 4.9543e-04\n",
      "Epoch 67/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.6715e-04 - val_loss: 4.9754e-04\n",
      "Epoch 68/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.5801e-04 - val_loss: 4.7433e-04\n",
      "Epoch 69/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.4961e-04 - val_loss: 4.8560e-04\n",
      "Epoch 70/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.4057e-04 - val_loss: 4.9011e-04\n",
      "Epoch 71/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.3492e-04 - val_loss: 4.7145e-04\n",
      "Epoch 72/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.2986e-04 - val_loss: 4.5509e-04\n",
      "Epoch 73/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.1384e-04 - val_loss: 4.7425e-04\n",
      "Epoch 74/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.0816e-04 - val_loss: 4.5524e-04\n",
      "Epoch 75/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.0295e-04 - val_loss: 4.5921e-04\n",
      "Epoch 76/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.9573e-04 - val_loss: 4.8903e-04\n",
      "Epoch 77/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.8747e-04 - val_loss: 4.5990e-04\n",
      "Epoch 78/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.8072e-04 - val_loss: 4.5853e-04\n",
      "Epoch 79/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.7113e-04 - val_loss: 4.3122e-04\n",
      "Epoch 80/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.6603e-04 - val_loss: 4.2891e-04\n",
      "Epoch 81/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.5508e-04 - val_loss: 4.3244e-04\n",
      "Epoch 82/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.4648e-04 - val_loss: 4.5544e-04\n",
      "Epoch 83/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.4624e-04 - val_loss: 4.2555e-04\n",
      "Epoch 84/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.3616e-04 - val_loss: 4.3428e-04\n",
      "Epoch 85/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.2580e-04 - val_loss: 4.1914e-04\n",
      "Epoch 86/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.2092e-04 - val_loss: 4.1059e-04\n",
      "Epoch 87/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.1329e-04 - val_loss: 4.6046e-04\n",
      "Epoch 88/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.0705e-04 - val_loss: 4.1010e-04\n",
      "Epoch 89/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.0135e-04 - val_loss: 3.9632e-04\n",
      "Epoch 90/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.9348e-04 - val_loss: 4.1429e-04\n",
      "Epoch 91/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.8693e-04 - val_loss: 3.9319e-04\n",
      "Epoch 92/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.8469e-04 - val_loss: 4.1105e-04\n",
      "Epoch 93/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.7535e-04 - val_loss: 4.0183e-04\n",
      "Epoch 94/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.7071e-04 - val_loss: 3.8381e-04\n",
      "Epoch 95/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.7120e-04 - val_loss: 3.7999e-04\n",
      "Epoch 96/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.5694e-04 - val_loss: 3.8555e-04\n",
      "Epoch 97/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.5418e-04 - val_loss: 3.7486e-04\n",
      "Epoch 98/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.5151e-04 - val_loss: 3.9004e-04\n",
      "Epoch 99/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.4185e-04 - val_loss: 3.8899e-04\n",
      "Epoch 100/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.3584e-04 - val_loss: 3.9081e-04\n",
      "Epoch 101/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.3193e-04 - val_loss: 3.7499e-04\n",
      "Epoch 102/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.2630e-04 - val_loss: 3.7103e-04\n",
      "Epoch 103/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.2144e-04 - val_loss: 3.7468e-04\n",
      "Epoch 104/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.1488e-04 - val_loss: 3.6643e-04\n",
      "Epoch 105/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 2ms/step - loss: 7.1179e-04 - val_loss: 3.6459e-04\n",
      "Epoch 106/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.0503e-04 - val_loss: 3.6736e-04\n",
      "Epoch 107/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.0087e-04 - val_loss: 3.8456e-04\n",
      "Epoch 108/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.0291e-04 - val_loss: 3.7077e-04\n",
      "Epoch 109/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.9940e-04 - val_loss: 3.9210e-04\n",
      "Epoch 110/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.8633e-04 - val_loss: 3.5356e-04\n",
      "Epoch 111/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.8680e-04 - val_loss: 4.2644e-04\n",
      "Epoch 112/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.8419e-04 - val_loss: 3.5185e-04\n",
      "Epoch 113/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.7474e-04 - val_loss: 3.4376e-04\n",
      "Epoch 114/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.7353e-04 - val_loss: 3.3823e-04\n",
      "Epoch 115/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.6826e-04 - val_loss: 3.4851e-04\n",
      "Epoch 116/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.6480e-04 - val_loss: 3.3697e-04\n",
      "Epoch 117/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.6544e-04 - val_loss: 3.6570e-04\n",
      "Epoch 118/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.5513e-04 - val_loss: 3.4205e-04\n",
      "Epoch 119/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.5183e-04 - val_loss: 3.3890e-04\n",
      "Epoch 120/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.4854e-04 - val_loss: 3.3526e-04\n",
      "Epoch 121/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.4425e-04 - val_loss: 3.3913e-04\n",
      "Epoch 122/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.4403e-04 - val_loss: 3.4141e-04\n",
      "Epoch 123/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.3769e-04 - val_loss: 3.4461e-04\n",
      "Epoch 124/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.3995e-04 - val_loss: 3.5773e-04\n",
      "Epoch 125/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.3744e-04 - val_loss: 3.5533e-04\n",
      "Epoch 126/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.2927e-04 - val_loss: 3.1925e-04\n",
      "Epoch 127/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.3182e-04 - val_loss: 3.2663e-04\n",
      "Epoch 128/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.2321e-04 - val_loss: 3.1808e-04\n",
      "Epoch 129/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.2129e-04 - val_loss: 3.2449e-04\n",
      "Epoch 130/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.1813e-04 - val_loss: 3.2055e-04\n",
      "Epoch 131/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.1685e-04 - val_loss: 3.1240e-04\n",
      "Epoch 132/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.2455e-04 - val_loss: 3.1221e-04\n",
      "Epoch 133/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.1531e-04 - val_loss: 3.3893e-04\n",
      "Epoch 134/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.1161e-04 - val_loss: 3.1793e-04\n",
      "Epoch 135/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.0502e-04 - val_loss: 3.1047e-04\n",
      "Epoch 136/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.0189e-04 - val_loss: 3.2282e-04\n",
      "Epoch 137/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.9976e-04 - val_loss: 3.1223e-04\n",
      "Epoch 138/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.9879e-04 - val_loss: 3.4529e-04\n",
      "Epoch 139/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.0237e-04 - val_loss: 3.2355e-04\n",
      "Epoch 140/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.9645e-04 - val_loss: 3.1052e-04\n",
      "Epoch 141/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.9158e-04 - val_loss: 3.0373e-04\n",
      "Epoch 142/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.9031e-04 - val_loss: 3.0527e-04\n",
      "Epoch 143/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.8717e-04 - val_loss: 3.1034e-04\n",
      "Epoch 144/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.8707e-04 - val_loss: 3.0490e-04\n",
      "Epoch 145/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.8296e-04 - val_loss: 2.9933e-04\n",
      "Epoch 146/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.8252e-04 - val_loss: 2.9834e-04\n",
      "Epoch 147/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.8388e-04 - val_loss: 2.9865e-04\n",
      "Epoch 148/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.8721e-04 - val_loss: 2.9890e-04\n",
      "Epoch 149/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.7739e-04 - val_loss: 2.9697e-04\n",
      "Epoch 150/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.7511e-04 - val_loss: 2.9586e-04\n",
      "Epoch 151/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.7367e-04 - val_loss: 3.0943e-04\n",
      "Epoch 152/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.6930e-04 - val_loss: 3.0118e-04\n",
      "Epoch 153/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.6954e-04 - val_loss: 2.9893e-04\n",
      "Epoch 154/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.6824e-04 - val_loss: 2.9541e-04\n",
      "Epoch 155/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.6528e-04 - val_loss: 2.9777e-04\n",
      "Epoch 156/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.6456e-04 - val_loss: 2.9032e-04\n",
      "Epoch 157/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.7291e-04 - val_loss: 2.9577e-04\n",
      "Epoch 158/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.7133e-04 - val_loss: 2.8991e-04\n",
      "Epoch 159/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.6778e-04 - val_loss: 3.0220e-04\n",
      "Epoch 160/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.6049e-04 - val_loss: 2.9884e-04\n",
      "Epoch 161/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.6313e-04 - val_loss: 2.9596e-04\n",
      "Epoch 162/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.5595e-04 - val_loss: 2.9403e-04\n",
      "Epoch 163/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.5235e-04 - val_loss: 3.1395e-04\n",
      "Epoch 164/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.6049e-04 - val_loss: 2.9382e-04\n",
      "Epoch 165/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.5530e-04 - val_loss: 3.0523e-04\n",
      "Epoch 166/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.5263e-04 - val_loss: 2.8511e-04\n",
      "Epoch 167/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.4890e-04 - val_loss: 2.9206e-04\n",
      "Epoch 168/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.4335e-04 - val_loss: 3.2886e-04\n",
      "Epoch 169/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.5025e-04 - val_loss: 3.0674e-04\n",
      "Epoch 170/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.4920e-04 - val_loss: 2.8829e-04\n",
      "Epoch 171/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.4283e-04 - val_loss: 2.8562e-04\n",
      "Epoch 172/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.4652e-04 - val_loss: 2.9358e-04\n",
      "Epoch 173/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.4389e-04 - val_loss: 2.7997e-04\n",
      "Epoch 174/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.3474e-04 - val_loss: 3.1273e-04\n",
      "Epoch 175/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.3951e-04 - val_loss: 2.8396e-04\n",
      "Epoch 176/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.3654e-04 - val_loss: 2.8064e-04\n",
      "Epoch 177/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.3735e-04 - val_loss: 2.7841e-04\n",
      "Epoch 178/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.3443e-04 - val_loss: 2.7795e-04\n",
      "Epoch 179/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.4006e-04 - val_loss: 2.7715e-04\n",
      "Epoch 180/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 2ms/step - loss: 5.3627e-04 - val_loss: 2.7805e-04\n",
      "Epoch 181/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.3779e-04 - val_loss: 2.7608e-04\n",
      "Epoch 182/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.2967e-04 - val_loss: 2.8018e-04\n",
      "Epoch 183/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.3055e-04 - val_loss: 2.7656e-04\n",
      "Epoch 184/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.3039e-04 - val_loss: 2.7755e-04\n",
      "Epoch 185/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.2777e-04 - val_loss: 2.7467e-04\n",
      "Epoch 186/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.2433e-04 - val_loss: 3.0055e-04\n",
      "Epoch 187/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.2621e-04 - val_loss: 2.8015e-04\n",
      "Epoch 188/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.2589e-04 - val_loss: 2.7929e-04\n",
      "Epoch 189/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.2335e-04 - val_loss: 2.8764e-04\n",
      "Epoch 190/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.2252e-04 - val_loss: 2.8622e-04\n",
      "Epoch 191/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.1929e-04 - val_loss: 2.7219e-04\n",
      "Epoch 192/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.2050e-04 - val_loss: 2.7711e-04\n",
      "Epoch 193/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.2301e-04 - val_loss: 2.7108e-04\n",
      "Epoch 194/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.1449e-04 - val_loss: 2.8003e-04\n",
      "Epoch 195/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.1897e-04 - val_loss: 2.8633e-04\n",
      "Epoch 196/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.1773e-04 - val_loss: 2.7331e-04\n",
      "Epoch 197/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.2145e-04 - val_loss: 2.7242e-04\n",
      "Epoch 198/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.1274e-04 - val_loss: 2.8524e-04\n",
      "Epoch 199/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.1371e-04 - val_loss: 2.9553e-04\n",
      "Epoch 200/200\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.1612e-04 - val_loss: 2.8501e-04\n",
      "Thời gian huấn luyện:  13.295851469039917\n",
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_80 (Dense)            (None, 10, 96)            192       \n",
      "                                                                 \n",
      " flatten_64 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,153\n",
      "Trainable params: 1,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "30/30 [==============================] - 1s 8ms/step - loss: 0.0174 - val_loss: 0.0029\n",
      "Epoch 2/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 7.6924e-04\n",
      "Epoch 3/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 7.6851e-04\n",
      "Epoch 4/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 8.3985e-04\n",
      "Epoch 5/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 6.6088e-04\n",
      "Epoch 6/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.8670e-04\n",
      "Epoch 7/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.7854e-04\n",
      "Epoch 8/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.6046e-04\n",
      "Epoch 9/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.5542e-04\n",
      "Epoch 10/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.3445e-04\n",
      "Epoch 11/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.7736e-04 - val_loss: 6.2268e-04\n",
      "Epoch 12/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.6133e-04 - val_loss: 4.8323e-04\n",
      "Epoch 13/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.3570e-04 - val_loss: 4.9176e-04\n",
      "Epoch 14/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.2227e-04 - val_loss: 4.7863e-04\n",
      "Epoch 15/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.9440e-04 - val_loss: 4.7925e-04\n",
      "Epoch 16/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.7776e-04 - val_loss: 4.6652e-04\n",
      "Epoch 17/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.7685e-04 - val_loss: 5.3971e-04\n",
      "Epoch 18/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.6560e-04 - val_loss: 4.7060e-04\n",
      "Epoch 19/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.3901e-04 - val_loss: 4.6871e-04\n",
      "Epoch 20/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.3884e-04 - val_loss: 4.6329e-04\n",
      "Epoch 21/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.1648e-04 - val_loss: 4.5461e-04\n",
      "Epoch 22/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.0847e-04 - val_loss: 4.3471e-04\n",
      "Epoch 23/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.8934e-04 - val_loss: 4.1053e-04\n",
      "Epoch 24/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.2916e-04 - val_loss: 4.1920e-04\n",
      "Epoch 25/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.7246e-04 - val_loss: 4.1994e-04\n",
      "Epoch 26/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.6767e-04 - val_loss: 4.0782e-04\n",
      "Epoch 27/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.6096e-04 - val_loss: 4.8608e-04\n",
      "Epoch 28/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 7.6106e-04 - val_loss: 4.6646e-04\n",
      "Epoch 29/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.6062e-04 - val_loss: 3.9185e-04\n",
      "Epoch 30/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.3592e-04 - val_loss: 4.0755e-04\n",
      "Epoch 31/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.3880e-04 - val_loss: 3.8319e-04\n",
      "Epoch 32/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.3965e-04 - val_loss: 4.0224e-04\n",
      "Epoch 33/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.1365e-04 - val_loss: 4.2446e-04\n",
      "Epoch 34/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.0004e-04 - val_loss: 3.8112e-04\n",
      "Epoch 35/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.0141e-04 - val_loss: 4.2407e-04\n",
      "Epoch 36/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.9863e-04 - val_loss: 4.8700e-04\n",
      "Epoch 37/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.0037e-04 - val_loss: 3.7593e-04\n",
      "Epoch 38/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.9239e-04 - val_loss: 3.7341e-04\n",
      "Epoch 39/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.7553e-04 - val_loss: 3.9154e-04\n",
      "Epoch 40/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.6728e-04 - val_loss: 3.5164e-04\n",
      "Epoch 41/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.6976e-04 - val_loss: 4.1900e-04\n",
      "Epoch 42/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.6006e-04 - val_loss: 3.4766e-04\n",
      "Epoch 43/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.1016e-04 - val_loss: 3.7583e-04\n",
      "Epoch 44/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.5461e-04 - val_loss: 3.7754e-04\n",
      "Epoch 45/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.6517e-04 - val_loss: 4.4032e-04\n",
      "Epoch 46/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.6883e-04 - val_loss: 3.9793e-04\n",
      "Epoch 47/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.2702e-04 - val_loss: 3.3729e-04\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 3ms/step - loss: 6.7912e-04 - val_loss: 3.4239e-04\n",
      "Epoch 49/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.5055e-04 - val_loss: 3.4003e-04\n",
      "Epoch 50/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.3882e-04 - val_loss: 3.3189e-04\n",
      "Epoch 51/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.4214e-04 - val_loss: 3.2989e-04\n",
      "Epoch 52/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.2267e-04 - val_loss: 3.4541e-04\n",
      "Epoch 53/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.1352e-04 - val_loss: 3.4183e-04\n",
      "Epoch 54/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.1304e-04 - val_loss: 3.3620e-04\n",
      "Epoch 55/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.1120e-04 - val_loss: 3.2533e-04\n",
      "Epoch 56/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.0622e-04 - val_loss: 3.2236e-04\n",
      "Epoch 57/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.1972e-04 - val_loss: 3.2243e-04\n",
      "Epoch 58/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.0855e-04 - val_loss: 3.2010e-04\n",
      "Epoch 59/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.0387e-04 - val_loss: 3.2506e-04\n",
      "Epoch 60/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.4511e-04 - val_loss: 3.2284e-04\n",
      "Epoch 61/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.9827e-04 - val_loss: 3.1950e-04\n",
      "Epoch 62/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.0160e-04 - val_loss: 3.1645e-04\n",
      "Epoch 63/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.9278e-04 - val_loss: 3.1767e-04\n",
      "Epoch 64/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.8433e-04 - val_loss: 3.1384e-04\n",
      "Epoch 65/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.8356e-04 - val_loss: 3.1016e-04\n",
      "Epoch 66/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.8767e-04 - val_loss: 3.1523e-04\n",
      "Epoch 67/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.7963e-04 - val_loss: 3.0784e-04\n",
      "Epoch 68/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.9864e-04 - val_loss: 3.0747e-04\n",
      "Epoch 69/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.8859e-04 - val_loss: 3.0623e-04\n",
      "Epoch 70/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.7167e-04 - val_loss: 3.0985e-04\n",
      "Epoch 71/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.9064e-04 - val_loss: 4.8496e-04\n",
      "Epoch 72/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.9986e-04 - val_loss: 3.0551e-04\n",
      "Epoch 73/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.6054e-04 - val_loss: 3.1571e-04\n",
      "Epoch 74/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.6124e-04 - val_loss: 3.0973e-04\n",
      "Epoch 75/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.6768e-04 - val_loss: 3.0037e-04\n",
      "Epoch 76/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.7489e-04 - val_loss: 3.7402e-04\n",
      "Epoch 77/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.5504e-04 - val_loss: 2.9768e-04\n",
      "Epoch 78/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.6266e-04 - val_loss: 3.0711e-04\n",
      "Epoch 79/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.7287e-04 - val_loss: 3.6000e-04\n",
      "Epoch 80/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.5040e-04 - val_loss: 3.3118e-04\n",
      "Epoch 81/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.4850e-04 - val_loss: 3.2141e-04\n",
      "Epoch 82/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.4250e-04 - val_loss: 3.0289e-04\n",
      "Epoch 83/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.4853e-04 - val_loss: 2.9722e-04\n",
      "Epoch 84/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.4708e-04 - val_loss: 2.9535e-04\n",
      "Epoch 85/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.5771e-04 - val_loss: 3.3319e-04\n",
      "Epoch 86/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.4096e-04 - val_loss: 3.1234e-04\n",
      "Epoch 87/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.5399e-04 - val_loss: 3.2916e-04\n",
      "Epoch 88/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.3291e-04 - val_loss: 3.2463e-04\n",
      "Epoch 89/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.3602e-04 - val_loss: 2.9011e-04\n",
      "Epoch 90/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.3603e-04 - val_loss: 3.0541e-04\n",
      "Epoch 91/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.3379e-04 - val_loss: 2.8503e-04\n",
      "Epoch 92/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.3391e-04 - val_loss: 3.7196e-04\n",
      "Epoch 93/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.5627e-04 - val_loss: 2.8619e-04\n",
      "Epoch 94/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.2662e-04 - val_loss: 2.8461e-04\n",
      "Epoch 95/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.3455e-04 - val_loss: 3.2749e-04\n",
      "Epoch 96/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.3223e-04 - val_loss: 2.9021e-04\n",
      "Epoch 97/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.2073e-04 - val_loss: 3.5001e-04\n",
      "Epoch 98/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.4578e-04 - val_loss: 4.0256e-04\n",
      "Epoch 99/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.3130e-04 - val_loss: 2.8873e-04\n",
      "Epoch 100/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.2189e-04 - val_loss: 2.8284e-04\n",
      "Epoch 101/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.1565e-04 - val_loss: 2.7760e-04\n",
      "Epoch 102/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.2237e-04 - val_loss: 3.2786e-04\n",
      "Epoch 103/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.1608e-04 - val_loss: 3.0046e-04\n",
      "Epoch 104/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.2057e-04 - val_loss: 2.7607e-04\n",
      "Epoch 105/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.1697e-04 - val_loss: 2.8592e-04\n",
      "Epoch 106/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.1109e-04 - val_loss: 3.1978e-04\n",
      "Epoch 107/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.2260e-04 - val_loss: 2.9123e-04\n",
      "Epoch 108/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.0662e-04 - val_loss: 3.0758e-04\n",
      "Epoch 109/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 5.1311e-04 - val_loss: 2.7542e-04\n",
      "Epoch 110/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 5.0822e-04 - val_loss: 3.5020e-04\n",
      "Epoch 111/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.0773e-04 - val_loss: 2.8793e-04\n",
      "Epoch 112/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.1063e-04 - val_loss: 2.7648e-04\n",
      "Epoch 113/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.1978e-04 - val_loss: 2.8344e-04\n",
      "Epoch 114/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.2935e-04 - val_loss: 3.3007e-04\n",
      "Epoch 115/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.2387e-04 - val_loss: 2.7662e-04\n",
      "Epoch 116/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.0449e-04 - val_loss: 2.6644e-04\n",
      "Epoch 117/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.0853e-04 - val_loss: 2.8533e-04\n",
      "Epoch 118/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.4508e-04 - val_loss: 2.8414e-04\n",
      "Epoch 119/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.3685e-04 - val_loss: 3.0198e-04\n",
      "Epoch 120/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.9644e-04 - val_loss: 3.0577e-04\n",
      "Epoch 121/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.2674e-04 - val_loss: 2.6382e-04\n",
      "Epoch 122/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.8874e-04 - val_loss: 3.2681e-04\n",
      "Epoch 123/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.9043e-04 - val_loss: 2.6810e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.8978e-04 - val_loss: 2.7553e-04\n",
      "Epoch 125/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.9279e-04 - val_loss: 2.6981e-04\n",
      "Epoch 126/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.1687e-04 - val_loss: 2.6045e-04\n",
      "Epoch 127/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.2170e-04 - val_loss: 2.8124e-04\n",
      "Epoch 128/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.0183e-04 - val_loss: 2.7190e-04\n",
      "Epoch 129/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.9472e-04 - val_loss: 2.5948e-04\n",
      "Epoch 130/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.2447e-04 - val_loss: 3.5284e-04\n",
      "Epoch 131/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.9778e-04 - val_loss: 2.7353e-04\n",
      "Epoch 132/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.9420e-04 - val_loss: 3.1651e-04\n",
      "Epoch 133/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.8712e-04 - val_loss: 2.5650e-04\n",
      "Epoch 134/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.7836e-04 - val_loss: 2.5597e-04\n",
      "Epoch 135/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.8297e-04 - val_loss: 3.0101e-04\n",
      "Epoch 136/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 4.9204e-04 - val_loss: 2.5736e-04\n",
      "Epoch 137/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.1232e-04 - val_loss: 3.1469e-04\n",
      "Epoch 138/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.9549e-04 - val_loss: 2.5764e-04\n",
      "Epoch 139/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.9258e-04 - val_loss: 2.5453e-04\n",
      "Epoch 140/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.7816e-04 - val_loss: 2.6846e-04\n",
      "Epoch 141/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.0009e-04 - val_loss: 2.8178e-04\n",
      "Epoch 142/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.7481e-04 - val_loss: 2.6139e-04\n",
      "Epoch 143/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.7700e-04 - val_loss: 2.5979e-04\n",
      "Epoch 144/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.7684e-04 - val_loss: 2.5186e-04\n",
      "Epoch 145/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.8942e-04 - val_loss: 3.0020e-04\n",
      "Epoch 146/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.7271e-04 - val_loss: 2.5502e-04\n",
      "Epoch 147/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.7608e-04 - val_loss: 2.6217e-04\n",
      "Epoch 148/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.8303e-04 - val_loss: 2.5109e-04\n",
      "Epoch 149/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.6937e-04 - val_loss: 2.5136e-04\n",
      "Epoch 150/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.7483e-04 - val_loss: 2.5012e-04\n",
      "Epoch 151/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.6578e-04 - val_loss: 2.5614e-04\n",
      "Epoch 152/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.2990e-04 - val_loss: 2.5649e-04\n",
      "Epoch 153/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.8517e-04 - val_loss: 2.6297e-04\n",
      "Epoch 154/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.8499e-04 - val_loss: 2.7900e-04\n",
      "Epoch 155/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.7671e-04 - val_loss: 2.9114e-04\n",
      "Epoch 156/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 4.7030e-04 - val_loss: 3.2807e-04\n",
      "Epoch 157/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.6619e-04 - val_loss: 2.7434e-04\n",
      "Epoch 158/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.6192e-04 - val_loss: 2.6131e-04\n",
      "Epoch 159/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.5908e-04 - val_loss: 2.7754e-04\n",
      "Epoch 160/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.6695e-04 - val_loss: 2.4647e-04\n",
      "Epoch 161/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.7904e-04 - val_loss: 3.2432e-04\n",
      "Epoch 162/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.7113e-04 - val_loss: 3.1749e-04\n",
      "Epoch 163/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.7699e-04 - val_loss: 2.5127e-04\n",
      "Epoch 164/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.6887e-04 - val_loss: 2.5721e-04\n",
      "Epoch 165/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.5361e-04 - val_loss: 2.4155e-04\n",
      "Epoch 166/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.6805e-04 - val_loss: 3.1880e-04\n",
      "Epoch 167/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.7801e-04 - val_loss: 2.4072e-04\n",
      "Epoch 168/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.7927e-04 - val_loss: 2.6534e-04\n",
      "Epoch 169/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.5580e-04 - val_loss: 2.4279e-04\n",
      "Epoch 170/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.5961e-04 - val_loss: 2.4050e-04\n",
      "Epoch 171/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.5533e-04 - val_loss: 2.5258e-04\n",
      "Epoch 172/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.5472e-04 - val_loss: 2.5281e-04\n",
      "Epoch 173/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.6521e-04 - val_loss: 2.6764e-04\n",
      "Epoch 174/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.5758e-04 - val_loss: 3.0741e-04\n",
      "Epoch 175/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.6066e-04 - val_loss: 2.9915e-04\n",
      "Epoch 176/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.9444e-04 - val_loss: 2.7422e-04\n",
      "Epoch 177/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.7795e-04 - val_loss: 2.7589e-04\n",
      "Epoch 178/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.7652e-04 - val_loss: 2.3703e-04\n",
      "Epoch 179/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.5084e-04 - val_loss: 2.4984e-04\n",
      "Epoch 180/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.4861e-04 - val_loss: 2.4918e-04\n",
      "Epoch 181/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.5094e-04 - val_loss: 2.3543e-04\n",
      "Epoch 182/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.6216e-04 - val_loss: 2.3527e-04\n",
      "Epoch 183/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.5955e-04 - val_loss: 2.5253e-04\n",
      "Epoch 184/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.6026e-04 - val_loss: 2.3616e-04\n",
      "Epoch 185/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.6290e-04 - val_loss: 2.6298e-04\n",
      "Epoch 186/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.4827e-04 - val_loss: 2.3472e-04\n",
      "Epoch 187/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.5579e-04 - val_loss: 2.3589e-04\n",
      "Epoch 188/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.8614e-04 - val_loss: 2.3766e-04\n",
      "Epoch 189/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.5414e-04 - val_loss: 2.3598e-04\n",
      "Epoch 190/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.4837e-04 - val_loss: 3.0694e-04\n",
      "Epoch 191/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.6598e-04 - val_loss: 2.7503e-04\n",
      "Epoch 192/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.6236e-04 - val_loss: 2.3212e-04\n",
      "Epoch 193/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.6685e-04 - val_loss: 2.3199e-04\n",
      "Epoch 194/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.4118e-04 - val_loss: 2.5442e-04\n",
      "Epoch 195/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.7780e-04 - val_loss: 2.5206e-04\n",
      "Epoch 196/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.6142e-04 - val_loss: 2.5859e-04\n",
      "Epoch 197/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.5836e-04 - val_loss: 2.3213e-04\n",
      "Epoch 198/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.4650e-04 - val_loss: 2.6074e-04\n",
      "Epoch 199/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 3ms/step - loss: 4.4910e-04 - val_loss: 2.6207e-04\n",
      "Epoch 200/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 4.5316e-04 - val_loss: 2.8534e-04\n",
      "Thời gian huấn luyện:  20.53654718399048\n",
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_16 (SimpleRNN)   (None, 10, 96)            9408      \n",
      "                                                                 \n",
      " flatten_65 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,369\n",
      "Trainable params: 10,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "30/30 [==============================] - 2s 18ms/step - loss: 0.0218 - val_loss: 9.5073e-04\n",
      "Epoch 2/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 3/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 9.2563e-04\n",
      "Epoch 4/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 9.1449e-04\n",
      "Epoch 5/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 8.5583e-04\n",
      "Epoch 6/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 9.0651e-04\n",
      "Epoch 7/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 8.7032e-04\n",
      "Epoch 8/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 9.1766e-04\n",
      "Epoch 9/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 8.4688e-04\n",
      "Epoch 10/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 8.2121e-04\n",
      "Epoch 11/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 8.2493e-04\n",
      "Epoch 12/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.1338e-04\n",
      "Epoch 13/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.8567e-04\n",
      "Epoch 14/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 7.9584e-04\n",
      "Epoch 15/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.0970e-04\n",
      "Epoch 16/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.6937e-04\n",
      "Epoch 17/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.5756e-04\n",
      "Epoch 18/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.6458e-04\n",
      "Epoch 19/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.6525e-04\n",
      "Epoch 20/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 8.1793e-04\n",
      "Epoch 21/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.8270e-04\n",
      "Epoch 22/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 8.7358e-04\n",
      "Epoch 23/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.4874e-04\n",
      "Epoch 24/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.3538e-04\n",
      "Epoch 25/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.2983e-04\n",
      "Epoch 26/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.4594e-04\n",
      "Epoch 27/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.0872e-04\n",
      "Epoch 28/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 6.9473e-04\n",
      "Epoch 29/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 6.8876e-04\n",
      "Epoch 30/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.6432e-04\n",
      "Epoch 31/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 8.0635e-04\n",
      "Epoch 32/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.3551e-04\n",
      "Epoch 33/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 6.5711e-04\n",
      "Epoch 34/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 6.6380e-04\n",
      "Epoch 35/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.6356e-04\n",
      "Epoch 36/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.8550e-04\n",
      "Epoch 37/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.5873e-04\n",
      "Epoch 38/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.1874e-04\n",
      "Epoch 39/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.9973e-04\n",
      "Epoch 40/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.2256e-04\n",
      "Epoch 41/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 6.1656e-04\n",
      "Epoch 42/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.8520e-04\n",
      "Epoch 43/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 6.5064e-04\n",
      "Epoch 44/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.7280e-04\n",
      "Epoch 45/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 6.3902e-04\n",
      "Epoch 46/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.5621e-04\n",
      "Epoch 47/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.8510e-04\n",
      "Epoch 48/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.7923e-04\n",
      "Epoch 49/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.4554e-04\n",
      "Epoch 50/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.4594e-04\n",
      "Epoch 51/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.5242e-04\n",
      "Epoch 52/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.3788e-04\n",
      "Epoch 53/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.3184e-04\n",
      "Epoch 54/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 6.1369e-04\n",
      "Epoch 55/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 5.4658e-04\n",
      "Epoch 56/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 6.9415e-04\n",
      "Epoch 57/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 5.3799e-04\n",
      "Epoch 58/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 5.4223e-04\n",
      "Epoch 59/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.9557e-04 - val_loss: 5.8152e-04\n",
      "Epoch 60/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.9670e-04 - val_loss: 5.6196e-04\n",
      "Epoch 61/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 5.2771e-04\n",
      "Epoch 62/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.8058e-04 - val_loss: 4.9830e-04\n",
      "Epoch 63/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.7145e-04 - val_loss: 5.1934e-04\n",
      "Epoch 64/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.6602e-04 - val_loss: 4.9328e-04\n",
      "Epoch 65/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.7695e-04 - val_loss: 5.7304e-04\n",
      "Epoch 66/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.8654e-04 - val_loss: 5.4905e-04\n",
      "Epoch 67/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.5518e-04 - val_loss: 4.8618e-04\n",
      "Epoch 68/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.5568e-04 - val_loss: 5.3377e-04\n",
      "Epoch 69/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 7ms/step - loss: 9.4424e-04 - val_loss: 5.8208e-04\n",
      "Epoch 70/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.4325e-04 - val_loss: 4.9472e-04\n",
      "Epoch 71/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.3300e-04 - val_loss: 5.8017e-04\n",
      "Epoch 72/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.3258e-04 - val_loss: 4.9576e-04\n",
      "Epoch 73/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.2530e-04 - val_loss: 4.7616e-04\n",
      "Epoch 74/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.2794e-04 - val_loss: 5.8977e-04\n",
      "Epoch 75/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.2606e-04 - val_loss: 4.9341e-04\n",
      "Epoch 76/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.3410e-04 - val_loss: 4.6460e-04\n",
      "Epoch 77/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.3812e-04 - val_loss: 5.0625e-04\n",
      "Epoch 78/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.0751e-04 - val_loss: 4.9227e-04\n",
      "Epoch 79/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.0218e-04 - val_loss: 4.8269e-04\n",
      "Epoch 80/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.1363e-04 - val_loss: 4.9577e-04\n",
      "Epoch 81/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.9767e-04 - val_loss: 5.0225e-04\n",
      "Epoch 82/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.9715e-04 - val_loss: 5.6551e-04\n",
      "Epoch 83/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.1426e-04 - val_loss: 4.6733e-04\n",
      "Epoch 84/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.9348e-04 - val_loss: 5.6030e-04\n",
      "Epoch 85/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.9664e-04 - val_loss: 5.8204e-04\n",
      "Epoch 86/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.9596e-04 - val_loss: 4.5649e-04\n",
      "Epoch 87/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.8026e-04 - val_loss: 4.8790e-04\n",
      "Epoch 88/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.8164e-04 - val_loss: 5.2949e-04\n",
      "Epoch 89/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.8507e-04 - val_loss: 4.9823e-04\n",
      "Epoch 90/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.7151e-04 - val_loss: 4.7650e-04\n",
      "Epoch 91/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.6404e-04 - val_loss: 5.2566e-04\n",
      "Epoch 92/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.7311e-04 - val_loss: 4.6188e-04\n",
      "Epoch 93/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.6255e-04 - val_loss: 4.4944e-04\n",
      "Epoch 94/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.6477e-04 - val_loss: 5.0459e-04\n",
      "Epoch 95/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.5112e-04 - val_loss: 4.6816e-04\n",
      "Epoch 96/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 8.5423e-04 - val_loss: 5.0940e-04\n",
      "Epoch 97/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.4732e-04 - val_loss: 4.4575e-04\n",
      "Epoch 98/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.6763e-04 - val_loss: 4.6139e-04\n",
      "Epoch 99/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.6607e-04 - val_loss: 6.3302e-04\n",
      "Epoch 100/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.6491e-04 - val_loss: 5.0827e-04\n",
      "Epoch 101/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.5218e-04 - val_loss: 4.8344e-04\n",
      "Epoch 102/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.3271e-04 - val_loss: 5.1158e-04\n",
      "Epoch 103/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.3067e-04 - val_loss: 4.3083e-04\n",
      "Epoch 104/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.3873e-04 - val_loss: 4.8670e-04\n",
      "Epoch 105/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.2735e-04 - val_loss: 4.2789e-04\n",
      "Epoch 106/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.2358e-04 - val_loss: 5.0328e-04\n",
      "Epoch 107/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.2155e-04 - val_loss: 4.2788e-04\n",
      "Epoch 108/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.3334e-04 - val_loss: 4.8334e-04\n",
      "Epoch 109/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.1999e-04 - val_loss: 6.0340e-04\n",
      "Epoch 110/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.2744e-04 - val_loss: 4.5399e-04\n",
      "Epoch 111/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.0805e-04 - val_loss: 4.9280e-04\n",
      "Epoch 112/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.0486e-04 - val_loss: 4.9748e-04\n",
      "Epoch 113/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.1796e-04 - val_loss: 4.2090e-04\n",
      "Epoch 114/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.1132e-04 - val_loss: 4.7133e-04\n",
      "Epoch 115/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.1056e-04 - val_loss: 4.3392e-04\n",
      "Epoch 116/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.0614e-04 - val_loss: 4.8985e-04\n",
      "Epoch 117/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.0862e-04 - val_loss: 4.1195e-04\n",
      "Epoch 118/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.0549e-04 - val_loss: 4.9796e-04\n",
      "Epoch 119/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.0613e-04 - val_loss: 5.0936e-04\n",
      "Epoch 120/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.9913e-04 - val_loss: 4.5026e-04\n",
      "Epoch 121/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.8034e-04 - val_loss: 4.6577e-04\n",
      "Epoch 122/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.8049e-04 - val_loss: 4.2189e-04\n",
      "Epoch 123/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.7297e-04 - val_loss: 4.3621e-04\n",
      "Epoch 124/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.8651e-04 - val_loss: 4.6021e-04\n",
      "Epoch 125/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.8224e-04 - val_loss: 4.6478e-04\n",
      "Epoch 126/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.6572e-04 - val_loss: 5.3336e-04\n",
      "Epoch 127/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.9216e-04 - val_loss: 4.1780e-04\n",
      "Epoch 128/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 8.2595e-04 - val_loss: 4.0354e-04\n",
      "Epoch 129/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.7515e-04 - val_loss: 4.0827e-04\n",
      "Epoch 130/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.7420e-04 - val_loss: 4.8000e-04\n",
      "Epoch 131/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.7841e-04 - val_loss: 4.3564e-04\n",
      "Epoch 132/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.7027e-04 - val_loss: 3.9696e-04\n",
      "Epoch 133/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.9147e-04 - val_loss: 6.3954e-04\n",
      "Epoch 134/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.5805e-04 - val_loss: 4.4397e-04\n",
      "Epoch 135/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.5977e-04 - val_loss: 4.4147e-04\n",
      "Epoch 136/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.4962e-04 - val_loss: 4.8794e-04\n",
      "Epoch 137/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.4435e-04 - val_loss: 3.9591e-04\n",
      "Epoch 138/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.4593e-04 - val_loss: 5.1043e-04\n",
      "Epoch 139/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.6144e-04 - val_loss: 4.2205e-04\n",
      "Epoch 140/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.2963e-04 - val_loss: 4.1891e-04\n",
      "Epoch 141/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.2819e-04 - val_loss: 3.9175e-04\n",
      "Epoch 142/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.2550e-04 - val_loss: 4.3545e-04\n",
      "Epoch 143/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.1708e-04 - val_loss: 4.7054e-04\n",
      "Epoch 144/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 7ms/step - loss: 7.2203e-04 - val_loss: 4.3265e-04\n",
      "Epoch 145/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.3831e-04 - val_loss: 3.8328e-04\n",
      "Epoch 146/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.3040e-04 - val_loss: 4.7910e-04\n",
      "Epoch 147/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.1795e-04 - val_loss: 4.3322e-04\n",
      "Epoch 148/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.0890e-04 - val_loss: 3.8896e-04\n",
      "Epoch 149/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.0955e-04 - val_loss: 4.5814e-04\n",
      "Epoch 150/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.2190e-04 - val_loss: 4.1662e-04\n",
      "Epoch 151/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.0663e-04 - val_loss: 3.7967e-04\n",
      "Epoch 152/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.9913e-04 - val_loss: 4.1398e-04\n",
      "Epoch 153/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.0583e-04 - val_loss: 3.9653e-04\n",
      "Epoch 154/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.9399e-04 - val_loss: 4.6757e-04\n",
      "Epoch 155/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.1783e-04 - val_loss: 4.7420e-04\n",
      "Epoch 156/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.1742e-04 - val_loss: 3.8738e-04\n",
      "Epoch 157/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.9690e-04 - val_loss: 3.7131e-04\n",
      "Epoch 158/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.8846e-04 - val_loss: 4.9392e-04\n",
      "Epoch 159/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.9300e-04 - val_loss: 4.2153e-04\n",
      "Epoch 160/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.8799e-04 - val_loss: 3.8744e-04\n",
      "Epoch 161/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.8673e-04 - val_loss: 3.8903e-04\n",
      "Epoch 162/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.7967e-04 - val_loss: 3.6715e-04\n",
      "Epoch 163/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.9964e-04 - val_loss: 4.3799e-04\n",
      "Epoch 164/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.7994e-04 - val_loss: 4.2297e-04\n",
      "Epoch 165/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.8034e-04 - val_loss: 4.0451e-04\n",
      "Epoch 166/200\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 6.8466e-04 - val_loss: 3.6956e-04\n",
      "Epoch 167/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 7.0097e-04 - val_loss: 4.4249e-04\n",
      "Epoch 168/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.7495e-04 - val_loss: 4.0778e-04\n",
      "Epoch 169/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.6870e-04 - val_loss: 3.8255e-04\n",
      "Epoch 170/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.7146e-04 - val_loss: 4.2987e-04\n",
      "Epoch 171/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 6.6462e-04 - val_loss: 3.6297e-04\n",
      "Epoch 172/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 6.7258e-04 - val_loss: 4.1314e-04\n",
      "Epoch 173/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.7380e-04 - val_loss: 5.2188e-04\n",
      "Epoch 174/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.6745e-04 - val_loss: 3.9814e-04\n",
      "Epoch 175/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.5472e-04 - val_loss: 3.7767e-04\n",
      "Epoch 176/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.5331e-04 - val_loss: 3.6493e-04\n",
      "Epoch 177/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.5831e-04 - val_loss: 3.5540e-04\n",
      "Epoch 178/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 6.7564e-04 - val_loss: 3.5465e-04\n",
      "Epoch 179/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 6.5193e-04 - val_loss: 3.5418e-04\n",
      "Epoch 180/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.5786e-04 - val_loss: 4.1049e-04\n",
      "Epoch 181/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 6.6032e-04 - val_loss: 4.4384e-04\n",
      "Epoch 182/200\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 6.6057e-04 - val_loss: 4.0891e-04\n",
      "Epoch 183/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 6.4700e-04 - val_loss: 3.9756e-04\n",
      "Epoch 184/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 6.4946e-04 - val_loss: 3.7545e-04\n",
      "Epoch 185/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 6.4365e-04 - val_loss: 3.4968e-04\n",
      "Epoch 186/200\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 6.5037e-04 - val_loss: 3.7712e-04\n",
      "Epoch 187/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 6.3277e-04 - val_loss: 3.8348e-04\n",
      "Epoch 188/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 6.3991e-04 - val_loss: 3.5052e-04\n",
      "Epoch 189/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 6.3743e-04 - val_loss: 3.4876e-04\n",
      "Epoch 190/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.3409e-04 - val_loss: 3.4753e-04\n",
      "Epoch 191/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.3668e-04 - val_loss: 3.5065e-04\n",
      "Epoch 192/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 6.2939e-04 - val_loss: 4.1167e-04\n",
      "Epoch 193/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 6.2972e-04 - val_loss: 3.4625e-04\n",
      "Epoch 194/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 6.3092e-04 - val_loss: 4.2372e-04\n",
      "Epoch 195/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 6.3697e-04 - val_loss: 3.7201e-04\n",
      "Epoch 196/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 6.3906e-04 - val_loss: 3.5584e-04\n",
      "Epoch 197/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 6.1922e-04 - val_loss: 3.5574e-04\n",
      "Epoch 198/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 6.3025e-04 - val_loss: 3.5028e-04\n",
      "Epoch 199/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.2110e-04 - val_loss: 4.6623e-04\n",
      "Epoch 200/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.3243e-04 - val_loss: 3.8634e-04\n",
      "Thời gian huấn luyện:  43.75351309776306\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_16 (LSTM)              (None, 10, 96)            37632     \n",
      "                                                                 \n",
      " flatten_66 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,593\n",
      "Trainable params: 38,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "30/30 [==============================] - 2s 17ms/step - loss: 0.0168 - val_loss: 0.0011\n",
      "Epoch 2/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.0010\n",
      "Epoch 3/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 4/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.6803e-04\n",
      "Epoch 5/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 7.6204e-04\n",
      "Epoch 6/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.3014e-04\n",
      "Epoch 7/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 7.6896e-04\n",
      "Epoch 8/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 6.9919e-04\n",
      "Epoch 9/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 7.3988e-04\n",
      "Epoch 10/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 6.8522e-04\n",
      "Epoch 11/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 6.7700e-04\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 6.5198e-04\n",
      "Epoch 13/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.8141e-04\n",
      "Epoch 14/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.2454e-04\n",
      "Epoch 15/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.2370e-04\n",
      "Epoch 16/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.1024e-04\n",
      "Epoch 17/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.2036e-04\n",
      "Epoch 18/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 6.3298e-04\n",
      "Epoch 19/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.0498e-04\n",
      "Epoch 20/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 5.6836e-04\n",
      "Epoch 21/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.7021e-04\n",
      "Epoch 22/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.7284e-04\n",
      "Epoch 23/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.6086e-04\n",
      "Epoch 24/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.5587e-04\n",
      "Epoch 25/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.2863e-04\n",
      "Epoch 26/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.1575e-04\n",
      "Epoch 27/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.0785e-04\n",
      "Epoch 28/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.2267e-04\n",
      "Epoch 29/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.2299e-04\n",
      "Epoch 30/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.7693e-04 - val_loss: 4.9859e-04\n",
      "Epoch 31/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.6804e-04 - val_loss: 5.3968e-04\n",
      "Epoch 32/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.5356e-04 - val_loss: 5.1527e-04\n",
      "Epoch 33/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.3964e-04 - val_loss: 5.0529e-04\n",
      "Epoch 34/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.2456e-04 - val_loss: 4.8872e-04\n",
      "Epoch 35/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.1116e-04 - val_loss: 5.9855e-04\n",
      "Epoch 36/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.9782e-04 - val_loss: 4.7998e-04\n",
      "Epoch 37/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.0167e-04 - val_loss: 4.4307e-04\n",
      "Epoch 38/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.8641e-04 - val_loss: 5.3937e-04\n",
      "Epoch 39/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.7446e-04 - val_loss: 4.8104e-04\n",
      "Epoch 40/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.5678e-04 - val_loss: 4.9852e-04\n",
      "Epoch 41/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.6067e-04 - val_loss: 5.2687e-04\n",
      "Epoch 42/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.4315e-04 - val_loss: 4.2934e-04\n",
      "Epoch 43/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.3836e-04 - val_loss: 4.4787e-04\n",
      "Epoch 44/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.3254e-04 - val_loss: 4.7833e-04\n",
      "Epoch 45/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.1924e-04 - val_loss: 4.3276e-04\n",
      "Epoch 46/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.1638e-04 - val_loss: 5.1030e-04\n",
      "Epoch 47/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.3144e-04 - val_loss: 4.3303e-04\n",
      "Epoch 48/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.0570e-04 - val_loss: 4.2019e-04\n",
      "Epoch 49/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.9559e-04 - val_loss: 4.1785e-04\n",
      "Epoch 50/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.8962e-04 - val_loss: 4.0572e-04\n",
      "Epoch 51/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.8856e-04 - val_loss: 4.0191e-04\n",
      "Epoch 52/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.7887e-04 - val_loss: 4.3684e-04\n",
      "Epoch 53/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.7902e-04 - val_loss: 4.2661e-04\n",
      "Epoch 54/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.6636e-04 - val_loss: 4.1649e-04\n",
      "Epoch 55/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.6289e-04 - val_loss: 4.0318e-04\n",
      "Epoch 56/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.6646e-04 - val_loss: 4.1003e-04\n",
      "Epoch 57/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.5250e-04 - val_loss: 4.1466e-04\n",
      "Epoch 58/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.5079e-04 - val_loss: 4.1858e-04\n",
      "Epoch 59/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.4086e-04 - val_loss: 4.0307e-04\n",
      "Epoch 60/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 7.4147e-04 - val_loss: 3.8621e-04\n",
      "Epoch 61/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.3742e-04 - val_loss: 3.8760e-04\n",
      "Epoch 62/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.2786e-04 - val_loss: 4.0531e-04\n",
      "Epoch 63/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 7.2395e-04 - val_loss: 4.2051e-04\n",
      "Epoch 64/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 7.2302e-04 - val_loss: 3.8756e-04\n",
      "Epoch 65/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.1711e-04 - val_loss: 4.2511e-04\n",
      "Epoch 66/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.1540e-04 - val_loss: 3.7524e-04\n",
      "Epoch 67/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 7.2463e-04 - val_loss: 3.9365e-04\n",
      "Epoch 68/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.0224e-04 - val_loss: 3.8129e-04\n",
      "Epoch 69/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.0421e-04 - val_loss: 4.1293e-04\n",
      "Epoch 70/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.9879e-04 - val_loss: 3.7446e-04\n",
      "Epoch 71/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.9346e-04 - val_loss: 3.6786e-04\n",
      "Epoch 72/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.9935e-04 - val_loss: 3.6661e-04\n",
      "Epoch 73/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.9289e-04 - val_loss: 4.3845e-04\n",
      "Epoch 74/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.0746e-04 - val_loss: 3.7660e-04\n",
      "Epoch 75/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.9177e-04 - val_loss: 4.0631e-04\n",
      "Epoch 76/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 6.7706e-04 - val_loss: 3.7687e-04\n",
      "Epoch 77/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.7131e-04 - val_loss: 3.6896e-04\n",
      "Epoch 78/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.7297e-04 - val_loss: 3.7367e-04\n",
      "Epoch 79/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 6.6172e-04 - val_loss: 3.7160e-04\n",
      "Epoch 80/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.6574e-04 - val_loss: 3.9080e-04\n",
      "Epoch 81/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.8338e-04 - val_loss: 3.7021e-04\n",
      "Epoch 82/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.7729e-04 - val_loss: 3.5689e-04\n",
      "Epoch 83/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.5059e-04 - val_loss: 3.4895e-04\n",
      "Epoch 84/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.5208e-04 - val_loss: 3.9398e-04\n",
      "Epoch 85/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.4492e-04 - val_loss: 3.5827e-04\n",
      "Epoch 86/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.4037e-04 - val_loss: 3.4871e-04\n",
      "Epoch 87/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.3664e-04 - val_loss: 4.0264e-04\n",
      "Epoch 88/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 7ms/step - loss: 6.3848e-04 - val_loss: 3.7155e-04\n",
      "Epoch 89/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.3426e-04 - val_loss: 3.7857e-04\n",
      "Epoch 90/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.3329e-04 - val_loss: 3.4238e-04\n",
      "Epoch 91/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.3651e-04 - val_loss: 3.6880e-04\n",
      "Epoch 92/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.2109e-04 - val_loss: 3.7760e-04\n",
      "Epoch 93/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.2543e-04 - val_loss: 3.5592e-04\n",
      "Epoch 94/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.2395e-04 - val_loss: 3.6547e-04\n",
      "Epoch 95/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.1329e-04 - val_loss: 3.3408e-04\n",
      "Epoch 96/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.2217e-04 - val_loss: 3.4242e-04\n",
      "Epoch 97/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.1525e-04 - val_loss: 3.3167e-04\n",
      "Epoch 98/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.1394e-04 - val_loss: 3.3174e-04\n",
      "Epoch 99/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.0691e-04 - val_loss: 3.4054e-04\n",
      "Epoch 100/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.2144e-04 - val_loss: 3.9475e-04\n",
      "Epoch 101/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.0033e-04 - val_loss: 3.6919e-04\n",
      "Epoch 102/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.9942e-04 - val_loss: 3.3235e-04\n",
      "Epoch 103/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.0740e-04 - val_loss: 3.3919e-04\n",
      "Epoch 104/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.0116e-04 - val_loss: 3.2337e-04\n",
      "Epoch 105/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 5.9493e-04 - val_loss: 3.2394e-04\n",
      "Epoch 106/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.0330e-04 - val_loss: 3.8281e-04\n",
      "Epoch 107/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 5.8686e-04 - val_loss: 3.4627e-04\n",
      "Epoch 108/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.8745e-04 - val_loss: 3.2346e-04\n",
      "Epoch 109/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.9688e-04 - val_loss: 3.4918e-04\n",
      "Epoch 110/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.8497e-04 - val_loss: 3.2515e-04\n",
      "Epoch 111/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.8687e-04 - val_loss: 3.7732e-04\n",
      "Epoch 112/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.8358e-04 - val_loss: 3.1526e-04\n",
      "Epoch 113/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.7326e-04 - val_loss: 3.3327e-04\n",
      "Epoch 114/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.7455e-04 - val_loss: 3.1418e-04\n",
      "Epoch 115/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.7610e-04 - val_loss: 4.1849e-04\n",
      "Epoch 116/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.9338e-04 - val_loss: 3.1788e-04\n",
      "Epoch 117/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.8670e-04 - val_loss: 3.1417e-04\n",
      "Epoch 118/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 5.6440e-04 - val_loss: 3.4005e-04\n",
      "Epoch 119/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 5.7235e-04 - val_loss: 3.0913e-04\n",
      "Epoch 120/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 5.5909e-04 - val_loss: 3.6164e-04\n",
      "Epoch 121/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 5.6460e-04 - val_loss: 3.1090e-04\n",
      "Epoch 122/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.5463e-04 - val_loss: 3.0597e-04\n",
      "Epoch 123/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.5912e-04 - val_loss: 3.3333e-04\n",
      "Epoch 124/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.7095e-04 - val_loss: 3.0538e-04\n",
      "Epoch 125/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 5.5653e-04 - val_loss: 3.1191e-04\n",
      "Epoch 126/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.4787e-04 - val_loss: 3.0478e-04\n",
      "Epoch 127/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 5.5564e-04 - val_loss: 3.3558e-04\n",
      "Epoch 128/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 5.5142e-04 - val_loss: 3.1488e-04\n",
      "Epoch 129/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 5.4310e-04 - val_loss: 3.0664e-04\n",
      "Epoch 130/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.5261e-04 - val_loss: 2.9926e-04\n",
      "Epoch 131/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.4400e-04 - val_loss: 3.0580e-04\n",
      "Epoch 132/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.3976e-04 - val_loss: 3.0928e-04\n",
      "Epoch 133/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.4515e-04 - val_loss: 2.9646e-04\n",
      "Epoch 134/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 5.4155e-04 - val_loss: 3.7574e-04\n",
      "Epoch 135/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.3831e-04 - val_loss: 3.2079e-04\n",
      "Epoch 136/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.4039e-04 - val_loss: 3.4102e-04\n",
      "Epoch 137/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.3214e-04 - val_loss: 3.2176e-04\n",
      "Epoch 138/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.3145e-04 - val_loss: 2.9483e-04\n",
      "Epoch 139/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 5.3282e-04 - val_loss: 2.9334e-04\n",
      "Epoch 140/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 5.3975e-04 - val_loss: 3.5437e-04\n",
      "Epoch 141/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.3660e-04 - val_loss: 3.1567e-04\n",
      "Epoch 142/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.3020e-04 - val_loss: 3.1019e-04\n",
      "Epoch 143/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.2276e-04 - val_loss: 2.9562e-04\n",
      "Epoch 144/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 5.2466e-04 - val_loss: 3.0100e-04\n",
      "Epoch 145/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 5.2389e-04 - val_loss: 2.9989e-04\n",
      "Epoch 146/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.2152e-04 - val_loss: 2.9714e-04\n",
      "Epoch 147/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.2573e-04 - val_loss: 3.0282e-04\n",
      "Epoch 148/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.1856e-04 - val_loss: 2.8489e-04\n",
      "Epoch 149/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 5.2317e-04 - val_loss: 3.0980e-04\n",
      "Epoch 150/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.1238e-04 - val_loss: 2.8315e-04\n",
      "Epoch 151/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.2005e-04 - val_loss: 2.8158e-04\n",
      "Epoch 152/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.0973e-04 - val_loss: 2.8292e-04\n",
      "Epoch 153/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 5.1345e-04 - val_loss: 2.8596e-04\n",
      "Epoch 154/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 5.1836e-04 - val_loss: 2.9668e-04\n",
      "Epoch 155/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 5.1997e-04 - val_loss: 3.8826e-04\n",
      "Epoch 156/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 5.1553e-04 - val_loss: 2.8927e-04\n",
      "Epoch 157/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.0814e-04 - val_loss: 2.7745e-04\n",
      "Epoch 158/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.0309e-04 - val_loss: 2.8159e-04\n",
      "Epoch 159/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 5.0925e-04 - val_loss: 2.7556e-04\n",
      "Epoch 160/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.1396e-04 - val_loss: 2.8475e-04\n",
      "Epoch 161/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.0470e-04 - val_loss: 2.8322e-04\n",
      "Epoch 162/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.0021e-04 - val_loss: 2.7583e-04\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 6ms/step - loss: 4.9929e-04 - val_loss: 2.9069e-04\n",
      "Epoch 164/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 4.9941e-04 - val_loss: 3.0511e-04\n",
      "Epoch 165/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 4.9561e-04 - val_loss: 2.8034e-04\n",
      "Epoch 166/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 4.9422e-04 - val_loss: 2.7084e-04\n",
      "Epoch 167/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 4.9420e-04 - val_loss: 2.7005e-04\n",
      "Epoch 168/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 4.9922e-04 - val_loss: 2.7087e-04\n",
      "Epoch 169/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 4.9170e-04 - val_loss: 3.1900e-04\n",
      "Epoch 170/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 4.9832e-04 - val_loss: 3.4993e-04\n",
      "Epoch 171/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 5.2837e-04 - val_loss: 2.6733e-04\n",
      "Epoch 172/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.1412e-04 - val_loss: 2.6742e-04\n",
      "Epoch 173/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 4.9464e-04 - val_loss: 2.7059e-04\n",
      "Epoch 174/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 4.9044e-04 - val_loss: 2.6821e-04\n",
      "Epoch 175/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 4.8498e-04 - val_loss: 2.8692e-04\n",
      "Epoch 176/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 4.8177e-04 - val_loss: 2.8527e-04\n",
      "Epoch 177/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 4.8675e-04 - val_loss: 2.6349e-04\n",
      "Epoch 178/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 4.9310e-04 - val_loss: 2.8552e-04\n",
      "Epoch 179/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 4.8280e-04 - val_loss: 2.6454e-04\n",
      "Epoch 180/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 4.8219e-04 - val_loss: 3.1439e-04\n",
      "Epoch 181/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 4.7603e-04 - val_loss: 2.7366e-04\n",
      "Epoch 182/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 4.8203e-04 - val_loss: 2.6402e-04\n",
      "Epoch 183/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 4.8701e-04 - val_loss: 2.7265e-04\n",
      "Epoch 184/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 4.9298e-04 - val_loss: 2.6044e-04\n",
      "Epoch 185/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 4.7325e-04 - val_loss: 2.6796e-04\n",
      "Epoch 186/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 4.7641e-04 - val_loss: 3.1261e-04\n",
      "Epoch 187/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 4.8655e-04 - val_loss: 2.6843e-04\n",
      "Epoch 188/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 4.7815e-04 - val_loss: 2.9718e-04\n",
      "Epoch 189/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 4.8742e-04 - val_loss: 2.6157e-04\n",
      "Epoch 190/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 4.7021e-04 - val_loss: 2.6288e-04\n",
      "Epoch 191/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 4.7100e-04 - val_loss: 2.5514e-04\n",
      "Epoch 192/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 4.8749e-04 - val_loss: 2.6272e-04\n",
      "Epoch 193/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 4.7061e-04 - val_loss: 2.7252e-04\n",
      "Epoch 194/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 4.7225e-04 - val_loss: 2.7436e-04\n",
      "Epoch 195/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 4.7039e-04 - val_loss: 2.8896e-04\n",
      "Epoch 196/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 4.8203e-04 - val_loss: 3.0307e-04\n",
      "Epoch 197/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 4.6748e-04 - val_loss: 2.7170e-04\n",
      "Epoch 198/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 4.7187e-04 - val_loss: 2.7315e-04\n",
      "Epoch 199/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 4.7853e-04 - val_loss: 2.6961e-04\n",
      "Epoch 200/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 4.7038e-04 - val_loss: 3.4855e-04\n",
      "Thời gian huấn luyện:  41.05868577957153\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_16 (GRU)                (None, 10, 96)            28512     \n",
      "                                                                 \n",
      " flatten_67 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,473\n",
      "Trainable params: 29,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "35/35 [==============================] - 0s 853us/step\n",
      "15/15 [==============================] - 0s 999us/step\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.0573 - val_loss: 0.0082\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0054\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 9.8780e-04\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 9.8278e-04\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 9.8464e-04\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 9.6626e-04\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 9.5685e-04\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 9.5178e-04\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 9.4514e-04\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.9661e-04 - val_loss: 9.3619e-04\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.8929e-04 - val_loss: 9.2678e-04\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.8471e-04 - val_loss: 9.2303e-04\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.7327e-04 - val_loss: 9.1576e-04\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.7210e-04 - val_loss: 9.0438e-04\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.6128e-04 - val_loss: 9.0406e-04\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.6025e-04 - val_loss: 8.9354e-04\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.4692e-04 - val_loss: 8.8619e-04\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.3596e-04 - val_loss: 8.7878e-04\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.3259e-04 - val_loss: 8.6881e-04\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.2373e-04 - val_loss: 8.6227e-04\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.1997e-04 - val_loss: 8.5600e-04\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.1357e-04 - val_loss: 8.4761e-04\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.0574e-04 - val_loss: 8.5782e-04\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.0851e-04 - val_loss: 8.3424e-04\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.9333e-04 - val_loss: 8.2756e-04\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.8470e-04 - val_loss: 8.2120e-04\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.7857e-04 - val_loss: 8.1433e-04\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.7408e-04 - val_loss: 8.0826e-04\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.6599e-04 - val_loss: 8.0610e-04\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.6352e-04 - val_loss: 7.9641e-04\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.5351e-04 - val_loss: 7.8777e-04\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.5116e-04 - val_loss: 7.8456e-04\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.4340e-04 - val_loss: 7.7486e-04\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.3634e-04 - val_loss: 7.6934e-04\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.3087e-04 - val_loss: 7.6247e-04\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.2511e-04 - val_loss: 7.6021e-04\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.2160e-04 - val_loss: 7.5325e-04\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.1379e-04 - val_loss: 7.4655e-04\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.0841e-04 - val_loss: 7.3896e-04\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.0697e-04 - val_loss: 7.4060e-04\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.9452e-04 - val_loss: 7.2869e-04\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.9813e-04 - val_loss: 7.2335e-04\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.8706e-04 - val_loss: 7.1587e-04\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.8322e-04 - val_loss: 7.1673e-04\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.7560e-04 - val_loss: 7.0558e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.7101e-04 - val_loss: 7.0041e-04\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.6638e-04 - val_loss: 6.9608e-04\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.6257e-04 - val_loss: 6.9347e-04\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.5529e-04 - val_loss: 6.8544e-04\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.5100e-04 - val_loss: 6.7861e-04\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.4402e-04 - val_loss: 6.7518e-04\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.4438e-04 - val_loss: 6.7774e-04\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.4090e-04 - val_loss: 6.6465e-04\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.3509e-04 - val_loss: 6.6542e-04\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.3105e-04 - val_loss: 6.5466e-04\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.2815e-04 - val_loss: 6.4984e-04\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.1809e-04 - val_loss: 6.4608e-04\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.1527e-04 - val_loss: 6.4203e-04\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.1092e-04 - val_loss: 6.3975e-04\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.1048e-04 - val_loss: 6.3501e-04\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.0095e-04 - val_loss: 6.2859e-04\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.9790e-04 - val_loss: 6.2383e-04\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.9660e-04 - val_loss: 6.1851e-04\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.9330e-04 - val_loss: 6.1524e-04\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.8450e-04 - val_loss: 6.1369e-04\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.8714e-04 - val_loss: 6.0983e-04\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.8122e-04 - val_loss: 6.0527e-04\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.7497e-04 - val_loss: 6.0038e-04\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.7210e-04 - val_loss: 6.0220e-04\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.7565e-04 - val_loss: 6.2270e-04\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.7534e-04 - val_loss: 5.9233e-04\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.6260e-04 - val_loss: 5.8527e-04\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.5971e-04 - val_loss: 5.8081e-04\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.5877e-04 - val_loss: 5.7712e-04\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.5262e-04 - val_loss: 5.7544e-04\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.4963e-04 - val_loss: 5.7330e-04\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.4523e-04 - val_loss: 5.7195e-04\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.4578e-04 - val_loss: 5.6667e-04\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.4115e-04 - val_loss: 5.6412e-04\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.3816e-04 - val_loss: 5.6400e-04\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.3432e-04 - val_loss: 5.6007e-04\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.3610e-04 - val_loss: 5.6754e-04\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.3416e-04 - val_loss: 5.5026e-04\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.3028e-04 - val_loss: 5.4812e-04\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.2060e-04 - val_loss: 5.4928e-04\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.2467e-04 - val_loss: 5.4196e-04\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.2296e-04 - val_loss: 5.4116e-04\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.1889e-04 - val_loss: 5.4154e-04\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.1554e-04 - val_loss: 5.3682e-04\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.1200e-04 - val_loss: 5.3836e-04\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.0888e-04 - val_loss: 5.3390e-04\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.0856e-04 - val_loss: 5.2796e-04\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.0941e-04 - val_loss: 5.2560e-04\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.0768e-04 - val_loss: 5.2513e-04\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.0509e-04 - val_loss: 5.2007e-04\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.0330e-04 - val_loss: 5.1785e-04\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.0141e-04 - val_loss: 5.2061e-04\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.9724e-04 - val_loss: 5.1442e-04\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.9140e-04 - val_loss: 5.1142e-04\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.9268e-04 - val_loss: 5.1560e-04\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.9216e-04 - val_loss: 5.0770e-04\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.8690e-04 - val_loss: 5.0831e-04\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.8663e-04 - val_loss: 5.1263e-04\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.8470e-04 - val_loss: 5.0378e-04\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.8302e-04 - val_loss: 5.0128e-04\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.8280e-04 - val_loss: 4.9896e-04\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.7861e-04 - val_loss: 4.9895e-04\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.7893e-04 - val_loss: 5.0131e-04\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.7444e-04 - val_loss: 4.9516e-04\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.8002e-04 - val_loss: 4.9152e-04\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.7084e-04 - val_loss: 4.9030e-04\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.7439e-04 - val_loss: 4.9620e-04\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.7211e-04 - val_loss: 5.1396e-04\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.7452e-04 - val_loss: 4.8618e-04\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.6919e-04 - val_loss: 4.8440e-04\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.6534e-04 - val_loss: 4.8287e-04\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.6266e-04 - val_loss: 4.8107e-04\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.6356e-04 - val_loss: 4.7941e-04\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.6080e-04 - val_loss: 4.7790e-04\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.5795e-04 - val_loss: 4.7738e-04\n",
      "Epoch 183/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 5.5927e-04 - val_loss: 4.7474e-04\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.6153e-04 - val_loss: 4.7642e-04\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.5520e-04 - val_loss: 4.7243e-04\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.6579e-04 - val_loss: 4.7132e-04\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.5494e-04 - val_loss: 4.6901e-04\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.5096e-04 - val_loss: 4.7294e-04\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.5132e-04 - val_loss: 4.7171e-04\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.4980e-04 - val_loss: 4.6693e-04\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.5002e-04 - val_loss: 4.6668e-04\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.4666e-04 - val_loss: 4.6395e-04\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.4661e-04 - val_loss: 4.6256e-04\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.4870e-04 - val_loss: 4.6669e-04\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.4595e-04 - val_loss: 4.5985e-04\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.4160e-04 - val_loss: 4.6011e-04\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.4458e-04 - val_loss: 4.6655e-04\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.4209e-04 - val_loss: 4.5767e-04\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.3794e-04 - val_loss: 4.5564e-04\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.3786e-04 - val_loss: 4.5911e-04\n",
      "Thời gian huấn luyện:  13.57018256187439\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_85 (Dense)            (None, 10, 96)            192       \n",
      "                                                                 \n",
      " flatten_68 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,153\n",
      "Trainable params: 1,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "28/28 [==============================] - 1s 9ms/step - loss: 0.0962 - val_loss: 0.0066\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 9.8960e-04\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 9.8798e-04\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 9.4632e-04\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 9.3063e-04\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 9.2775e-04\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 9.5322e-04\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.8171e-04 - val_loss: 9.4637e-04\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.7922e-04 - val_loss: 9.4661e-04\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.6675e-04 - val_loss: 8.9476e-04\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.7422e-04 - val_loss: 9.1257e-04\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.7022e-04 - val_loss: 8.8919e-04\n",
      "Epoch 54/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 3ms/step - loss: 9.7474e-04 - val_loss: 9.2490e-04\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.5712e-04 - val_loss: 8.6899e-04\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.7047e-04 - val_loss: 8.6710e-04\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.3084e-04 - val_loss: 9.4873e-04\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 9.3493e-04 - val_loss: 8.4522e-04\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.2239e-04 - val_loss: 8.8073e-04\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.1089e-04 - val_loss: 8.6661e-04\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.0744e-04 - val_loss: 8.9054e-04\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 9.6213e-04 - val_loss: 8.2727e-04\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 8.9563e-04 - val_loss: 8.2082e-04\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 8.9806e-04 - val_loss: 8.6441e-04\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.8249e-04 - val_loss: 8.0545e-04\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 8.7102e-04 - val_loss: 8.0127e-04\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 8.9472e-04 - val_loss: 8.1456e-04\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 8.7983e-04 - val_loss: 7.9109e-04\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 8.6265e-04 - val_loss: 8.0740e-04\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.7354e-04 - val_loss: 7.7904e-04\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.5665e-04 - val_loss: 8.0154e-04\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.4139e-04 - val_loss: 7.8697e-04\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 8.3618e-04 - val_loss: 7.6431e-04\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 8.5567e-04 - val_loss: 7.6286e-04\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.4858e-04 - val_loss: 7.8712e-04\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.2981e-04 - val_loss: 7.4809e-04\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.2624e-04 - val_loss: 7.6161e-04\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.1682e-04 - val_loss: 7.7845e-04\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 8.0766e-04 - val_loss: 7.3762e-04\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 8.1093e-04 - val_loss: 7.3055e-04\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 8.1654e-04 - val_loss: 7.2610e-04\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.9186e-04 - val_loss: 7.3188e-04\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.2745e-04 - val_loss: 7.2071e-04\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.2329e-04 - val_loss: 8.6798e-04\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 8.0632e-04 - val_loss: 7.0963e-04\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.9136e-04 - val_loss: 7.0694e-04\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.9393e-04 - val_loss: 7.1864e-04\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.8157e-04 - val_loss: 8.0603e-04\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.8589e-04 - val_loss: 7.1403e-04\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.5643e-04 - val_loss: 6.9136e-04\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.9500e-04 - val_loss: 6.9121e-04\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.8125e-04 - val_loss: 6.8413e-04\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.7937e-04 - val_loss: 6.7997e-04\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.7439e-04 - val_loss: 7.6718e-04\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.5915e-04 - val_loss: 6.7286e-04\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.5057e-04 - val_loss: 6.9798e-04\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.4633e-04 - val_loss: 6.6338e-04\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.2791e-04 - val_loss: 6.5767e-04\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.4391e-04 - val_loss: 7.0392e-04\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.5631e-04 - val_loss: 6.7459e-04\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.2183e-04 - val_loss: 6.4745e-04\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.3098e-04 - val_loss: 6.6085e-04\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.3716e-04 - val_loss: 7.1698e-04\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.2889e-04 - val_loss: 6.9568e-04\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.1639e-04 - val_loss: 6.3682e-04\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.0567e-04 - val_loss: 6.5011e-04\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.1305e-04 - val_loss: 6.4725e-04\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.5437e-04 - val_loss: 6.5106e-04\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.2895e-04 - val_loss: 6.3797e-04\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.9480e-04 - val_loss: 6.3516e-04\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.9854e-04 - val_loss: 6.5071e-04\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.9330e-04 - val_loss: 6.1491e-04\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.0282e-04 - val_loss: 6.2426e-04\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.8386e-04 - val_loss: 6.3861e-04\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.7668e-04 - val_loss: 6.1888e-04\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.7243e-04 - val_loss: 5.9998e-04\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.9457e-04 - val_loss: 5.9821e-04\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.6633e-04 - val_loss: 6.1048e-04\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.7068e-04 - val_loss: 6.5049e-04\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.6468e-04 - val_loss: 6.1803e-04\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.9637e-04 - val_loss: 6.4309e-04\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.0009e-04 - val_loss: 6.3367e-04\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.5812e-04 - val_loss: 5.8745e-04\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.5172e-04 - val_loss: 5.9125e-04\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.5025e-04 - val_loss: 5.9031e-04\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.4900e-04 - val_loss: 5.7157e-04\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.5172e-04 - val_loss: 5.6923e-04\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.5510e-04 - val_loss: 5.7360e-04\n",
      "Epoch 129/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 4ms/step - loss: 6.4401e-04 - val_loss: 6.1048e-04\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.3956e-04 - val_loss: 6.2393e-04\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.7634e-04 - val_loss: 6.5587e-04\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.5478e-04 - val_loss: 5.7288e-04\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.6866e-04 - val_loss: 5.9776e-04\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.4559e-04 - val_loss: 5.5147e-04\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.4028e-04 - val_loss: 6.5772e-04\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.8580e-04 - val_loss: 5.5433e-04\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.1398e-04 - val_loss: 5.4540e-04\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.1425e-04 - val_loss: 5.5485e-04\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.2863e-04 - val_loss: 5.5040e-04\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.5290e-04 - val_loss: 5.4248e-04\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.4148e-04 - val_loss: 5.5431e-04\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.1892e-04 - val_loss: 5.7334e-04\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.0328e-04 - val_loss: 5.8912e-04\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.9631e-04 - val_loss: 5.4081e-04\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.0831e-04 - val_loss: 5.3208e-04\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.9396e-04 - val_loss: 5.2893e-04\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.9400e-04 - val_loss: 5.2904e-04\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.0768e-04 - val_loss: 5.2044e-04\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.1344e-04 - val_loss: 5.4375e-04\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.0172e-04 - val_loss: 5.2353e-04\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.7969e-04 - val_loss: 5.9036e-04\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.9144e-04 - val_loss: 5.5683e-04\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.8046e-04 - val_loss: 5.4100e-04\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.8868e-04 - val_loss: 5.0612e-04\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.8102e-04 - val_loss: 5.0896e-04\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.8574e-04 - val_loss: 5.1440e-04\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.8508e-04 - val_loss: 5.8086e-04\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.0235e-04 - val_loss: 5.9429e-04\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.2106e-04 - val_loss: 6.2582e-04\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.8267e-04 - val_loss: 5.2036e-04\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.0351e-04 - val_loss: 4.9855e-04\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.9764e-04 - val_loss: 4.9301e-04\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.9202e-04 - val_loss: 4.9319e-04\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.1056e-04 - val_loss: 5.3971e-04\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.8773e-04 - val_loss: 5.0017e-04\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.5699e-04 - val_loss: 5.0368e-04\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.5530e-04 - val_loss: 4.8306e-04\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.7213e-04 - val_loss: 4.8034e-04\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.6929e-04 - val_loss: 5.2375e-04\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.4802e-04 - val_loss: 4.8361e-04\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.5298e-04 - val_loss: 4.9839e-04\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.6592e-04 - val_loss: 4.7335e-04\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.5522e-04 - val_loss: 4.7241e-04\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.4864e-04 - val_loss: 5.7263e-04\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.7550e-04 - val_loss: 5.1202e-04\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.4235e-04 - val_loss: 4.6705e-04\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.5049e-04 - val_loss: 5.3296e-04\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.6070e-04 - val_loss: 4.6733e-04\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.3187e-04 - val_loss: 4.6145e-04\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.3475e-04 - val_loss: 4.5862e-04\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.4862e-04 - val_loss: 5.1205e-04\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.5945e-04 - val_loss: 4.5716e-04\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.3289e-04 - val_loss: 4.5562e-04\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.4022e-04 - val_loss: 4.5974e-04\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.4104e-04 - val_loss: 4.6330e-04\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.6520e-04 - val_loss: 4.5184e-04\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.4077e-04 - val_loss: 4.5761e-04\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.3630e-04 - val_loss: 4.6981e-04\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.5965e-04 - val_loss: 5.4616e-04\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.4828e-04 - val_loss: 4.8842e-04\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.2718e-04 - val_loss: 4.8525e-04\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.2704e-04 - val_loss: 4.5101e-04\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.1733e-04 - val_loss: 4.4472e-04\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.1395e-04 - val_loss: 4.4069e-04\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.1561e-04 - val_loss: 4.3757e-04\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.4220e-04 - val_loss: 5.4118e-04\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.2364e-04 - val_loss: 4.4590e-04\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.0655e-04 - val_loss: 4.3823e-04\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.1218e-04 - val_loss: 4.3241e-04\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.3635e-04 - val_loss: 4.8436e-04\n",
      "Thời gian huấn luyện:  20.329962730407715\n",
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_17 (SimpleRNN)   (None, 10, 96)            9408      \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " flatten_69 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,369\n",
      "Trainable params: 10,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "28/28 [==============================] - 2s 22ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Thời gian huấn luyện:  42.06900882720947\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_17 (LSTM)              (None, 10, 96)            37632     \n",
      "                                                                 \n",
      " flatten_70 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,593\n",
      "Trainable params: 38,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "28/28 [==============================] - 2s 17ms/step - loss: 0.0181 - val_loss: 0.0020\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 32/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 9.8540e-04\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 9.6228e-04\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 9.5380e-04\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 9.4544e-04\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 9.4324e-04\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.9695e-04 - val_loss: 9.2208e-04\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.7662e-04 - val_loss: 9.1444e-04\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.8025e-04 - val_loss: 8.9645e-04\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.5319e-04 - val_loss: 8.8234e-04\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.4821e-04 - val_loss: 8.6257e-04\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.4391e-04 - val_loss: 8.4892e-04\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.1556e-04 - val_loss: 8.4501e-04\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.2048e-04 - val_loss: 8.3425e-04\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.1580e-04 - val_loss: 8.7515e-04\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.9605e-04 - val_loss: 8.3145e-04\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.8826e-04 - val_loss: 8.3080e-04\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.8854e-04 - val_loss: 8.1120e-04\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.6944e-04 - val_loss: 8.0521e-04\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.6196e-04 - val_loss: 7.8808e-04\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.6094e-04 - val_loss: 7.7574e-04\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.6166e-04 - val_loss: 8.0175e-04\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.5291e-04 - val_loss: 7.6694e-04\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.3897e-04 - val_loss: 7.7113e-04\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 8.2756e-04 - val_loss: 7.6179e-04\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.2275e-04 - val_loss: 7.4573e-04\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.1879e-04 - val_loss: 7.4204e-04\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.0803e-04 - val_loss: 7.5024e-04\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.1076e-04 - val_loss: 7.2815e-04\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.0958e-04 - val_loss: 7.2574e-04\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.9062e-04 - val_loss: 7.2821e-04\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.8588e-04 - val_loss: 7.1379e-04\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.8316e-04 - val_loss: 7.4026e-04\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.8107e-04 - val_loss: 7.1118e-04\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.7068e-04 - val_loss: 7.0659e-04\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.6513e-04 - val_loss: 7.0586e-04\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.6320e-04 - val_loss: 6.9270e-04\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.6444e-04 - val_loss: 6.8993e-04\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 7.5007e-04 - val_loss: 6.9849e-04\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.4907e-04 - val_loss: 6.8134e-04\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.4181e-04 - val_loss: 6.8478e-04\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.3820e-04 - val_loss: 6.7625e-04\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.3071e-04 - val_loss: 6.6556e-04\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.2646e-04 - val_loss: 6.5892e-04\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.3555e-04 - val_loss: 6.7375e-04\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.2229e-04 - val_loss: 6.5275e-04\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.1091e-04 - val_loss: 6.5111e-04\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.0934e-04 - val_loss: 6.4643e-04\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.1716e-04 - val_loss: 6.4231e-04\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.0062e-04 - val_loss: 6.3742e-04\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.9685e-04 - val_loss: 6.3765e-04\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 7.0293e-04 - val_loss: 6.4544e-04\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.8988e-04 - val_loss: 6.3107e-04\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.8870e-04 - val_loss: 6.5570e-04\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 6.9385e-04 - val_loss: 6.2401e-04\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.8095e-04 - val_loss: 6.3591e-04\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.9125e-04 - val_loss: 6.1629e-04\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.6907e-04 - val_loss: 6.3002e-04\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.8890e-04 - val_loss: 6.0791e-04\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.6244e-04 - val_loss: 6.0510e-04\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.7150e-04 - val_loss: 6.1696e-04\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.6988e-04 - val_loss: 6.0016e-04\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 6.6231e-04 - val_loss: 6.2620e-04\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.5799e-04 - val_loss: 5.9042e-04\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 6.4833e-04 - val_loss: 6.0355e-04\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.5586e-04 - val_loss: 6.1357e-04\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.4041e-04 - val_loss: 5.8304e-04\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.6465e-04 - val_loss: 6.0150e-04\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.3619e-04 - val_loss: 5.8220e-04\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 6.3566e-04 - val_loss: 5.8871e-04\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.3275e-04 - val_loss: 5.7179e-04\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4478e-04 - val_loss: 5.7757e-04\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.2667e-04 - val_loss: 5.6795e-04\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.2581e-04 - val_loss: 5.6893e-04\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.3161e-04 - val_loss: 5.8253e-04\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.1660e-04 - val_loss: 5.6740e-04\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 6.1504e-04 - val_loss: 5.5498e-04\n",
      "Epoch 108/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0940e-04 - val_loss: 5.6059e-04\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.1137e-04 - val_loss: 5.5156e-04\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.0982e-04 - val_loss: 5.5081e-04\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.0599e-04 - val_loss: 5.7495e-04\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.1221e-04 - val_loss: 5.4522e-04\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.1296e-04 - val_loss: 5.5447e-04\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.1665e-04 - val_loss: 5.5316e-04\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 5.9584e-04 - val_loss: 5.4075e-04\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.9341e-04 - val_loss: 5.6959e-04\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.9172e-04 - val_loss: 5.3949e-04\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.8891e-04 - val_loss: 5.3571e-04\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.9728e-04 - val_loss: 5.7175e-04\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8657e-04 - val_loss: 5.2689e-04\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.7819e-04 - val_loss: 5.3725e-04\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8262e-04 - val_loss: 5.2297e-04\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.7933e-04 - val_loss: 5.2647e-04\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.8610e-04 - val_loss: 5.3580e-04\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.0152e-04 - val_loss: 5.2467e-04\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.7543e-04 - val_loss: 5.2222e-04\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.9927e-04 - val_loss: 5.6423e-04\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.7912e-04 - val_loss: 5.1073e-04\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.9128e-04 - val_loss: 5.1427e-04\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.6713e-04 - val_loss: 5.1716e-04\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.6142e-04 - val_loss: 5.3843e-04\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.6544e-04 - val_loss: 5.0516e-04\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.6051e-04 - val_loss: 5.0251e-04\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.5566e-04 - val_loss: 5.0812e-04\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.6041e-04 - val_loss: 5.0056e-04\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.5028e-04 - val_loss: 5.4342e-04\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.6276e-04 - val_loss: 5.0089e-04\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.4993e-04 - val_loss: 5.1262e-04\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.6380e-04 - val_loss: 4.9205e-04\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.4885e-04 - val_loss: 4.8968e-04\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.5363e-04 - val_loss: 4.9031e-04\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 5.4927e-04 - val_loss: 5.0149e-04\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 5.4950e-04 - val_loss: 5.0947e-04\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 5.3892e-04 - val_loss: 4.8615e-04\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.4219e-04 - val_loss: 4.8611e-04\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.4588e-04 - val_loss: 4.8607e-04\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.4227e-04 - val_loss: 4.8924e-04\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.5694e-04 - val_loss: 5.0610e-04\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.5114e-04 - val_loss: 4.7849e-04\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.4630e-04 - val_loss: 4.7421e-04\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.3103e-04 - val_loss: 4.7260e-04\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.4466e-04 - val_loss: 5.1287e-04\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.3716e-04 - val_loss: 4.6935e-04\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.2701e-04 - val_loss: 4.6761e-04\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.3333e-04 - val_loss: 4.9747e-04\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.2354e-04 - val_loss: 4.6796e-04\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.2403e-04 - val_loss: 4.6649e-04\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.1863e-04 - val_loss: 4.7820e-04\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.2862e-04 - val_loss: 4.6033e-04\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.1811e-04 - val_loss: 4.6592e-04\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.1783e-04 - val_loss: 4.6283e-04\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 5.1599e-04 - val_loss: 4.5644e-04\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2018e-04 - val_loss: 4.6135e-04\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.2975e-04 - val_loss: 4.7870e-04\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.1692e-04 - val_loss: 4.5324e-04\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.3308e-04 - val_loss: 4.9810e-04\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.1073e-04 - val_loss: 4.4992e-04\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.0590e-04 - val_loss: 4.4931e-04\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.2084e-04 - val_loss: 4.8134e-04\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.0979e-04 - val_loss: 4.5404e-04\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.0184e-04 - val_loss: 4.4374e-04\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.0237e-04 - val_loss: 4.4273e-04\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.0650e-04 - val_loss: 4.5639e-04\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.0065e-04 - val_loss: 4.5034e-04\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 4.9474e-04 - val_loss: 4.4213e-04\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.0153e-04 - val_loss: 4.5940e-04\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 4.9823e-04 - val_loss: 4.3592e-04\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 4.9476e-04 - val_loss: 4.4346e-04\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 4.9080e-04 - val_loss: 4.6930e-04\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 5.0137e-04 - val_loss: 4.3402e-04\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 4.9141e-04 - val_loss: 4.3850e-04\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 4.9269e-04 - val_loss: 4.3886e-04\n",
      "Epoch 183/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 7ms/step - loss: 4.9419e-04 - val_loss: 4.6064e-04\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 4.9047e-04 - val_loss: 4.2828e-04\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 4.9085e-04 - val_loss: 4.9095e-04\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 5.0505e-04 - val_loss: 4.2449e-04\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 4.8572e-04 - val_loss: 4.6346e-04\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 4.8670e-04 - val_loss: 4.5269e-04\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 4.8689e-04 - val_loss: 4.4050e-04\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 4.8638e-04 - val_loss: 4.2043e-04\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 4.8104e-04 - val_loss: 4.3903e-04\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 4.7856e-04 - val_loss: 4.2281e-04\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 4.7987e-04 - val_loss: 4.2432e-04\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 4.8110e-04 - val_loss: 4.2457e-04\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 4.7585e-04 - val_loss: 4.2338e-04\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 4.8164e-04 - val_loss: 4.1310e-04\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 4.7501e-04 - val_loss: 4.1421e-04\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 4.7886e-04 - val_loss: 4.1754e-04\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 4.8778e-04 - val_loss: 4.1117e-04\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 4.7453e-04 - val_loss: 4.2219e-04\n",
      "Thời gian huấn luyện:  39.72018599510193\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_17 (GRU)                (None, 10, 96)            28512     \n",
      "                                                                 \n",
      " flatten_71 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,473\n",
      "Trainable params: 29,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "35/35 [==============================] - 0s 941us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0515 - val_loss: 0.0047\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 5.7810e-04\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 6.2056e-04\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 5.9266e-04\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 5.8795e-04\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 6.1971e-04\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 5.8766e-04\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 5.3020e-04\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 5.8034e-04\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 5.6732e-04\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 5.9191e-04\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 5.3062e-04\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 5.2579e-04\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 5.7511e-04\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 5.2515e-04\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.3809e-04\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.2492e-04\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.2621e-04\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.2346e-04\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.2421e-04\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.2460e-04\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.2911e-04\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.2640e-04\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 5.2865e-04\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 5.1723e-04\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 5.1012e-04\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 5.1833e-04\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 5.2359e-04\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 5.0118e-04\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.9921e-04\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.1117e-04\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.0277e-04\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.1653e-04\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.8570e-04\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.9355e-04\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.7876e-04\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.7603e-04\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.9787e-04\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.7038e-04\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.6859e-04\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.6243e-04\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.6498e-04\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.5800e-04\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.5330e-04\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.5698e-04\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.4571e-04\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.4945e-04\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.3925e-04\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.3733e-04\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 4.3245e-04\n",
      "Thời gian huấn luyện:  3.7347781658172607\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_90 (Dense)            (None, 10, 103)           206       \n",
      "                                                                 \n",
      " flatten_72 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,237\n",
      "Trainable params: 1,237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 1s 7ms/step - loss: 0.0070 - val_loss: 7.8200e-04\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 6.3081e-04\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 6.0455e-04\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 5.3405e-04\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 4.9411e-04\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 4.7308e-04\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 4.5191e-04\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 4.3994e-04\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 4.5850e-04\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 9.9034e-04 - val_loss: 4.3556e-04\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 9.9073e-04 - val_loss: 4.9546e-04\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 9.2797e-04 - val_loss: 4.1730e-04\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.8501e-04 - val_loss: 3.9637e-04\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.7380e-04 - val_loss: 3.9470e-04\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.5378e-04 - val_loss: 4.1442e-04\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.3622e-04 - val_loss: 4.0434e-04\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.2458e-04 - val_loss: 4.4767e-04\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.9738e-04 - val_loss: 3.7458e-04\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.2798e-04 - val_loss: 7.1781e-04\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.0344e-04 - val_loss: 3.6246e-04\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.6435e-04 - val_loss: 3.9177e-04\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.6019e-04 - val_loss: 3.9922e-04\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.6099e-04 - val_loss: 4.3109e-04\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.3428e-04 - val_loss: 3.5270e-04\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.3708e-04 - val_loss: 3.9091e-04\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.3781e-04 - val_loss: 3.7428e-04\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.2522e-04 - val_loss: 3.4895e-04\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.9762e-04 - val_loss: 3.3854e-04\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.1444e-04 - val_loss: 4.6429e-04\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.8895e-04 - val_loss: 3.3403e-04\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.8439e-04 - val_loss: 3.3123e-04\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.8506e-04 - val_loss: 3.3237e-04\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.6424e-04 - val_loss: 3.3032e-04\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.8387e-04 - val_loss: 3.5477e-04\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.7206e-04 - val_loss: 3.2485e-04\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.7562e-04 - val_loss: 3.2405e-04\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.4528e-04 - val_loss: 3.1849e-04\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.5816e-04 - val_loss: 3.1840e-04\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.3243e-04 - val_loss: 3.1487e-04\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.5894e-04 - val_loss: 3.1343e-04\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.1838e-04 - val_loss: 3.1197e-04\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.0978e-04 - val_loss: 3.1995e-04\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.1402e-04 - val_loss: 3.4050e-04\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.1714e-04 - val_loss: 3.2664e-04\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.9854e-04 - val_loss: 3.4319e-04\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.0318e-04 - val_loss: 3.1362e-04\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.0067e-04 - val_loss: 3.0974e-04\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.0191e-04 - val_loss: 3.0053e-04\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.0725e-04 - val_loss: 2.9983e-04\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.7788e-04 - val_loss: 3.0223e-04\n",
      "Thời gian huấn luyện:  6.351500749588013\n",
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_18 (SimpleRNN)   (None, 10, 103)           10815     \n",
      "                                                                 \n",
      " flatten_73 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,846\n",
      "Trainable params: 11,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 2s 16ms/step - loss: 0.0358 - val_loss: 0.0012\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0024 - val_loss: 6.4968e-04\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 6.5912e-04\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 6.7035e-04\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 6.7201e-04\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 6.7042e-04\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 7.3347e-04\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 7.3588e-04\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 6.6006e-04\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 6.5645e-04\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 6.5866e-04\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 6.5029e-04\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 6.4166e-04\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 6.3665e-04\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 6.3165e-04\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 6.2550e-04\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 6.3428e-04\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 6.2706e-04\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 6.3570e-04\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 6.1427e-04\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 6.0151e-04\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 5.9355e-04\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 6.0256e-04\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 5.9738e-04\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 5.7711e-04\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 5.8225e-04\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 5.9924e-04\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 5.7501e-04\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 5.6074e-04\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 5.9967e-04\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 5.4948e-04\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 5.7367e-04\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 5.3880e-04\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 5.4999e-04\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 5.2564e-04\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 5.3497e-04\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 5.2484e-04\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.2396e-04\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 5.0274e-04\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.0027e-04\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.3667e-04\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.5022e-04\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 4.9721e-04\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.4962e-04\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.3617e-04\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.2677e-04\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 4.7721e-04\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.1071e-04\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.2940e-04\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 4.6761e-04\n",
      "Thời gian huấn luyện:  14.368176221847534\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_18 (LSTM)              (None, 10, 103)           43260     \n",
      "                                                                 \n",
      " flatten_74 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,291\n",
      "Trainable params: 44,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 2s 15ms/step - loss: 0.0111 - val_loss: 7.8211e-04\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 5.4311e-04\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 5.5574e-04\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 5.4961e-04\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 5.4146e-04\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 5.3074e-04\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 5.2362e-04\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 5.1176e-04\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 5.1195e-04\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 4.9602e-04\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 4.9287e-04\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 4.9462e-04\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 4.8526e-04\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 4.6361e-04\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 4.5394e-04\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 4.4596e-04\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 4.6561e-04\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 4.3104e-04\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 4.3031e-04\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.9664e-04 - val_loss: 4.1642e-04\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.7659e-04 - val_loss: 4.1719e-04\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.6867e-04 - val_loss: 4.0605e-04\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.3940e-04 - val_loss: 4.0404e-04\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.1882e-04 - val_loss: 3.9395e-04\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.0313e-04 - val_loss: 3.9833e-04\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 8.8472e-04 - val_loss: 3.8565e-04\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 8.6722e-04 - val_loss: 3.8017e-04\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 8.5866e-04 - val_loss: 3.7767e-04\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 8.4273e-04 - val_loss: 3.7665e-04\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 8.2250e-04 - val_loss: 3.6924e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 8.0823e-04 - val_loss: 3.6891e-04\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 8.0127e-04 - val_loss: 3.6693e-04\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.8592e-04 - val_loss: 3.6476e-04\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.8589e-04 - val_loss: 3.6174e-04\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6972e-04 - val_loss: 3.7954e-04\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.7509e-04 - val_loss: 3.5896e-04\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6276e-04 - val_loss: 3.6242e-04\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.5041e-04 - val_loss: 3.6915e-04\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.4181e-04 - val_loss: 3.4679e-04\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.3986e-04 - val_loss: 3.7384e-04\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.3428e-04 - val_loss: 3.4398e-04\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.2089e-04 - val_loss: 3.4521e-04\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.1454e-04 - val_loss: 3.4285e-04\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.0683e-04 - val_loss: 3.6111e-04\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.1404e-04 - val_loss: 3.4238e-04\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.9797e-04 - val_loss: 3.5336e-04\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.9776e-04 - val_loss: 3.4128e-04\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.8376e-04 - val_loss: 3.4046e-04\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.8365e-04 - val_loss: 3.4095e-04\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.7637e-04 - val_loss: 3.2923e-04\n",
      "Thời gian huấn luyện:  13.569928169250488\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_18 (GRU)                (None, 10, 103)           32754     \n",
      "                                                                 \n",
      " flatten_75 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,785\n",
      "Trainable params: 33,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 0s 898us/step\n",
      "10/10 [==============================] - 0s 999us/step\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Thời gian huấn luyện:  3.776926040649414\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_95 (Dense)            (None, 10, 103)           206       \n",
      "                                                                 \n",
      " flatten_76 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,237\n",
      "Trainable params: 1,237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 1s 7ms/step - loss: 0.0107 - val_loss: 0.0023\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 9.0512e-04\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 8.1187e-04\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 7.5178e-04\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 7.0173e-04\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 6.7031e-04\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9.7162e-04 - val_loss: 6.5647e-04\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9.3785e-04 - val_loss: 6.2359e-04\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9.1042e-04 - val_loss: 6.1354e-04\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8.5900e-04 - val_loss: 5.8597e-04\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8.5923e-04 - val_loss: 5.7154e-04\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8.5884e-04 - val_loss: 5.8673e-04\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8.2589e-04 - val_loss: 5.5583e-04\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.7809e-04 - val_loss: 5.3863e-04\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.7083e-04 - val_loss: 5.6057e-04\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.5707e-04 - val_loss: 5.4283e-04\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.4360e-04 - val_loss: 5.0341e-04\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.2434e-04 - val_loss: 5.1163e-04\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.2198e-04 - val_loss: 5.2630e-04\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.1685e-04 - val_loss: 4.8600e-04\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.5395e-04 - val_loss: 5.0170e-04\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.1646e-04 - val_loss: 6.4720e-04\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.0513e-04 - val_loss: 4.7782e-04\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.6857e-04 - val_loss: 4.6551e-04\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.6568e-04 - val_loss: 4.6902e-04\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.4953e-04 - val_loss: 5.0157e-04\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.6905e-04 - val_loss: 5.0978e-04\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.6095e-04 - val_loss: 4.6751e-04\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.3774e-04 - val_loss: 4.4236e-04\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.1719e-04 - val_loss: 4.3929e-04\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.2488e-04 - val_loss: 4.3553e-04\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.1479e-04 - val_loss: 4.3203e-04\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.1390e-04 - val_loss: 4.5295e-04\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.9912e-04 - val_loss: 4.3035e-04\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.2632e-04 - val_loss: 4.2666e-04\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.1708e-04 - val_loss: 4.7603e-04\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.0658e-04 - val_loss: 4.6603e-04\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.2051e-04 - val_loss: 4.6125e-04\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.9724e-04 - val_loss: 4.4585e-04\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.2262e-04 - val_loss: 4.0976e-04\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.8202e-04 - val_loss: 4.1374e-04\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.7368e-04 - val_loss: 4.0405e-04\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.6861e-04 - val_loss: 4.0247e-04\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.8509e-04 - val_loss: 4.1742e-04\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.6438e-04 - val_loss: 3.9784e-04\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.5579e-04 - val_loss: 4.0488e-04\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.5548e-04 - val_loss: 3.9641e-04\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.6087e-04 - val_loss: 4.1876e-04\n",
      "Thời gian huấn luyện:  6.222161293029785\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_19 (SimpleRNN)   (None, 10, 103)           10815     \n",
      "                                                                 \n",
      " flatten_77 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,846\n",
      "Trainable params: 11,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 2s 17ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Thời gian huấn luyện:  13.960326433181763\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_19 (LSTM)              (None, 10, 103)           43260     \n",
      "                                                                 \n",
      " flatten_78 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,291\n",
      "Trainable params: 44,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 2s 15ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Thời gian huấn luyện:  12.790480613708496\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_19 (GRU)                (None, 10, 103)           32754     \n",
      "                                                                 \n",
      " flatten_79 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,785\n",
      "Trainable params: 33,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 0s 923us/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0469 - val_loss: 0.0020\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0017\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0016\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0015\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0010\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 9.6514e-04\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 9.1875e-04\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 9.0952e-04\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 8.4243e-04\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 8.3339e-04\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 8.0422e-04\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.8289e-04\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.6986e-04\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.7285e-04\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.5716e-04\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.3630e-04\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.4196e-04\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.2968e-04\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.2677e-04\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.2748e-04\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.3116e-04\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.1305e-04\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.1803e-04\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.0455e-04\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.2291e-04\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.0702e-04\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.8916e-04\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.9114e-04\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.0641e-04\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.8303e-04\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.8061e-04\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.8264e-04\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.6847e-04\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.7639e-04\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.7247e-04\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.6192e-04\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 6.5591e-04\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 6.5074e-04\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 6.3758e-04\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 6.3161e-04\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 6.3055e-04\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 6.2394e-04\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.9908e-04 - val_loss: 6.2902e-04\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.9001e-04 - val_loss: 6.1959e-04\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.8537e-04 - val_loss: 6.1826e-04\n",
      "Thời gian huấn luyện:  3.74310564994812\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_100 (Dense)           (None, 10, 103)           206       \n",
      "                                                                 \n",
      " flatten_80 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,237\n",
      "Trainable params: 1,237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 1s 8ms/step - loss: 0.0418 - val_loss: 0.0034\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 9.6832e-04\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 9.5806e-04\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 8.8546e-04\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 8.7807e-04\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 8.1855e-04\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 8.0871e-04\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 7.7544e-04\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 7.4906e-04\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 7.2522e-04\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 7.1022e-04\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.9027e-04\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.8150e-04\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.6280e-04\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.5774e-04\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 6.3954e-04\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 7.1806e-04\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 6.2270e-04\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 6.1758e-04\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.8443e-04 - val_loss: 6.1497e-04\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.7330e-04 - val_loss: 6.2142e-04\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.6155e-04 - val_loss: 5.8933e-04\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.5285e-04 - val_loss: 5.8032e-04\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.3959e-04 - val_loss: 5.8172e-04\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.2489e-04 - val_loss: 5.6959e-04\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.1723e-04 - val_loss: 6.1058e-04\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.2979e-04 - val_loss: 5.5448e-04\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.9804e-04 - val_loss: 5.4868e-04\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.8596e-04 - val_loss: 5.4455e-04\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.8584e-04 - val_loss: 6.5194e-04\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.7355e-04 - val_loss: 5.3683e-04\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.5877e-04 - val_loss: 6.4719e-04\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.6327e-04 - val_loss: 5.3800e-04\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.6070e-04 - val_loss: 5.1856e-04\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.4189e-04 - val_loss: 5.4457e-04\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.2243e-04 - val_loss: 5.1079e-04\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.1680e-04 - val_loss: 5.0659e-04\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.1768e-04 - val_loss: 4.9983e-04\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.0206e-04 - val_loss: 5.1542e-04\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.0889e-04 - val_loss: 4.9206e-04\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.9221e-04 - val_loss: 4.8786e-04\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.8668e-04 - val_loss: 6.3193e-04\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.4565e-04 - val_loss: 5.9261e-04\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.1209e-04 - val_loss: 4.7911e-04\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.9722e-04 - val_loss: 4.7443e-04\n",
      "Thời gian huấn luyện:  6.1780900955200195\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_20 (SimpleRNN)   (None, 10, 103)           10815     \n",
      "                                                                 \n",
      " flatten_81 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,846\n",
      "Trainable params: 11,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 2s 18ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Thời gian huấn luyện:  13.688827991485596\n",
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_20 (LSTM)              (None, 10, 103)           43260     \n",
      "                                                                 \n",
      " flatten_82 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,291\n",
      "Trainable params: 44,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 2s 16ms/step - loss: 0.0241 - val_loss: 0.0017\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 9.9281e-04\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 9.5364e-04\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 9.3798e-04\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 9.1741e-04\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 9.1086e-04\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 8.7673e-04\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 8.5933e-04\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 8.4821e-04\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 8.7793e-04\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 8.6031e-04\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 8.2304e-04\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 7.6544e-04\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 7.5235e-04\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 7.3311e-04\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 7.1291e-04\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 6.9892e-04\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 7.0465e-04\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 6.7517e-04\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 6.6750e-04\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 6.4092e-04\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 6.2869e-04\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 6.1514e-04\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.8277e-04 - val_loss: 6.1261e-04\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.6879e-04 - val_loss: 6.5379e-04\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.5722e-04 - val_loss: 5.8613e-04\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.3512e-04 - val_loss: 6.1443e-04\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.2300e-04 - val_loss: 6.3678e-04\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.0392e-04 - val_loss: 5.5526e-04\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.8639e-04 - val_loss: 5.8992e-04\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.9000e-04 - val_loss: 5.4881e-04\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.6340e-04 - val_loss: 5.3650e-04\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.4922e-04 - val_loss: 5.3434e-04\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 8.5272e-04 - val_loss: 5.4586e-04\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.3285e-04 - val_loss: 5.1907e-04\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.2755e-04 - val_loss: 5.6376e-04\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.2166e-04 - val_loss: 5.2386e-04\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.2536e-04 - val_loss: 5.0890e-04\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.4156e-04 - val_loss: 5.0484e-04\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.0344e-04 - val_loss: 5.8914e-04\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.9292e-04 - val_loss: 4.9539e-04\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.8776e-04 - val_loss: 5.4980e-04\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.8030e-04 - val_loss: 5.6887e-04\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.7896e-04 - val_loss: 5.0045e-04\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.7914e-04 - val_loss: 4.8594e-04\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.5875e-04 - val_loss: 5.2217e-04\n",
      "Thời gian huấn luyện:  12.706525802612305\n",
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_20 (GRU)                (None, 10, 103)           32754     \n",
      "                                                                 \n",
      " flatten_83 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,785\n",
      "Trainable params: 33,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Thời gian huấn luyện:  7.204378604888916\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_105 (Dense)           (None, 10, 103)           206       \n",
      "                                                                 \n",
      " flatten_84 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,237\n",
      "Trainable params: 1,237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "36/36 [==============================] - 1s 7ms/step - loss: 0.0408 - val_loss: 0.0035\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0033 - val_loss: 0.0010\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 8.7495e-04\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 8.1093e-04\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 7.5675e-04\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 7.3467e-04\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 6.7346e-04\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 7.0337e-04\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 6.6031e-04\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 5.9390e-04\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 5.8267e-04\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 6.2704e-04\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 5.3868e-04\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 5.2934e-04\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 5.1872e-04\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 5.4346e-04\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 5.4052e-04\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 4.8894e-04\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 5.2577e-04\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 4.7840e-04\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 4.8654e-04\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 4.6392e-04\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 4.6466e-04\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 4.8691e-04\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 4.4763e-04\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 4.4339e-04\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 9.8501e-04 - val_loss: 4.4314e-04\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 3ms/step - loss: 9.8387e-04 - val_loss: 4.7881e-04\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 9.6364e-04 - val_loss: 4.2911e-04\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 9.7049e-04 - val_loss: 4.2749e-04\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 9.3672e-04 - val_loss: 4.3071e-04\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 9.1793e-04 - val_loss: 4.2291e-04\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 9.1634e-04 - val_loss: 4.2472e-04\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.9613e-04 - val_loss: 4.1240e-04\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.8623e-04 - val_loss: 4.3714e-04\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.7200e-04 - val_loss: 4.1223e-04\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.7240e-04 - val_loss: 3.9969e-04\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.5156e-04 - val_loss: 4.4947e-04\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.7776e-04 - val_loss: 4.1247e-04\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.3118e-04 - val_loss: 3.9547e-04\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.2234e-04 - val_loss: 3.8763e-04\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.2043e-04 - val_loss: 3.8131e-04\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.1033e-04 - val_loss: 3.7788e-04\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.0453e-04 - val_loss: 4.1424e-04\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.8854e-04 - val_loss: 3.7314e-04\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.7837e-04 - val_loss: 3.6957e-04\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.6866e-04 - val_loss: 3.6850e-04\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.7725e-04 - val_loss: 3.8032e-04\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.6687e-04 - val_loss: 4.4587e-04\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.5485e-04 - val_loss: 3.5808e-04\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.3870e-04 - val_loss: 3.7693e-04\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.4360e-04 - val_loss: 3.5403e-04\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.2177e-04 - val_loss: 3.5271e-04\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.2408e-04 - val_loss: 3.5062e-04\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.4961e-04 - val_loss: 3.4675e-04\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.0726e-04 - val_loss: 3.5094e-04\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.0225e-04 - val_loss: 3.7064e-04\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.9134e-04 - val_loss: 3.4485e-04\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.8774e-04 - val_loss: 3.4813e-04\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.0108e-04 - val_loss: 3.6276e-04\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.7810e-04 - val_loss: 3.6066e-04\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.9840e-04 - val_loss: 3.3343e-04\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.0137e-04 - val_loss: 3.4566e-04\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.6912e-04 - val_loss: 3.7711e-04\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.6533e-04 - val_loss: 3.3607e-04\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.6078e-04 - val_loss: 3.2730e-04\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.8228e-04 - val_loss: 3.3978e-04\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.5525e-04 - val_loss: 3.2607e-04\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.3800e-04 - val_loss: 3.2685e-04\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.3262e-04 - val_loss: 3.2679e-04\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.3654e-04 - val_loss: 3.2963e-04\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.3094e-04 - val_loss: 3.4637e-04\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.2695e-04 - val_loss: 3.5306e-04\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.4249e-04 - val_loss: 3.4873e-04\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.7619e-04 - val_loss: 3.1860e-04\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.3713e-04 - val_loss: 3.1786e-04\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.1295e-04 - val_loss: 3.1874e-04\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.1483e-04 - val_loss: 3.1051e-04\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.0058e-04 - val_loss: 3.4927e-04\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.1432e-04 - val_loss: 3.4794e-04\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.1477e-04 - val_loss: 3.0367e-04\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.0144e-04 - val_loss: 3.0200e-04\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.9552e-04 - val_loss: 3.0400e-04\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.0290e-04 - val_loss: 3.0488e-04\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.8967e-04 - val_loss: 3.1904e-04\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.9498e-04 - val_loss: 3.0118e-04\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.8110e-04 - val_loss: 3.4655e-04\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.8614e-04 - val_loss: 3.0055e-04\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.1978e-04 - val_loss: 3.0515e-04\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.7724e-04 - val_loss: 2.9995e-04\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.8284e-04 - val_loss: 3.1927e-04\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.6811e-04 - val_loss: 3.0189e-04\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.6657e-04 - val_loss: 3.0132e-04\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.5996e-04 - val_loss: 3.2351e-04\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.6239e-04 - val_loss: 3.5242e-04\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.7094e-04 - val_loss: 2.8720e-04\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.7093e-04 - val_loss: 3.0402e-04\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.7262e-04 - val_loss: 2.9241e-04\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.4976e-04 - val_loss: 2.8547e-04\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.6950e-04 - val_loss: 2.8762e-04\n",
      "Thời gian huấn luyện:  11.859864711761475\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_21 (SimpleRNN)   (None, 10, 103)           10815     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " flatten_85 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,846\n",
      "Trainable params: 11,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "36/36 [==============================] - 2s 16ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Thời gian huấn luyện:  26.969664573669434\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_21 (LSTM)              (None, 10, 103)           43260     \n",
      "                                                                 \n",
      " flatten_86 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,291\n",
      "Trainable params: 44,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "36/36 [==============================] - 2s 26ms/step - loss: 0.0137 - val_loss: 0.0013\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 5.9559e-04\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 5.4886e-04\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 5.6173e-04\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 5.3451e-04\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 5.2939e-04\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 5.2927e-04\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 5.1581e-04\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 5.2167e-04\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.3784e-04\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 4.9663e-04\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 4.8728e-04\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 4.8494e-04\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 4.8245e-04\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 4.7335e-04\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 4.6350e-04\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 4.5690e-04\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 4.4999e-04\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 4.6871e-04\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 4.3684e-04\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 4.3130e-04\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 4.3130e-04\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.9053e-04 - val_loss: 4.2521e-04\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.6392e-04 - val_loss: 4.1782e-04\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.5034e-04 - val_loss: 4.1325e-04\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.3492e-04 - val_loss: 4.1130e-04\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.2076e-04 - val_loss: 4.5909e-04\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.1705e-04 - val_loss: 4.1146e-04\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 8.9425e-04 - val_loss: 3.9924e-04\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 8.8222e-04 - val_loss: 3.9405e-04\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.8015e-04 - val_loss: 4.0310e-04\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 8.7997e-04 - val_loss: 4.5248e-04\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.5530e-04 - val_loss: 3.8948e-04\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.4546e-04 - val_loss: 3.8332e-04\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.2995e-04 - val_loss: 3.8798e-04\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.2079e-04 - val_loss: 3.7823e-04\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.1329e-04 - val_loss: 3.8048e-04\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.0908e-04 - val_loss: 3.7447e-04\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 8.0201e-04 - val_loss: 4.0012e-04\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.9615e-04 - val_loss: 4.0972e-04\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.8600e-04 - val_loss: 3.8011e-04\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.9300e-04 - val_loss: 3.7245e-04\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.7034e-04 - val_loss: 3.7029e-04\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6907e-04 - val_loss: 3.6393e-04\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.8476e-04 - val_loss: 3.9454e-04\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6114e-04 - val_loss: 3.6633e-04\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 6ms/step - loss: 7.4861e-04 - val_loss: 3.6244e-04\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.4953e-04 - val_loss: 3.8474e-04\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.4381e-04 - val_loss: 3.5615e-04\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.3947e-04 - val_loss: 3.6426e-04\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.4757e-04 - val_loss: 3.7693e-04\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.3080e-04 - val_loss: 3.5534e-04\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.1904e-04 - val_loss: 3.5032e-04\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.2982e-04 - val_loss: 3.9103e-04\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.1687e-04 - val_loss: 3.5001e-04\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.1616e-04 - val_loss: 3.7516e-04\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.2182e-04 - val_loss: 3.4515e-04\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.9794e-04 - val_loss: 3.4822e-04\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.0915e-04 - val_loss: 3.4104e-04\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.8868e-04 - val_loss: 3.3774e-04\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.8580e-04 - val_loss: 3.7307e-04\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.7584e-04 - val_loss: 3.3619e-04\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.7647e-04 - val_loss: 3.4739e-04\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.7408e-04 - val_loss: 3.4233e-04\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.7464e-04 - val_loss: 3.4221e-04\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.7582e-04 - val_loss: 3.3617e-04\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.5686e-04 - val_loss: 3.5949e-04\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.5915e-04 - val_loss: 3.2781e-04\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.5149e-04 - val_loss: 3.5195e-04\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.6353e-04 - val_loss: 3.3057e-04\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.4549e-04 - val_loss: 3.3210e-04\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.3847e-04 - val_loss: 3.2400e-04\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.3834e-04 - val_loss: 3.5243e-04\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.4493e-04 - val_loss: 3.2088e-04\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.3028e-04 - val_loss: 3.1950e-04\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.2833e-04 - val_loss: 3.2477e-04\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.2626e-04 - val_loss: 3.3768e-04\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.2365e-04 - val_loss: 3.1756e-04\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.1645e-04 - val_loss: 3.1562e-04\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.1785e-04 - val_loss: 3.1804e-04\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.3571e-04 - val_loss: 3.2899e-04\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.1782e-04 - val_loss: 3.1189e-04\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.1410e-04 - val_loss: 3.1040e-04\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.0022e-04 - val_loss: 3.1112e-04\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.0493e-04 - val_loss: 3.0858e-04\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.9577e-04 - val_loss: 3.3599e-04\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.0901e-04 - val_loss: 3.0713e-04\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.9738e-04 - val_loss: 3.1326e-04\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.9739e-04 - val_loss: 3.0514e-04\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.8898e-04 - val_loss: 3.0516e-04\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.8684e-04 - val_loss: 3.0601e-04\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.8049e-04 - val_loss: 3.0210e-04\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.8626e-04 - val_loss: 3.1999e-04\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.7892e-04 - val_loss: 3.0365e-04\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.7948e-04 - val_loss: 3.0045e-04\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.7024e-04 - val_loss: 2.9972e-04\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.7348e-04 - val_loss: 2.9822e-04\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.7157e-04 - val_loss: 3.0771e-04\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.7448e-04 - val_loss: 2.9554e-04\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.6338e-04 - val_loss: 2.9569e-04\n",
      "Thời gian huấn luyện:  25.85622811317444\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_21 (GRU)                (None, 10, 103)           32754     \n",
      "                                                                 \n",
      " flatten_87 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,785\n",
      "Trainable params: 33,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 0s 919us/step\n",
      "10/10 [==============================] - 0s 1000us/step\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0415 - val_loss: 0.0014\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0013\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0010\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 9.8671e-04\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 9.4421e-04\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 9.1069e-04\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 8.8289e-04\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 8.6046e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 8.4355e-04\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 8.3913e-04\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 8.2138e-04\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.1847e-04\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.1252e-04\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 8.1582e-04\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 8.0003e-04\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.9635e-04\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.9174e-04\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 8.0125e-04\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 8.0122e-04\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.8419e-04\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.7575e-04\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.7307e-04\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.6536e-04\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.6714e-04\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.5418e-04\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.5128e-04\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.5115e-04\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.3722e-04\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.5150e-04\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.3280e-04\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.2033e-04\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 7.1700e-04\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 7.1153e-04\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 7.0853e-04\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 7.0187e-04\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 7.0282e-04\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 6.8528e-04\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9.8740e-04 - val_loss: 6.7566e-04\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9.8058e-04 - val_loss: 6.7300e-04\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9.6863e-04 - val_loss: 6.6932e-04\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9.5790e-04 - val_loss: 6.8606e-04\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9.5375e-04 - val_loss: 6.5379e-04\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9.3911e-04 - val_loss: 6.4983e-04\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9.2989e-04 - val_loss: 6.3994e-04\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9.2309e-04 - val_loss: 6.3167e-04\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9.1086e-04 - val_loss: 6.3183e-04\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9.0657e-04 - val_loss: 6.3682e-04\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8.9662e-04 - val_loss: 6.2058e-04\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8.8777e-04 - val_loss: 6.1452e-04\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8.7625e-04 - val_loss: 6.1695e-04\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8.6544e-04 - val_loss: 5.9627e-04\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8.6415e-04 - val_loss: 6.1266e-04\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8.5456e-04 - val_loss: 5.8539e-04\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8.4040e-04 - val_loss: 5.7883e-04\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8.3156e-04 - val_loss: 5.8602e-04\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8.2732e-04 - val_loss: 5.6767e-04\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8.1675e-04 - val_loss: 5.7635e-04\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8.0914e-04 - val_loss: 5.9068e-04\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8.0711e-04 - val_loss: 5.6453e-04\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7.9504e-04 - val_loss: 5.4689e-04\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7.8366e-04 - val_loss: 5.4946e-04\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7.7712e-04 - val_loss: 5.3882e-04\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7.6712e-04 - val_loss: 5.3046e-04\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7.6395e-04 - val_loss: 5.2639e-04\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7.5653e-04 - val_loss: 5.2173e-04\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7.4512e-04 - val_loss: 5.2098e-04\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7.4147e-04 - val_loss: 5.2013e-04\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7.3598e-04 - val_loss: 5.1865e-04\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7.2590e-04 - val_loss: 5.0936e-04\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7.1533e-04 - val_loss: 5.0308e-04\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7.1355e-04 - val_loss: 4.9530e-04\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7.0299e-04 - val_loss: 5.0148e-04\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7.0023e-04 - val_loss: 4.9900e-04\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6.9075e-04 - val_loss: 4.8646e-04\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6.8468e-04 - val_loss: 4.8914e-04\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6.8183e-04 - val_loss: 4.7268e-04\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6.7455e-04 - val_loss: 4.6995e-04\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6.6902e-04 - val_loss: 4.6440e-04\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6.6082e-04 - val_loss: 4.6109e-04\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6.5532e-04 - val_loss: 4.5694e-04\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6.5022e-04 - val_loss: 4.5788e-04\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6.4407e-04 - val_loss: 4.6418e-04\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6.5681e-04 - val_loss: 4.5529e-04\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6.3602e-04 - val_loss: 4.4401e-04\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6.3332e-04 - val_loss: 4.4110e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6.2742e-04 - val_loss: 4.3767e-04\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6.2056e-04 - val_loss: 4.3601e-04\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6.1541e-04 - val_loss: 4.4942e-04\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6.1341e-04 - val_loss: 4.3139e-04\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6.0700e-04 - val_loss: 4.2617e-04\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6.0470e-04 - val_loss: 4.3274e-04\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6.0179e-04 - val_loss: 4.2076e-04\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5.9944e-04 - val_loss: 4.2094e-04\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5.9027e-04 - val_loss: 4.1597e-04\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5.8991e-04 - val_loss: 4.1338e-04\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5.8213e-04 - val_loss: 4.1881e-04\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5.7827e-04 - val_loss: 4.0947e-04\n",
      "Thời gian huấn luyện:  7.236530065536499\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_110 (Dense)           (None, 10, 103)           206       \n",
      "                                                                 \n",
      " flatten_88 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,237\n",
      "Trainable params: 1,237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "34/34 [==============================] - 1s 7ms/step - loss: 0.0070 - val_loss: 0.0016\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 9.6773e-04\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 8.6723e-04\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 8.1168e-04\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 8.1698e-04\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 7.2949e-04\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 7.0653e-04\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 7.4297e-04\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9.9100e-04 - val_loss: 6.6024e-04\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9.4650e-04 - val_loss: 6.4654e-04\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9.6842e-04 - val_loss: 7.0225e-04\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9.0312e-04 - val_loss: 6.8680e-04\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8.8416e-04 - val_loss: 6.2541e-04\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8.4207e-04 - val_loss: 5.8779e-04\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8.3016e-04 - val_loss: 5.8582e-04\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8.0667e-04 - val_loss: 5.6902e-04\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8.0833e-04 - val_loss: 6.3508e-04\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8.2768e-04 - val_loss: 5.8904e-04\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9.0618e-04 - val_loss: 5.5614e-04\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.7207e-04 - val_loss: 5.5590e-04\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.8658e-04 - val_loss: 5.6088e-04\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.3434e-04 - val_loss: 5.3527e-04\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.4877e-04 - val_loss: 6.7394e-04\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.3666e-04 - val_loss: 5.0341e-04\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.1265e-04 - val_loss: 4.9750e-04\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.0045e-04 - val_loss: 4.9444e-04\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.8336e-04 - val_loss: 4.9707e-04\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.7414e-04 - val_loss: 5.4557e-04\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.9748e-04 - val_loss: 5.3244e-04\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.8266e-04 - val_loss: 4.8854e-04\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.5868e-04 - val_loss: 4.7567e-04\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.6407e-04 - val_loss: 6.4236e-04\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.3104e-04 - val_loss: 4.7034e-04\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.5722e-04 - val_loss: 4.5738e-04\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.3595e-04 - val_loss: 4.5423e-04\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.8043e-04 - val_loss: 4.5472e-04\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.3062e-04 - val_loss: 5.5494e-04\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.4516e-04 - val_loss: 4.6281e-04\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.2353e-04 - val_loss: 4.4718e-04\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.0985e-04 - val_loss: 4.4699e-04\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.4090e-04 - val_loss: 4.3388e-04\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.1006e-04 - val_loss: 5.4767e-04\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.9729e-04 - val_loss: 4.2591e-04\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.1649e-04 - val_loss: 5.7461e-04\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.0029e-04 - val_loss: 4.3784e-04\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.0416e-04 - val_loss: 4.5437e-04\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.8134e-04 - val_loss: 4.1302e-04\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.0306e-04 - val_loss: 4.1683e-04\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.6562e-04 - val_loss: 4.1882e-04\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.7416e-04 - val_loss: 4.0890e-04\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.7454e-04 - val_loss: 4.3706e-04\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.7073e-04 - val_loss: 4.0198e-04\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.8146e-04 - val_loss: 4.0237e-04\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.5905e-04 - val_loss: 3.9685e-04\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.7104e-04 - val_loss: 4.7142e-04\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 3ms/step - loss: 5.6967e-04 - val_loss: 3.9367e-04\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.5858e-04 - val_loss: 3.9077e-04\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.4393e-04 - val_loss: 3.8831e-04\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.4259e-04 - val_loss: 3.9996e-04\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.5389e-04 - val_loss: 4.0331e-04\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.9251e-04 - val_loss: 4.3527e-04\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.4136e-04 - val_loss: 3.8664e-04\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.3427e-04 - val_loss: 3.9209e-04\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.2388e-04 - val_loss: 3.9288e-04\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.2293e-04 - val_loss: 3.8631e-04\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.3816e-04 - val_loss: 3.7803e-04\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.4334e-04 - val_loss: 3.7530e-04\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.4601e-04 - val_loss: 3.7131e-04\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.2508e-04 - val_loss: 3.7536e-04\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.1249e-04 - val_loss: 3.8293e-04\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.0889e-04 - val_loss: 3.7087e-04\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.1154e-04 - val_loss: 3.8574e-04\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.0720e-04 - val_loss: 3.6728e-04\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.3147e-04 - val_loss: 3.6953e-04\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.5478e-04 - val_loss: 3.6864e-04\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.2762e-04 - val_loss: 3.6004e-04\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.1646e-04 - val_loss: 3.7355e-04\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.9109e-04 - val_loss: 4.0048e-04\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.7094e-04 - val_loss: 3.9717e-04\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.2112e-04 - val_loss: 3.5660e-04\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.9203e-04 - val_loss: 3.5273e-04\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.8769e-04 - val_loss: 3.6389e-04\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 4.9108e-04 - val_loss: 3.5438e-04\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 5.0466e-04 - val_loss: 3.9484e-04\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.9253e-04 - val_loss: 4.0377e-04\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.0303e-04 - val_loss: 3.6384e-04\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.9495e-04 - val_loss: 3.5934e-04\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.0217e-04 - val_loss: 3.5786e-04\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.9993e-04 - val_loss: 3.4327e-04\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.9067e-04 - val_loss: 3.4699e-04\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.8029e-04 - val_loss: 3.8470e-04\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.8144e-04 - val_loss: 3.4092e-04\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.7082e-04 - val_loss: 3.4094e-04\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.8410e-04 - val_loss: 3.9387e-04\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.9198e-04 - val_loss: 3.8325e-04\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 5.2150e-04 - val_loss: 3.4236e-04\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 4.9428e-04 - val_loss: 3.4201e-04\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 4.6940e-04 - val_loss: 3.6646e-04\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.7185e-04 - val_loss: 3.3796e-04\n",
      "Thời gian huấn luyện:  11.903225898742676\n",
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_22 (SimpleRNN)   (None, 10, 103)           10815     \n",
      "                                                                 \n",
      " flatten_89 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,846\n",
      "Trainable params: 11,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "34/34 [==============================] - 2s 17ms/step - loss: 0.0196 - val_loss: 0.0023\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 9.9864e-04\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 9.7665e-04\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 9.9128e-04\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 9.9125e-04\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 9.4860e-04\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 9.3900e-04\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 9.3950e-04\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 9.2054e-04\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 9.1948e-04\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 8.7882e-04\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 8.6890e-04\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 8.6875e-04\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 8.5574e-04\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 8.3871e-04\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 8.2681e-04\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 8.2016e-04\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 8.1131e-04\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 7.9889e-04\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 7.9347e-04\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 7.8422e-04\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 8.0522e-04\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 8.2001e-04\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 8.6377e-04\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 7.5181e-04\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 7.6458e-04\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 7.9117e-04\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 7.2927e-04\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 7.2758e-04\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 7.2092e-04\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 7.1192e-04\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 7.1871e-04\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 6.9907e-04\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.9636e-04 - val_loss: 7.0199e-04\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.9749e-04 - val_loss: 6.8939e-04\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.7716e-04 - val_loss: 6.8680e-04\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.9034e-04 - val_loss: 6.9330e-04\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.7165e-04 - val_loss: 6.8442e-04\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.6139e-04 - val_loss: 6.9432e-04\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.5440e-04 - val_loss: 7.0125e-04\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.5739e-04 - val_loss: 6.8902e-04\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.6008e-04 - val_loss: 6.5833e-04\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.3488e-04 - val_loss: 6.5547e-04\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.6139e-04 - val_loss: 6.5223e-04\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.4853e-04 - val_loss: 6.5420e-04\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.2248e-04 - val_loss: 6.8317e-04\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.1091e-04 - val_loss: 6.4762e-04\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.0788e-04 - val_loss: 6.4196e-04\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.0256e-04 - val_loss: 6.3781e-04\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.1027e-04 - val_loss: 8.0011e-04\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.3719e-04 - val_loss: 6.6282e-04\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.0179e-04 - val_loss: 6.3387e-04\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.8383e-04 - val_loss: 6.5323e-04\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.8355e-04 - val_loss: 6.9372e-04\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.8688e-04 - val_loss: 6.3745e-04\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.7242e-04 - val_loss: 6.2537e-04\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.7628e-04 - val_loss: 6.2207e-04\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.7111e-04 - val_loss: 6.1568e-04\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.6959e-04 - val_loss: 6.4348e-04\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.7882e-04 - val_loss: 6.1786e-04\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.5703e-04 - val_loss: 6.2502e-04\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.5851e-04 - val_loss: 6.0730e-04\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.5644e-04 - val_loss: 6.0531e-04\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.4172e-04 - val_loss: 6.1476e-04\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.4735e-04 - val_loss: 6.1523e-04\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.4839e-04 - val_loss: 6.0998e-04\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.4835e-04 - val_loss: 6.1190e-04\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.2682e-04 - val_loss: 6.0210e-04\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 8.4276e-04 - val_loss: 6.3104e-04\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.2597e-04 - val_loss: 6.6514e-04\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.8368e-04 - val_loss: 5.8829e-04\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.1733e-04 - val_loss: 5.8693e-04\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.1484e-04 - val_loss: 5.8399e-04\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.1708e-04 - val_loss: 5.7654e-04\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.0305e-04 - val_loss: 5.7823e-04\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 7.9972e-04 - val_loss: 6.0946e-04\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 7.9827e-04 - val_loss: 5.7246e-04\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.0107e-04 - val_loss: 5.7415e-04\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 7.9254e-04 - val_loss: 5.7358e-04\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 7.8382e-04 - val_loss: 5.9044e-04\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 7.8540e-04 - val_loss: 5.7433e-04\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 7.8345e-04 - val_loss: 5.6432e-04\n",
      "Thời gian huấn luyện:  26.44625210762024\n",
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lstm_22 (LSTM)              (None, 10, 103)           43260     \n",
      "                                                                 \n",
      " flatten_90 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,291\n",
      "Trainable params: 44,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "34/34 [==============================] - 2s 16ms/step - loss: 0.0218 - val_loss: 0.0027\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.0010\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 9.8114e-04\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 9.5261e-04\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 9.8041e-04\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 9.2203e-04\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 9.1939e-04\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 8.9449e-04\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 8.8035e-04\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 8.6943e-04\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 8.4874e-04\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 8.2725e-04\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 8.3868e-04\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 8.2543e-04\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 7.8339e-04\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 7.6961e-04\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 7.6268e-04\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 7.5095e-04\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 7.3863e-04\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 7.1854e-04\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 7.4757e-04\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 6.9695e-04\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 6.8247e-04\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.8084e-04 - val_loss: 6.8147e-04\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.6602e-04 - val_loss: 6.8627e-04\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.6175e-04 - val_loss: 6.8474e-04\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3887e-04 - val_loss: 6.6411e-04\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4123e-04 - val_loss: 6.3962e-04\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.0435e-04 - val_loss: 6.3133e-04\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 8.9565e-04 - val_loss: 6.2445e-04\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 8.7876e-04 - val_loss: 6.1415e-04\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 8.7100e-04 - val_loss: 6.1317e-04\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 8.6016e-04 - val_loss: 5.9921e-04\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 8.4813e-04 - val_loss: 5.9603e-04\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 8.4552e-04 - val_loss: 6.0475e-04\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 8.2109e-04 - val_loss: 5.9909e-04\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.3643e-04 - val_loss: 5.9819e-04\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 8.2089e-04 - val_loss: 5.7146e-04\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 8.1560e-04 - val_loss: 5.6877e-04\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 7.9623e-04 - val_loss: 5.6513e-04\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 7.8451e-04 - val_loss: 5.5849e-04\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 7.8146e-04 - val_loss: 5.5284e-04\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.6877e-04 - val_loss: 5.6996e-04\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 7.6541e-04 - val_loss: 5.5089e-04\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 7.6790e-04 - val_loss: 5.4455e-04\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 7.5322e-04 - val_loss: 5.3796e-04\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 7.4924e-04 - val_loss: 5.3547e-04\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 7.4764e-04 - val_loss: 5.2832e-04\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 7.4230e-04 - val_loss: 5.3319e-04\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 7.4107e-04 - val_loss: 5.4843e-04\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 7.2835e-04 - val_loss: 5.3993e-04\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 7.2878e-04 - val_loss: 5.6953e-04\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 7.1973e-04 - val_loss: 5.1445e-04\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 7.0949e-04 - val_loss: 5.0897e-04\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 7.0449e-04 - val_loss: 5.0559e-04\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 6.9781e-04 - val_loss: 5.0741e-04\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 6.9389e-04 - val_loss: 5.0780e-04\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 6.9273e-04 - val_loss: 4.9547e-04\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 6.9024e-04 - val_loss: 4.9255e-04\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 6.9637e-04 - val_loss: 4.9663e-04\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 6.9129e-04 - val_loss: 4.8970e-04\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 6.7660e-04 - val_loss: 5.2665e-04\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 6.8387e-04 - val_loss: 4.8755e-04\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 6.6077e-04 - val_loss: 4.8179e-04\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 6.6504e-04 - val_loss: 4.7763e-04\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 6.5753e-04 - val_loss: 4.7762e-04\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 7ms/step - loss: 6.5779e-04 - val_loss: 4.7105e-04\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 6.4857e-04 - val_loss: 4.6943e-04\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 6.6023e-04 - val_loss: 5.2322e-04\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 6.3972e-04 - val_loss: 4.6255e-04\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 6.3320e-04 - val_loss: 4.7360e-04\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 6.3868e-04 - val_loss: 4.6649e-04\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 6.4323e-04 - val_loss: 4.5981e-04\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 6.2432e-04 - val_loss: 4.5367e-04\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 6.3963e-04 - val_loss: 5.1192e-04\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 6.3209e-04 - val_loss: 4.4982e-04\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 6.1612e-04 - val_loss: 4.4800e-04\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 6.0867e-04 - val_loss: 4.4559e-04\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 6.1004e-04 - val_loss: 4.4487e-04\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 6.0945e-04 - val_loss: 4.4018e-04\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 6.1895e-04 - val_loss: 4.4013e-04\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 6.0285e-04 - val_loss: 4.4304e-04\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 5.9615e-04 - val_loss: 4.3846e-04\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 5.9916e-04 - val_loss: 4.3306e-04\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 5.9343e-04 - val_loss: 4.4682e-04\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 5.9367e-04 - val_loss: 4.3741e-04\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 5.8415e-04 - val_loss: 4.2873e-04\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 5.7928e-04 - val_loss: 4.2640e-04\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 5.8138e-04 - val_loss: 4.2742e-04\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 5.7771e-04 - val_loss: 4.2528e-04\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 5.7461e-04 - val_loss: 4.5223e-04\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 5.7444e-04 - val_loss: 4.1874e-04\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 5.7782e-04 - val_loss: 4.4086e-04\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 5.7011e-04 - val_loss: 4.1441e-04\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 5.7597e-04 - val_loss: 4.2037e-04\n",
      "Thời gian huấn luyện:  24.11690855026245\n",
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_22 (GRU)                (None, 10, 103)           32754     \n",
      "                                                                 \n",
      " flatten_91 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,785\n",
      "Trainable params: 33,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 0s 897us/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0420 - val_loss: 0.0016\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0016\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 9.9706e-04\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 9.9112e-04\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 9.3907e-04\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 9.4690e-04\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 8.7624e-04\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 8.5804e-04\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 8.4113e-04\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 8.3428e-04\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.3448e-04\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.3512e-04\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.0591e-04\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 8.0535e-04\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.9689e-04\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.9318e-04\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 8.0638e-04\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 7.7928e-04\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 8.0370e-04\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 7.7185e-04\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 7.6332e-04\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 7.6714e-04\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.9739e-04\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.4709e-04\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.4661e-04\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.4995e-04\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.3103e-04\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.2573e-04\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.2204e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.1610e-04\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.2526e-04\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.0219e-04\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.9726e-04\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.9033e-04\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.9218e-04\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.7997e-04\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.8090e-04\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.7818e-04\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.6491e-04\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.6098e-04\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.5384e-04\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.4436e-04\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 6.6108e-04\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 6.3269e-04\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 6.3854e-04\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 6.2824e-04\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 6.1679e-04\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.9102e-04 - val_loss: 6.1316e-04\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.8048e-04 - val_loss: 6.1890e-04\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.7394e-04 - val_loss: 6.0087e-04\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.6265e-04 - val_loss: 5.9364e-04\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.5369e-04 - val_loss: 5.8778e-04\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.4668e-04 - val_loss: 5.8309e-04\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.4771e-04 - val_loss: 5.7959e-04\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.2742e-04 - val_loss: 5.8948e-04\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.1937e-04 - val_loss: 5.9262e-04\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.0894e-04 - val_loss: 5.6053e-04\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.9509e-04 - val_loss: 5.7214e-04\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.9245e-04 - val_loss: 5.5854e-04\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.8454e-04 - val_loss: 5.5146e-04\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.7837e-04 - val_loss: 5.4032e-04\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.6122e-04 - val_loss: 5.4865e-04\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.5350e-04 - val_loss: 5.2949e-04\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.4815e-04 - val_loss: 5.2733e-04\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.3972e-04 - val_loss: 5.2148e-04\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.3018e-04 - val_loss: 5.1628e-04\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.2184e-04 - val_loss: 5.1387e-04\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.1714e-04 - val_loss: 5.0696e-04\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.1050e-04 - val_loss: 5.0111e-04\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.9962e-04 - val_loss: 4.9534e-04\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.8849e-04 - val_loss: 5.0984e-04\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.8858e-04 - val_loss: 4.9309e-04\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.7625e-04 - val_loss: 4.9077e-04\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.7059e-04 - val_loss: 4.8742e-04\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.6435e-04 - val_loss: 4.7349e-04\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.5749e-04 - val_loss: 4.6794e-04\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.5123e-04 - val_loss: 4.6401e-04\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.4182e-04 - val_loss: 4.6337e-04\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.3427e-04 - val_loss: 4.5980e-04\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.3046e-04 - val_loss: 4.5193e-04\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.2543e-04 - val_loss: 4.5129e-04\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.1634e-04 - val_loss: 4.4625e-04\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.1171e-04 - val_loss: 4.4402e-04\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.0045e-04 - val_loss: 4.6992e-04\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.0374e-04 - val_loss: 4.4424e-04\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.9197e-04 - val_loss: 4.3184e-04\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.8477e-04 - val_loss: 4.2768e-04\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.7990e-04 - val_loss: 4.3106e-04\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.7325e-04 - val_loss: 4.4340e-04\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.7694e-04 - val_loss: 4.3431e-04\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.6475e-04 - val_loss: 4.2241e-04\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6185e-04 - val_loss: 4.1534e-04\n",
      "Thời gian huấn luyện:  8.447487831115723\n",
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_115 (Dense)           (None, 10, 103)           206       \n",
      "                                                                 \n",
      " flatten_92 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,237\n",
      "Trainable params: 1,237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 1s 10ms/step - loss: 0.0039 - val_loss: 7.7898e-04\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 6.4980e-04\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 5.9517e-04\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.6858e-04 - val_loss: 5.6146e-04\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.0867e-04 - val_loss: 7.0924e-04\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 8.9622e-04 - val_loss: 6.7039e-04\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.3510e-04 - val_loss: 5.8744e-04\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.1277e-04 - val_loss: 4.9524e-04\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.8641e-04 - val_loss: 5.7848e-04\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.9156e-04 - val_loss: 7.0469e-04\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.1666e-04 - val_loss: 4.7419e-04\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.5478e-04 - val_loss: 4.5621e-04\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.3603e-04 - val_loss: 4.6187e-04\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.5460e-04 - val_loss: 4.4114e-04\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1627e-04 - val_loss: 5.6624e-04\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.4035e-04 - val_loss: 4.8906e-04\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0197e-04 - val_loss: 4.2905e-04\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8204e-04 - val_loss: 4.2523e-04\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9280e-04 - val_loss: 4.5387e-04\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6853e-04 - val_loss: 4.3655e-04\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4115e-04 - val_loss: 4.0377e-04\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3978e-04 - val_loss: 4.3835e-04\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6167e-04 - val_loss: 4.8644e-04\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3216e-04 - val_loss: 3.9516e-04\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5562e-04 - val_loss: 4.8272e-04\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6012e-04 - val_loss: 3.8687e-04\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1331e-04 - val_loss: 4.5968e-04\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1079e-04 - val_loss: 3.9377e-04\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1497e-04 - val_loss: 3.9743e-04\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9774e-04 - val_loss: 4.0743e-04\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8607e-04 - val_loss: 3.8802e-04\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8756e-04 - val_loss: 3.7273e-04\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8763e-04 - val_loss: 5.4364e-04\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1306e-04 - val_loss: 4.2915e-04\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2757e-04 - val_loss: 3.6322e-04\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7948e-04 - val_loss: 3.6499e-04\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8394e-04 - val_loss: 3.6389e-04\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.6535e-04 - val_loss: 3.5532e-04\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5962e-04 - val_loss: 3.5977e-04\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7299e-04 - val_loss: 3.8664e-04\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0731e-04 - val_loss: 4.5097e-04\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7477e-04 - val_loss: 3.4830e-04\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.6969e-04 - val_loss: 3.4718e-04\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5048e-04 - val_loss: 3.5255e-04\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.6723e-04 - val_loss: 3.4400e-04\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8807e-04 - val_loss: 3.5457e-04\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7834e-04 - val_loss: 3.4033e-04\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3672e-04 - val_loss: 3.4115e-04\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4069e-04 - val_loss: 4.5460e-04\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8778e-04 - val_loss: 3.3510e-04\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4644e-04 - val_loss: 3.3460e-04\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3059e-04 - val_loss: 3.3417e-04\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3001e-04 - val_loss: 3.3879e-04\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3900e-04 - val_loss: 3.4636e-04\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5255e-04 - val_loss: 4.7282e-04\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4283e-04 - val_loss: 3.5731e-04\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.2469e-04 - val_loss: 3.5759e-04\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1675e-04 - val_loss: 3.6209e-04\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3226e-04 - val_loss: 3.3674e-04\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3862e-04 - val_loss: 3.2239e-04\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.2490e-04 - val_loss: 3.2137e-04\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.0579e-04 - val_loss: 3.7854e-04\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3470e-04 - val_loss: 3.1906e-04\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9761e-04 - val_loss: 3.3558e-04\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3137e-04 - val_loss: 3.7511e-04\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.0533e-04 - val_loss: 3.1543e-04\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9889e-04 - val_loss: 3.2841e-04\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9945e-04 - val_loss: 3.1869e-04\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1133e-04 - val_loss: 3.1246e-04\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1268e-04 - val_loss: 3.3326e-04\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3568e-04 - val_loss: 3.1373e-04\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1115e-04 - val_loss: 3.4874e-04\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1951e-04 - val_loss: 3.1051e-04\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9417e-04 - val_loss: 3.2369e-04\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9601e-04 - val_loss: 3.1374e-04\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.0269e-04 - val_loss: 3.1179e-04\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8635e-04 - val_loss: 3.3730e-04\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8296e-04 - val_loss: 3.0477e-04\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8487e-04 - val_loss: 3.3959e-04\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8132e-04 - val_loss: 3.0543e-04\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8857e-04 - val_loss: 3.2306e-04\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9190e-04 - val_loss: 3.0182e-04\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7982e-04 - val_loss: 3.7298e-04\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0263e-04 - val_loss: 3.1279e-04\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8120e-04 - val_loss: 3.0006e-04\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7148e-04 - val_loss: 3.0789e-04\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8405e-04 - val_loss: 3.3630e-04\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7344e-04 - val_loss: 3.0647e-04\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.7394e-04 - val_loss: 3.0307e-04\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9070e-04 - val_loss: 3.1429e-04\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9179e-04 - val_loss: 3.7382e-04\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1452e-04 - val_loss: 3.0993e-04\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8755e-04 - val_loss: 3.1090e-04\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6991e-04 - val_loss: 2.9353e-04\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6864e-04 - val_loss: 2.9859e-04\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8559e-04 - val_loss: 2.9932e-04\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9724e-04 - val_loss: 2.9976e-04\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6419e-04 - val_loss: 3.2204e-04\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6731e-04 - val_loss: 3.1684e-04\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5948e-04 - val_loss: 3.0015e-04\n",
      "Thời gian huấn luyện:  13.396818399429321\n",
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_23 (SimpleRNN)   (None, 10, 103)           10815     \n",
      "                                                                 \n",
      " flatten_93 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,846\n",
      "Trainable params: 11,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 2s 18ms/step - loss: 0.0151 - val_loss: 0.0019\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 9.8462e-04\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 9.7290e-04\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 9.8937e-04\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 9.4957e-04\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 9.4424e-04\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 9.3798e-04\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 9.2158e-04\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 9.0656e-04\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 8.9707e-04\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 8.8273e-04\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 8.7351e-04\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 8.8106e-04\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 8.6765e-04\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 8.6871e-04\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 8.2475e-04\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 8.1254e-04\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 8.2214e-04\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 7.9221e-04\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 8.3108e-04\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 7.7930e-04\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 7.6959e-04\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 8.0562e-04\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 7.5636e-04\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 7.9675e-04\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 7.7468e-04\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 7.4273e-04\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 7.1387e-04\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.1104e-04\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.0293e-04\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 6.7959e-04\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.2258e-04\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 6.6785e-04\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 6.7889e-04\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 6.9265e-04\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 6.5927e-04\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 6.6675e-04\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 6.8156e-04\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 6.4658e-04\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 6.3002e-04\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 6.2798e-04\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 6.2272e-04\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 6.3305e-04\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.8851e-04 - val_loss: 6.3126e-04\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.8625e-04 - val_loss: 6.4125e-04\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.8217e-04 - val_loss: 6.1376e-04\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.7749e-04 - val_loss: 6.2277e-04\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.7844e-04 - val_loss: 6.1854e-04\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.6232e-04 - val_loss: 5.9954e-04\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.6867e-04 - val_loss: 6.0755e-04\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.5756e-04 - val_loss: 6.0521e-04\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.5855e-04 - val_loss: 6.1883e-04\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.7732e-04 - val_loss: 6.3669e-04\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.7123e-04 - val_loss: 5.9674e-04\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.7934e-04 - val_loss: 5.8469e-04\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.3097e-04 - val_loss: 6.1496e-04\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.2543e-04 - val_loss: 6.1328e-04\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.2958e-04 - val_loss: 6.0803e-04\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.2141e-04 - val_loss: 5.7691e-04\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.3125e-04 - val_loss: 6.2950e-04\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.4316e-04 - val_loss: 6.0519e-04\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.0301e-04 - val_loss: 6.1408e-04\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 9.1158e-04 - val_loss: 5.7182e-04\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.0120e-04 - val_loss: 6.7161e-04\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.0043e-04 - val_loss: 5.7581e-04\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.8896e-04 - val_loss: 6.1073e-04\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.8823e-04 - val_loss: 5.6326e-04\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.8301e-04 - val_loss: 5.9080e-04\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.7872e-04 - val_loss: 5.5671e-04\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.7815e-04 - val_loss: 6.2578e-04\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.7631e-04 - val_loss: 5.8874e-04\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.8357e-04 - val_loss: 5.5611e-04\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.8185e-04 - val_loss: 6.0087e-04\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.7107e-04 - val_loss: 5.4481e-04\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.6860e-04 - val_loss: 5.3987e-04\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.7130e-04 - val_loss: 6.5574e-04\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.5624e-04 - val_loss: 5.4157e-04\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.6458e-04 - val_loss: 5.5827e-04\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.4363e-04 - val_loss: 5.5987e-04\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.4615e-04 - val_loss: 5.2994e-04\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.4496e-04 - val_loss: 5.2956e-04\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.5285e-04 - val_loss: 5.3986e-04\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.4008e-04 - val_loss: 5.2494e-04\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.3919e-04 - val_loss: 6.0711e-04\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.3231e-04 - val_loss: 5.2071e-04\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.4005e-04 - val_loss: 5.2222e-04\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.1849e-04 - val_loss: 5.9548e-04\n",
      "Thời gian huấn luyện:  26.956953763961792\n",
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_23 (LSTM)              (None, 10, 103)           43260     \n",
      "                                                                 \n",
      " flatten_94 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,291\n",
      "Trainable params: 44,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 2s 18ms/step - loss: 0.0174 - val_loss: 0.0021\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 9.8987e-04\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 9.2040e-04\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 8.9076e-04\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 9.0012e-04\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 8.8750e-04\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 8.4316e-04\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 8.0437e-04\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 7.8980e-04\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 7.8401e-04\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 7.5632e-04\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 7.3924e-04\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 7.2441e-04\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 7.1169e-04\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 7.0111e-04\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 6.7829e-04\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.3196e-04\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 6.5172e-04\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 6.4136e-04\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 6.4119e-04\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 6.1682e-04\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.8901e-04 - val_loss: 6.1200e-04\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.6884e-04 - val_loss: 6.4547e-04\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.6403e-04 - val_loss: 6.0747e-04\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.3519e-04 - val_loss: 6.0455e-04\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.2293e-04 - val_loss: 5.6891e-04\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.0217e-04 - val_loss: 5.7732e-04\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.9172e-04 - val_loss: 5.5018e-04\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.8379e-04 - val_loss: 5.5420e-04\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.7057e-04 - val_loss: 5.4873e-04\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.5124e-04 - val_loss: 5.2695e-04\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.4896e-04 - val_loss: 5.2918e-04\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.3155e-04 - val_loss: 5.3352e-04\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.2555e-04 - val_loss: 5.3104e-04\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.2027e-04 - val_loss: 5.1235e-04\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.0614e-04 - val_loss: 5.0444e-04\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.0120e-04 - val_loss: 5.4126e-04\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.0846e-04 - val_loss: 4.9324e-04\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.8566e-04 - val_loss: 4.9889e-04\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.7801e-04 - val_loss: 4.8603e-04\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.8140e-04 - val_loss: 4.9009e-04\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.7148e-04 - val_loss: 5.0245e-04\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.6447e-04 - val_loss: 4.9393e-04\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.6168e-04 - val_loss: 4.7557e-04\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.5048e-04 - val_loss: 4.7031e-04\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.4488e-04 - val_loss: 4.7100e-04\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.4374e-04 - val_loss: 4.6641e-04\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.3816e-04 - val_loss: 4.8396e-04\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.3865e-04 - val_loss: 4.6874e-04\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.2245e-04 - val_loss: 4.5629e-04\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.3294e-04 - val_loss: 4.6882e-04\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.2064e-04 - val_loss: 4.5150e-04\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.1262e-04 - val_loss: 4.5318e-04\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.0677e-04 - val_loss: 5.1515e-04\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.1383e-04 - val_loss: 4.4500e-04\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.1175e-04 - val_loss: 4.8090e-04\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.0822e-04 - val_loss: 4.4166e-04\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.0427e-04 - val_loss: 4.5629e-04\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.9570e-04 - val_loss: 4.9741e-04\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.1758e-04 - val_loss: 4.4055e-04\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.8725e-04 - val_loss: 4.3125e-04\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.7996e-04 - val_loss: 4.2936e-04\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.8264e-04 - val_loss: 4.2811e-04\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.8769e-04 - val_loss: 4.2510e-04\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.7119e-04 - val_loss: 4.2746e-04\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.7058e-04 - val_loss: 4.3109e-04\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.6283e-04 - val_loss: 4.2780e-04\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.6647e-04 - val_loss: 4.3140e-04\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.6412e-04 - val_loss: 4.4099e-04\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.5506e-04 - val_loss: 4.1260e-04\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.5281e-04 - val_loss: 4.2085e-04\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.4826e-04 - val_loss: 4.0981e-04\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.4632e-04 - val_loss: 4.1378e-04\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.3949e-04 - val_loss: 4.2401e-04\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.3811e-04 - val_loss: 4.0334e-04\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.3235e-04 - val_loss: 4.1047e-04\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.3836e-04 - val_loss: 4.0083e-04\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.2672e-04 - val_loss: 3.9831e-04\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.2366e-04 - val_loss: 4.2489e-04\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.2885e-04 - val_loss: 3.9482e-04\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.2031e-04 - val_loss: 4.1644e-04\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.2142e-04 - val_loss: 4.2715e-04\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.2406e-04 - val_loss: 3.9202e-04\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.3224e-04 - val_loss: 4.0068e-04\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.1924e-04 - val_loss: 3.8958e-04\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.0367e-04 - val_loss: 3.9631e-04\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.0421e-04 - val_loss: 3.8974e-04\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.0794e-04 - val_loss: 3.9846e-04\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.0265e-04 - val_loss: 3.8135e-04\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.0134e-04 - val_loss: 3.7985e-04\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.0247e-04 - val_loss: 4.2504e-04\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.9469e-04 - val_loss: 3.7639e-04\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.9023e-04 - val_loss: 3.8812e-04\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.8549e-04 - val_loss: 4.4967e-04\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.9870e-04 - val_loss: 3.8161e-04\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.9221e-04 - val_loss: 4.2726e-04\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 5.8608e-04 - val_loss: 3.7008e-04\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.7758e-04 - val_loss: 4.3066e-04\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.9808e-04 - val_loss: 3.7634e-04\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.7450e-04 - val_loss: 3.8014e-04\n",
      "Thời gian huấn luyện:  24.103625774383545\n",
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_23 (GRU)                (None, 10, 103)           32754     \n",
      "                                                                 \n",
      " flatten_95 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,785\n",
      "Trainable params: 33,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 0s 975us/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0719 - val_loss: 0.0186\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 5.4365e-04\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 5.8287e-04\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 6.2576e-04\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 5.6733e-04\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 5.4836e-04\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 5.4929e-04\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 5.5085e-04\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 5.4225e-04\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 5.3925e-04\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 5.3542e-04\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 5.5492e-04\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 5.1938e-04\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 5.1599e-04\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.2720e-04\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.1532e-04\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.2355e-04\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.1359e-04\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.0887e-04\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.1045e-04\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 5.0721e-04\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 5.2614e-04\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 5.0461e-04\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 5.0427e-04\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 5.0209e-04\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.9905e-04\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.2365e-04\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.9021e-04\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.8798e-04\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.8416e-04\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.8088e-04\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.8869e-04\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.7676e-04\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.7090e-04\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.7217e-04\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.7010e-04\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.5984e-04\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.5576e-04\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.5318e-04\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.5083e-04\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.4906e-04\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.5095e-04\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.4078e-04\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 4.3851e-04\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 4.4426e-04\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 4.3396e-04\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 4.2787e-04\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 4.2412e-04\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 9.9770e-04 - val_loss: 4.2041e-04\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 9.8970e-04 - val_loss: 4.1725e-04\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 9.7615e-04 - val_loss: 4.2876e-04\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 9.7419e-04 - val_loss: 4.1093e-04\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 9.6393e-04 - val_loss: 4.1130e-04\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 9.4909e-04 - val_loss: 4.1340e-04\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 9.4599e-04 - val_loss: 4.0268e-04\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 9.3279e-04 - val_loss: 4.1249e-04\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 9.2655e-04 - val_loss: 3.9981e-04\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 9.0806e-04 - val_loss: 4.0376e-04\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 9.1375e-04 - val_loss: 3.9564e-04\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 8.9677e-04 - val_loss: 3.9135e-04\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 8.8531e-04 - val_loss: 3.8780e-04\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 8.7548e-04 - val_loss: 3.8176e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 8.7123e-04 - val_loss: 3.8138e-04\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 8.5877e-04 - val_loss: 3.9657e-04\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 8.6655e-04 - val_loss: 4.0137e-04\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 8.4645e-04 - val_loss: 3.7329e-04\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 8.3766e-04 - val_loss: 3.6961e-04\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 8.2684e-04 - val_loss: 3.6620e-04\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 8.1725e-04 - val_loss: 3.6796e-04\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 8.1069e-04 - val_loss: 3.7770e-04\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 8.0644e-04 - val_loss: 3.6097e-04\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 7.9381e-04 - val_loss: 3.5684e-04\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 7.8649e-04 - val_loss: 3.5355e-04\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 7.7775e-04 - val_loss: 3.5311e-04\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 7.7314e-04 - val_loss: 3.5139e-04\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 7.6746e-04 - val_loss: 3.5481e-04\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 7.5815e-04 - val_loss: 3.4478e-04\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 7.5517e-04 - val_loss: 3.4566e-04\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 7.4509e-04 - val_loss: 3.5793e-04\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 7.4209e-04 - val_loss: 3.3835e-04\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 7.3254e-04 - val_loss: 3.3904e-04\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 7.2372e-04 - val_loss: 3.3699e-04\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 7.1790e-04 - val_loss: 3.5698e-04\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 7.1770e-04 - val_loss: 3.3356e-04\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 7.1077e-04 - val_loss: 3.3063e-04\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.9808e-04 - val_loss: 3.3282e-04\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.9350e-04 - val_loss: 3.2730e-04\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.9034e-04 - val_loss: 3.3003e-04\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.8014e-04 - val_loss: 3.2154e-04\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.7616e-04 - val_loss: 3.2074e-04\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.7301e-04 - val_loss: 3.1958e-04\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.6690e-04 - val_loss: 3.1845e-04\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.6126e-04 - val_loss: 3.1882e-04\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.6497e-04 - val_loss: 3.1577e-04\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.5227e-04 - val_loss: 3.1453e-04\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.4610e-04 - val_loss: 3.1602e-04\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.4189e-04 - val_loss: 3.3435e-04\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.4293e-04 - val_loss: 3.0896e-04\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.3276e-04 - val_loss: 3.0761e-04\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.2890e-04 - val_loss: 3.0763e-04\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.3011e-04 - val_loss: 3.1021e-04\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.2412e-04 - val_loss: 3.0410e-04\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.1968e-04 - val_loss: 3.0736e-04\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.1252e-04 - val_loss: 3.0497e-04\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.1195e-04 - val_loss: 3.0108e-04\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.0740e-04 - val_loss: 3.0011e-04\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.0398e-04 - val_loss: 2.9949e-04\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.0120e-04 - val_loss: 2.9879e-04\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.0074e-04 - val_loss: 3.0382e-04\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.9793e-04 - val_loss: 2.9643e-04\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.9150e-04 - val_loss: 3.1048e-04\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.8923e-04 - val_loss: 3.0648e-04\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.9047e-04 - val_loss: 2.9538e-04\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.8394e-04 - val_loss: 2.9331e-04\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.7996e-04 - val_loss: 2.9263e-04\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.8080e-04 - val_loss: 2.9289e-04\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.7655e-04 - val_loss: 3.0201e-04\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.8153e-04 - val_loss: 2.9470e-04\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.7076e-04 - val_loss: 2.9007e-04\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.7759e-04 - val_loss: 2.9149e-04\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6964e-04 - val_loss: 2.8837e-04\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6493e-04 - val_loss: 2.9397e-04\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6293e-04 - val_loss: 2.9900e-04\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6536e-04 - val_loss: 2.9321e-04\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.5884e-04 - val_loss: 2.9011e-04\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.5600e-04 - val_loss: 2.8702e-04\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.5454e-04 - val_loss: 2.8496e-04\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.5220e-04 - val_loss: 2.8411e-04\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.5017e-04 - val_loss: 2.8412e-04\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4707e-04 - val_loss: 2.8326e-04\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4563e-04 - val_loss: 2.8388e-04\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4396e-04 - val_loss: 2.8413e-04\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4559e-04 - val_loss: 2.8187e-04\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4379e-04 - val_loss: 2.8583e-04\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3848e-04 - val_loss: 2.9042e-04\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4412e-04 - val_loss: 2.8035e-04\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4246e-04 - val_loss: 2.8186e-04\n",
      "Epoch 138/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4271e-04 - val_loss: 2.8548e-04\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3272e-04 - val_loss: 2.7929e-04\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3042e-04 - val_loss: 3.0524e-04\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3354e-04 - val_loss: 2.7762e-04\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2782e-04 - val_loss: 2.8390e-04\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2689e-04 - val_loss: 2.9499e-04\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2774e-04 - val_loss: 2.7650e-04\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2375e-04 - val_loss: 2.7618e-04\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2227e-04 - val_loss: 2.7668e-04\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2332e-04 - val_loss: 2.7509e-04\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2418e-04 - val_loss: 2.7817e-04\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.1759e-04 - val_loss: 3.0312e-04\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2333e-04 - val_loss: 2.7396e-04\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.1790e-04 - val_loss: 2.7380e-04\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.1537e-04 - val_loss: 2.7279e-04\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.1269e-04 - val_loss: 2.7867e-04\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.1831e-04 - val_loss: 2.8665e-04\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0964e-04 - val_loss: 2.7571e-04\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.1095e-04 - val_loss: 2.7395e-04\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0803e-04 - val_loss: 2.7110e-04\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.1004e-04 - val_loss: 2.8495e-04\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0712e-04 - val_loss: 2.7021e-04\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0843e-04 - val_loss: 2.6967e-04\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0944e-04 - val_loss: 2.7780e-04\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0201e-04 - val_loss: 2.6898e-04\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0738e-04 - val_loss: 2.8935e-04\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0165e-04 - val_loss: 2.7017e-04\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9960e-04 - val_loss: 2.6915e-04\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0307e-04 - val_loss: 2.8224e-04\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9739e-04 - val_loss: 2.7463e-04\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9894e-04 - val_loss: 2.7879e-04\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9881e-04 - val_loss: 2.6715e-04\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9304e-04 - val_loss: 2.7116e-04\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0013e-04 - val_loss: 2.6559e-04\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9700e-04 - val_loss: 2.6549e-04\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.9208e-04 - val_loss: 2.6475e-04\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9209e-04 - val_loss: 2.6477e-04\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9884e-04 - val_loss: 2.8078e-04\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8974e-04 - val_loss: 2.6414e-04\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.8675e-04 - val_loss: 2.6835e-04\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.8531e-04 - val_loss: 2.6662e-04\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.8885e-04 - val_loss: 2.7762e-04\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.8885e-04 - val_loss: 2.6376e-04\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8486e-04 - val_loss: 2.6260e-04\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.8953e-04 - val_loss: 2.7228e-04\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9095e-04 - val_loss: 2.6730e-04\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.7950e-04 - val_loss: 2.6294e-04\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.7971e-04 - val_loss: 2.6360e-04\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.7962e-04 - val_loss: 2.6446e-04\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.8699e-04 - val_loss: 2.7976e-04\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.8833e-04 - val_loss: 2.7123e-04\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.7509e-04 - val_loss: 2.6721e-04\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.7855e-04 - val_loss: 2.6221e-04\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.7929e-04 - val_loss: 2.6137e-04\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.7566e-04 - val_loss: 2.6091e-04\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.7585e-04 - val_loss: 2.7209e-04\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.7984e-04 - val_loss: 2.5905e-04\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.7274e-04 - val_loss: 2.5884e-04\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.7291e-04 - val_loss: 2.6147e-04\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.7452e-04 - val_loss: 2.5835e-04\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.6996e-04 - val_loss: 2.5843e-04\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.6994e-04 - val_loss: 2.5904e-04\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.7008e-04 - val_loss: 2.6101e-04\n",
      "Thời gian huấn luyện:  14.651963710784912\n",
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_120 (Dense)           (None, 10, 103)           206       \n",
      "                                                                 \n",
      " flatten_96 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,237\n",
      "Trainable params: 1,237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 1s 8ms/step - loss: 0.0071 - val_loss: 8.8783e-04\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 7.9661e-04\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 6.2887e-04\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 6.0721e-04\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 5.4113e-04\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 4.9356e-04\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 5.1374e-04\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 4.8894e-04\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 4.3044e-04\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 9.8254e-04 - val_loss: 4.4216e-04\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.4689e-04 - val_loss: 4.1211e-04\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.1372e-04 - val_loss: 4.1942e-04\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 9.0221e-04 - val_loss: 3.9003e-04\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.4687e-04 - val_loss: 3.8685e-04\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.1129e-04 - val_loss: 3.7110e-04\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.2387e-04 - val_loss: 3.7686e-04\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.9284e-04 - val_loss: 4.2159e-04\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.7930e-04 - val_loss: 3.7954e-04\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.5523e-04 - val_loss: 3.5373e-04\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.2036e-04 - val_loss: 3.5986e-04\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.4475e-04 - val_loss: 4.3712e-04\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.9737e-04 - val_loss: 3.3877e-04\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.0905e-04 - val_loss: 3.3046e-04\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.0786e-04 - val_loss: 3.9238e-04\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.8192e-04 - val_loss: 3.2968e-04\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.8600e-04 - val_loss: 3.2184e-04\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.7436e-04 - val_loss: 3.4074e-04\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.5234e-04 - val_loss: 3.2099e-04\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.6472e-04 - val_loss: 3.3564e-04\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.3367e-04 - val_loss: 4.1900e-04\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.6499e-04 - val_loss: 3.7289e-04\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.1580e-04 - val_loss: 3.4101e-04\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.2096e-04 - val_loss: 3.1263e-04\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.2213e-04 - val_loss: 3.0520e-04\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.9186e-04 - val_loss: 4.1233e-04\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.3149e-04 - val_loss: 3.2054e-04\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.0268e-04 - val_loss: 3.0537e-04\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.9821e-04 - val_loss: 3.3112e-04\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.8991e-04 - val_loss: 2.9420e-04\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.7509e-04 - val_loss: 2.9714e-04\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.7379e-04 - val_loss: 2.9144e-04\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.6492e-04 - val_loss: 2.9950e-04\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.6653e-04 - val_loss: 3.5132e-04\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.8070e-04 - val_loss: 3.4984e-04\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.9931e-04 - val_loss: 3.0504e-04\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.7371e-04 - val_loss: 3.2803e-04\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.6610e-04 - val_loss: 2.9950e-04\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.5283e-04 - val_loss: 2.8434e-04\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.7571e-04 - val_loss: 2.8360e-04\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.4046e-04 - val_loss: 2.9612e-04\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.3681e-04 - val_loss: 3.0505e-04\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.4307e-04 - val_loss: 2.7650e-04\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.2169e-04 - val_loss: 3.2065e-04\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.3400e-04 - val_loss: 3.2898e-04\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.1705e-04 - val_loss: 2.9228e-04\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.2778e-04 - val_loss: 3.1958e-04\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.2040e-04 - val_loss: 3.0508e-04\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.2962e-04 - val_loss: 2.6908e-04\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.1749e-04 - val_loss: 3.1159e-04\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.1280e-04 - val_loss: 2.7191e-04\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0325e-04 - val_loss: 2.6784e-04\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.2062e-04 - val_loss: 2.8919e-04\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.3887e-04 - val_loss: 3.1395e-04\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.1679e-04 - val_loss: 2.7720e-04\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0862e-04 - val_loss: 2.6173e-04\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9196e-04 - val_loss: 2.6209e-04\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0744e-04 - val_loss: 2.8688e-04\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9548e-04 - val_loss: 3.1061e-04\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9943e-04 - val_loss: 2.6693e-04\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9272e-04 - val_loss: 2.6236e-04\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0221e-04 - val_loss: 2.7033e-04\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8953e-04 - val_loss: 2.6822e-04\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7978e-04 - val_loss: 2.8602e-04\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.3328e-04 - val_loss: 2.6489e-04\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0006e-04 - val_loss: 2.7922e-04\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.7282e-04 - val_loss: 2.6942e-04\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.7507e-04 - val_loss: 2.5645e-04\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8544e-04 - val_loss: 2.5360e-04\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6968e-04 - val_loss: 2.5649e-04\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6774e-04 - val_loss: 2.6703e-04\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 4ms/step - loss: 4.7913e-04 - val_loss: 2.6108e-04\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6871e-04 - val_loss: 2.5296e-04\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6696e-04 - val_loss: 2.5090e-04\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6471e-04 - val_loss: 2.4940e-04\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7256e-04 - val_loss: 2.5211e-04\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5950e-04 - val_loss: 2.4965e-04\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6062e-04 - val_loss: 2.5223e-04\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5823e-04 - val_loss: 2.5053e-04\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6130e-04 - val_loss: 3.0745e-04\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8497e-04 - val_loss: 2.6376e-04\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5549e-04 - val_loss: 2.4915e-04\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7367e-04 - val_loss: 2.7883e-04\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6539e-04 - val_loss: 2.9134e-04\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6692e-04 - val_loss: 2.4895e-04\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4399e-04 - val_loss: 2.4260e-04\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4783e-04 - val_loss: 2.4209e-04\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4340e-04 - val_loss: 2.4153e-04\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6766e-04 - val_loss: 3.2603e-04\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8220e-04 - val_loss: 2.5690e-04\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4635e-04 - val_loss: 2.4100e-04\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4213e-04 - val_loss: 2.9504e-04\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4117e-04 - val_loss: 2.4020e-04\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4235e-04 - val_loss: 2.4934e-04\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5224e-04 - val_loss: 2.5777e-04\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4349e-04 - val_loss: 2.3795e-04\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3798e-04 - val_loss: 2.9213e-04\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3500e-04 - val_loss: 2.4141e-04\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5603e-04 - val_loss: 2.7822e-04\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3487e-04 - val_loss: 2.4774e-04\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3819e-04 - val_loss: 2.3656e-04\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2812e-04 - val_loss: 2.4870e-04\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3340e-04 - val_loss: 2.7261e-04\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4105e-04 - val_loss: 2.3553e-04\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3883e-04 - val_loss: 2.4157e-04\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2720e-04 - val_loss: 2.3682e-04\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3201e-04 - val_loss: 2.3736e-04\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3279e-04 - val_loss: 2.4968e-04\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3113e-04 - val_loss: 2.3431e-04\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3090e-04 - val_loss: 2.3496e-04\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3582e-04 - val_loss: 2.4168e-04\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3903e-04 - val_loss: 2.9150e-04\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3354e-04 - val_loss: 2.6531e-04\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2924e-04 - val_loss: 2.3345e-04\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2239e-04 - val_loss: 2.3308e-04\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2780e-04 - val_loss: 2.3663e-04\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3586e-04 - val_loss: 2.8112e-04\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3908e-04 - val_loss: 2.9249e-04\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3248e-04 - val_loss: 2.4214e-04\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3213e-04 - val_loss: 2.3951e-04\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2762e-04 - val_loss: 2.3337e-04\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2984e-04 - val_loss: 2.3866e-04\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3085e-04 - val_loss: 2.3346e-04\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1585e-04 - val_loss: 2.6513e-04\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2191e-04 - val_loss: 2.5198e-04\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2046e-04 - val_loss: 2.3444e-04\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2529e-04 - val_loss: 2.4483e-04\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3634e-04 - val_loss: 2.5576e-04\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1496e-04 - val_loss: 2.2996e-04\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2055e-04 - val_loss: 2.3029e-04\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2963e-04 - val_loss: 2.3036e-04\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2009e-04 - val_loss: 2.3434e-04\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1842e-04 - val_loss: 2.3813e-04\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3452e-04 - val_loss: 3.6751e-04\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5001e-04 - val_loss: 2.3742e-04\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6090e-04 - val_loss: 2.7160e-04\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1364e-04 - val_loss: 2.4896e-04\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1666e-04 - val_loss: 2.2950e-04\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3273e-04 - val_loss: 2.4306e-04\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2229e-04 - val_loss: 2.5740e-04\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1099e-04 - val_loss: 2.2918e-04\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2770e-04 - val_loss: 2.3714e-04\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4313e-04 - val_loss: 2.2873e-04\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1217e-04 - val_loss: 2.2863e-04\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2364e-04 - val_loss: 2.2884e-04\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0596e-04 - val_loss: 2.3104e-04\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1874e-04 - val_loss: 2.3384e-04\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2040e-04 - val_loss: 2.3953e-04\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1115e-04 - val_loss: 2.3037e-04\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1084e-04 - val_loss: 2.4741e-04\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1324e-04 - val_loss: 2.4964e-04\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1716e-04 - val_loss: 2.2831e-04\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3596e-04 - val_loss: 2.3931e-04\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1126e-04 - val_loss: 2.5064e-04\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2097e-04 - val_loss: 2.4086e-04\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0956e-04 - val_loss: 2.2905e-04\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1701e-04 - val_loss: 2.4502e-04\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0126e-04 - val_loss: 2.3466e-04\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1158e-04 - val_loss: 2.3375e-04\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1546e-04 - val_loss: 2.3796e-04\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1761e-04 - val_loss: 2.7488e-04\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1078e-04 - val_loss: 2.3491e-04\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2189e-04 - val_loss: 2.2750e-04\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1822e-04 - val_loss: 2.2924e-04\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0904e-04 - val_loss: 2.3753e-04\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1103e-04 - val_loss: 2.2801e-04\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1256e-04 - val_loss: 2.2800e-04\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0703e-04 - val_loss: 2.8765e-04\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3637e-04 - val_loss: 2.3998e-04\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0879e-04 - val_loss: 2.5611e-04\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1279e-04 - val_loss: 2.3029e-04\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1125e-04 - val_loss: 2.3285e-04\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1056e-04 - val_loss: 2.4912e-04\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1094e-04 - val_loss: 2.3088e-04\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0581e-04 - val_loss: 2.3209e-04\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0277e-04 - val_loss: 2.2996e-04\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0742e-04 - val_loss: 2.3417e-04\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1719e-04 - val_loss: 2.6629e-04\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1555e-04 - val_loss: 2.3670e-04\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1368e-04 - val_loss: 3.3958e-04\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2100e-04 - val_loss: 2.2914e-04\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1672e-04 - val_loss: 2.7398e-04\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2626e-04 - val_loss: 2.3058e-04\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1262e-04 - val_loss: 2.5648e-04\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1335e-04 - val_loss: 2.3019e-04\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0478e-04 - val_loss: 2.3117e-04\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.1009e-04 - val_loss: 2.2850e-04\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1205e-04 - val_loss: 2.4198e-04\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3116e-04 - val_loss: 2.2793e-04\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2184e-04 - val_loss: 3.0611e-04\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.1631e-04 - val_loss: 2.2782e-04\n",
      "Thời gian huấn luyện:  24.29134488105774\n",
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_24 (SimpleRNN)   (None, 10, 103)           10815     \n",
      "                                                                 \n",
      " flatten_97 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,846\n",
      "Trainable params: 11,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 2s 16ms/step - loss: 0.0162 - val_loss: 0.0019\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 7.4548e-04\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 6.2759e-04\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 6.2809e-04\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 6.2613e-04\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 6.4310e-04\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 6.1752e-04\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 6.1201e-04\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 6.1713e-04\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 6.2202e-04\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 6.0427e-04\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 6.2573e-04\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 6.0565e-04\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 5.9462e-04\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 5.9162e-04\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 5.7713e-04\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 5.8121e-04\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 6.2673e-04\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 5.5779e-04\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 5.5948e-04\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 5.5056e-04\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 6.1306e-04\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 5.4679e-04\n",
      "Epoch 24/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 5.3373e-04\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 5.2817e-04\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 5.2650e-04\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 5.1639e-04\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 5.1391e-04\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 5.1702e-04\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 5.1390e-04\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 4.9657e-04\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 4.9114e-04\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.2077e-04\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 4.9013e-04\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 4.9354e-04\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 4.9000e-04\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 4.6998e-04\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 4.6879e-04\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 4.6556e-04\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 4.8826e-04\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 4.5665e-04\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 4.5611e-04\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 4.4865e-04\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 5.3251e-04\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 4.4932e-04\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 4.9475e-04\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 4.6446e-04\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 4.4152e-04\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 4.3095e-04\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.9611e-04 - val_loss: 4.4316e-04\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.7787e-04 - val_loss: 4.3235e-04\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.8915e-04 - val_loss: 4.2530e-04\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.6658e-04 - val_loss: 4.6751e-04\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.9518e-04 - val_loss: 4.2484e-04\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.6772e-04 - val_loss: 4.6306e-04\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.9350e-04 - val_loss: 4.5699e-04\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 9.6005e-04 - val_loss: 4.1788e-04\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.3008e-04 - val_loss: 4.3214e-04\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.5057e-04 - val_loss: 4.7780e-04\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.4744e-04 - val_loss: 4.3536e-04\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.2603e-04 - val_loss: 4.2760e-04\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.4020e-04 - val_loss: 4.2171e-04\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.0519e-04 - val_loss: 4.1327e-04\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.0236e-04 - val_loss: 4.1068e-04\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.0627e-04 - val_loss: 4.0606e-04\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.8992e-04 - val_loss: 4.5166e-04\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.1507e-04 - val_loss: 4.0678e-04\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.0087e-04 - val_loss: 4.3664e-04\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.0412e-04 - val_loss: 4.4464e-04\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.9716e-04 - val_loss: 4.0764e-04\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.7599e-04 - val_loss: 3.9990e-04\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.7958e-04 - val_loss: 4.5003e-04\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.6341e-04 - val_loss: 4.1556e-04\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.7038e-04 - val_loss: 4.1354e-04\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.5783e-04 - val_loss: 4.2864e-04\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.9721e-04 - val_loss: 3.9167e-04\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.4899e-04 - val_loss: 3.9232e-04\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.4430e-04 - val_loss: 4.1995e-04\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.4804e-04 - val_loss: 3.9220e-04\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.6307e-04 - val_loss: 3.8645e-04\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.5127e-04 - val_loss: 3.8713e-04\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.4744e-04 - val_loss: 4.0234e-04\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.4055e-04 - val_loss: 3.9289e-04\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.4393e-04 - val_loss: 3.8348e-04\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.3281e-04 - val_loss: 3.7986e-04\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.4387e-04 - val_loss: 3.8447e-04\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.1200e-04 - val_loss: 3.7932e-04\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.2862e-04 - val_loss: 3.7610e-04\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.1013e-04 - val_loss: 3.8121e-04\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.0877e-04 - val_loss: 3.9867e-04\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.0356e-04 - val_loss: 3.7410e-04\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.9147e-04 - val_loss: 3.7052e-04\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.9215e-04 - val_loss: 3.6914e-04\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.0223e-04 - val_loss: 3.7849e-04\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.9394e-04 - val_loss: 3.6957e-04\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.8041e-04 - val_loss: 3.7308e-04\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.8373e-04 - val_loss: 3.7889e-04\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6828e-04 - val_loss: 4.1333e-04\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.9694e-04 - val_loss: 3.6420e-04\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6609e-04 - val_loss: 3.8253e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6773e-04 - val_loss: 3.7422e-04\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.9061e-04 - val_loss: 3.7391e-04\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.5108e-04 - val_loss: 3.5849e-04\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6002e-04 - val_loss: 3.5719e-04\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.4750e-04 - val_loss: 3.5795e-04\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.5055e-04 - val_loss: 3.5651e-04\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.4384e-04 - val_loss: 3.5714e-04\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.3348e-04 - val_loss: 3.5269e-04\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.3186e-04 - val_loss: 3.4995e-04\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 7.3005e-04 - val_loss: 3.5015e-04\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.2393e-04 - val_loss: 3.4934e-04\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.2470e-04 - val_loss: 3.5022e-04\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.1524e-04 - val_loss: 3.4779e-04\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.1955e-04 - val_loss: 3.4452e-04\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.1025e-04 - val_loss: 3.4337e-04\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.1187e-04 - val_loss: 3.4297e-04\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.0393e-04 - val_loss: 3.4561e-04\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.0184e-04 - val_loss: 3.5384e-04\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.0713e-04 - val_loss: 3.3986e-04\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.0913e-04 - val_loss: 3.6326e-04\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.9286e-04 - val_loss: 3.4216e-04\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.0252e-04 - val_loss: 3.3429e-04\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.8521e-04 - val_loss: 3.3323e-04\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.8787e-04 - val_loss: 3.4291e-04\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.7486e-04 - val_loss: 3.3752e-04\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.6889e-04 - val_loss: 3.2939e-04\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.6993e-04 - val_loss: 3.3794e-04\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.6923e-04 - val_loss: 3.2863e-04\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.7574e-04 - val_loss: 3.3152e-04\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.8851e-04 - val_loss: 3.9910e-04\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.6770e-04 - val_loss: 3.8441e-04\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.6333e-04 - val_loss: 3.2642e-04\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.5646e-04 - val_loss: 3.4332e-04\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.5931e-04 - val_loss: 3.2253e-04\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.5789e-04 - val_loss: 3.5555e-04\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.5074e-04 - val_loss: 3.2619e-04\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.5545e-04 - val_loss: 4.0603e-04\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.5920e-04 - val_loss: 3.9254e-04\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.4587e-04 - val_loss: 3.1818e-04\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.4019e-04 - val_loss: 3.1726e-04\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.5642e-04 - val_loss: 3.1589e-04\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.3879e-04 - val_loss: 3.5701e-04\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.3858e-04 - val_loss: 3.1564e-04\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.2656e-04 - val_loss: 3.4335e-04\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.2486e-04 - val_loss: 3.1488e-04\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.2440e-04 - val_loss: 3.2067e-04\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.2491e-04 - val_loss: 3.5502e-04\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.2153e-04 - val_loss: 3.1128e-04\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.1086e-04 - val_loss: 3.3135e-04\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.1487e-04 - val_loss: 3.2127e-04\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.1906e-04 - val_loss: 3.0882e-04\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.1637e-04 - val_loss: 3.2380e-04\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.2815e-04 - val_loss: 3.1329e-04\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.1622e-04 - val_loss: 3.0972e-04\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.1185e-04 - val_loss: 3.1989e-04\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.0207e-04 - val_loss: 3.1499e-04\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.9396e-04 - val_loss: 3.2161e-04\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.0044e-04 - val_loss: 3.2396e-04\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.9284e-04 - val_loss: 3.0522e-04\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.8873e-04 - val_loss: 3.1054e-04\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.9215e-04 - val_loss: 3.0297e-04\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.8335e-04 - val_loss: 3.0815e-04\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.8350e-04 - val_loss: 3.0658e-04\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.8437e-04 - val_loss: 3.0172e-04\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.8089e-04 - val_loss: 3.0125e-04\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.8402e-04 - val_loss: 3.0539e-04\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.7937e-04 - val_loss: 3.0894e-04\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.7339e-04 - val_loss: 2.9958e-04\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.6806e-04 - val_loss: 2.9902e-04\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.6979e-04 - val_loss: 3.4947e-04\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.8324e-04 - val_loss: 2.9632e-04\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.7561e-04 - val_loss: 2.9973e-04\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.6734e-04 - val_loss: 3.0812e-04\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.6196e-04 - val_loss: 2.9551e-04\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.6758e-04 - val_loss: 3.1882e-04\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 7ms/step - loss: 5.6713e-04 - val_loss: 2.9387e-04\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.5630e-04 - val_loss: 3.0634e-04\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.6059e-04 - val_loss: 3.1109e-04\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.6932e-04 - val_loss: 3.1779e-04\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.7904e-04 - val_loss: 2.9158e-04\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.7237e-04 - val_loss: 2.9166e-04\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.5544e-04 - val_loss: 2.9152e-04\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.4476e-04 - val_loss: 2.9057e-04\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.7900e-04 - val_loss: 2.9046e-04\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.6469e-04 - val_loss: 2.9268e-04\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.5149e-04 - val_loss: 2.9994e-04\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.5413e-04 - val_loss: 2.8809e-04\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.4026e-04 - val_loss: 2.8688e-04\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.4496e-04 - val_loss: 3.3805e-04\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.5266e-04 - val_loss: 2.8671e-04\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.3839e-04 - val_loss: 2.9021e-04\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.3694e-04 - val_loss: 3.0150e-04\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.3070e-04 - val_loss: 2.8425e-04\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.2783e-04 - val_loss: 2.9343e-04\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.3674e-04 - val_loss: 2.8328e-04\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.3100e-04 - val_loss: 3.1591e-04\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.4283e-04 - val_loss: 2.8704e-04\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.2933e-04 - val_loss: 2.8291e-04\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.3829e-04 - val_loss: 2.8123e-04\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.3655e-04 - val_loss: 3.0367e-04\n",
      "Thời gian huấn luyện:  53.78579902648926\n",
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_24 (LSTM)              (None, 10, 103)           43260     \n",
      "                                                                 \n",
      " flatten_98 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,291\n",
      "Trainable params: 44,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 2s 15ms/step - loss: 0.0156 - val_loss: 0.0018\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 6.3018e-04\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 6.1897e-04\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 5.7302e-04\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 5.7859e-04\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 5.7172e-04\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 5.5926e-04\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 5.5943e-04\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 5.4092e-04\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 5.4001e-04\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 5.3460e-04\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 5.1514e-04\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 5.1791e-04\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.1284e-04\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 4.9682e-04\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 5.0635e-04\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 5.0935e-04\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 4.6956e-04\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 4.6369e-04\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 4.5416e-04\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 4.4780e-04\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 4.4306e-04\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 4.3795e-04\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 4.3036e-04\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 4.2167e-04\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.7004e-04 - val_loss: 4.2369e-04\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.5219e-04 - val_loss: 4.1358e-04\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.3242e-04 - val_loss: 4.0615e-04\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 9.2820e-04 - val_loss: 4.0144e-04\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.0622e-04 - val_loss: 4.0339e-04\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 8.8984e-04 - val_loss: 3.9783e-04\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 8.9681e-04 - val_loss: 3.9219e-04\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.6517e-04 - val_loss: 4.0839e-04\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.7212e-04 - val_loss: 4.0369e-04\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.4267e-04 - val_loss: 3.8880e-04\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 8.3909e-04 - val_loss: 3.8195e-04\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.3421e-04 - val_loss: 3.8634e-04\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.1026e-04 - val_loss: 3.7358e-04\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.1087e-04 - val_loss: 3.7044e-04\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.9573e-04 - val_loss: 3.7177e-04\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.8494e-04 - val_loss: 4.0395e-04\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.9354e-04 - val_loss: 4.0773e-04\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.7382e-04 - val_loss: 3.6780e-04\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6145e-04 - val_loss: 3.7340e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.5285e-04 - val_loss: 3.6372e-04\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.4543e-04 - val_loss: 3.6502e-04\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.5575e-04 - val_loss: 3.6305e-04\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.5356e-04 - val_loss: 3.6562e-04\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.4270e-04 - val_loss: 3.5395e-04\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.2741e-04 - val_loss: 3.6633e-04\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.2175e-04 - val_loss: 3.4979e-04\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.2529e-04 - val_loss: 3.6548e-04\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.2280e-04 - val_loss: 3.4752e-04\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.0875e-04 - val_loss: 3.5665e-04\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.0337e-04 - val_loss: 3.5283e-04\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.9806e-04 - val_loss: 3.4267e-04\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.9900e-04 - val_loss: 3.6852e-04\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.0299e-04 - val_loss: 3.4569e-04\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.9060e-04 - val_loss: 3.6765e-04\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.8734e-04 - val_loss: 3.5870e-04\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.8929e-04 - val_loss: 3.5972e-04\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.8140e-04 - val_loss: 3.4043e-04\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.7214e-04 - val_loss: 3.3601e-04\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.7176e-04 - val_loss: 3.3217e-04\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.5817e-04 - val_loss: 3.3149e-04\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.6810e-04 - val_loss: 3.3065e-04\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.5555e-04 - val_loss: 3.3246e-04\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.5117e-04 - val_loss: 3.3134e-04\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.4484e-04 - val_loss: 3.5537e-04\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.5197e-04 - val_loss: 3.2506e-04\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.5938e-04 - val_loss: 3.5637e-04\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.3778e-04 - val_loss: 3.4007e-04\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.3145e-04 - val_loss: 3.2265e-04\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.3419e-04 - val_loss: 3.2122e-04\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.2679e-04 - val_loss: 3.2949e-04\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.2847e-04 - val_loss: 3.1950e-04\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.3235e-04 - val_loss: 3.1698e-04\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.2118e-04 - val_loss: 3.1686e-04\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.1360e-04 - val_loss: 3.2150e-04\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.1430e-04 - val_loss: 3.4876e-04\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.1065e-04 - val_loss: 3.2259e-04\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.0728e-04 - val_loss: 3.1860e-04\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.1043e-04 - val_loss: 3.1851e-04\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.9669e-04 - val_loss: 3.1662e-04\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.9152e-04 - val_loss: 3.0892e-04\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.9102e-04 - val_loss: 3.0871e-04\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.9023e-04 - val_loss: 3.0902e-04\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.8471e-04 - val_loss: 3.0645e-04\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.8571e-04 - val_loss: 3.0609e-04\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.8743e-04 - val_loss: 3.0823e-04\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.8448e-04 - val_loss: 3.2834e-04\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.7668e-04 - val_loss: 3.5175e-04\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.8693e-04 - val_loss: 3.4566e-04\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.8209e-04 - val_loss: 3.0644e-04\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.7594e-04 - val_loss: 3.0144e-04\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.6270e-04 - val_loss: 3.0174e-04\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.6492e-04 - val_loss: 3.0431e-04\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.6488e-04 - val_loss: 3.0050e-04\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.6329e-04 - val_loss: 3.1364e-04\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.5854e-04 - val_loss: 3.3741e-04\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.5611e-04 - val_loss: 3.0819e-04\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.5248e-04 - val_loss: 2.9381e-04\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.6195e-04 - val_loss: 3.1151e-04\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.5551e-04 - val_loss: 2.9367e-04\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.4740e-04 - val_loss: 2.9089e-04\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.4120e-04 - val_loss: 3.1021e-04\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.4977e-04 - val_loss: 3.2189e-04\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.7025e-04 - val_loss: 3.2689e-04\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.4230e-04 - val_loss: 2.9306e-04\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.4630e-04 - val_loss: 2.8662e-04\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.5954e-04 - val_loss: 3.0412e-04\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.5615e-04 - val_loss: 2.8493e-04\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.4026e-04 - val_loss: 2.9204e-04\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.3237e-04 - val_loss: 2.9783e-04\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.4148e-04 - val_loss: 3.0163e-04\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.3782e-04 - val_loss: 2.8568e-04\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.1618e-04 - val_loss: 2.8420e-04\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.2332e-04 - val_loss: 2.8253e-04\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.1883e-04 - val_loss: 2.8162e-04\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 6ms/step - loss: 5.2151e-04 - val_loss: 2.8952e-04\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.1356e-04 - val_loss: 3.3150e-04\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.1415e-04 - val_loss: 3.1028e-04\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.3776e-04 - val_loss: 2.8728e-04\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.2095e-04 - val_loss: 2.9822e-04\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.1854e-04 - val_loss: 2.8453e-04\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.1288e-04 - val_loss: 2.7325e-04\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.0240e-04 - val_loss: 2.7326e-04\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.1294e-04 - val_loss: 2.7881e-04\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.1965e-04 - val_loss: 2.7130e-04\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.0286e-04 - val_loss: 2.8326e-04\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.0105e-04 - val_loss: 2.7036e-04\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.9526e-04 - val_loss: 2.8371e-04\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.9440e-04 - val_loss: 2.9565e-04\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.0523e-04 - val_loss: 2.6798e-04\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.8829e-04 - val_loss: 2.7102e-04\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.9427e-04 - val_loss: 2.6695e-04\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.9390e-04 - val_loss: 2.9665e-04\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.9351e-04 - val_loss: 2.7061e-04\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.8485e-04 - val_loss: 2.6351e-04\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.9475e-04 - val_loss: 2.6569e-04\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.8146e-04 - val_loss: 2.6564e-04\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.7889e-04 - val_loss: 2.6801e-04\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.8210e-04 - val_loss: 2.6787e-04\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.8140e-04 - val_loss: 2.7731e-04\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.7130e-04 - val_loss: 2.6038e-04\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.7498e-04 - val_loss: 2.6688e-04\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.7855e-04 - val_loss: 2.6491e-04\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.8484e-04 - val_loss: 2.5896e-04\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.6856e-04 - val_loss: 2.5828e-04\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.6966e-04 - val_loss: 2.6467e-04\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.6484e-04 - val_loss: 2.5557e-04\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.6641e-04 - val_loss: 2.5355e-04\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.6721e-04 - val_loss: 2.5462e-04\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.6352e-04 - val_loss: 2.5269e-04\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.7614e-04 - val_loss: 2.5671e-04\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.6660e-04 - val_loss: 2.6316e-04\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.9802e-04 - val_loss: 2.5303e-04\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.6653e-04 - val_loss: 2.5808e-04\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.6124e-04 - val_loss: 2.5277e-04\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.5367e-04 - val_loss: 2.5414e-04\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.5406e-04 - val_loss: 2.6704e-04\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.5488e-04 - val_loss: 2.8088e-04\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.6024e-04 - val_loss: 2.4990e-04\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.5012e-04 - val_loss: 2.7797e-04\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.4810e-04 - val_loss: 2.4906e-04\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.4961e-04 - val_loss: 2.4599e-04\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 4.4557e-04 - val_loss: 2.8459e-04\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.6599e-04 - val_loss: 2.8077e-04\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.5206e-04 - val_loss: 3.1895e-04\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.6584e-04 - val_loss: 2.4826e-04\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.4578e-04 - val_loss: 2.5527e-04\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.4397e-04 - val_loss: 2.4231e-04\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 4.3756e-04 - val_loss: 2.4287e-04\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.4138e-04 - val_loss: 2.4272e-04\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3987e-04 - val_loss: 2.5973e-04\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 4.4008e-04 - val_loss: 2.6341e-04\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.4973e-04 - val_loss: 2.3903e-04\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3770e-04 - val_loss: 2.3990e-04\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3515e-04 - val_loss: 2.3852e-04\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3918e-04 - val_loss: 2.5228e-04\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3554e-04 - val_loss: 2.3999e-04\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3372e-04 - val_loss: 2.4047e-04\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3353e-04 - val_loss: 2.3903e-04\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3822e-04 - val_loss: 2.4026e-04\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3317e-04 - val_loss: 2.4311e-04\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2814e-04 - val_loss: 2.3603e-04\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3492e-04 - val_loss: 2.4604e-04\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3933e-04 - val_loss: 2.5104e-04\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3532e-04 - val_loss: 2.4338e-04\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3682e-04 - val_loss: 2.3593e-04\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2325e-04 - val_loss: 2.3414e-04\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2642e-04 - val_loss: 2.4231e-04\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3044e-04 - val_loss: 2.3369e-04\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2179e-04 - val_loss: 2.3564e-04\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3799e-04 - val_loss: 2.3313e-04\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.1807e-04 - val_loss: 2.5786e-04\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.4136e-04 - val_loss: 2.3773e-04\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2296e-04 - val_loss: 2.4004e-04\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2237e-04 - val_loss: 2.3191e-04\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2114e-04 - val_loss: 2.3197e-04\n",
      "Thời gian huấn luyện:  49.49434757232666\n",
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_24 (GRU)                (None, 10, 103)           32754     \n",
      "                                                                 \n",
      " flatten_99 (Flatten)        (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,785\n",
      "Trainable params: 33,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 162/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Thời gian huấn luyện:  14.123104810714722\n",
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_125 (Dense)           (None, 10, 103)           206       \n",
      "                                                                 \n",
      " flatten_100 (Flatten)       (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,237\n",
      "Trainable params: 1,237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "34/34 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 9.7128e-04\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 9.0700e-04\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 7.9815e-04\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 7.1789e-04\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 8.1808e-04\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9.7137e-04 - val_loss: 6.5583e-04\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9.4913e-04 - val_loss: 6.4413e-04\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9.1951e-04 - val_loss: 6.0892e-04\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8.9407e-04 - val_loss: 5.9074e-04\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8.4085e-04 - val_loss: 5.7594e-04\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8.7535e-04 - val_loss: 5.6513e-04\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8.1771e-04 - val_loss: 5.7599e-04\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8.1161e-04 - val_loss: 5.7191e-04\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.8691e-04 - val_loss: 5.3020e-04\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.5592e-04 - val_loss: 5.6072e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.5075e-04 - val_loss: 6.1066e-04\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.4017e-04 - val_loss: 5.5336e-04\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.1807e-04 - val_loss: 5.2701e-04\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.9826e-04 - val_loss: 5.0114e-04\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.0174e-04 - val_loss: 4.9403e-04\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.7672e-04 - val_loss: 4.7985e-04\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.6900e-04 - val_loss: 5.1164e-04\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.7477e-04 - val_loss: 4.8220e-04\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.6274e-04 - val_loss: 4.7403e-04\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.5591e-04 - val_loss: 4.6988e-04\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.3711e-04 - val_loss: 4.6039e-04\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.4750e-04 - val_loss: 4.6027e-04\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.3579e-04 - val_loss: 4.7962e-04\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.4171e-04 - val_loss: 4.4374e-04\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.2658e-04 - val_loss: 4.7650e-04\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.5145e-04 - val_loss: 4.5998e-04\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.0866e-04 - val_loss: 4.3717e-04\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.5616e-04 - val_loss: 4.5561e-04\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.1521e-04 - val_loss: 4.2776e-04\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.8445e-04 - val_loss: 4.2447e-04\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6.0015e-04 - val_loss: 4.4326e-04\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.8755e-04 - val_loss: 4.2544e-04\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.8504e-04 - val_loss: 4.3090e-04\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.8921e-04 - val_loss: 4.2115e-04\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.8666e-04 - val_loss: 4.1138e-04\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.6381e-04 - val_loss: 4.0748e-04\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.6775e-04 - val_loss: 4.0498e-04\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.5639e-04 - val_loss: 4.0066e-04\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.6845e-04 - val_loss: 4.1508e-04\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.7206e-04 - val_loss: 4.3700e-04\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.6204e-04 - val_loss: 3.9590e-04\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 5.8492e-04 - val_loss: 4.2684e-04\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 5.6129e-04 - val_loss: 4.4626e-04\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 5.4534e-04 - val_loss: 4.0685e-04\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 5.5109e-04 - val_loss: 3.8620e-04\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 5.4040e-04 - val_loss: 4.1879e-04\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.4623e-04 - val_loss: 3.8499e-04\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 5.6990e-04 - val_loss: 3.9514e-04\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.4345e-04 - val_loss: 3.8251e-04\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.4943e-04 - val_loss: 3.7757e-04\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.3547e-04 - val_loss: 3.9215e-04\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.3742e-04 - val_loss: 4.0085e-04\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.2032e-04 - val_loss: 3.8210e-04\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.1611e-04 - val_loss: 3.7152e-04\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.1180e-04 - val_loss: 3.6917e-04\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.2336e-04 - val_loss: 3.9726e-04\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.4150e-04 - val_loss: 3.6734e-04\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.6272e-04 - val_loss: 4.1045e-04\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.3346e-04 - val_loss: 4.0834e-04\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.1223e-04 - val_loss: 3.6651e-04\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.0279e-04 - val_loss: 3.6149e-04\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.0245e-04 - val_loss: 3.7383e-04\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.9440e-04 - val_loss: 3.9144e-04\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.8954e-04 - val_loss: 4.5015e-04\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.0606e-04 - val_loss: 3.5292e-04\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.1872e-04 - val_loss: 4.0540e-04\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.9581e-04 - val_loss: 4.2794e-04\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.0566e-04 - val_loss: 3.5898e-04\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.1237e-04 - val_loss: 3.4846e-04\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.0180e-04 - val_loss: 3.4886e-04\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.8244e-04 - val_loss: 3.4670e-04\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.0847e-04 - val_loss: 4.2889e-04\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.1053e-04 - val_loss: 3.5227e-04\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.7583e-04 - val_loss: 3.4256e-04\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.7396e-04 - val_loss: 3.4228e-04\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.7845e-04 - val_loss: 3.5465e-04\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.9150e-04 - val_loss: 3.3884e-04\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.6870e-04 - val_loss: 3.6537e-04\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.6168e-04 - val_loss: 3.5073e-04\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.6567e-04 - val_loss: 3.3999e-04\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.6873e-04 - val_loss: 3.6933e-04\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.7760e-04 - val_loss: 3.4140e-04\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.7187e-04 - val_loss: 3.3251e-04\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.5803e-04 - val_loss: 3.3151e-04\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.6523e-04 - val_loss: 3.3034e-04\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.6069e-04 - val_loss: 3.3322e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.5560e-04 - val_loss: 3.4571e-04\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.5991e-04 - val_loss: 3.3474e-04\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.5393e-04 - val_loss: 3.3586e-04\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.6341e-04 - val_loss: 3.2745e-04\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.7645e-04 - val_loss: 5.1615e-04\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.0174e-04 - val_loss: 3.2490e-04\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.5076e-04 - val_loss: 3.8594e-04\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.5015e-04 - val_loss: 3.3772e-04\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.5087e-04 - val_loss: 3.2755e-04\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.4965e-04 - val_loss: 3.2295e-04\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.4780e-04 - val_loss: 3.2204e-04\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.5993e-04 - val_loss: 3.3282e-04\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.6332e-04 - val_loss: 3.1878e-04\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.5064e-04 - val_loss: 3.3613e-04\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.6036e-04 - val_loss: 3.1759e-04\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.4398e-04 - val_loss: 3.2989e-04\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.4256e-04 - val_loss: 3.1812e-04\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.3981e-04 - val_loss: 3.3749e-04\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.5095e-04 - val_loss: 3.1418e-04\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.4805e-04 - val_loss: 3.4880e-04\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.8246e-04 - val_loss: 3.4648e-04\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.3671e-04 - val_loss: 3.4724e-04\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.2983e-04 - val_loss: 3.2793e-04\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.3627e-04 - val_loss: 3.1880e-04\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.4366e-04 - val_loss: 3.1131e-04\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.3320e-04 - val_loss: 3.2163e-04\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.3071e-04 - val_loss: 3.0852e-04\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.2716e-04 - val_loss: 3.6860e-04\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.4337e-04 - val_loss: 3.1796e-04\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.2618e-04 - val_loss: 3.0695e-04\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.4654e-04 - val_loss: 3.1670e-04\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.2549e-04 - val_loss: 3.0712e-04\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.3032e-04 - val_loss: 3.0489e-04\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.2688e-04 - val_loss: 3.3588e-04\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.3771e-04 - val_loss: 3.2014e-04\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.2834e-04 - val_loss: 3.0793e-04\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.3511e-04 - val_loss: 3.1319e-04\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.3303e-04 - val_loss: 3.4403e-04\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.2100e-04 - val_loss: 3.1873e-04\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.2905e-04 - val_loss: 3.3414e-04\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.3258e-04 - val_loss: 3.1037e-04\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1763e-04 - val_loss: 3.1527e-04\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.2482e-04 - val_loss: 3.0734e-04\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.3823e-04 - val_loss: 3.3398e-04\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1828e-04 - val_loss: 3.0381e-04\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.2569e-04 - val_loss: 3.0216e-04\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1221e-04 - val_loss: 3.1237e-04\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.3980e-04 - val_loss: 3.9709e-04\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.3858e-04 - val_loss: 2.9999e-04\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1930e-04 - val_loss: 3.0108e-04\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.4656e-04 - val_loss: 3.0982e-04\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1579e-04 - val_loss: 3.1666e-04\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.3878e-04 - val_loss: 2.9839e-04\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.3748e-04 - val_loss: 3.0011e-04\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1789e-04 - val_loss: 3.2184e-04\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.7169e-04 - val_loss: 2.9581e-04\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1561e-04 - val_loss: 3.1345e-04\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1993e-04 - val_loss: 3.0370e-04\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.2078e-04 - val_loss: 3.1236e-04\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.2134e-04 - val_loss: 2.9574e-04\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1465e-04 - val_loss: 3.0368e-04\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1934e-04 - val_loss: 3.0684e-04\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1921e-04 - val_loss: 3.1012e-04\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1427e-04 - val_loss: 3.3923e-04\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.0880e-04 - val_loss: 3.2005e-04\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1613e-04 - val_loss: 2.9551e-04\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1018e-04 - val_loss: 2.9669e-04\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1360e-04 - val_loss: 3.1871e-04\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1047e-04 - val_loss: 3.1919e-04\n",
      "Epoch 162/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1636e-04 - val_loss: 3.0931e-04\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.2027e-04 - val_loss: 2.9257e-04\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.0588e-04 - val_loss: 2.9241e-04\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.2479e-04 - val_loss: 3.3399e-04\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1455e-04 - val_loss: 2.9248e-04\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1773e-04 - val_loss: 3.0589e-04\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1372e-04 - val_loss: 2.9720e-04\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.0928e-04 - val_loss: 2.9341e-04\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1165e-04 - val_loss: 3.0247e-04\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1597e-04 - val_loss: 3.5259e-04\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.4587e-04 - val_loss: 2.9139e-04\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1291e-04 - val_loss: 2.9172e-04\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.0551e-04 - val_loss: 3.0318e-04\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1678e-04 - val_loss: 2.9718e-04\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.2379e-04 - val_loss: 3.3256e-04\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.0667e-04 - val_loss: 2.9243e-04\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1449e-04 - val_loss: 2.9939e-04\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.0850e-04 - val_loss: 2.9212e-04\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1663e-04 - val_loss: 2.9107e-04\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.0983e-04 - val_loss: 3.1745e-04\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1876e-04 - val_loss: 3.0114e-04\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.2003e-04 - val_loss: 3.1344e-04\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.2954e-04 - val_loss: 2.9177e-04\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1300e-04 - val_loss: 2.9055e-04\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1804e-04 - val_loss: 2.9471e-04\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.2347e-04 - val_loss: 2.9160e-04\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1358e-04 - val_loss: 3.0811e-04\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.0965e-04 - val_loss: 2.9066e-04\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1271e-04 - val_loss: 2.9401e-04\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 4.1890e-04 - val_loss: 2.9620e-04\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.0672e-04 - val_loss: 2.9047e-04\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.0369e-04 - val_loss: 2.9754e-04\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.2170e-04 - val_loss: 2.9010e-04\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.2910e-04 - val_loss: 3.7038e-04\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1310e-04 - val_loss: 3.1152e-04\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.0928e-04 - val_loss: 3.2539e-04\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.2647e-04 - val_loss: 2.9495e-04\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1985e-04 - val_loss: 2.9260e-04\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.1819e-04 - val_loss: 2.9144e-04\n",
      "Thời gian huấn luyện:  23.41905927658081\n",
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_25 (SimpleRNN)   (None, 10, 103)           10815     \n",
      "                                                                 \n",
      " flatten_101 (Flatten)       (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,846\n",
      "Trainable params: 11,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "34/34 [==============================] - 2s 18ms/step - loss: 0.0183 - val_loss: 0.0021\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 9.7107e-04\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 9.6740e-04\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 9.5301e-04\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 9.3551e-04\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 9.1573e-04\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 9.3629e-04\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 9.5094e-04\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 9.1818e-04\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 8.8841e-04\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 8.6597e-04\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 8.7226e-04\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 8.3596e-04\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 8.3787e-04\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 8.1949e-04\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 8.3936e-04\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 8.4132e-04\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 7.8956e-04\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.7499e-04\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.9727e-04\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.7302e-04\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.7087e-04\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.4396e-04\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.3496e-04\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 7.8685e-04\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.2124e-04\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 7.1407e-04\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 7.0707e-04\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 7.2708e-04\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 6.9518e-04\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 7.3990e-04\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 7.2291e-04\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 9.9308e-04 - val_loss: 6.9873e-04\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 9.8356e-04 - val_loss: 6.7700e-04\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 9.6384e-04 - val_loss: 6.8459e-04\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 9.6154e-04 - val_loss: 6.9677e-04\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 9.5592e-04 - val_loss: 6.9203e-04\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 9.4897e-04 - val_loss: 6.7237e-04\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 9.4500e-04 - val_loss: 6.7006e-04\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 9.4415e-04 - val_loss: 6.7948e-04\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 9.4493e-04 - val_loss: 6.5306e-04\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 9.2793e-04 - val_loss: 6.5486e-04\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 9.2919e-04 - val_loss: 6.6719e-04\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 9.2969e-04 - val_loss: 6.5397e-04\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 9.1272e-04 - val_loss: 6.4193e-04\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.1334e-04 - val_loss: 7.0446e-04\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 9.1977e-04 - val_loss: 6.3773e-04\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 9.0226e-04 - val_loss: 6.5476e-04\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 9.0078e-04 - val_loss: 6.3570e-04\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 9.0158e-04 - val_loss: 6.3170e-04\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 8.9821e-04 - val_loss: 6.4542e-04\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 8.7794e-04 - val_loss: 6.2424e-04\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 8.8304e-04 - val_loss: 6.5125e-04\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 8.8353e-04 - val_loss: 6.2034e-04\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 8.7949e-04 - val_loss: 6.2097e-04\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 8.6189e-04 - val_loss: 6.2064e-04\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 8.6543e-04 - val_loss: 6.1296e-04\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 8.5850e-04 - val_loss: 6.1885e-04\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 8.6260e-04 - val_loss: 6.0691e-04\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 8.4953e-04 - val_loss: 6.0973e-04\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 8.5133e-04 - val_loss: 6.0683e-04\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 8.4493e-04 - val_loss: 6.0959e-04\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 8.4126e-04 - val_loss: 6.2530e-04\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 8.4945e-04 - val_loss: 5.9254e-04\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 8.3148e-04 - val_loss: 5.9792e-04\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 8.4004e-04 - val_loss: 5.8802e-04\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 8.2608e-04 - val_loss: 5.8456e-04\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 8.2813e-04 - val_loss: 5.8591e-04\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 8.1201e-04 - val_loss: 5.7831e-04\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 8.1755e-04 - val_loss: 5.8311e-04\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 8.2534e-04 - val_loss: 6.2270e-04\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 8.0788e-04 - val_loss: 5.7482e-04\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.9718e-04 - val_loss: 5.8081e-04\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 8.0012e-04 - val_loss: 5.8879e-04\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.9914e-04 - val_loss: 5.6614e-04\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 7.9470e-04 - val_loss: 5.6415e-04\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.9444e-04 - val_loss: 5.8256e-04\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.8237e-04 - val_loss: 5.7481e-04\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 7.9428e-04 - val_loss: 5.9935e-04\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 7.9674e-04 - val_loss: 5.8062e-04\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.7826e-04 - val_loss: 5.5446e-04\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.7080e-04 - val_loss: 5.4931e-04\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.6746e-04 - val_loss: 5.5162e-04\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.6003e-04 - val_loss: 5.9458e-04\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.6018e-04 - val_loss: 5.4765e-04\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 9ms/step - loss: 7.5680e-04 - val_loss: 5.7081e-04\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.6559e-04 - val_loss: 5.5248e-04\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.4397e-04 - val_loss: 5.3426e-04\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.4373e-04 - val_loss: 5.3546e-04\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.6667e-04 - val_loss: 5.3769e-04\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.3868e-04 - val_loss: 6.2112e-04\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.4955e-04 - val_loss: 5.2852e-04\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.2812e-04 - val_loss: 5.3151e-04\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.2795e-04 - val_loss: 5.2895e-04\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.2831e-04 - val_loss: 5.2366e-04\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.2149e-04 - val_loss: 5.2136e-04\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.2642e-04 - val_loss: 5.1914e-04\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.1448e-04 - val_loss: 5.1511e-04\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.2316e-04 - val_loss: 5.7648e-04\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.0948e-04 - val_loss: 5.5857e-04\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.1792e-04 - val_loss: 5.4725e-04\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.0458e-04 - val_loss: 5.0651e-04\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.0255e-04 - val_loss: 5.1181e-04\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.0308e-04 - val_loss: 5.0154e-04\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.1391e-04 - val_loss: 5.2379e-04\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7.0203e-04 - val_loss: 5.0841e-04\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.9342e-04 - val_loss: 4.9610e-04\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.8796e-04 - val_loss: 5.1252e-04\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.8617e-04 - val_loss: 5.0260e-04\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.8005e-04 - val_loss: 4.9278e-04\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.8084e-04 - val_loss: 5.0200e-04\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.7211e-04 - val_loss: 4.9307e-04\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.8076e-04 - val_loss: 4.9154e-04\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.6616e-04 - val_loss: 4.9179e-04\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.7630e-04 - val_loss: 5.2525e-04\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.7788e-04 - val_loss: 5.1160e-04\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.7575e-04 - val_loss: 5.0440e-04\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.5673e-04 - val_loss: 4.8434e-04\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.5526e-04 - val_loss: 4.7722e-04\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.6563e-04 - val_loss: 4.7450e-04\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.5317e-04 - val_loss: 4.7875e-04\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.4713e-04 - val_loss: 5.0236e-04\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.4965e-04 - val_loss: 4.9661e-04\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.8078e-04 - val_loss: 4.8933e-04\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.6915e-04 - val_loss: 4.6915e-04\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.4026e-04 - val_loss: 4.6787e-04\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.3714e-04 - val_loss: 4.6885e-04\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.3741e-04 - val_loss: 4.7303e-04\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.3753e-04 - val_loss: 5.0400e-04\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.2626e-04 - val_loss: 4.6408e-04\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.3004e-04 - val_loss: 4.7423e-04\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.2029e-04 - val_loss: 4.7546e-04\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.3121e-04 - val_loss: 4.6862e-04\n",
      "Epoch 162/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.6786e-04 - val_loss: 4.5597e-04\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.8177e-04 - val_loss: 4.6336e-04\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.2207e-04 - val_loss: 4.6661e-04\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.3885e-04 - val_loss: 4.7745e-04\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.1963e-04 - val_loss: 4.7324e-04\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.1583e-04 - val_loss: 4.6539e-04\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.4179e-04 - val_loss: 5.1379e-04\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.2397e-04 - val_loss: 4.4936e-04\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.1406e-04 - val_loss: 4.6023e-04\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.2260e-04 - val_loss: 4.7481e-04\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.2451e-04 - val_loss: 4.4502e-04\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.1186e-04 - val_loss: 4.5038e-04\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.1811e-04 - val_loss: 4.6747e-04\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.1768e-04 - val_loss: 4.4228e-04\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.0055e-04 - val_loss: 4.4914e-04\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 5.9566e-04 - val_loss: 4.6868e-04\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.1071e-04 - val_loss: 4.3889e-04\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 5.9227e-04 - val_loss: 4.3873e-04\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 5.9850e-04 - val_loss: 4.3713e-04\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.0022e-04 - val_loss: 4.3737e-04\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.1571e-04 - val_loss: 4.8276e-04\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 6.0644e-04 - val_loss: 4.7663e-04\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 5.9549e-04 - val_loss: 4.8826e-04\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 5.9386e-04 - val_loss: 4.3515e-04\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 5.8956e-04 - val_loss: 4.5955e-04\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 5.9447e-04 - val_loss: 4.3394e-04\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 5.8098e-04 - val_loss: 4.5061e-04\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 8ms/step - loss: 5.8637e-04 - val_loss: 4.3432e-04\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 5.8868e-04 - val_loss: 4.3866e-04\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 5.7767e-04 - val_loss: 4.2958e-04\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 5.8143e-04 - val_loss: 4.4658e-04\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 5.8355e-04 - val_loss: 4.2562e-04\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 5.7036e-04 - val_loss: 4.3797e-04\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 5.7340e-04 - val_loss: 4.2326e-04\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 5.7707e-04 - val_loss: 4.2275e-04\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 5.7626e-04 - val_loss: 4.3080e-04\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 5.7834e-04 - val_loss: 4.3951e-04\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 5.7890e-04 - val_loss: 4.1867e-04\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 5.8146e-04 - val_loss: 4.2257e-04\n",
      "Thời gian huấn luyện:  54.589377641677856\n",
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_25 (LSTM)              (None, 10, 103)           43260     \n",
      "                                                                 \n",
      " flatten_102 (Flatten)       (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,291\n",
      "Trainable params: 44,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "34/34 [==============================] - 2s 16ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 10ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 142/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 162/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0908\n",
      "Thời gian huấn luyện:  51.19121050834656\n",
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_25 (GRU)                (None, 10, 103)           32754     \n",
      "                                                                 \n",
      " flatten_103 (Flatten)       (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,785\n",
      "Trainable params: 33,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 92/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0856\n",
      "Thời gian huấn luyện:  14.958252429962158\n",
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_130 (Dense)           (None, 10, 103)           206       \n",
      "                                                                 \n",
      " flatten_104 (Flatten)       (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,237\n",
      "Trainable params: 1,237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 1s 8ms/step - loss: 0.0234 - val_loss: 0.0039\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 9.4131e-04\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 9.1034e-04\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 8.4670e-04\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 8.2340e-04\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 7.7079e-04\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 7.7499e-04\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 7.6753e-04\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 7.2799e-04\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 6.9896e-04\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 6.8818e-04\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 6.6624e-04\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 6.4121e-04\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 6.2543e-04\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 6.2339e-04\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.9874e-04 - val_loss: 6.6243e-04\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.8153e-04 - val_loss: 6.0222e-04\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.6323e-04 - val_loss: 5.9299e-04\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.5948e-04 - val_loss: 5.8370e-04\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.4905e-04 - val_loss: 5.6675e-04\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.1896e-04 - val_loss: 6.0640e-04\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.0129e-04 - val_loss: 5.6608e-04\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.9366e-04 - val_loss: 5.4326e-04\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.7272e-04 - val_loss: 5.4913e-04\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.7042e-04 - val_loss: 5.2490e-04\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.0214e-04 - val_loss: 5.1876e-04\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.3970e-04 - val_loss: 5.3249e-04\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.3838e-04 - val_loss: 5.4653e-04\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.2217e-04 - val_loss: 5.5269e-04\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.3853e-04 - val_loss: 5.0365e-04\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.2834e-04 - val_loss: 4.8934e-04\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.0532e-04 - val_loss: 5.0379e-04\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.1909e-04 - val_loss: 5.0876e-04\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.9067e-04 - val_loss: 4.7669e-04\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.6760e-04 - val_loss: 4.8695e-04\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.8756e-04 - val_loss: 5.4005e-04\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 7.6376e-04 - val_loss: 4.6720e-04\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.5937e-04 - val_loss: 5.2755e-04\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.7145e-04 - val_loss: 4.9232e-04\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.7406e-04 - val_loss: 4.9701e-04\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.5035e-04 - val_loss: 4.6797e-04\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2490e-04 - val_loss: 4.4444e-04\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.1490e-04 - val_loss: 4.4953e-04\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0998e-04 - val_loss: 4.7053e-04\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.4210e-04 - val_loss: 4.3715e-04\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0330e-04 - val_loss: 4.3785e-04\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0121e-04 - val_loss: 4.6726e-04\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.9727e-04 - val_loss: 4.2727e-04\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.1526e-04 - val_loss: 4.2742e-04\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.9991e-04 - val_loss: 4.2524e-04\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.0691e-04 - val_loss: 4.5660e-04\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8964e-04 - val_loss: 4.1620e-04\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7551e-04 - val_loss: 4.7415e-04\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8519e-04 - val_loss: 4.1170e-04\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7516e-04 - val_loss: 4.7705e-04\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6738e-04 - val_loss: 4.1407e-04\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6353e-04 - val_loss: 4.0808e-04\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5636e-04 - val_loss: 4.1994e-04\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5962e-04 - val_loss: 4.1767e-04\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3649e-04 - val_loss: 4.2236e-04\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3914e-04 - val_loss: 4.0336e-04\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5743e-04 - val_loss: 4.0210e-04\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3658e-04 - val_loss: 3.9460e-04\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2904e-04 - val_loss: 4.3456e-04\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3175e-04 - val_loss: 3.9101e-04\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3038e-04 - val_loss: 3.9490e-04\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2709e-04 - val_loss: 3.8624e-04\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2568e-04 - val_loss: 3.9169e-04\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1594e-04 - val_loss: 4.4028e-04\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2311e-04 - val_loss: 3.9260e-04\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1459e-04 - val_loss: 4.3206e-04\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1118e-04 - val_loss: 4.2794e-04\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1286e-04 - val_loss: 3.8111e-04\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2879e-04 - val_loss: 3.7755e-04\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1459e-04 - val_loss: 4.2629e-04\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0890e-04 - val_loss: 3.9800e-04\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0066e-04 - val_loss: 3.8067e-04\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0422e-04 - val_loss: 3.7009e-04\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0854e-04 - val_loss: 3.8518e-04\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8715e-04 - val_loss: 3.7469e-04\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9967e-04 - val_loss: 3.6648e-04\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9636e-04 - val_loss: 3.9875e-04\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1246e-04 - val_loss: 4.0263e-04\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8587e-04 - val_loss: 3.6424e-04\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9837e-04 - val_loss: 3.7403e-04\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0874e-04 - val_loss: 3.8388e-04\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0546e-04 - val_loss: 4.1657e-04\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2806e-04 - val_loss: 3.7039e-04\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7378e-04 - val_loss: 3.6788e-04\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7702e-04 - val_loss: 3.8400e-04\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7265e-04 - val_loss: 3.5715e-04\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7815e-04 - val_loss: 3.7824e-04\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7085e-04 - val_loss: 3.5276e-04\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7412e-04 - val_loss: 3.5641e-04\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9307e-04 - val_loss: 3.9042e-04\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6233e-04 - val_loss: 3.5627e-04\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7074e-04 - val_loss: 3.6299e-04\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5035e-04 - val_loss: 3.5069e-04\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6760e-04 - val_loss: 3.5165e-04\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5859e-04 - val_loss: 3.5489e-04\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8008e-04 - val_loss: 3.5655e-04\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6164e-04 - val_loss: 3.6682e-04\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5798e-04 - val_loss: 3.5157e-04\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5987e-04 - val_loss: 3.9219e-04\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.6948e-04 - val_loss: 3.4490e-04\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6690e-04 - val_loss: 3.4394e-04\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6807e-04 - val_loss: 3.4661e-04\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9850e-04 - val_loss: 3.5355e-04\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7647e-04 - val_loss: 3.6535e-04\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.6334e-04 - val_loss: 3.7667e-04\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7586e-04 - val_loss: 3.8308e-04\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4308e-04 - val_loss: 3.8654e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3642e-04 - val_loss: 3.5374e-04\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4376e-04 - val_loss: 3.3601e-04\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.6517e-04 - val_loss: 3.6925e-04\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3852e-04 - val_loss: 3.3814e-04\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3595e-04 - val_loss: 3.3730e-04\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5048e-04 - val_loss: 3.3411e-04\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3626e-04 - val_loss: 3.7105e-04\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4714e-04 - val_loss: 3.4677e-04\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3415e-04 - val_loss: 3.3783e-04\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3138e-04 - val_loss: 3.4642e-04\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3843e-04 - val_loss: 3.2712e-04\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6749e-04 - val_loss: 3.5427e-04\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1429e-04 - val_loss: 3.2599e-04\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1150e-04 - val_loss: 3.2655e-04\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1659e-04 - val_loss: 3.2935e-04\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4629e-04 - val_loss: 3.2426e-04\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1718e-04 - val_loss: 3.3286e-04\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2997e-04 - val_loss: 3.4457e-04\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1603e-04 - val_loss: 3.2974e-04\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1555e-04 - val_loss: 3.2045e-04\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1793e-04 - val_loss: 3.2205e-04\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0890e-04 - val_loss: 3.2288e-04\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0891e-04 - val_loss: 3.1762e-04\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0531e-04 - val_loss: 3.2028e-04\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0295e-04 - val_loss: 3.3547e-04\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0688e-04 - val_loss: 3.3837e-04\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2496e-04 - val_loss: 3.1934e-04\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1287e-04 - val_loss: 3.8856e-04\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3560e-04 - val_loss: 3.3793e-04\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4335e-04 - val_loss: 3.2339e-04\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0951e-04 - val_loss: 3.2681e-04\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0171e-04 - val_loss: 3.3555e-04\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0955e-04 - val_loss: 3.1895e-04\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2443e-04 - val_loss: 3.1761e-04\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2668e-04 - val_loss: 3.2632e-04\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9997e-04 - val_loss: 3.1025e-04\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9176e-04 - val_loss: 3.0876e-04\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9852e-04 - val_loss: 3.5413e-04\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.0953e-04 - val_loss: 3.4237e-04\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0010e-04 - val_loss: 3.3072e-04\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8867e-04 - val_loss: 3.0636e-04\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9015e-04 - val_loss: 3.1909e-04\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0954e-04 - val_loss: 3.0554e-04\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8589e-04 - val_loss: 3.1033e-04\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1039e-04 - val_loss: 3.1489e-04\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.7982e-04 - val_loss: 3.0773e-04\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8536e-04 - val_loss: 3.0563e-04\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9074e-04 - val_loss: 3.2599e-04\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8094e-04 - val_loss: 3.0191e-04\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8392e-04 - val_loss: 3.0034e-04\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7682e-04 - val_loss: 3.6004e-04\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0621e-04 - val_loss: 3.3350e-04\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.7671e-04 - val_loss: 2.9821e-04\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9430e-04 - val_loss: 3.0937e-04\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8325e-04 - val_loss: 3.1180e-04\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8251e-04 - val_loss: 3.9150e-04\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.7772e-04 - val_loss: 2.9707e-04\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.7851e-04 - val_loss: 3.0421e-04\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.7166e-04 - val_loss: 2.9982e-04\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9646e-04 - val_loss: 2.9557e-04\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8121e-04 - val_loss: 3.2828e-04\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8799e-04 - val_loss: 2.9343e-04\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.7222e-04 - val_loss: 2.9345e-04\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.7410e-04 - val_loss: 2.9389e-04\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6309e-04 - val_loss: 2.9871e-04\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6617e-04 - val_loss: 2.9136e-04\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7613e-04 - val_loss: 2.9516e-04\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6057e-04 - val_loss: 3.1266e-04\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6634e-04 - val_loss: 2.9603e-04\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7271e-04 - val_loss: 2.9196e-04\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8901e-04 - val_loss: 3.5317e-04\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8396e-04 - val_loss: 3.0615e-04\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5652e-04 - val_loss: 3.2354e-04\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6219e-04 - val_loss: 2.8824e-04\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.5299e-04 - val_loss: 3.6824e-04\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6050e-04 - val_loss: 2.9531e-04\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6889e-04 - val_loss: 2.9735e-04\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6420e-04 - val_loss: 2.9282e-04\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6238e-04 - val_loss: 2.8470e-04\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5053e-04 - val_loss: 3.2554e-04\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5966e-04 - val_loss: 2.9560e-04\n",
      "Thời gian huấn luyện:  23.81832480430603\n",
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_26 (SimpleRNN)   (None, 10, 103)           10815     \n",
      "                                                                 \n",
      " flatten_105 (Flatten)       (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,846\n",
      "Trainable params: 11,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 2s 30ms/step - loss: 0.0171 - val_loss: 0.0018\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 9.9393e-04\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 9.8051e-04\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 9.7114e-04\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 9.6720e-04\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 9.6453e-04\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 9.4551e-04\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 9.3789e-04\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 9.2531e-04\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 9.3779e-04\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 9.5402e-04\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 9.0320e-04\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 8.8677e-04\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 8.8085e-04\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 8.6876e-04\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 8.6299e-04\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 8.6477e-04\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 8.4450e-04\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 8.3222e-04\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 8.2257e-04\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 8.1421e-04\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 8.2436e-04\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 8.7913e-04\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 7.8721e-04\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 8.2742e-04\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 8.2639e-04\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 7.9995e-04\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 7.5876e-04\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 7.8103e-04\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 7.3408e-04\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 7.2502e-04\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 7.1707e-04\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 7.7896e-04\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 7.0033e-04\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 7.1578e-04\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 6.8809e-04\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.1620e-04\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 6.9588e-04\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 6.7758e-04\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 6.7072e-04\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 6.4936e-04\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 6.4906e-04\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 6.4027e-04\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 6.4816e-04\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 6.2699e-04\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 6.2296e-04\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 6.2796e-04\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 6.1415e-04\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 6.1764e-04\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.8826e-04 - val_loss: 6.1177e-04\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.6890e-04 - val_loss: 6.0194e-04\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.5794e-04 - val_loss: 6.0211e-04\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.7057e-04 - val_loss: 5.9551e-04\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.5237e-04 - val_loss: 5.9342e-04\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.5548e-04 - val_loss: 6.2588e-04\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.3902e-04 - val_loss: 6.0818e-04\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.3395e-04 - val_loss: 5.8519e-04\n",
      "Epoch 65/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 8ms/step - loss: 9.4292e-04 - val_loss: 5.8242e-04\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.5002e-04 - val_loss: 6.3262e-04\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.4067e-04 - val_loss: 5.8298e-04\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.4326e-04 - val_loss: 5.8406e-04\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.1145e-04 - val_loss: 5.7289e-04\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.1825e-04 - val_loss: 6.2426e-04\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.2203e-04 - val_loss: 5.9749e-04\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.1417e-04 - val_loss: 5.6472e-04\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.9854e-04 - val_loss: 5.6365e-04\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.9659e-04 - val_loss: 5.5791e-04\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.8888e-04 - val_loss: 5.5674e-04\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.8328e-04 - val_loss: 5.5679e-04\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.8304e-04 - val_loss: 5.9437e-04\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.8892e-04 - val_loss: 5.7614e-04\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.8063e-04 - val_loss: 5.5917e-04\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.8186e-04 - val_loss: 5.5900e-04\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.6545e-04 - val_loss: 5.5335e-04\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.6684e-04 - val_loss: 6.2344e-04\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.5712e-04 - val_loss: 5.3823e-04\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.6364e-04 - val_loss: 5.3577e-04\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.5133e-04 - val_loss: 5.3421e-04\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.6461e-04 - val_loss: 5.3520e-04\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.7023e-04 - val_loss: 6.9638e-04\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.3814e-04 - val_loss: 5.2702e-04\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.3354e-04 - val_loss: 5.9873e-04\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.4216e-04 - val_loss: 5.5235e-04\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.3275e-04 - val_loss: 5.7250e-04\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.2573e-04 - val_loss: 5.7527e-04\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.2475e-04 - val_loss: 5.1863e-04\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.1775e-04 - val_loss: 5.4636e-04\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.1997e-04 - val_loss: 5.6911e-04\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.4339e-04 - val_loss: 5.0918e-04\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.1563e-04 - val_loss: 5.0624e-04\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.0156e-04 - val_loss: 5.5060e-04\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.0126e-04 - val_loss: 5.2842e-04\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.0233e-04 - val_loss: 5.4159e-04\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.8586e-04 - val_loss: 5.0003e-04\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.8192e-04 - val_loss: 4.9575e-04\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.9523e-04 - val_loss: 4.9373e-04\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.7880e-04 - val_loss: 5.5549e-04\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.7827e-04 - val_loss: 4.9105e-04\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.8191e-04 - val_loss: 5.2925e-04\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.8317e-04 - val_loss: 5.4599e-04\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.7830e-04 - val_loss: 5.0105e-04\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.7483e-04 - val_loss: 5.0513e-04\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.8665e-04 - val_loss: 4.8811e-04\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.6940e-04 - val_loss: 5.1026e-04\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.4999e-04 - val_loss: 5.0855e-04\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.5080e-04 - val_loss: 4.8295e-04\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.5142e-04 - val_loss: 4.9770e-04\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.5374e-04 - val_loss: 5.6729e-04\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.4674e-04 - val_loss: 4.6888e-04\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.4298e-04 - val_loss: 4.9891e-04\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.2950e-04 - val_loss: 4.7816e-04\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.3326e-04 - val_loss: 4.6953e-04\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.2191e-04 - val_loss: 4.7007e-04\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.4086e-04 - val_loss: 4.7270e-04\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.4185e-04 - val_loss: 4.5849e-04\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.2778e-04 - val_loss: 4.8214e-04\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.2322e-04 - val_loss: 4.9944e-04\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.0579e-04 - val_loss: 4.6800e-04\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.0538e-04 - val_loss: 4.5454e-04\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.0916e-04 - val_loss: 4.5977e-04\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.9552e-04 - val_loss: 4.5518e-04\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.0095e-04 - val_loss: 4.4248e-04\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.9900e-04 - val_loss: 4.4006e-04\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.0146e-04 - val_loss: 4.5824e-04\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.8997e-04 - val_loss: 4.3699e-04\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.9310e-04 - val_loss: 5.4124e-04\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.8770e-04 - val_loss: 5.4679e-04\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.8891e-04 - val_loss: 4.4593e-04\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.7679e-04 - val_loss: 4.3618e-04\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.7558e-04 - val_loss: 4.4571e-04\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.7090e-04 - val_loss: 4.6225e-04\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.7824e-04 - val_loss: 4.4595e-04\n",
      "Epoch 140/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 8ms/step - loss: 6.6456e-04 - val_loss: 4.4707e-04\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.6794e-04 - val_loss: 4.3314e-04\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.5724e-04 - val_loss: 4.3259e-04\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.5580e-04 - val_loss: 4.1918e-04\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.6828e-04 - val_loss: 4.2900e-04\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.5316e-04 - val_loss: 4.3836e-04\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.4750e-04 - val_loss: 4.3668e-04\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.4573e-04 - val_loss: 4.2474e-04\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.5345e-04 - val_loss: 4.1137e-04\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.4194e-04 - val_loss: 4.1197e-04\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.4208e-04 - val_loss: 4.0722e-04\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.4136e-04 - val_loss: 4.1068e-04\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.3378e-04 - val_loss: 4.0988e-04\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.3274e-04 - val_loss: 4.3777e-04\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.5206e-04 - val_loss: 4.0615e-04\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.4542e-04 - val_loss: 4.1078e-04\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.2269e-04 - val_loss: 4.0224e-04\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.2227e-04 - val_loss: 4.7627e-04\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.1593e-04 - val_loss: 4.0461e-04\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.1946e-04 - val_loss: 3.9632e-04\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.1933e-04 - val_loss: 4.0844e-04\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.1206e-04 - val_loss: 4.0213e-04\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.1509e-04 - val_loss: 5.3318e-04\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.1972e-04 - val_loss: 4.2976e-04\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.1521e-04 - val_loss: 4.2535e-04\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.0826e-04 - val_loss: 4.0317e-04\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.0705e-04 - val_loss: 3.9229e-04\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.0280e-04 - val_loss: 3.9067e-04\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.0670e-04 - val_loss: 4.8692e-04\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.9934e-04 - val_loss: 3.8399e-04\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.1453e-04 - val_loss: 3.8450e-04\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.0309e-04 - val_loss: 4.1727e-04\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.9955e-04 - val_loss: 4.2861e-04\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.9591e-04 - val_loss: 3.8629e-04\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.1179e-04 - val_loss: 4.2162e-04\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.9510e-04 - val_loss: 4.1784e-04\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.0169e-04 - val_loss: 4.0015e-04\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.9400e-04 - val_loss: 4.1017e-04\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.8337e-04 - val_loss: 3.7506e-04\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.9755e-04 - val_loss: 4.2687e-04\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.8470e-04 - val_loss: 3.7338e-04\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.8310e-04 - val_loss: 3.8361e-04\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.9199e-04 - val_loss: 3.7491e-04\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.8894e-04 - val_loss: 3.8478e-04\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.8220e-04 - val_loss: 4.4251e-04\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.7165e-04 - val_loss: 3.7168e-04\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.7730e-04 - val_loss: 3.6790e-04\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.8012e-04 - val_loss: 3.7921e-04\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.7340e-04 - val_loss: 3.7678e-04\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.7003e-04 - val_loss: 4.0562e-04\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.6710e-04 - val_loss: 3.6477e-04\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.6382e-04 - val_loss: 3.9431e-04\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.6844e-04 - val_loss: 3.6500e-04\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.6135e-04 - val_loss: 3.8481e-04\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.8002e-04 - val_loss: 3.7322e-04\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.7325e-04 - val_loss: 3.6122e-04\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.8351e-04 - val_loss: 3.6030e-04\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.7238e-04 - val_loss: 3.5961e-04\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.7085e-04 - val_loss: 3.8194e-04\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.7747e-04 - val_loss: 3.5721e-04\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.6517e-04 - val_loss: 3.7535e-04\n",
      "Thời gian huấn luyện:  51.498714208602905\n",
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_26 (LSTM)              (None, 10, 103)           43260     \n",
      "                                                                 \n",
      " flatten_106 (Flatten)       (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,291\n",
      "Trainable params: 44,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 2s 17ms/step - loss: 0.0184 - val_loss: 0.0018\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 9.0594e-04\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 8.7384e-04\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 9.1058e-04\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 8.4914e-04\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 8.4340e-04\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 8.2283e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 8.1485e-04\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 8.1058e-04\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 8.0108e-04\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 7.7156e-04\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 7.6184e-04\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 7.6796e-04\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 7.3381e-04\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 7.2548e-04\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 7.2727e-04\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.1183e-04\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.0184e-04\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 6.7866e-04\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 6.6691e-04\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 6.7515e-04\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 6.5315e-04\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 6.3669e-04\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 6.3520e-04\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 6.2302e-04\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 6.1527e-04\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 6.1781e-04\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.6664e-04 - val_loss: 6.1145e-04\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.6720e-04 - val_loss: 5.8502e-04\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.4656e-04 - val_loss: 5.8091e-04\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.2554e-04 - val_loss: 5.7001e-04\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.3854e-04 - val_loss: 5.6598e-04\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.0854e-04 - val_loss: 6.2109e-04\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.2462e-04 - val_loss: 5.6373e-04\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.8819e-04 - val_loss: 5.5222e-04\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.7871e-04 - val_loss: 5.4885e-04\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.6745e-04 - val_loss: 5.4051e-04\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.5698e-04 - val_loss: 5.3082e-04\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.6282e-04 - val_loss: 5.3681e-04\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.4391e-04 - val_loss: 5.6792e-04\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.4611e-04 - val_loss: 5.2520e-04\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.2305e-04 - val_loss: 5.5255e-04\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.2617e-04 - val_loss: 5.1444e-04\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.1666e-04 - val_loss: 5.0589e-04\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.0844e-04 - val_loss: 5.2633e-04\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.0591e-04 - val_loss: 4.9894e-04\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.9505e-04 - val_loss: 4.9608e-04\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.9334e-04 - val_loss: 4.9184e-04\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.8362e-04 - val_loss: 5.0055e-04\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.9385e-04 - val_loss: 4.8642e-04\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.8385e-04 - val_loss: 4.9181e-04\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.7488e-04 - val_loss: 4.8519e-04\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.7270e-04 - val_loss: 4.7737e-04\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.6429e-04 - val_loss: 5.3494e-04\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.6669e-04 - val_loss: 5.2509e-04\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.6394e-04 - val_loss: 4.9165e-04\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.4253e-04 - val_loss: 4.6962e-04\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.4740e-04 - val_loss: 4.6306e-04\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.3635e-04 - val_loss: 4.9729e-04\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.3848e-04 - val_loss: 4.6399e-04\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.3966e-04 - val_loss: 4.7418e-04\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.3366e-04 - val_loss: 4.6085e-04\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.4653e-04 - val_loss: 5.1631e-04\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.3094e-04 - val_loss: 4.4716e-04\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.1935e-04 - val_loss: 4.4485e-04\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.0411e-04 - val_loss: 4.4767e-04\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.0095e-04 - val_loss: 4.4177e-04\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.0423e-04 - val_loss: 4.5899e-04\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.9242e-04 - val_loss: 4.6064e-04\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.0222e-04 - val_loss: 4.3210e-04\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.9779e-04 - val_loss: 4.4466e-04\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.8360e-04 - val_loss: 4.5164e-04\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.7758e-04 - val_loss: 4.2509e-04\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.8372e-04 - val_loss: 4.5929e-04\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.7882e-04 - val_loss: 4.2275e-04\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.7497e-04 - val_loss: 4.1960e-04\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.6260e-04 - val_loss: 4.4117e-04\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.6446e-04 - val_loss: 4.1459e-04\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.5352e-04 - val_loss: 4.1141e-04\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.5751e-04 - val_loss: 4.3541e-04\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.5527e-04 - val_loss: 4.2055e-04\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.4191e-04 - val_loss: 4.2675e-04\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.4017e-04 - val_loss: 4.0775e-04\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 6.3990e-04 - val_loss: 4.0323e-04\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.3242e-04 - val_loss: 4.2225e-04\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.3274e-04 - val_loss: 4.0256e-04\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.3715e-04 - val_loss: 3.9657e-04\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.2770e-04 - val_loss: 4.0340e-04\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.4139e-04 - val_loss: 4.0993e-04\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.2022e-04 - val_loss: 3.9409e-04\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.1949e-04 - val_loss: 4.1044e-04\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.1864e-04 - val_loss: 3.8917e-04\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.1145e-04 - val_loss: 3.8940e-04\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.1249e-04 - val_loss: 3.8442e-04\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.1124e-04 - val_loss: 3.8280e-04\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.9940e-04 - val_loss: 3.9167e-04\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.0783e-04 - val_loss: 4.1857e-04\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.0154e-04 - val_loss: 3.7605e-04\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.0074e-04 - val_loss: 4.2517e-04\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.9391e-04 - val_loss: 4.2403e-04\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.8304e-04 - val_loss: 3.9748e-04\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.9954e-04 - val_loss: 3.9015e-04\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.0003e-04 - val_loss: 3.8005e-04\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.0156e-04 - val_loss: 3.7664e-04\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.8242e-04 - val_loss: 3.6603e-04\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.7994e-04 - val_loss: 3.9461e-04\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.7075e-04 - val_loss: 3.7584e-04\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.7357e-04 - val_loss: 3.6112e-04\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.7601e-04 - val_loss: 3.5948e-04\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.8027e-04 - val_loss: 3.9176e-04\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.6985e-04 - val_loss: 3.5671e-04\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.6224e-04 - val_loss: 3.5757e-04\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.8061e-04 - val_loss: 4.1158e-04\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.8135e-04 - val_loss: 3.5571e-04\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.9478e-04 - val_loss: 3.5294e-04\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.5259e-04 - val_loss: 3.5974e-04\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.5686e-04 - val_loss: 3.5791e-04\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.5979e-04 - val_loss: 3.6038e-04\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.4838e-04 - val_loss: 3.4796e-04\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.4832e-04 - val_loss: 3.7551e-04\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.4667e-04 - val_loss: 3.5887e-04\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.4804e-04 - val_loss: 3.7359e-04\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.4396e-04 - val_loss: 3.4819e-04\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.4222e-04 - val_loss: 3.4115e-04\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.4714e-04 - val_loss: 3.4744e-04\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.4426e-04 - val_loss: 3.4337e-04\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.3826e-04 - val_loss: 3.4513e-04\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.4970e-04 - val_loss: 3.7898e-04\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.4185e-04 - val_loss: 3.4029e-04\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.2668e-04 - val_loss: 4.1321e-04\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.6036e-04 - val_loss: 3.5662e-04\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.3477e-04 - val_loss: 3.3320e-04\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.2282e-04 - val_loss: 3.4932e-04\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.3815e-04 - val_loss: 3.4735e-04\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.2020e-04 - val_loss: 3.3410e-04\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.1594e-04 - val_loss: 3.2793e-04\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.2253e-04 - val_loss: 3.2739e-04\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.1844e-04 - val_loss: 3.2573e-04\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.1836e-04 - val_loss: 3.3312e-04\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.2345e-04 - val_loss: 3.6824e-04\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.1324e-04 - val_loss: 3.2281e-04\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.1168e-04 - val_loss: 3.2453e-04\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.0603e-04 - val_loss: 3.2191e-04\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.0578e-04 - val_loss: 3.4043e-04\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.0932e-04 - val_loss: 3.2031e-04\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.1492e-04 - val_loss: 3.2320e-04\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.0466e-04 - val_loss: 3.1778e-04\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.0099e-04 - val_loss: 3.2485e-04\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.0873e-04 - val_loss: 3.1559e-04\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.1487e-04 - val_loss: 3.1712e-04\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.9790e-04 - val_loss: 3.3124e-04\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.9663e-04 - val_loss: 3.1403e-04\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.0643e-04 - val_loss: 3.3617e-04\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.9686e-04 - val_loss: 3.4163e-04\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.9461e-04 - val_loss: 3.4181e-04\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.9752e-04 - val_loss: 3.5982e-04\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.9636e-04 - val_loss: 3.2523e-04\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.9962e-04 - val_loss: 3.1543e-04\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 4.8725e-04 - val_loss: 3.2401e-04\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.8717e-04 - val_loss: 3.1166e-04\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.8626e-04 - val_loss: 3.1048e-04\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.8550e-04 - val_loss: 3.0474e-04\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.8387e-04 - val_loss: 3.4211e-04\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.8593e-04 - val_loss: 3.0333e-04\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.8360e-04 - val_loss: 3.3157e-04\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.8558e-04 - val_loss: 3.2682e-04\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.8025e-04 - val_loss: 3.0149e-04\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.7767e-04 - val_loss: 3.1175e-04\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.0109e-04 - val_loss: 3.0280e-04\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.8310e-04 - val_loss: 3.0589e-04\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.7942e-04 - val_loss: 2.9971e-04\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.8624e-04 - val_loss: 3.2377e-04\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.8106e-04 - val_loss: 3.0336e-04\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.7217e-04 - val_loss: 3.1548e-04\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.7274e-04 - val_loss: 2.9623e-04\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.6978e-04 - val_loss: 2.9868e-04\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.7765e-04 - val_loss: 3.0062e-04\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.9543e-04 - val_loss: 3.1713e-04\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.6223e-04 - val_loss: 3.1656e-04\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.7338e-04 - val_loss: 3.5403e-04\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.6586e-04 - val_loss: 2.9700e-04\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.6377e-04 - val_loss: 3.1808e-04\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.6198e-04 - val_loss: 2.9138e-04\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.7156e-04 - val_loss: 2.9100e-04\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.6749e-04 - val_loss: 2.9093e-04\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.7557e-04 - val_loss: 2.8912e-04\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.6034e-04 - val_loss: 2.8829e-04\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.6234e-04 - val_loss: 3.0908e-04\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.5529e-04 - val_loss: 3.0503e-04\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.5800e-04 - val_loss: 2.8711e-04\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.5544e-04 - val_loss: 3.0514e-04\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.7169e-04 - val_loss: 3.3276e-04\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.6111e-04 - val_loss: 3.0182e-04\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.5872e-04 - val_loss: 2.9326e-04\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.7582e-04 - val_loss: 3.5960e-04\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 4.6867e-04 - val_loss: 3.6698e-04\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.5789e-04 - val_loss: 3.0672e-04\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.4770e-04 - val_loss: 2.8965e-04\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.5154e-04 - val_loss: 2.8497e-04\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.5596e-04 - val_loss: 2.9774e-04\n",
      "Thời gian huấn luyện:  48.14784383773804\n",
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_26 (GRU)                (None, 10, 103)           32754     \n",
      "                                                                 \n",
      " flatten_107 (Flatten)       (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,785\n",
      "Trainable params: 33,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "40/40 [==============================] - 1s 3ms/step\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#dataset_ratio, epoch, batch_size, validation\n",
    "information_FFNN_df = []\n",
    "information_RNN_df = []\n",
    "information_LSTM_df = []\n",
    "information_GRU_df = []\n",
    "params = [[0.6, 0.7, 0.8], [50, 100, 200], [32], [0.1, 0.15, 0.2]]\n",
    "# params = [[0.8], [1, 2], [32], [0.15]]\n",
    "params = get_combinations(params)\n",
    "for p in params:\n",
    "    ratio = p[0]\n",
    "    train_size = int(len(ds) * ratio)\n",
    "    test_size = len(ds) - train_size\n",
    "    train, test = ds[0:train_size,:], ds[train_size:len(ds)+1,:]\n",
    "    trainX, trainY, testX, testY = create_train_test_data(train, test, look_back)\n",
    "    \n",
    "    epochs = p[1]\n",
    "    batch_size= p[2]\n",
    "    validation_split= p[3]\n",
    "    \n",
    "    \n",
    "    delta_ffnn, model_ffnn = create_ffnn_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split)\n",
    "    delta_rnn, model_rnn = create_rnn_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split)\n",
    "    delta_lstm, model_lstm = create_lstm_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split)\n",
    "    delta_gru, model_gru =create_gru_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split)\n",
    "    \n",
    "    models_bag = {\n",
    "        \"FFNN\": model_ffnn,\n",
    "        \"RNN\": model_rnn,\n",
    "        \"LSTM\": model_lstm,\n",
    "        \"GRU\": model_gru\n",
    "    }\n",
    "    \n",
    "    accuracy_bag = {}\n",
    "    \n",
    "    for model_name, trained_model in models_bag.items():\n",
    "        if model_name == 'FFNN':\n",
    "            mse, mae, mape, rmse, trainPredict, testPredict = create_accuracy(trained_model, scaler, trainX, trainY, testX, testY)\n",
    "            info = [model_name] + list(p) + [mse, mae] + [delta_ffnn]\n",
    "            information_FFNN_df.append(info)\n",
    "        elif model_name == 'RNN':\n",
    "            mse, mae, mape, rmse, trainPredict, testPredict = create_accuracy(trained_model, scaler, trainX, trainY, testX, testY)\n",
    "            info = [model_name] + list(p) + [mse, mae] + [delta_rnn]\n",
    "            information_RNN_df.append(info)\n",
    "        elif model_name == 'LSTM':\n",
    "            mse, mae, mape, rmse, trainPredict, testPredict = create_accuracy(trained_model, scaler, trainX, trainY, testX, testY)\n",
    "            info = [model_name] + list(p) + [mse, mae] + [delta_lstm]\n",
    "            information_LSTM_df.append(info)\n",
    "        elif model_name == 'GRU':\n",
    "            mse, mae, mape, rmse, trainPredict, testPredict = create_accuracy(trained_model, scaler, trainX, trainY, testX, testY)\n",
    "            info = [model_name] + list(p) + [mse, mae] + [delta_gru]\n",
    "            information_GRU_df.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0f886a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "information_FFNN_df = pd.DataFrame(information_FFNN_df)\n",
    "information_FFNN_df.columns = ['Model', 'Training ratio', 'Epochs', 'Batch_size', 'Validation', 'MSE', 'MAE', 'Training Time']\n",
    "\n",
    "information_RNN_df = pd.DataFrame(information_RNN_df)\n",
    "information_RNN_df.columns = ['Model', 'Training ratio', 'Epochs', 'Batch_size', 'Validation', 'MSE', 'MAE', 'Training Time']\n",
    "\n",
    "information_LSTM_df = pd.DataFrame(information_LSTM_df)\n",
    "information_LSTM_df.columns = ['Model', 'Training ratio', 'Epochs', 'Batch_size', 'Validation', 'MSE', 'MAE', 'Training Time']\n",
    "\n",
    "information_GRU_df = pd.DataFrame(information_GRU_df)\n",
    "information_GRU_df.columns = ['Model', 'Training ratio', 'Epochs', 'Batch_size', 'Validation', 'MSE', 'MAE', 'Training Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c830b6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training ratio</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Batch_size</th>\n",
       "      <th>Validation</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.408</td>\n",
       "      <td>4.199555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.354</td>\n",
       "      <td>3.406341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.348</td>\n",
       "      <td>3.294192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>19.476</td>\n",
       "      <td>4.130</td>\n",
       "      <td>5.884693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.284</td>\n",
       "      <td>6.463672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>19.476</td>\n",
       "      <td>4.130</td>\n",
       "      <td>6.399706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.235</td>\n",
       "      <td>12.309435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>19.476</td>\n",
       "      <td>4.130</td>\n",
       "      <td>12.725681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.241</td>\n",
       "      <td>12.234004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.326</td>\n",
       "      <td>3.748246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.307</td>\n",
       "      <td>3.734735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.333</td>\n",
       "      <td>3.634754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.250</td>\n",
       "      <td>7.003791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.255</td>\n",
       "      <td>7.050419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.273</td>\n",
       "      <td>7.116065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.215</td>\n",
       "      <td>13.653239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.221</td>\n",
       "      <td>13.302845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.229</td>\n",
       "      <td>13.575185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.311</td>\n",
       "      <td>3.740782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>18.856</td>\n",
       "      <td>4.111</td>\n",
       "      <td>3.782929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.300</td>\n",
       "      <td>3.749107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>18.856</td>\n",
       "      <td>4.111</td>\n",
       "      <td>7.210380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.233</td>\n",
       "      <td>7.243532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.242</td>\n",
       "      <td>8.457491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.213</td>\n",
       "      <td>14.657964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>18.856</td>\n",
       "      <td>4.111</td>\n",
       "      <td>14.130098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>18.856</td>\n",
       "      <td>4.111</td>\n",
       "      <td>14.964251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Training ratio  Epochs  Batch_size  Validation     MSE    MAE  \\\n",
       "0   FFNN             0.6      50          32        0.10   0.293  0.408   \n",
       "1   FFNN             0.6      50          32        0.15   0.245  0.354   \n",
       "2   FFNN             0.6      50          32        0.20   0.239  0.348   \n",
       "3   FFNN             0.6     100          32        0.10  19.476  4.130   \n",
       "4   FFNN             0.6     100          32        0.15   0.160  0.284   \n",
       "5   FFNN             0.6     100          32        0.20  19.476  4.130   \n",
       "6   FFNN             0.6     200          32        0.10   0.110  0.235   \n",
       "7   FFNN             0.6     200          32        0.15  19.476  4.130   \n",
       "8   FFNN             0.6     200          32        0.20   0.116  0.241   \n",
       "9   FFNN             0.7      50          32        0.10   0.210  0.326   \n",
       "10  FFNN             0.7      50          32        0.15   0.188  0.307   \n",
       "11  FFNN             0.7      50          32        0.20   0.216  0.333   \n",
       "12  FFNN             0.7     100          32        0.10   0.126  0.250   \n",
       "13  FFNN             0.7     100          32        0.15   0.131  0.255   \n",
       "14  FFNN             0.7     100          32        0.20   0.148  0.273   \n",
       "15  FFNN             0.7     200          32        0.10   0.089  0.215   \n",
       "16  FFNN             0.7     200          32        0.15   0.094  0.221   \n",
       "17  FFNN             0.7     200          32        0.20   0.103  0.229   \n",
       "18  FFNN             0.8      50          32        0.10   0.193  0.311   \n",
       "19  FFNN             0.8      50          32        0.15  18.856  4.111   \n",
       "20  FFNN             0.8      50          32        0.20   0.178  0.300   \n",
       "21  FFNN             0.8     100          32        0.10  18.856  4.111   \n",
       "22  FFNN             0.8     100          32        0.15   0.109  0.233   \n",
       "23  FFNN             0.8     100          32        0.20   0.119  0.242   \n",
       "24  FFNN             0.8     200          32        0.10   0.089  0.213   \n",
       "25  FFNN             0.8     200          32        0.15  18.856  4.111   \n",
       "26  FFNN             0.8     200          32        0.20  18.856  4.111   \n",
       "\n",
       "    Training Time  \n",
       "0        4.199555  \n",
       "1        3.406341  \n",
       "2        3.294192  \n",
       "3        5.884693  \n",
       "4        6.463672  \n",
       "5        6.399706  \n",
       "6       12.309435  \n",
       "7       12.725681  \n",
       "8       12.234004  \n",
       "9        3.748246  \n",
       "10       3.734735  \n",
       "11       3.634754  \n",
       "12       7.003791  \n",
       "13       7.050419  \n",
       "14       7.116065  \n",
       "15      13.653239  \n",
       "16      13.302845  \n",
       "17      13.575185  \n",
       "18       3.740782  \n",
       "19       3.782929  \n",
       "20       3.749107  \n",
       "21       7.210380  \n",
       "22       7.243532  \n",
       "23       8.457491  \n",
       "24      14.657964  \n",
       "25      14.130098  \n",
       "26      14.964251  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_FFNN_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7adadef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training ratio</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Batch_size</th>\n",
       "      <th>Validation</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.239</td>\n",
       "      <td>5.401724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.250</td>\n",
       "      <td>5.264991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.288</td>\n",
       "      <td>5.324592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.253</td>\n",
       "      <td>9.271211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.282</td>\n",
       "      <td>9.803492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.257</td>\n",
       "      <td>9.855024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.218</td>\n",
       "      <td>19.164577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.218</td>\n",
       "      <td>19.299520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.220</td>\n",
       "      <td>18.653427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.256</td>\n",
       "      <td>6.038972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.285</td>\n",
       "      <td>5.909424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.264</td>\n",
       "      <td>5.756642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.229</td>\n",
       "      <td>11.244850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.218</td>\n",
       "      <td>10.996140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.211</td>\n",
       "      <td>10.804173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.199</td>\n",
       "      <td>21.381994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.215</td>\n",
       "      <td>20.542548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.237</td>\n",
       "      <td>20.339966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.233</td>\n",
       "      <td>6.357504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.231</td>\n",
       "      <td>6.227163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.263</td>\n",
       "      <td>6.184090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.224</td>\n",
       "      <td>11.866866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.208</td>\n",
       "      <td>11.908227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.206</td>\n",
       "      <td>13.401821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.190</td>\n",
       "      <td>24.296347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.191</td>\n",
       "      <td>23.426054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.206</td>\n",
       "      <td>23.824328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Training ratio  Epochs  Batch_size  Validation    MSE    MAE  \\\n",
       "0    RNN             0.6      50          32        0.10  0.114  0.239   \n",
       "1    RNN             0.6      50          32        0.15  0.120  0.250   \n",
       "2    RNN             0.6      50          32        0.20  0.159  0.288   \n",
       "3    RNN             0.6     100          32        0.10  0.114  0.253   \n",
       "4    RNN             0.6     100          32        0.15  0.139  0.282   \n",
       "5    RNN             0.6     100          32        0.20  0.125  0.257   \n",
       "6    RNN             0.6     200          32        0.10  0.095  0.218   \n",
       "7    RNN             0.6     200          32        0.15  0.094  0.218   \n",
       "8    RNN             0.6     200          32        0.20  0.096  0.220   \n",
       "9    RNN             0.7      50          32        0.10  0.131  0.256   \n",
       "10   RNN             0.7      50          32        0.15  0.160  0.285   \n",
       "11   RNN             0.7      50          32        0.20  0.138  0.264   \n",
       "12   RNN             0.7     100          32        0.10  0.102  0.229   \n",
       "13   RNN             0.7     100          32        0.15  0.094  0.218   \n",
       "14   RNN             0.7     100          32        0.20  0.089  0.211   \n",
       "15   RNN             0.7     200          32        0.10  0.080  0.199   \n",
       "16   RNN             0.7     200          32        0.15  0.086  0.215   \n",
       "17   RNN             0.7     200          32        0.20  0.103  0.237   \n",
       "18   RNN             0.8      50          32        0.10  0.107  0.233   \n",
       "19   RNN             0.8      50          32        0.15  0.107  0.231   \n",
       "20   RNN             0.8      50          32        0.20  0.139  0.263   \n",
       "21   RNN             0.8     100          32        0.10  0.101  0.224   \n",
       "22   RNN             0.8     100          32        0.15  0.087  0.208   \n",
       "23   RNN             0.8     100          32        0.20  0.083  0.206   \n",
       "24   RNN             0.8     200          32        0.10  0.075  0.190   \n",
       "25   RNN             0.8     200          32        0.15  0.076  0.191   \n",
       "26   RNN             0.8     200          32        0.20  0.082  0.206   \n",
       "\n",
       "    Training Time  \n",
       "0        5.401724  \n",
       "1        5.264991  \n",
       "2        5.324592  \n",
       "3        9.271211  \n",
       "4        9.803492  \n",
       "5        9.855024  \n",
       "6       19.164577  \n",
       "7       19.299520  \n",
       "8       18.653427  \n",
       "9        6.038972  \n",
       "10       5.909424  \n",
       "11       5.756642  \n",
       "12      11.244850  \n",
       "13      10.996140  \n",
       "14      10.804173  \n",
       "15      21.381994  \n",
       "16      20.542548  \n",
       "17      20.339966  \n",
       "18       6.357504  \n",
       "19       6.227163  \n",
       "20       6.184090  \n",
       "21      11.866866  \n",
       "22      11.908227  \n",
       "23      13.401821  \n",
       "24      24.296347  \n",
       "25      23.426054  \n",
       "26      23.824328  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_RNN_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52633989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training ratio</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Batch_size</th>\n",
       "      <th>Validation</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>19.476</td>\n",
       "      <td>4.130</td>\n",
       "      <td>10.024253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.380</td>\n",
       "      <td>9.788896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.396</td>\n",
       "      <td>9.821333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.322</td>\n",
       "      <td>17.726716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.308</td>\n",
       "      <td>18.174770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.326</td>\n",
       "      <td>20.574812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>19.476</td>\n",
       "      <td>4.130</td>\n",
       "      <td>39.326111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>19.476</td>\n",
       "      <td>4.130</td>\n",
       "      <td>39.183990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>19.476</td>\n",
       "      <td>4.130</td>\n",
       "      <td>37.998355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.329</td>\n",
       "      <td>12.860132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.329</td>\n",
       "      <td>11.975036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.330</td>\n",
       "      <td>11.955189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>18.771</td>\n",
       "      <td>4.072</td>\n",
       "      <td>24.065937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.294</td>\n",
       "      <td>23.252172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.299</td>\n",
       "      <td>21.748524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>18.771</td>\n",
       "      <td>4.072</td>\n",
       "      <td>44.464824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.245</td>\n",
       "      <td>43.761514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>18.771</td>\n",
       "      <td>4.072</td>\n",
       "      <td>42.074008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.313</td>\n",
       "      <td>14.373178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>18.856</td>\n",
       "      <td>4.111</td>\n",
       "      <td>13.966328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>18.856</td>\n",
       "      <td>4.111</td>\n",
       "      <td>13.694829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>18.856</td>\n",
       "      <td>4.111</td>\n",
       "      <td>26.976666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.275</td>\n",
       "      <td>26.453254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.291</td>\n",
       "      <td>26.962955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.231</td>\n",
       "      <td>53.791799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54.596379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.229</td>\n",
       "      <td>51.504717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Training ratio  Epochs  Batch_size  Validation     MSE    MAE  \\\n",
       "0   LSTM             0.6      50          32        0.10  19.476  4.130   \n",
       "1   LSTM             0.6      50          32        0.15   0.282  0.380   \n",
       "2   LSTM             0.6      50          32        0.20   0.301  0.396   \n",
       "3   LSTM             0.6     100          32        0.10   0.194  0.322   \n",
       "4   LSTM             0.6     100          32        0.15   0.183  0.308   \n",
       "5   LSTM             0.6     100          32        0.20   0.198  0.326   \n",
       "6   LSTM             0.6     200          32        0.10  19.476  4.130   \n",
       "7   LSTM             0.6     200          32        0.15  19.476  4.130   \n",
       "8   LSTM             0.6     200          32        0.20  19.476  4.130   \n",
       "9   LSTM             0.7      50          32        0.10   0.211  0.329   \n",
       "10  LSTM             0.7      50          32        0.15   0.214  0.329   \n",
       "11  LSTM             0.7      50          32        0.20   0.216  0.330   \n",
       "12  LSTM             0.7     100          32        0.10  18.771  4.072   \n",
       "13  LSTM             0.7     100          32        0.15   0.166  0.294   \n",
       "14  LSTM             0.7     100          32        0.20   0.170  0.299   \n",
       "15  LSTM             0.7     200          32        0.10  18.771  4.072   \n",
       "16  LSTM             0.7     200          32        0.15   0.114  0.245   \n",
       "17  LSTM             0.7     200          32        0.20  18.771  4.072   \n",
       "18  LSTM             0.8      50          32        0.10   0.198  0.313   \n",
       "19  LSTM             0.8      50          32        0.15  18.856  4.111   \n",
       "20  LSTM             0.8      50          32        0.20  18.856  4.111   \n",
       "21  LSTM             0.8     100          32        0.10  18.856  4.111   \n",
       "22  LSTM             0.8     100          32        0.15   0.145  0.275   \n",
       "23  LSTM             0.8     100          32        0.20   0.155  0.291   \n",
       "24  LSTM             0.8     200          32        0.10   0.101  0.231   \n",
       "25  LSTM             0.8     200          32        0.15   0.106  0.232   \n",
       "26  LSTM             0.8     200          32        0.20   0.101  0.229   \n",
       "\n",
       "    Training Time  \n",
       "0       10.024253  \n",
       "1        9.788896  \n",
       "2        9.821333  \n",
       "3       17.726716  \n",
       "4       18.174770  \n",
       "5       20.574812  \n",
       "6       39.326111  \n",
       "7       39.183990  \n",
       "8       37.998355  \n",
       "9       12.860132  \n",
       "10      11.975036  \n",
       "11      11.955189  \n",
       "12      24.065937  \n",
       "13      23.252172  \n",
       "14      21.748524  \n",
       "15      44.464824  \n",
       "16      43.761514  \n",
       "17      42.074008  \n",
       "18      14.373178  \n",
       "19      13.966328  \n",
       "20      13.694829  \n",
       "21      26.976666  \n",
       "22      26.453254  \n",
       "23      26.962955  \n",
       "24      53.791799  \n",
       "25      54.596379  \n",
       "26      51.504717  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_LSTM_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "768ef36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training ratio</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Batch_size</th>\n",
       "      <th>Validation</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.301</td>\n",
       "      <td>9.530610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.308</td>\n",
       "      <td>9.311809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.318</td>\n",
       "      <td>9.168694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.256</td>\n",
       "      <td>18.113237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.265</td>\n",
       "      <td>17.211354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>19.476</td>\n",
       "      <td>4.130</td>\n",
       "      <td>18.315636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.224</td>\n",
       "      <td>35.969904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.228</td>\n",
       "      <td>35.328555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.224</td>\n",
       "      <td>34.167230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.268</td>\n",
       "      <td>12.052829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.289</td>\n",
       "      <td>11.290604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>18.771</td>\n",
       "      <td>4.072</td>\n",
       "      <td>11.295202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.243</td>\n",
       "      <td>22.478534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.245</td>\n",
       "      <td>20.932621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.256</td>\n",
       "      <td>20.775977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.211</td>\n",
       "      <td>43.014334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.233</td>\n",
       "      <td>41.066688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.217</td>\n",
       "      <td>39.726188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.250</td>\n",
       "      <td>13.576930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>18.856</td>\n",
       "      <td>4.111</td>\n",
       "      <td>12.795482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.273</td>\n",
       "      <td>12.714527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.230</td>\n",
       "      <td>25.863229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.231</td>\n",
       "      <td>24.122911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.232</td>\n",
       "      <td>24.109627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.196</td>\n",
       "      <td>49.500348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>18.856</td>\n",
       "      <td>4.111</td>\n",
       "      <td>51.197213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.205</td>\n",
       "      <td>48.154847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Training ratio  Epochs  Batch_size  Validation     MSE    MAE  \\\n",
       "0    GRU             0.6      50          32        0.10   0.179  0.301   \n",
       "1    GRU             0.6      50          32        0.15   0.189  0.308   \n",
       "2    GRU             0.6      50          32        0.20   0.198  0.318   \n",
       "3    GRU             0.6     100          32        0.10   0.128  0.256   \n",
       "4    GRU             0.6     100          32        0.15   0.135  0.265   \n",
       "5    GRU             0.6     100          32        0.20  19.476  4.130   \n",
       "6    GRU             0.6     200          32        0.10   0.099  0.224   \n",
       "7    GRU             0.6     200          32        0.15   0.101  0.228   \n",
       "8    GRU             0.6     200          32        0.20   0.099  0.224   \n",
       "9    GRU             0.7      50          32        0.10   0.143  0.268   \n",
       "10   GRU             0.7      50          32        0.15   0.160  0.289   \n",
       "11   GRU             0.7      50          32        0.20  18.771  4.072   \n",
       "12   GRU             0.7     100          32        0.10   0.111  0.243   \n",
       "13   GRU             0.7     100          32        0.15   0.119  0.245   \n",
       "14   GRU             0.7     100          32        0.20   0.122  0.256   \n",
       "15   GRU             0.7     200          32        0.10   0.086  0.211   \n",
       "16   GRU             0.7     200          32        0.15   0.096  0.233   \n",
       "17   GRU             0.7     200          32        0.20   0.091  0.217   \n",
       "18   GRU             0.8      50          32        0.10   0.125  0.250   \n",
       "19   GRU             0.8      50          32        0.15  18.856  4.111   \n",
       "20   GRU             0.8      50          32        0.20   0.141  0.273   \n",
       "21   GRU             0.8     100          32        0.10   0.104  0.230   \n",
       "22   GRU             0.8     100          32        0.15   0.107  0.231   \n",
       "23   GRU             0.8     100          32        0.20   0.105  0.232   \n",
       "24   GRU             0.8     200          32        0.10   0.078  0.196   \n",
       "25   GRU             0.8     200          32        0.15  18.856  4.111   \n",
       "26   GRU             0.8     200          32        0.20   0.082  0.205   \n",
       "\n",
       "    Training Time  \n",
       "0        9.530610  \n",
       "1        9.311809  \n",
       "2        9.168694  \n",
       "3       18.113237  \n",
       "4       17.211354  \n",
       "5       18.315636  \n",
       "6       35.969904  \n",
       "7       35.328555  \n",
       "8       34.167230  \n",
       "9       12.052829  \n",
       "10      11.290604  \n",
       "11      11.295202  \n",
       "12      22.478534  \n",
       "13      20.932621  \n",
       "14      20.775977  \n",
       "15      43.014334  \n",
       "16      41.066688  \n",
       "17      39.726188  \n",
       "18      13.576930  \n",
       "19      12.795482  \n",
       "20      12.714527  \n",
       "21      25.863229  \n",
       "22      24.122911  \n",
       "23      24.109627  \n",
       "24      49.500348  \n",
       "25      51.197213  \n",
       "26      48.154847  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_GRU_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42f959e",
   "metadata": {},
   "source": [
    "## Best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c148fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_best_params(info_df, ds, look_back, opt):\n",
    "    index = info_df.MSE.argmin()\n",
    "    ratio = info_df.iloc[index, 1]\n",
    "    epochs = info_df.iloc[index, 2]\n",
    "    batch_size = info_df.iloc[index, 3]\n",
    "    validation = info_df.iloc[index, 4]\n",
    "    \n",
    "    train_size = int(len(ds) * ratio)\n",
    "    test_size = len(ds) - train_size\n",
    "    train, test = ds[0:train_size,:], ds[train_size:len(ds)+1,:]\n",
    "    trainX, trainY, testX, testY = create_train_test_data(train, test, look_back)\n",
    "    \n",
    "    return [trainX, trainY, testX, testY], [trainX, trainY, look_back, opt, epochs, batch_size, validation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52707d6e",
   "metadata": {},
   "source": [
    "### Chose the best look_back in (1,3,5,10,20,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96cfdfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "32/32 [==============================] - 1s 6ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Thời gian huấn luyện:  12.395793199539185\n",
      "Model: \"sequential_108\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_135 (Dense)           (None, 1, 96)             192       \n",
      "                                                                 \n",
      " flatten_108 (Flatten)       (None, 96)                0         \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 1)                 97        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 289\n",
      "Trainable params: 289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "36/36 [==============================] - 0s 867us/step\n",
      "16/16 [==============================] - 0s 981us/step\n",
      "Epoch 1/200\n",
      "37/37 [==============================] - 1s 6ms/step - loss: 0.0588 - val_loss: 0.0016\n",
      "Epoch 2/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 5.1725e-04\n",
      "Epoch 3/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 6.8020e-04\n",
      "Epoch 4/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 5.9405e-04\n",
      "Epoch 5/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 4.9518e-04\n",
      "Epoch 6/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 4.8357e-04\n",
      "Epoch 7/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 4.5975e-04\n",
      "Epoch 8/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 4.0178e-04\n",
      "Epoch 9/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 3.8942e-04\n",
      "Epoch 10/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 3.6376e-04\n",
      "Epoch 11/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 3.3310e-04\n",
      "Epoch 12/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 3.0452e-04\n",
      "Epoch 13/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 2.8456e-04\n",
      "Epoch 14/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 2.7752e-04\n",
      "Epoch 15/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 2.8166e-04\n",
      "Epoch 16/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 2.6876e-04\n",
      "Epoch 17/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 2.7035e-04\n",
      "Epoch 18/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.5516e-04\n",
      "Epoch 19/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.4196e-04\n",
      "Epoch 20/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 9.9248e-04 - val_loss: 2.2993e-04\n",
      "Epoch 21/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 8.9247e-04 - val_loss: 2.3469e-04\n",
      "Epoch 22/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 8.1352e-04 - val_loss: 2.2368e-04\n",
      "Epoch 23/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 7.4342e-04 - val_loss: 2.2855e-04\n",
      "Epoch 24/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 6.8100e-04 - val_loss: 2.2380e-04\n",
      "Epoch 25/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 6.3114e-04 - val_loss: 2.2587e-04\n",
      "Epoch 26/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 5.9040e-04 - val_loss: 2.2103e-04\n",
      "Epoch 27/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 5.5585e-04 - val_loss: 2.2416e-04\n",
      "Epoch 28/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 5.2542e-04 - val_loss: 2.2195e-04\n",
      "Epoch 29/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 5.0189e-04 - val_loss: 2.2470e-04\n",
      "Epoch 30/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.8192e-04 - val_loss: 2.2227e-04\n",
      "Epoch 31/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.6600e-04 - val_loss: 2.2185e-04\n",
      "Epoch 32/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.5282e-04 - val_loss: 2.2435e-04\n",
      "Epoch 33/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.4208e-04 - val_loss: 2.2396e-04\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 2ms/step - loss: 4.3380e-04 - val_loss: 2.2450e-04\n",
      "Epoch 35/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.2611e-04 - val_loss: 2.2570e-04\n",
      "Epoch 36/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.2098e-04 - val_loss: 2.2536e-04\n",
      "Epoch 37/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.1713e-04 - val_loss: 2.2598e-04\n",
      "Epoch 38/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.1492e-04 - val_loss: 2.3443e-04\n",
      "Epoch 39/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.1325e-04 - val_loss: 2.2717e-04\n",
      "Epoch 40/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.1141e-04 - val_loss: 2.3065e-04\n",
      "Epoch 41/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0866e-04 - val_loss: 2.2794e-04\n",
      "Epoch 42/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0774e-04 - val_loss: 2.2854e-04\n",
      "Epoch 43/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0679e-04 - val_loss: 2.2861e-04\n",
      "Epoch 44/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0502e-04 - val_loss: 2.3081e-04\n",
      "Epoch 45/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0726e-04 - val_loss: 2.2933e-04\n",
      "Epoch 46/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0454e-04 - val_loss: 2.3119e-04\n",
      "Epoch 47/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0484e-04 - val_loss: 2.3034e-04\n",
      "Epoch 48/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0456e-04 - val_loss: 2.3030e-04\n",
      "Epoch 49/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0397e-04 - val_loss: 2.3024e-04\n",
      "Epoch 50/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0445e-04 - val_loss: 2.3461e-04\n",
      "Epoch 51/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0569e-04 - val_loss: 2.3218e-04\n",
      "Epoch 52/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0333e-04 - val_loss: 2.3091e-04\n",
      "Epoch 53/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0528e-04 - val_loss: 2.3310e-04\n",
      "Epoch 54/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0353e-04 - val_loss: 2.3126e-04\n",
      "Epoch 55/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0352e-04 - val_loss: 2.3479e-04\n",
      "Epoch 56/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0475e-04 - val_loss: 2.3133e-04\n",
      "Epoch 57/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0438e-04 - val_loss: 2.3267e-04\n",
      "Epoch 58/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0320e-04 - val_loss: 2.3082e-04\n",
      "Epoch 59/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0459e-04 - val_loss: 2.3291e-04\n",
      "Epoch 60/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0394e-04 - val_loss: 2.3131e-04\n",
      "Epoch 61/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0566e-04 - val_loss: 2.3100e-04\n",
      "Epoch 62/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0513e-04 - val_loss: 2.3098e-04\n",
      "Epoch 63/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0439e-04 - val_loss: 2.3109e-04\n",
      "Epoch 64/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0449e-04 - val_loss: 2.3288e-04\n",
      "Epoch 65/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0455e-04 - val_loss: 2.3095e-04\n",
      "Epoch 66/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0371e-04 - val_loss: 2.3217e-04\n",
      "Epoch 67/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0349e-04 - val_loss: 2.3112e-04\n",
      "Epoch 68/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0494e-04 - val_loss: 2.3124e-04\n",
      "Epoch 69/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0522e-04 - val_loss: 2.3090e-04\n",
      "Epoch 70/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.1997e-04 - val_loss: 2.3283e-04\n",
      "Epoch 71/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0402e-04 - val_loss: 2.3179e-04\n",
      "Epoch 72/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0490e-04 - val_loss: 2.3114e-04\n",
      "Epoch 73/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0492e-04 - val_loss: 2.3189e-04\n",
      "Epoch 74/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0451e-04 - val_loss: 2.3139e-04\n",
      "Epoch 75/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0428e-04 - val_loss: 2.3193e-04\n",
      "Epoch 76/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0399e-04 - val_loss: 2.3220e-04\n",
      "Epoch 77/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0429e-04 - val_loss: 2.3192e-04\n",
      "Epoch 78/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0661e-04 - val_loss: 2.3568e-04\n",
      "Epoch 79/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0506e-04 - val_loss: 2.3274e-04\n",
      "Epoch 80/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0572e-04 - val_loss: 2.3221e-04\n",
      "Epoch 81/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0407e-04 - val_loss: 2.3140e-04\n",
      "Epoch 82/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0454e-04 - val_loss: 2.3114e-04\n",
      "Epoch 83/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0398e-04 - val_loss: 2.3203e-04\n",
      "Epoch 84/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0495e-04 - val_loss: 2.3139e-04\n",
      "Epoch 85/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0374e-04 - val_loss: 2.3899e-04\n",
      "Epoch 86/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.1657e-04 - val_loss: 2.3148e-04\n",
      "Epoch 87/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0441e-04 - val_loss: 2.3646e-04\n",
      "Epoch 88/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0431e-04 - val_loss: 2.3091e-04\n",
      "Epoch 89/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0426e-04 - val_loss: 2.3296e-04\n",
      "Epoch 90/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0420e-04 - val_loss: 2.3206e-04\n",
      "Epoch 91/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0662e-04 - val_loss: 2.3268e-04\n",
      "Epoch 92/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0468e-04 - val_loss: 2.3329e-04\n",
      "Epoch 93/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0404e-04 - val_loss: 2.3313e-04\n",
      "Epoch 94/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0452e-04 - val_loss: 2.3136e-04\n",
      "Epoch 95/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0534e-04 - val_loss: 2.3441e-04\n",
      "Epoch 96/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0605e-04 - val_loss: 2.3144e-04\n",
      "Epoch 97/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0340e-04 - val_loss: 2.3141e-04\n",
      "Epoch 98/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0528e-04 - val_loss: 2.3535e-04\n",
      "Epoch 99/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0474e-04 - val_loss: 2.3182e-04\n",
      "Epoch 100/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0431e-04 - val_loss: 2.3180e-04\n",
      "Epoch 101/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0443e-04 - val_loss: 2.3494e-04\n",
      "Epoch 102/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0554e-04 - val_loss: 2.3214e-04\n",
      "Epoch 103/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0711e-04 - val_loss: 2.3144e-04\n",
      "Epoch 104/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0568e-04 - val_loss: 2.3178e-04\n",
      "Epoch 105/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0526e-04 - val_loss: 2.3382e-04\n",
      "Epoch 106/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0553e-04 - val_loss: 2.3186e-04\n",
      "Epoch 107/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0569e-04 - val_loss: 2.3743e-04\n",
      "Epoch 108/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0770e-04 - val_loss: 2.3764e-04\n",
      "Epoch 109/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0545e-04 - val_loss: 2.4681e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0888e-04 - val_loss: 2.3306e-04\n",
      "Epoch 111/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.1016e-04 - val_loss: 2.3543e-04\n",
      "Epoch 112/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0380e-04 - val_loss: 2.3556e-04\n",
      "Epoch 113/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0593e-04 - val_loss: 2.3178e-04\n",
      "Epoch 114/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0669e-04 - val_loss: 2.4773e-04\n",
      "Epoch 115/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0379e-04 - val_loss: 2.3297e-04\n",
      "Epoch 116/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0410e-04 - val_loss: 2.3406e-04\n",
      "Epoch 117/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0491e-04 - val_loss: 2.3163e-04\n",
      "Epoch 118/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0454e-04 - val_loss: 2.3358e-04\n",
      "Epoch 119/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0442e-04 - val_loss: 2.3189e-04\n",
      "Epoch 120/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.1026e-04 - val_loss: 2.3376e-04\n",
      "Epoch 121/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0665e-04 - val_loss: 2.3262e-04\n",
      "Epoch 122/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0475e-04 - val_loss: 2.3134e-04\n",
      "Epoch 123/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0635e-04 - val_loss: 2.3137e-04\n",
      "Epoch 124/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0489e-04 - val_loss: 2.3622e-04\n",
      "Epoch 125/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0482e-04 - val_loss: 2.3286e-04\n",
      "Epoch 126/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0598e-04 - val_loss: 2.3555e-04\n",
      "Epoch 127/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0428e-04 - val_loss: 2.3304e-04\n",
      "Epoch 128/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0961e-04 - val_loss: 2.3872e-04\n",
      "Epoch 129/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0443e-04 - val_loss: 2.3154e-04\n",
      "Epoch 130/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0525e-04 - val_loss: 2.3222e-04\n",
      "Epoch 131/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0810e-04 - val_loss: 2.3111e-04\n",
      "Epoch 132/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0551e-04 - val_loss: 2.3100e-04\n",
      "Epoch 133/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0528e-04 - val_loss: 2.3162e-04\n",
      "Epoch 134/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0399e-04 - val_loss: 2.3358e-04\n",
      "Epoch 135/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0557e-04 - val_loss: 2.3763e-04\n",
      "Epoch 136/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0944e-04 - val_loss: 2.3375e-04\n",
      "Epoch 137/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0239e-04 - val_loss: 2.4674e-04\n",
      "Epoch 138/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0859e-04 - val_loss: 2.3497e-04\n",
      "Epoch 139/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0485e-04 - val_loss: 2.3227e-04\n",
      "Epoch 140/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0370e-04 - val_loss: 2.3238e-04\n",
      "Epoch 141/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0362e-04 - val_loss: 2.3210e-04\n",
      "Epoch 142/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0626e-04 - val_loss: 2.3269e-04\n",
      "Epoch 143/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0976e-04 - val_loss: 2.4093e-04\n",
      "Epoch 144/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0713e-04 - val_loss: 2.3265e-04\n",
      "Epoch 145/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0859e-04 - val_loss: 2.3347e-04\n",
      "Epoch 146/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0411e-04 - val_loss: 2.3525e-04\n",
      "Epoch 147/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0694e-04 - val_loss: 2.3131e-04\n",
      "Epoch 148/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0548e-04 - val_loss: 2.3259e-04\n",
      "Epoch 149/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0710e-04 - val_loss: 2.3776e-04\n",
      "Epoch 150/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0642e-04 - val_loss: 2.3129e-04\n",
      "Epoch 151/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0523e-04 - val_loss: 2.3189e-04\n",
      "Epoch 152/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0509e-04 - val_loss: 2.3493e-04\n",
      "Epoch 153/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.1039e-04 - val_loss: 2.3338e-04\n",
      "Epoch 154/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0860e-04 - val_loss: 2.3136e-04\n",
      "Epoch 155/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.1096e-04 - val_loss: 2.3172e-04\n",
      "Epoch 156/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0492e-04 - val_loss: 2.3243e-04\n",
      "Epoch 157/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0881e-04 - val_loss: 2.3417e-04\n",
      "Epoch 158/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.1666e-04 - val_loss: 2.4003e-04\n",
      "Epoch 159/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.2001e-04 - val_loss: 2.3083e-04\n",
      "Epoch 160/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0434e-04 - val_loss: 2.3171e-04\n",
      "Epoch 161/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0347e-04 - val_loss: 2.3778e-04\n",
      "Epoch 162/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.1198e-04 - val_loss: 2.3577e-04\n",
      "Epoch 163/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0452e-04 - val_loss: 2.4105e-04\n",
      "Epoch 164/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0994e-04 - val_loss: 2.3302e-04\n",
      "Epoch 165/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0478e-04 - val_loss: 2.3315e-04\n",
      "Epoch 166/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0416e-04 - val_loss: 2.3193e-04\n",
      "Epoch 167/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0359e-04 - val_loss: 2.3983e-04\n",
      "Epoch 168/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.1408e-04 - val_loss: 2.3500e-04\n",
      "Epoch 169/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0415e-04 - val_loss: 2.3199e-04\n",
      "Epoch 170/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0367e-04 - val_loss: 2.3509e-04\n",
      "Epoch 171/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0394e-04 - val_loss: 2.3460e-04\n",
      "Epoch 172/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0586e-04 - val_loss: 2.3400e-04\n",
      "Epoch 173/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.1048e-04 - val_loss: 2.3553e-04\n",
      "Epoch 174/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0624e-04 - val_loss: 2.3171e-04\n",
      "Epoch 175/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0510e-04 - val_loss: 2.3840e-04\n",
      "Epoch 176/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0438e-04 - val_loss: 2.3165e-04\n",
      "Epoch 177/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0540e-04 - val_loss: 2.3157e-04\n",
      "Epoch 178/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.1384e-04 - val_loss: 2.3266e-04\n",
      "Epoch 179/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.1317e-04 - val_loss: 2.3712e-04\n",
      "Epoch 180/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0564e-04 - val_loss: 2.3456e-04\n",
      "Epoch 181/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0761e-04 - val_loss: 2.3505e-04\n",
      "Epoch 182/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0592e-04 - val_loss: 2.3642e-04\n",
      "Epoch 183/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0668e-04 - val_loss: 2.3655e-04\n",
      "Epoch 184/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0568e-04 - val_loss: 2.3177e-04\n",
      "Epoch 185/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 2ms/step - loss: 4.2319e-04 - val_loss: 2.3162e-04\n",
      "Epoch 186/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0505e-04 - val_loss: 2.3316e-04\n",
      "Epoch 187/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0600e-04 - val_loss: 2.3179e-04\n",
      "Epoch 188/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0619e-04 - val_loss: 2.3117e-04\n",
      "Epoch 189/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0645e-04 - val_loss: 2.3132e-04\n",
      "Epoch 190/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0482e-04 - val_loss: 2.3141e-04\n",
      "Epoch 191/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0895e-04 - val_loss: 2.3766e-04\n",
      "Epoch 192/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0540e-04 - val_loss: 2.3455e-04\n",
      "Epoch 193/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.1132e-04 - val_loss: 2.3116e-04\n",
      "Epoch 194/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0569e-04 - val_loss: 2.3217e-04\n",
      "Epoch 195/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0445e-04 - val_loss: 2.3159e-04\n",
      "Epoch 196/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0498e-04 - val_loss: 2.3481e-04\n",
      "Epoch 197/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0751e-04 - val_loss: 2.3139e-04\n",
      "Epoch 198/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0495e-04 - val_loss: 2.3818e-04\n",
      "Epoch 199/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0900e-04 - val_loss: 2.3206e-04\n",
      "Epoch 200/200\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.0726e-04 - val_loss: 2.3330e-04\n",
      "Thời gian huấn luyện:  17.00384020805359\n",
      "Model: \"sequential_109\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_27 (SimpleRNN)   (None, 1, 103)            10815     \n",
      "                                                                 \n",
      " flatten_109 (Flatten)       (None, 103)               0         \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 1)                 104       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,919\n",
      "Trainable params: 10,919\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "41/41 [==============================] - 0s 930us/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "37/37 [==============================] - 2s 12ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 2/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 3/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 4/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 5/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 6/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 7/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 8/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 9/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 10/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 11/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 12/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 13/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 14/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 15/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 16/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 17/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 18/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 19/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 20/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 21/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 22/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 23/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 24/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 25/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 26/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 27/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 28/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 29/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 30/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 31/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 32/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 33/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 34/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 35/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 36/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 37/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 38/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 39/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 40/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 41/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 42/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 43/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 44/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 45/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 46/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 47/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 48/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 49/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 50/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 51/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 52/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 53/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 54/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 55/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 57/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 58/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 59/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 60/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 61/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 62/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 63/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 64/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 65/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 66/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 67/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 68/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 69/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 70/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 71/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 72/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 73/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 74/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 75/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 76/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 77/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 78/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 79/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 80/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 81/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 82/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 83/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 84/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 85/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 86/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 87/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 88/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 89/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 90/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 91/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 92/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 93/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 94/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 95/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 96/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 97/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 98/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 99/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 100/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 101/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 102/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 103/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 104/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 105/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 106/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 107/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 108/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 109/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 110/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 111/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 112/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 113/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 114/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 115/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 116/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 117/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 118/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 119/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 120/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 121/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 122/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 123/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 124/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 125/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 126/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 127/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 128/200\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 129/200\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 130/200\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 131/200\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 132/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 133/200\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 134/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 135/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 136/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 137/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 138/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 139/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 140/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 141/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 142/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 143/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 144/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 145/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 146/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 147/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 148/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 149/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 150/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 151/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 152/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 153/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 154/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 155/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 156/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 157/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 158/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 159/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 160/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 161/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 162/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 163/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 164/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 165/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 166/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 167/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 168/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 169/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 170/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 171/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 172/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 173/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 174/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 175/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 176/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 177/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 178/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 179/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 180/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 181/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 182/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 183/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 184/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 185/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 186/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 187/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 188/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 189/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 190/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 191/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 192/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 193/200\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 194/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 195/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 196/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 197/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 198/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 199/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Epoch 200/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1020\n",
      "Thời gian huấn luyện:  23.506327390670776\n",
      "Model: \"sequential_110\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_27 (LSTM)              (None, 1, 103)            43260     \n",
      "                                                                 \n",
      " flatten_110 (Flatten)       (None, 103)               0         \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 1)                 104       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,364\n",
      "Trainable params: 43,364\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "41/41 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "37/37 [==============================] - 2s 22ms/step - loss: 0.0381 - val_loss: 0.0029\n",
      "Epoch 2/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 5.4100e-04\n",
      "Epoch 3/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 6.3296e-04\n",
      "Epoch 4/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 6.7229e-04\n",
      "Epoch 5/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 5.7641e-04\n",
      "Epoch 6/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 5.7961e-04\n",
      "Epoch 7/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 5.0037e-04\n",
      "Epoch 8/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 4.4036e-04\n",
      "Epoch 9/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 4.8786e-04\n",
      "Epoch 10/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 4.4603e-04\n",
      "Epoch 11/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0033 - val_loss: 4.3130e-04\n",
      "Epoch 12/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 3.9493e-04\n",
      "Epoch 13/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 3.7551e-04\n",
      "Epoch 14/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 3.5114e-04\n",
      "Epoch 15/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 3.1966e-04\n",
      "Epoch 16/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 3.2458e-04\n",
      "Epoch 17/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 3.0655e-04\n",
      "Epoch 18/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 3.1218e-04\n",
      "Epoch 19/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 2.9279e-04\n",
      "Epoch 20/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 2.6789e-04\n",
      "Epoch 21/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 2.7500e-04\n",
      "Epoch 22/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 2.6046e-04\n",
      "Epoch 23/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 2.5443e-04\n",
      "Epoch 24/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 9.9913e-04 - val_loss: 2.5883e-04\n",
      "Epoch 25/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 9.0405e-04 - val_loss: 2.4152e-04\n",
      "Epoch 26/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 8.2671e-04 - val_loss: 2.4071e-04\n",
      "Epoch 27/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 7.5872e-04 - val_loss: 2.4578e-04\n",
      "Epoch 28/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 7.0282e-04 - val_loss: 2.3195e-04\n",
      "Epoch 29/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 6.5208e-04 - val_loss: 2.4065e-04\n",
      "Epoch 30/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 6.1084e-04 - val_loss: 2.2878e-04\n",
      "Epoch 31/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 5.6849e-04 - val_loss: 2.2779e-04\n",
      "Epoch 32/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 5.3708e-04 - val_loss: 2.3056e-04\n",
      "Epoch 33/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 5.1037e-04 - val_loss: 2.2436e-04\n",
      "Epoch 34/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.9052e-04 - val_loss: 2.3175e-04\n",
      "Epoch 35/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.7552e-04 - val_loss: 2.2410e-04\n",
      "Epoch 36/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.6038e-04 - val_loss: 2.2756e-04\n",
      "Epoch 37/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.4905e-04 - val_loss: 2.2807e-04\n",
      "Epoch 38/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.4019e-04 - val_loss: 2.2981e-04\n",
      "Epoch 39/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.3371e-04 - val_loss: 2.2738e-04\n",
      "Epoch 40/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.2591e-04 - val_loss: 2.2887e-04\n",
      "Epoch 41/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.2199e-04 - val_loss: 2.2816e-04\n",
      "Epoch 42/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1928e-04 - val_loss: 2.3338e-04\n",
      "Epoch 43/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1627e-04 - val_loss: 2.2917e-04\n",
      "Epoch 44/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1421e-04 - val_loss: 2.3292e-04\n",
      "Epoch 45/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1480e-04 - val_loss: 2.3811e-04\n",
      "Epoch 46/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1153e-04 - val_loss: 2.3182e-04\n",
      "Epoch 47/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1212e-04 - val_loss: 2.3769e-04\n",
      "Epoch 48/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1194e-04 - val_loss: 2.3391e-04\n",
      "Epoch 49/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1039e-04 - val_loss: 2.3192e-04\n",
      "Epoch 50/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0951e-04 - val_loss: 2.3384e-04\n",
      "Epoch 51/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0828e-04 - val_loss: 2.3179e-04\n",
      "Epoch 52/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0757e-04 - val_loss: 2.3990e-04\n",
      "Epoch 53/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0933e-04 - val_loss: 2.3243e-04\n",
      "Epoch 54/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0910e-04 - val_loss: 2.3335e-04\n",
      "Epoch 55/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1107e-04 - val_loss: 2.3257e-04\n",
      "Epoch 56/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1048e-04 - val_loss: 2.3245e-04\n",
      "Epoch 57/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0885e-04 - val_loss: 2.3298e-04\n",
      "Epoch 58/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0725e-04 - val_loss: 2.3637e-04\n",
      "Epoch 59/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0783e-04 - val_loss: 2.3425e-04\n",
      "Epoch 60/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0729e-04 - val_loss: 2.3868e-04\n",
      "Epoch 61/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0905e-04 - val_loss: 2.3593e-04\n",
      "Epoch 62/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0736e-04 - val_loss: 2.3341e-04\n",
      "Epoch 63/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1586e-04 - val_loss: 2.3503e-04\n",
      "Epoch 64/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0788e-04 - val_loss: 2.3807e-04\n",
      "Epoch 65/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0741e-04 - val_loss: 2.3329e-04\n",
      "Epoch 66/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0943e-04 - val_loss: 2.3388e-04\n",
      "Epoch 67/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0958e-04 - val_loss: 2.3353e-04\n",
      "Epoch 68/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0746e-04 - val_loss: 2.3517e-04\n",
      "Epoch 69/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0763e-04 - val_loss: 2.3576e-04\n",
      "Epoch 70/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0754e-04 - val_loss: 2.3337e-04\n",
      "Epoch 71/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0814e-04 - val_loss: 2.3360e-04\n",
      "Epoch 72/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1017e-04 - val_loss: 2.3380e-04\n",
      "Epoch 73/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0772e-04 - val_loss: 2.3365e-04\n",
      "Epoch 74/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0769e-04 - val_loss: 2.3881e-04\n",
      "Epoch 75/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0756e-04 - val_loss: 2.3356e-04\n",
      "Epoch 76/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0782e-04 - val_loss: 2.3358e-04\n",
      "Epoch 77/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0835e-04 - val_loss: 2.3474e-04\n",
      "Epoch 78/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0888e-04 - val_loss: 2.3749e-04\n",
      "Epoch 79/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1153e-04 - val_loss: 2.5179e-04\n",
      "Epoch 80/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0970e-04 - val_loss: 2.3510e-04\n",
      "Epoch 81/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0964e-04 - val_loss: 2.3908e-04\n",
      "Epoch 82/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0796e-04 - val_loss: 2.3643e-04\n",
      "Epoch 83/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0782e-04 - val_loss: 2.3438e-04\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0696e-04 - val_loss: 2.3729e-04\n",
      "Epoch 85/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1192e-04 - val_loss: 2.3377e-04\n",
      "Epoch 86/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0834e-04 - val_loss: 2.3582e-04\n",
      "Epoch 87/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0708e-04 - val_loss: 2.3583e-04\n",
      "Epoch 88/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0796e-04 - val_loss: 2.3470e-04\n",
      "Epoch 89/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.2145e-04 - val_loss: 2.3383e-04\n",
      "Epoch 90/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1090e-04 - val_loss: 2.4039e-04\n",
      "Epoch 91/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1252e-04 - val_loss: 2.4399e-04\n",
      "Epoch 92/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0939e-04 - val_loss: 2.3471e-04\n",
      "Epoch 93/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0782e-04 - val_loss: 2.3749e-04\n",
      "Epoch 94/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0803e-04 - val_loss: 2.4451e-04\n",
      "Epoch 95/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0670e-04 - val_loss: 2.3425e-04\n",
      "Epoch 96/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0975e-04 - val_loss: 2.3347e-04\n",
      "Epoch 97/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0990e-04 - val_loss: 2.4079e-04\n",
      "Epoch 98/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1111e-04 - val_loss: 2.3496e-04\n",
      "Epoch 99/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0757e-04 - val_loss: 2.3353e-04\n",
      "Epoch 100/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1679e-04 - val_loss: 2.3395e-04\n",
      "Epoch 101/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0903e-04 - val_loss: 2.3335e-04\n",
      "Epoch 102/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0982e-04 - val_loss: 2.3334e-04\n",
      "Epoch 103/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0793e-04 - val_loss: 2.3367e-04\n",
      "Epoch 104/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0756e-04 - val_loss: 2.3464e-04\n",
      "Epoch 105/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0728e-04 - val_loss: 2.3517e-04\n",
      "Epoch 106/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0739e-04 - val_loss: 2.3428e-04\n",
      "Epoch 107/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0779e-04 - val_loss: 2.3953e-04\n",
      "Epoch 108/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0949e-04 - val_loss: 2.3444e-04\n",
      "Epoch 109/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0873e-04 - val_loss: 2.3617e-04\n",
      "Epoch 110/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0814e-04 - val_loss: 2.3633e-04\n",
      "Epoch 111/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0791e-04 - val_loss: 2.3946e-04\n",
      "Epoch 112/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0939e-04 - val_loss: 2.3429e-04\n",
      "Epoch 113/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0679e-04 - val_loss: 2.4050e-04\n",
      "Epoch 114/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1148e-04 - val_loss: 2.3952e-04\n",
      "Epoch 115/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1314e-04 - val_loss: 2.4403e-04\n",
      "Epoch 116/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0929e-04 - val_loss: 2.3405e-04\n",
      "Epoch 117/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0717e-04 - val_loss: 2.3405e-04\n",
      "Epoch 118/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0720e-04 - val_loss: 2.3589e-04\n",
      "Epoch 119/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1296e-04 - val_loss: 2.3487e-04\n",
      "Epoch 120/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0743e-04 - val_loss: 2.3412e-04\n",
      "Epoch 121/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0774e-04 - val_loss: 2.3733e-04\n",
      "Epoch 122/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1617e-04 - val_loss: 2.3694e-04\n",
      "Epoch 123/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.2144e-04 - val_loss: 2.4945e-04\n",
      "Epoch 124/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0633e-04 - val_loss: 2.3288e-04\n",
      "Epoch 125/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0781e-04 - val_loss: 2.3318e-04\n",
      "Epoch 126/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0826e-04 - val_loss: 2.3523e-04\n",
      "Epoch 127/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0741e-04 - val_loss: 2.3894e-04\n",
      "Epoch 128/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0742e-04 - val_loss: 2.3419e-04\n",
      "Epoch 129/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1132e-04 - val_loss: 2.3682e-04\n",
      "Epoch 130/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1165e-04 - val_loss: 2.4034e-04\n",
      "Epoch 131/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1037e-04 - val_loss: 2.4373e-04\n",
      "Epoch 132/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1088e-04 - val_loss: 2.3724e-04\n",
      "Epoch 133/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0693e-04 - val_loss: 2.4439e-04\n",
      "Epoch 134/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.2138e-04 - val_loss: 2.3550e-04\n",
      "Epoch 135/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0713e-04 - val_loss: 2.3515e-04\n",
      "Epoch 136/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0838e-04 - val_loss: 2.3320e-04\n",
      "Epoch 137/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0671e-04 - val_loss: 2.3397e-04\n",
      "Epoch 138/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0621e-04 - val_loss: 2.4306e-04\n",
      "Epoch 139/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0786e-04 - val_loss: 2.4205e-04\n",
      "Epoch 140/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0682e-04 - val_loss: 2.4040e-04\n",
      "Epoch 141/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0888e-04 - val_loss: 2.3386e-04\n",
      "Epoch 142/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1060e-04 - val_loss: 2.3629e-04\n",
      "Epoch 143/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0743e-04 - val_loss: 2.3424e-04\n",
      "Epoch 144/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0837e-04 - val_loss: 2.3473e-04\n",
      "Epoch 145/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0856e-04 - val_loss: 2.4022e-04\n",
      "Epoch 146/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1862e-04 - val_loss: 2.3992e-04\n",
      "Epoch 147/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1031e-04 - val_loss: 2.3262e-04\n",
      "Epoch 148/200\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 4.1023e-04 - val_loss: 2.3631e-04\n",
      "Epoch 149/200\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 4.0831e-04 - val_loss: 2.3290e-04\n",
      "Epoch 150/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0818e-04 - val_loss: 2.3882e-04\n",
      "Epoch 151/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0743e-04 - val_loss: 2.4387e-04\n",
      "Epoch 152/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0848e-04 - val_loss: 2.3423e-04\n",
      "Epoch 153/200\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 4.0743e-04 - val_loss: 2.3342e-04\n",
      "Epoch 154/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0959e-04 - val_loss: 2.3375e-04\n",
      "Epoch 155/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0748e-04 - val_loss: 2.3369e-04\n",
      "Epoch 156/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0741e-04 - val_loss: 2.3622e-04\n",
      "Epoch 157/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1072e-04 - val_loss: 2.3803e-04\n",
      "Epoch 158/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0733e-04 - val_loss: 2.3944e-04\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 4ms/step - loss: 4.0627e-04 - val_loss: 2.3442e-04\n",
      "Epoch 160/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0902e-04 - val_loss: 2.3444e-04\n",
      "Epoch 161/200\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 4.0896e-04 - val_loss: 2.3343e-04\n",
      "Epoch 162/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0962e-04 - val_loss: 2.3499e-04\n",
      "Epoch 163/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0784e-04 - val_loss: 2.3726e-04\n",
      "Epoch 164/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0555e-04 - val_loss: 2.3570e-04\n",
      "Epoch 165/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1644e-04 - val_loss: 2.3467e-04\n",
      "Epoch 166/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1004e-04 - val_loss: 2.3808e-04\n",
      "Epoch 167/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0863e-04 - val_loss: 2.3878e-04\n",
      "Epoch 168/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0923e-04 - val_loss: 2.3489e-04\n",
      "Epoch 169/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0756e-04 - val_loss: 2.3613e-04\n",
      "Epoch 170/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0864e-04 - val_loss: 2.3678e-04\n",
      "Epoch 171/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0866e-04 - val_loss: 2.5608e-04\n",
      "Epoch 172/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0830e-04 - val_loss: 2.3341e-04\n",
      "Epoch 173/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0935e-04 - val_loss: 2.3328e-04\n",
      "Epoch 174/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0807e-04 - val_loss: 2.3350e-04\n",
      "Epoch 175/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0953e-04 - val_loss: 2.3597e-04\n",
      "Epoch 176/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0624e-04 - val_loss: 2.4272e-04\n",
      "Epoch 177/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0930e-04 - val_loss: 2.3751e-04\n",
      "Epoch 178/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1361e-04 - val_loss: 2.3902e-04\n",
      "Epoch 179/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0979e-04 - val_loss: 2.3309e-04\n",
      "Epoch 180/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0772e-04 - val_loss: 2.3283e-04\n",
      "Epoch 181/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1034e-04 - val_loss: 2.4084e-04\n",
      "Epoch 182/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0831e-04 - val_loss: 2.3753e-04\n",
      "Epoch 183/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0614e-04 - val_loss: 2.3277e-04\n",
      "Epoch 184/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0921e-04 - val_loss: 2.3303e-04\n",
      "Epoch 185/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0752e-04 - val_loss: 2.3354e-04\n",
      "Epoch 186/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0824e-04 - val_loss: 2.3544e-04\n",
      "Epoch 187/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0783e-04 - val_loss: 2.3581e-04\n",
      "Epoch 188/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0682e-04 - val_loss: 2.3803e-04\n",
      "Epoch 189/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0892e-04 - val_loss: 2.3808e-04\n",
      "Epoch 190/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1017e-04 - val_loss: 2.3362e-04\n",
      "Epoch 191/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0868e-04 - val_loss: 2.3751e-04\n",
      "Epoch 192/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1747e-04 - val_loss: 2.3430e-04\n",
      "Epoch 193/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0772e-04 - val_loss: 2.3462e-04\n",
      "Epoch 194/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0574e-04 - val_loss: 2.3708e-04\n",
      "Epoch 195/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0953e-04 - val_loss: 2.3301e-04\n",
      "Epoch 196/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0904e-04 - val_loss: 2.3465e-04\n",
      "Epoch 197/200\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 4.0652e-04 - val_loss: 2.3361e-04\n",
      "Epoch 198/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1139e-04 - val_loss: 2.3638e-04\n",
      "Epoch 199/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.1049e-04 - val_loss: 2.3537e-04\n",
      "Epoch 200/200\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0783e-04 - val_loss: 2.3977e-04\n",
      "Thời gian huấn luyện:  23.895442724227905\n",
      "Model: \"sequential_111\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_27 (GRU)                (None, 1, 103)            32754     \n",
      "                                                                 \n",
      " flatten_111 (Flatten)       (None, 103)               0         \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 1)                 104       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,858\n",
      "Trainable params: 32,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "41/41 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0501 - val_loss: 0.0074\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0029\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 9.5828e-04\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 8.5369e-04\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 8.0714e-04\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.1934e-04\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.8670e-04\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.4550e-04\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.9104e-04\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.5437e-04\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.7574e-04 - val_loss: 5.2631e-04\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.1845e-04 - val_loss: 4.8358e-04\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 8.6783e-04 - val_loss: 4.5710e-04\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.2458e-04 - val_loss: 4.4613e-04\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.8781e-04 - val_loss: 4.3631e-04\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.5628e-04 - val_loss: 4.0105e-04\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.3044e-04 - val_loss: 3.9879e-04\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.0994e-04 - val_loss: 3.8484e-04\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.9264e-04 - val_loss: 3.7812e-04\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.7810e-04 - val_loss: 3.6609e-04\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.6655e-04 - val_loss: 3.6807e-04\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.5690e-04 - val_loss: 3.6037e-04\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.4847e-04 - val_loss: 3.5008e-04\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.4564e-04 - val_loss: 3.4620e-04\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.4033e-04 - val_loss: 3.5540e-04\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.3283e-04 - val_loss: 3.4066e-04\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.2980e-04 - val_loss: 3.3963e-04\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.2753e-04 - val_loss: 3.3764e-04\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.2369e-04 - val_loss: 3.3998e-04\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.2258e-04 - val_loss: 3.4011e-04\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.1997e-04 - val_loss: 3.4068e-04\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.1715e-04 - val_loss: 3.4172e-04\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.1679e-04 - val_loss: 3.4222e-04\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.1350e-04 - val_loss: 3.3367e-04\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.1823e-04 - val_loss: 3.3357e-04\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.1305e-04 - val_loss: 3.3871e-04\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.1118e-04 - val_loss: 3.3287e-04\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.1223e-04 - val_loss: 3.3331e-04\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.1059e-04 - val_loss: 3.4025e-04\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.1074e-04 - val_loss: 3.3178e-04\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0937e-04 - val_loss: 3.3873e-04\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0633e-04 - val_loss: 3.3148e-04\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0695e-04 - val_loss: 3.3359e-04\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0544e-04 - val_loss: 3.3246e-04\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0505e-04 - val_loss: 3.3154e-04\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0720e-04 - val_loss: 3.3136e-04\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0773e-04 - val_loss: 3.4224e-04\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0620e-04 - val_loss: 3.3321e-04\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0580e-04 - val_loss: 3.2984e-04\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0345e-04 - val_loss: 3.2843e-04\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0325e-04 - val_loss: 3.2772e-04\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9996e-04 - val_loss: 3.3255e-04\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9998e-04 - val_loss: 3.3260e-04\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0032e-04 - val_loss: 3.2628e-04\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9752e-04 - val_loss: 3.2784e-04\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9896e-04 - val_loss: 3.2535e-04\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9666e-04 - val_loss: 3.2577e-04\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9643e-04 - val_loss: 3.3517e-04\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9640e-04 - val_loss: 3.2453e-04\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9353e-04 - val_loss: 3.2700e-04\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9411e-04 - val_loss: 3.3230e-04\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9695e-04 - val_loss: 3.2557e-04\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9218e-04 - val_loss: 3.3015e-04\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9194e-04 - val_loss: 3.2190e-04\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9028e-04 - val_loss: 3.2437e-04\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8978e-04 - val_loss: 3.3468e-04\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8949e-04 - val_loss: 3.2031e-04\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8747e-04 - val_loss: 3.2267e-04\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8776e-04 - val_loss: 3.2367e-04\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8567e-04 - val_loss: 3.2334e-04\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8452e-04 - val_loss: 3.1929e-04\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8478e-04 - val_loss: 3.2179e-04\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8420e-04 - val_loss: 3.2134e-04\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8240e-04 - val_loss: 3.1802e-04\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8165e-04 - val_loss: 3.1731e-04\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8310e-04 - val_loss: 3.2126e-04\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8301e-04 - val_loss: 3.1572e-04\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8291e-04 - val_loss: 3.1498e-04\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8579e-04 - val_loss: 3.1453e-04\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7620e-04 - val_loss: 3.2237e-04\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7775e-04 - val_loss: 3.1522e-04\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7529e-04 - val_loss: 3.1972e-04\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7554e-04 - val_loss: 3.1305e-04\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7365e-04 - val_loss: 3.1466e-04\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7355e-04 - val_loss: 3.1566e-04\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7289e-04 - val_loss: 3.1516e-04\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7430e-04 - val_loss: 3.2259e-04\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7175e-04 - val_loss: 3.1157e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6927e-04 - val_loss: 3.0926e-04\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7502e-04 - val_loss: 3.1151e-04\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6855e-04 - val_loss: 3.0864e-04\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6887e-04 - val_loss: 3.1310e-04\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7704e-04 - val_loss: 3.1819e-04\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6722e-04 - val_loss: 3.1101e-04\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6811e-04 - val_loss: 3.1472e-04\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6327e-04 - val_loss: 3.0547e-04\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6285e-04 - val_loss: 3.0918e-04\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6399e-04 - val_loss: 3.1249e-04\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6195e-04 - val_loss: 3.0789e-04\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6166e-04 - val_loss: 3.1405e-04\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5909e-04 - val_loss: 3.0491e-04\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5983e-04 - val_loss: 3.0709e-04\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5938e-04 - val_loss: 3.0690e-04\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5907e-04 - val_loss: 3.0315e-04\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5560e-04 - val_loss: 3.0170e-04\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5510e-04 - val_loss: 3.1284e-04\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5570e-04 - val_loss: 3.0096e-04\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5438e-04 - val_loss: 3.0080e-04\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5334e-04 - val_loss: 3.0529e-04\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5331e-04 - val_loss: 2.9943e-04\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5462e-04 - val_loss: 3.0295e-04\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5236e-04 - val_loss: 3.2493e-04\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5109e-04 - val_loss: 2.9658e-04\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5040e-04 - val_loss: 2.9733e-04\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4657e-04 - val_loss: 3.0396e-04\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4931e-04 - val_loss: 2.9832e-04\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5038e-04 - val_loss: 3.1245e-04\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4810e-04 - val_loss: 2.9461e-04\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4648e-04 - val_loss: 2.9345e-04\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4551e-04 - val_loss: 2.9293e-04\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4359e-04 - val_loss: 2.9360e-04\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4306e-04 - val_loss: 3.1225e-04\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4380e-04 - val_loss: 2.9421e-04\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4008e-04 - val_loss: 2.9791e-04\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3919e-04 - val_loss: 2.9436e-04\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3886e-04 - val_loss: 2.9172e-04\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3869e-04 - val_loss: 2.9048e-04\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3643e-04 - val_loss: 2.9225e-04\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3713e-04 - val_loss: 2.9102e-04\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3743e-04 - val_loss: 2.8900e-04\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3809e-04 - val_loss: 2.9848e-04\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3406e-04 - val_loss: 2.8693e-04\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3417e-04 - val_loss: 2.8623e-04\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3379e-04 - val_loss: 2.9005e-04\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3213e-04 - val_loss: 2.8631e-04\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3762e-04 - val_loss: 2.8559e-04\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3768e-04 - val_loss: 2.8422e-04\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3241e-04 - val_loss: 2.9446e-04\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3089e-04 - val_loss: 2.9554e-04\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2539e-04 - val_loss: 2.8933e-04\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3444e-04 - val_loss: 2.8224e-04\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2553e-04 - val_loss: 2.8230e-04\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2463e-04 - val_loss: 2.8196e-04\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2768e-04 - val_loss: 2.8225e-04\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2338e-04 - val_loss: 2.8698e-04\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2410e-04 - val_loss: 2.8103e-04\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2290e-04 - val_loss: 2.8314e-04\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2323e-04 - val_loss: 2.7982e-04\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2116e-04 - val_loss: 2.7844e-04\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2208e-04 - val_loss: 2.8349e-04\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1783e-04 - val_loss: 2.8990e-04\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2330e-04 - val_loss: 2.7751e-04\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1985e-04 - val_loss: 2.8867e-04\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1975e-04 - val_loss: 2.9231e-04\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1997e-04 - val_loss: 2.8172e-04\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1446e-04 - val_loss: 2.7720e-04\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1653e-04 - val_loss: 2.7594e-04\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1773e-04 - val_loss: 2.7565e-04\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1135e-04 - val_loss: 2.8076e-04\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1422e-04 - val_loss: 2.7839e-04\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1042e-04 - val_loss: 2.8381e-04\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1520e-04 - val_loss: 2.8234e-04\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1456e-04 - val_loss: 2.7606e-04\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1271e-04 - val_loss: 3.0073e-04\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0603e-04 - val_loss: 2.7282e-04\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1078e-04 - val_loss: 2.7251e-04\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1215e-04 - val_loss: 2.7132e-04\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0657e-04 - val_loss: 2.6983e-04\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0683e-04 - val_loss: 2.7473e-04\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0749e-04 - val_loss: 2.7068e-04\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0936e-04 - val_loss: 2.6859e-04\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0726e-04 - val_loss: 2.7729e-04\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0577e-04 - val_loss: 2.7081e-04\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0559e-04 - val_loss: 2.7111e-04\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0368e-04 - val_loss: 2.7335e-04\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0189e-04 - val_loss: 2.6655e-04\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0398e-04 - val_loss: 2.7090e-04\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0060e-04 - val_loss: 2.6993e-04\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9892e-04 - val_loss: 2.6530e-04\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9917e-04 - val_loss: 2.6473e-04\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9899e-04 - val_loss: 2.6503e-04\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9804e-04 - val_loss: 2.6394e-04\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9658e-04 - val_loss: 2.6733e-04\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9643e-04 - val_loss: 2.6883e-04\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9548e-04 - val_loss: 2.7788e-04\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9512e-04 - val_loss: 2.6235e-04\n",
      "Thời gian huấn luyện:  12.581652641296387\n",
      "Model: \"sequential_112\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_140 (Dense)           (None, 3, 96)             192       \n",
      "                                                                 \n",
      " flatten_112 (Flatten)       (None, 288)               0         \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 1)                 289       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 481\n",
      "Trainable params: 481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "35/35 [==============================] - 0s 869us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 1s 6ms/step - loss: 0.0115 - val_loss: 4.2208e-04\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 8.5298e-04 - val_loss: 3.3027e-04\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 7.2458e-04 - val_loss: 3.4476e-04\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.9378e-04 - val_loss: 3.2526e-04\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.7596e-04 - val_loss: 3.2424e-04\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.6558e-04 - val_loss: 3.3677e-04\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.5769e-04 - val_loss: 3.2657e-04\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.4119e-04 - val_loss: 3.1685e-04\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.3389e-04 - val_loss: 3.1810e-04\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.2431e-04 - val_loss: 3.1093e-04\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.1297e-04 - val_loss: 3.2171e-04\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.1663e-04 - val_loss: 3.0458e-04\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.0159e-04 - val_loss: 3.0234e-04\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.9690e-04 - val_loss: 3.0154e-04\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.9525e-04 - val_loss: 3.0275e-04\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.8638e-04 - val_loss: 3.0478e-04\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.7568e-04 - val_loss: 2.9262e-04\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.7964e-04 - val_loss: 2.9055e-04\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6713e-04 - val_loss: 2.8906e-04\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6529e-04 - val_loss: 2.8744e-04\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6219e-04 - val_loss: 2.8786e-04\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.5718e-04 - val_loss: 2.8578e-04\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.5376e-04 - val_loss: 2.8198e-04\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4789e-04 - val_loss: 2.8210e-04\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4702e-04 - val_loss: 3.0886e-04\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4636e-04 - val_loss: 2.7771e-04\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3755e-04 - val_loss: 2.9671e-04\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4006e-04 - val_loss: 2.7627e-04\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3280e-04 - val_loss: 2.9654e-04\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3157e-04 - val_loss: 2.7504e-04\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2803e-04 - val_loss: 2.8238e-04\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2883e-04 - val_loss: 2.7230e-04\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2269e-04 - val_loss: 2.7777e-04\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2780e-04 - val_loss: 2.9976e-04\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2023e-04 - val_loss: 2.6866e-04\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.1611e-04 - val_loss: 2.6786e-04\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.1979e-04 - val_loss: 2.9825e-04\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0923e-04 - val_loss: 2.9651e-04\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.1064e-04 - val_loss: 2.6859e-04\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0803e-04 - val_loss: 2.6599e-04\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0156e-04 - val_loss: 2.6329e-04\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0788e-04 - val_loss: 2.6916e-04\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0327e-04 - val_loss: 2.6158e-04\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9893e-04 - val_loss: 2.6124e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9321e-04 - val_loss: 2.7821e-04\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9737e-04 - val_loss: 2.6436e-04\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9487e-04 - val_loss: 2.5908e-04\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9494e-04 - val_loss: 2.5824e-04\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9035e-04 - val_loss: 2.6802e-04\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8482e-04 - val_loss: 2.6235e-04\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.8540e-04 - val_loss: 2.7054e-04\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0278e-04 - val_loss: 2.5631e-04\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.8422e-04 - val_loss: 2.5511e-04\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.8116e-04 - val_loss: 2.5464e-04\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.7953e-04 - val_loss: 2.5368e-04\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.8722e-04 - val_loss: 2.6182e-04\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.8138e-04 - val_loss: 2.6411e-04\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9359e-04 - val_loss: 2.5643e-04\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7198e-04 - val_loss: 2.5143e-04\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7128e-04 - val_loss: 2.5073e-04\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.6972e-04 - val_loss: 2.5246e-04\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.7090e-04 - val_loss: 2.5615e-04\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.6521e-04 - val_loss: 2.4904e-04\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.6334e-04 - val_loss: 2.4827e-04\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.6382e-04 - val_loss: 2.5469e-04\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.6650e-04 - val_loss: 2.5062e-04\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.6159e-04 - val_loss: 2.5158e-04\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.5775e-04 - val_loss: 2.5927e-04\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.5985e-04 - val_loss: 2.5532e-04\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.6068e-04 - val_loss: 2.4521e-04\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.5710e-04 - val_loss: 2.5215e-04\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.5364e-04 - val_loss: 2.4444e-04\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.4925e-04 - val_loss: 2.4638e-04\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.5108e-04 - val_loss: 2.4346e-04\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.4814e-04 - val_loss: 2.4530e-04\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.4557e-04 - val_loss: 2.5578e-04\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.4975e-04 - val_loss: 2.4075e-04\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.4837e-04 - val_loss: 2.5473e-04\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.4575e-04 - val_loss: 2.4077e-04\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.4970e-04 - val_loss: 2.5978e-04\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.4645e-04 - val_loss: 2.5352e-04\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.5096e-04 - val_loss: 2.3834e-04\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4462e-04 - val_loss: 2.5327e-04\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.4195e-04 - val_loss: 2.3903e-04\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.4480e-04 - val_loss: 2.4055e-04\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.3663e-04 - val_loss: 2.3812e-04\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.3674e-04 - val_loss: 2.5726e-04\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.4638e-04 - val_loss: 2.3943e-04\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.4153e-04 - val_loss: 2.7335e-04\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.4703e-04 - val_loss: 2.3578e-04\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.3346e-04 - val_loss: 2.3858e-04\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.3320e-04 - val_loss: 2.3678e-04\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.3400e-04 - val_loss: 2.4466e-04\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.3011e-04 - val_loss: 2.4403e-04\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.3485e-04 - val_loss: 2.3357e-04\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.2464e-04 - val_loss: 2.3273e-04\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.3128e-04 - val_loss: 2.3454e-04\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.2819e-04 - val_loss: 2.5369e-04\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.2625e-04 - val_loss: 2.3197e-04\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.3354e-04 - val_loss: 2.4679e-04\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.2596e-04 - val_loss: 2.7609e-04\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.4619e-04 - val_loss: 2.3048e-04\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.2582e-04 - val_loss: 2.5889e-04\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.2517e-04 - val_loss: 2.4576e-04\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.2297e-04 - val_loss: 2.4055e-04\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.4311e-04 - val_loss: 2.3370e-04\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.3175e-04 - val_loss: 2.2996e-04\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.2868e-04 - val_loss: 2.3243e-04\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.2244e-04 - val_loss: 2.2940e-04\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1565e-04 - val_loss: 2.2997e-04\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.2099e-04 - val_loss: 2.5585e-04\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1791e-04 - val_loss: 2.3520e-04\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1986e-04 - val_loss: 2.2875e-04\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1651e-04 - val_loss: 2.3064e-04\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1540e-04 - val_loss: 2.3585e-04\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1722e-04 - val_loss: 2.2826e-04\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.2301e-04 - val_loss: 2.6997e-04\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.3566e-04 - val_loss: 2.3399e-04\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1912e-04 - val_loss: 2.2793e-04\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step - loss: 4.2533e-04 - val_loss: 2.3395e-04\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1423e-04 - val_loss: 2.2899e-04\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1301e-04 - val_loss: 2.2825e-04\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1118e-04 - val_loss: 2.2724e-04\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1151e-04 - val_loss: 2.5579e-04\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.2847e-04 - val_loss: 2.4866e-04\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1743e-04 - val_loss: 2.7421e-04\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.3479e-04 - val_loss: 3.2357e-04\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.3094e-04 - val_loss: 2.2865e-04\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1314e-04 - val_loss: 2.2778e-04\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1987e-04 - val_loss: 2.3023e-04\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0946e-04 - val_loss: 2.4809e-04\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.2035e-04 - val_loss: 2.5800e-04\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0854e-04 - val_loss: 2.2801e-04\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1356e-04 - val_loss: 2.2893e-04\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1412e-04 - val_loss: 2.2843e-04\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1236e-04 - val_loss: 2.5809e-04\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1384e-04 - val_loss: 2.2842e-04\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0735e-04 - val_loss: 2.2750e-04\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1457e-04 - val_loss: 2.3063e-04\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1468e-04 - val_loss: 2.7244e-04\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1846e-04 - val_loss: 2.2721e-04\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1116e-04 - val_loss: 2.2636e-04\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0391e-04 - val_loss: 2.4406e-04\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0860e-04 - val_loss: 2.2697e-04\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1270e-04 - val_loss: 2.2800e-04\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1627e-04 - val_loss: 2.3195e-04\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1206e-04 - val_loss: 2.3177e-04\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0606e-04 - val_loss: 2.2643e-04\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1486e-04 - val_loss: 2.3266e-04\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0994e-04 - val_loss: 2.5042e-04\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0705e-04 - val_loss: 2.3266e-04\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0694e-04 - val_loss: 2.3454e-04\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1324e-04 - val_loss: 2.2688e-04\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0900e-04 - val_loss: 2.2823e-04\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.2380e-04 - val_loss: 2.2590e-04\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0214e-04 - val_loss: 2.6276e-04\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0837e-04 - val_loss: 2.2780e-04\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0776e-04 - val_loss: 2.4547e-04\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0665e-04 - val_loss: 2.5736e-04\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0948e-04 - val_loss: 2.3208e-04\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0486e-04 - val_loss: 2.2662e-04\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0965e-04 - val_loss: 2.3085e-04\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1270e-04 - val_loss: 2.3730e-04\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0995e-04 - val_loss: 2.3030e-04\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.4248e-04 - val_loss: 2.4815e-04\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0925e-04 - val_loss: 2.4062e-04\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1354e-04 - val_loss: 2.3437e-04\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0924e-04 - val_loss: 2.2653e-04\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0550e-04 - val_loss: 2.2862e-04\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1335e-04 - val_loss: 2.2887e-04\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0834e-04 - val_loss: 2.2765e-04\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1225e-04 - val_loss: 2.3625e-04\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0894e-04 - val_loss: 2.3183e-04\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1280e-04 - val_loss: 2.2771e-04\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1845e-04 - val_loss: 2.2668e-04\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0424e-04 - val_loss: 2.4688e-04\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.2544e-04 - val_loss: 2.3873e-04\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1041e-04 - val_loss: 2.2821e-04\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0293e-04 - val_loss: 2.2861e-04\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0894e-04 - val_loss: 2.3681e-04\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0605e-04 - val_loss: 2.5918e-04\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.2384e-04 - val_loss: 2.2717e-04\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1244e-04 - val_loss: 2.3401e-04\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0452e-04 - val_loss: 2.2734e-04\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0675e-04 - val_loss: 2.2664e-04\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0454e-04 - val_loss: 2.2778e-04\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0164e-04 - val_loss: 2.2836e-04\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0529e-04 - val_loss: 2.2712e-04\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0599e-04 - val_loss: 2.3196e-04\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0622e-04 - val_loss: 2.3074e-04\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0535e-04 - val_loss: 2.3170e-04\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0692e-04 - val_loss: 2.5530e-04\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0701e-04 - val_loss: 2.3557e-04\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0655e-04 - val_loss: 2.4832e-04\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1049e-04 - val_loss: 2.2852e-04\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1087e-04 - val_loss: 2.5768e-04\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0917e-04 - val_loss: 2.3718e-04\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0325e-04 - val_loss: 2.3750e-04\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0546e-04 - val_loss: 2.2758e-04\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0771e-04 - val_loss: 2.3618e-04\n",
      "Thời gian huấn luyện:  17.468767642974854\n",
      "Model: \"sequential_113\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_28 (SimpleRNN)   (None, 3, 103)            10815     \n",
      "                                                                 \n",
      " flatten_113 (Flatten)       (None, 309)               0         \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 1)                 310       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,125\n",
      "Trainable params: 11,125\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "41/41 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 1s 13ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 148/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1020\n",
      "Thời gian huấn luyện:  27.184850692749023\n",
      "Model: \"sequential_114\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_28 (LSTM)              (None, 3, 103)            43260     \n",
      "                                                                 \n",
      " flatten_114 (Flatten)       (None, 309)               0         \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 1)                 310       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,570\n",
      "Trainable params: 43,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "41/41 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 1s 12ms/step - loss: 0.0400 - val_loss: 0.0023\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 4.5982e-04\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 3.8430e-04\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 3.4583e-04\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 3.6100e-04\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 3.6104e-04\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 9.4882e-04 - val_loss: 3.5203e-04\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.1984e-04 - val_loss: 3.4435e-04\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.4345e-04 - val_loss: 3.5275e-04\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.1308e-04 - val_loss: 3.5321e-04\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.9870e-04 - val_loss: 3.4221e-04\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.9520e-04 - val_loss: 3.4477e-04\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.9175e-04 - val_loss: 3.4657e-04\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.9033e-04 - val_loss: 3.5454e-04\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.9119e-04 - val_loss: 3.4765e-04\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.9057e-04 - val_loss: 3.5006e-04\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.8616e-04 - val_loss: 3.4514e-04\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.8619e-04 - val_loss: 3.4719e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.8503e-04 - val_loss: 3.4785e-04\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.8490e-04 - val_loss: 3.4124e-04\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.7947e-04 - val_loss: 3.4240e-04\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.8794e-04 - val_loss: 3.4327e-04\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.7947e-04 - val_loss: 3.5960e-04\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.8312e-04 - val_loss: 3.4800e-04\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.7989e-04 - val_loss: 3.6621e-04\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.8719e-04 - val_loss: 3.4846e-04\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.7279e-04 - val_loss: 3.4039e-04\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.7078e-04 - val_loss: 3.4356e-04\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.7660e-04 - val_loss: 3.3727e-04\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.6857e-04 - val_loss: 3.3662e-04\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.7165e-04 - val_loss: 3.5045e-04\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.6753e-04 - val_loss: 3.5043e-04\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.6518e-04 - val_loss: 3.3461e-04\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.6566e-04 - val_loss: 3.3713e-04\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.6208e-04 - val_loss: 3.3209e-04\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.6367e-04 - val_loss: 3.3387e-04\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.6219e-04 - val_loss: 3.3161e-04\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.5715e-04 - val_loss: 3.4178e-04\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.5658e-04 - val_loss: 3.3004e-04\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.5757e-04 - val_loss: 3.3315e-04\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.5825e-04 - val_loss: 3.4023e-04\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.5090e-04 - val_loss: 3.2756e-04\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.5423e-04 - val_loss: 3.3027e-04\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.4781e-04 - val_loss: 3.2652e-04\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.4518e-04 - val_loss: 3.2741e-04\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.4464e-04 - val_loss: 3.3211e-04\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.4402e-04 - val_loss: 3.2606e-04\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.4022e-04 - val_loss: 3.2858e-04\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.4056e-04 - val_loss: 3.2777e-04\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.3835e-04 - val_loss: 3.2200e-04\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.3530e-04 - val_loss: 3.2685e-04\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.3648e-04 - val_loss: 3.2001e-04\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.3753e-04 - val_loss: 3.2095e-04\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.3247e-04 - val_loss: 3.1992e-04\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.2833e-04 - val_loss: 3.2200e-04\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.2979e-04 - val_loss: 3.1757e-04\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.2700e-04 - val_loss: 3.1603e-04\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.2821e-04 - val_loss: 3.2681e-04\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.2702e-04 - val_loss: 3.1647e-04\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.2381e-04 - val_loss: 3.1335e-04\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.1996e-04 - val_loss: 3.1667e-04\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.2031e-04 - val_loss: 3.2021e-04\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.2096e-04 - val_loss: 3.1547e-04\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.2196e-04 - val_loss: 3.1527e-04\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.1739e-04 - val_loss: 3.0923e-04\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.1028e-04 - val_loss: 3.1214e-04\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.1260e-04 - val_loss: 3.0845e-04\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.0589e-04 - val_loss: 3.0872e-04\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.0686e-04 - val_loss: 3.2950e-04\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.0939e-04 - val_loss: 3.1127e-04\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.0441e-04 - val_loss: 3.1142e-04\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.0502e-04 - val_loss: 3.0487e-04\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.9959e-04 - val_loss: 3.0272e-04\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.0317e-04 - val_loss: 3.0833e-04\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.9399e-04 - val_loss: 3.0098e-04\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.9202e-04 - val_loss: 3.0207e-04\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.9822e-04 - val_loss: 2.9934e-04\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.8843e-04 - val_loss: 2.9954e-04\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.8805e-04 - val_loss: 2.9843e-04\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.8761e-04 - val_loss: 2.9874e-04\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.8430e-04 - val_loss: 3.1324e-04\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.9417e-04 - val_loss: 2.9531e-04\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.7867e-04 - val_loss: 3.0545e-04\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.7726e-04 - val_loss: 3.0209e-04\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.7975e-04 - val_loss: 2.9245e-04\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.7387e-04 - val_loss: 2.9737e-04\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.7275e-04 - val_loss: 2.9171e-04\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.7172e-04 - val_loss: 2.9008e-04\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.7245e-04 - val_loss: 2.9606e-04\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.6855e-04 - val_loss: 3.0327e-04\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.6875e-04 - val_loss: 2.9553e-04\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.6238e-04 - val_loss: 2.8660e-04\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.6144e-04 - val_loss: 2.9120e-04\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.5778e-04 - val_loss: 2.8693e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.5588e-04 - val_loss: 2.8490e-04\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.5731e-04 - val_loss: 3.0305e-04\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.5311e-04 - val_loss: 3.0219e-04\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.6023e-04 - val_loss: 2.8295e-04\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.4814e-04 - val_loss: 2.8077e-04\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.5140e-04 - val_loss: 2.9552e-04\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.5125e-04 - val_loss: 2.8131e-04\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.4050e-04 - val_loss: 2.9124e-04\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.4562e-04 - val_loss: 3.1436e-04\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.4164e-04 - val_loss: 2.7674e-04\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.3529e-04 - val_loss: 2.8383e-04\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.3847e-04 - val_loss: 2.7829e-04\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.4074e-04 - val_loss: 2.7459e-04\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.3940e-04 - val_loss: 2.8713e-04\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.3781e-04 - val_loss: 2.9734e-04\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.3433e-04 - val_loss: 2.7268e-04\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.3645e-04 - val_loss: 2.7035e-04\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.3147e-04 - val_loss: 2.8414e-04\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.2174e-04 - val_loss: 2.6897e-04\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.2533e-04 - val_loss: 2.7905e-04\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.1889e-04 - val_loss: 2.7520e-04\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.2012e-04 - val_loss: 2.6718e-04\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.1348e-04 - val_loss: 2.6833e-04\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.1142e-04 - val_loss: 2.6862e-04\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.1302e-04 - val_loss: 2.6791e-04\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.1044e-04 - val_loss: 2.6307e-04\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0719e-04 - val_loss: 2.8619e-04\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0658e-04 - val_loss: 2.6500e-04\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0742e-04 - val_loss: 2.6143e-04\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0237e-04 - val_loss: 2.6858e-04\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0421e-04 - val_loss: 2.6111e-04\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9745e-04 - val_loss: 2.6368e-04\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9593e-04 - val_loss: 2.9417e-04\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9716e-04 - val_loss: 2.5746e-04\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9422e-04 - val_loss: 2.5712e-04\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9284e-04 - val_loss: 2.6200e-04\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8867e-04 - val_loss: 2.5714e-04\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8696e-04 - val_loss: 2.5420e-04\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8724e-04 - val_loss: 2.5687e-04\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8429e-04 - val_loss: 2.5333e-04\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8285e-04 - val_loss: 2.5393e-04\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8048e-04 - val_loss: 2.6133e-04\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8196e-04 - val_loss: 2.5148e-04\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7872e-04 - val_loss: 2.5572e-04\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7556e-04 - val_loss: 2.4987e-04\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7448e-04 - val_loss: 2.5931e-04\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7625e-04 - val_loss: 2.5252e-04\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7341e-04 - val_loss: 2.4774e-04\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7339e-04 - val_loss: 2.4986e-04\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7663e-04 - val_loss: 2.4750e-04\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6594e-04 - val_loss: 2.5405e-04\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6527e-04 - val_loss: 2.4606e-04\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7145e-04 - val_loss: 2.5102e-04\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6520e-04 - val_loss: 2.4537e-04\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6135e-04 - val_loss: 2.4712e-04\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6342e-04 - val_loss: 2.4514e-04\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6202e-04 - val_loss: 2.5757e-04\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6000e-04 - val_loss: 2.4667e-04\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6097e-04 - val_loss: 2.4632e-04\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5910e-04 - val_loss: 2.4470e-04\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5630e-04 - val_loss: 2.7900e-04\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5308e-04 - val_loss: 2.4334e-04\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6399e-04 - val_loss: 2.4172e-04\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6288e-04 - val_loss: 2.4289e-04\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5057e-04 - val_loss: 2.4411e-04\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4969e-04 - val_loss: 2.6576e-04\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4732e-04 - val_loss: 2.4151e-04\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4949e-04 - val_loss: 2.4317e-04\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4793e-04 - val_loss: 2.3933e-04\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4654e-04 - val_loss: 2.3876e-04\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4881e-04 - val_loss: 2.4271e-04\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4497e-04 - val_loss: 2.5677e-04\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4644e-04 - val_loss: 2.3727e-04\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.4001e-04 - val_loss: 2.3717e-04\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4006e-04 - val_loss: 2.4128e-04\n",
      "Epoch 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3878e-04 - val_loss: 2.4463e-04\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4262e-04 - val_loss: 2.3620e-04\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3932e-04 - val_loss: 2.3548e-04\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3523e-04 - val_loss: 2.3486e-04\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3644e-04 - val_loss: 2.4247e-04\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3436e-04 - val_loss: 2.3688e-04\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3529e-04 - val_loss: 2.4120e-04\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4159e-04 - val_loss: 2.3524e-04\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3373e-04 - val_loss: 2.5430e-04\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3725e-04 - val_loss: 2.3646e-04\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3941e-04 - val_loss: 2.3444e-04\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2956e-04 - val_loss: 2.3345e-04\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2771e-04 - val_loss: 2.3359e-04\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3313e-04 - val_loss: 2.3640e-04\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3128e-04 - val_loss: 2.3674e-04\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2979e-04 - val_loss: 2.3315e-04\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3849e-04 - val_loss: 2.3382e-04\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2911e-04 - val_loss: 2.3541e-04\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3010e-04 - val_loss: 2.3286e-04\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2621e-04 - val_loss: 2.3268e-04\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2617e-04 - val_loss: 2.3255e-04\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2936e-04 - val_loss: 2.3709e-04\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2421e-04 - val_loss: 2.4366e-04\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2861e-04 - val_loss: 2.4660e-04\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3686e-04 - val_loss: 2.4017e-04\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3325e-04 - val_loss: 2.3948e-04\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2476e-04 - val_loss: 2.3807e-04\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2503e-04 - val_loss: 2.5303e-04\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3072e-04 - val_loss: 2.3067e-04\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2314e-04 - val_loss: 2.3401e-04\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2320e-04 - val_loss: 2.4316e-04\n",
      "Thời gian huấn luyện:  25.101818799972534\n",
      "Model: \"sequential_115\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_28 (GRU)                (None, 3, 103)            32754     \n",
      "                                                                 \n",
      " flatten_115 (Flatten)       (None, 309)               0         \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 1)                 310       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,064\n",
      "Trainable params: 33,064\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "41/41 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0721 - val_loss: 0.0213\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0023\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0033\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0028\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0028\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0026\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 9.7897e-04\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 9.1109e-04\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 8.7620e-04\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 7.9844e-04\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.6292e-04\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.0531e-04\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.7285e-04\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.4455e-04\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.2094e-04\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.0133e-04\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.8612e-04\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.5560e-04\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.6327e-04\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.9904e-04 - val_loss: 5.5109e-04\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.8225e-04 - val_loss: 5.2366e-04\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.6584e-04 - val_loss: 5.4128e-04\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.5214e-04 - val_loss: 5.1129e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.4353e-04 - val_loss: 5.1264e-04\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.3309e-04 - val_loss: 4.9908e-04\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.2713e-04 - val_loss: 5.0528e-04\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.2075e-04 - val_loss: 5.0923e-04\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.1383e-04 - val_loss: 4.9320e-04\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.1073e-04 - val_loss: 4.9691e-04\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.0694e-04 - val_loss: 4.9525e-04\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.0200e-04 - val_loss: 4.8517e-04\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.9747e-04 - val_loss: 4.8911e-04\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.9462e-04 - val_loss: 4.8313e-04\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.9680e-04 - val_loss: 4.9112e-04\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.9330e-04 - val_loss: 4.7686e-04\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.8676e-04 - val_loss: 4.8143e-04\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.8392e-04 - val_loss: 4.8061e-04\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.8143e-04 - val_loss: 4.7452e-04\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.7992e-04 - val_loss: 4.7447e-04\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.7667e-04 - val_loss: 4.7871e-04\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.7333e-04 - val_loss: 4.7793e-04\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.7144e-04 - val_loss: 4.7098e-04\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.6934e-04 - val_loss: 4.7555e-04\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.6726e-04 - val_loss: 4.7394e-04\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.6663e-04 - val_loss: 4.6765e-04\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.6378e-04 - val_loss: 4.6768e-04\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.6158e-04 - val_loss: 4.6415e-04\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.6091e-04 - val_loss: 4.7889e-04\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.5692e-04 - val_loss: 4.6106e-04\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.5640e-04 - val_loss: 4.6659e-04\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.5923e-04 - val_loss: 4.5898e-04\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.4969e-04 - val_loss: 4.6116e-04\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.5014e-04 - val_loss: 4.5836e-04\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.4490e-04 - val_loss: 4.5995e-04\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.4357e-04 - val_loss: 4.5858e-04\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.4045e-04 - val_loss: 4.6019e-04\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.3931e-04 - val_loss: 4.5893e-04\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.3786e-04 - val_loss: 4.4946e-04\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.3827e-04 - val_loss: 4.5156e-04\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.3327e-04 - val_loss: 4.4747e-04\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.3228e-04 - val_loss: 4.5711e-04\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.2796e-04 - val_loss: 4.5005e-04\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.2472e-04 - val_loss: 4.4307e-04\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.2716e-04 - val_loss: 4.5950e-04\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.1725e-04 - val_loss: 4.4048e-04\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.1892e-04 - val_loss: 4.5291e-04\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.1790e-04 - val_loss: 4.5562e-04\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.1791e-04 - val_loss: 4.5007e-04\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.1212e-04 - val_loss: 4.3948e-04\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.1108e-04 - val_loss: 4.4403e-04\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.0540e-04 - val_loss: 4.3356e-04\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.0744e-04 - val_loss: 4.4421e-04\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.0202e-04 - val_loss: 4.3419e-04\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.0200e-04 - val_loss: 4.3945e-04\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.9678e-04 - val_loss: 4.2834e-04\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.9467e-04 - val_loss: 4.3034e-04\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.9336e-04 - val_loss: 4.3814e-04\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.9083e-04 - val_loss: 4.3066e-04\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.8778e-04 - val_loss: 4.2587e-04\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.8575e-04 - val_loss: 4.2432e-04\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.8698e-04 - val_loss: 4.2105e-04\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.7989e-04 - val_loss: 4.2666e-04\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.7770e-04 - val_loss: 4.3236e-04\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.7670e-04 - val_loss: 4.1980e-04\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.7394e-04 - val_loss: 4.1497e-04\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.6997e-04 - val_loss: 4.3014e-04\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.6998e-04 - val_loss: 4.1497e-04\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.6554e-04 - val_loss: 4.1665e-04\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.6298e-04 - val_loss: 4.1647e-04\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.6085e-04 - val_loss: 4.1106e-04\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.5795e-04 - val_loss: 4.1709e-04\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.5632e-04 - val_loss: 4.0598e-04\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.5904e-04 - val_loss: 4.0314e-04\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.5396e-04 - val_loss: 4.0746e-04\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.4825e-04 - val_loss: 4.0038e-04\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.4782e-04 - val_loss: 4.0357e-04\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.4205e-04 - val_loss: 3.9997e-04\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.4059e-04 - val_loss: 4.0290e-04\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 7.3854e-04 - val_loss: 3.9605e-04\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.3700e-04 - val_loss: 4.1944e-04\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.3481e-04 - val_loss: 3.9337e-04\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.3101e-04 - val_loss: 4.0306e-04\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.3265e-04 - val_loss: 3.9664e-04\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.2757e-04 - val_loss: 4.0620e-04\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.2504e-04 - val_loss: 3.9026e-04\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.2223e-04 - val_loss: 3.8515e-04\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.2258e-04 - val_loss: 4.0510e-04\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.1762e-04 - val_loss: 4.1363e-04\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.2388e-04 - val_loss: 3.8661e-04\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.0983e-04 - val_loss: 3.8037e-04\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.1417e-04 - val_loss: 3.7857e-04\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.1328e-04 - val_loss: 3.7865e-04\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.0623e-04 - val_loss: 3.8391e-04\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.0229e-04 - val_loss: 3.7528e-04\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.0278e-04 - val_loss: 3.7873e-04\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.0048e-04 - val_loss: 3.7195e-04\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.9710e-04 - val_loss: 3.7235e-04\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.9291e-04 - val_loss: 3.7683e-04\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.9351e-04 - val_loss: 3.7258e-04\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.8938e-04 - val_loss: 3.6920e-04\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.8742e-04 - val_loss: 3.7743e-04\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.8296e-04 - val_loss: 3.6577e-04\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.8341e-04 - val_loss: 3.6293e-04\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.7739e-04 - val_loss: 3.6430e-04\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.7783e-04 - val_loss: 3.6728e-04\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.7477e-04 - val_loss: 3.5859e-04\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.7322e-04 - val_loss: 3.5898e-04\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.6773e-04 - val_loss: 3.7201e-04\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.6731e-04 - val_loss: 3.5485e-04\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.6436e-04 - val_loss: 3.5355e-04\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.6273e-04 - val_loss: 3.6135e-04\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.5912e-04 - val_loss: 3.5301e-04\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.5933e-04 - val_loss: 3.5284e-04\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.5917e-04 - val_loss: 3.5046e-04\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.5450e-04 - val_loss: 3.5019e-04\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.5013e-04 - val_loss: 3.4664e-04\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.4822e-04 - val_loss: 3.5293e-04\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.4749e-04 - val_loss: 3.5394e-04\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.4373e-04 - val_loss: 3.4743e-04\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.4047e-04 - val_loss: 3.4092e-04\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.4415e-04 - val_loss: 3.4190e-04\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.3569e-04 - val_loss: 3.5556e-04\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.4318e-04 - val_loss: 3.3747e-04\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.3928e-04 - val_loss: 3.3672e-04\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.3172e-04 - val_loss: 3.4020e-04\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.2755e-04 - val_loss: 3.3480e-04\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.2606e-04 - val_loss: 3.3452e-04\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.2883e-04 - val_loss: 3.3211e-04\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.2329e-04 - val_loss: 3.3372e-04\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.2027e-04 - val_loss: 3.3026e-04\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.2022e-04 - val_loss: 3.2777e-04\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.1701e-04 - val_loss: 3.3293e-04\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.1414e-04 - val_loss: 3.2560e-04\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.1636e-04 - val_loss: 3.3630e-04\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.1039e-04 - val_loss: 3.3669e-04\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0832e-04 - val_loss: 3.2949e-04\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0635e-04 - val_loss: 3.2847e-04\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0574e-04 - val_loss: 3.3226e-04\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0345e-04 - val_loss: 3.3478e-04\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0292e-04 - val_loss: 3.2300e-04\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9714e-04 - val_loss: 3.1830e-04\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9653e-04 - val_loss: 3.1571e-04\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9488e-04 - val_loss: 3.1710e-04\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9154e-04 - val_loss: 3.1639e-04\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9343e-04 - val_loss: 3.1619e-04\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9027e-04 - val_loss: 3.1827e-04\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8826e-04 - val_loss: 3.2041e-04\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8731e-04 - val_loss: 3.1704e-04\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8667e-04 - val_loss: 3.1001e-04\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8364e-04 - val_loss: 3.1496e-04\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8054e-04 - val_loss: 3.0615e-04\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7906e-04 - val_loss: 3.0513e-04\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7831e-04 - val_loss: 3.1221e-04\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7442e-04 - val_loss: 3.0708e-04\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7503e-04 - val_loss: 3.1414e-04\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6780e-04 - val_loss: 3.0120e-04\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7049e-04 - val_loss: 3.1367e-04\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7014e-04 - val_loss: 3.1157e-04\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6708e-04 - val_loss: 2.9885e-04\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6311e-04 - val_loss: 2.9848e-04\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6365e-04 - val_loss: 3.0614e-04\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5945e-04 - val_loss: 2.9560e-04\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6036e-04 - val_loss: 3.0170e-04\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6222e-04 - val_loss: 2.9373e-04\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5363e-04 - val_loss: 3.0555e-04\n",
      "Thời gian huấn luyện:  12.77134919166565\n",
      "Model: \"sequential_116\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_145 (Dense)           (None, 5, 96)             192       \n",
      "                                                                 \n",
      " flatten_116 (Flatten)       (None, 480)               0         \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 1)                 481       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673\n",
      "Trainable params: 673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "35/35 [==============================] - 0s 957us/step\n",
      "15/15 [==============================] - 0s 928us/step\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 1s 6ms/step - loss: 0.0274 - val_loss: 0.0017\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 6.7432e-04\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.7959e-04\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.6227e-04\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 5.5463e-04\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 5.2928e-04\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.1870e-04\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 5.0487e-04\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 4.8738e-04\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.8138e-04\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 4.6629e-04\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 4.5567e-04\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 4.4638e-04\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 4.9036e-04\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 9.8586e-04 - val_loss: 4.3262e-04\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 9.4877e-04 - val_loss: 4.2377e-04\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 9.3481e-04 - val_loss: 4.1487e-04\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 9.1065e-04 - val_loss: 4.2504e-04\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.9736e-04 - val_loss: 4.0313e-04\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 8.6979e-04 - val_loss: 4.1925e-04\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 8.5996e-04 - val_loss: 3.9116e-04\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.4315e-04 - val_loss: 3.9810e-04\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.2889e-04 - val_loss: 3.8483e-04\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.1416e-04 - val_loss: 3.8454e-04\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.0845e-04 - val_loss: 3.7446e-04\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.8695e-04 - val_loss: 3.7088e-04\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.8088e-04 - val_loss: 3.6725e-04\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.6396e-04 - val_loss: 3.6827e-04\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.5403e-04 - val_loss: 3.6360e-04\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.4680e-04 - val_loss: 3.6961e-04\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.3973e-04 - val_loss: 3.6128e-04\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.3591e-04 - val_loss: 3.5440e-04\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.2142e-04 - val_loss: 3.5316e-04\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.1553e-04 - val_loss: 3.4948e-04\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.1065e-04 - val_loss: 3.4716e-04\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.0304e-04 - val_loss: 3.4749e-04\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.9061e-04 - val_loss: 3.4297e-04\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.9131e-04 - val_loss: 3.5646e-04\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.7884e-04 - val_loss: 3.6303e-04\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.7940e-04 - val_loss: 3.4744e-04\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.6993e-04 - val_loss: 3.4313e-04\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.6579e-04 - val_loss: 3.3516e-04\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.6996e-04 - val_loss: 3.3448e-04\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.5109e-04 - val_loss: 3.3156e-04\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.5785e-04 - val_loss: 3.4783e-04\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.4928e-04 - val_loss: 3.2874e-04\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.4517e-04 - val_loss: 3.3809e-04\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.3940e-04 - val_loss: 3.2476e-04\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.3989e-04 - val_loss: 3.3817e-04\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.3509e-04 - val_loss: 3.5548e-04\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.2568e-04 - val_loss: 3.2023e-04\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.2174e-04 - val_loss: 3.1903e-04\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.1646e-04 - val_loss: 3.1761e-04\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.1125e-04 - val_loss: 3.2876e-04\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.2888e-04 - val_loss: 3.2439e-04\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 3ms/step - loss: 6.1058e-04 - val_loss: 3.1878e-04\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.0984e-04 - val_loss: 3.6907e-04\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.1873e-04 - val_loss: 3.2735e-04\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.0179e-04 - val_loss: 3.6338e-04\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.0086e-04 - val_loss: 3.0886e-04\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.0527e-04 - val_loss: 3.1215e-04\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.0017e-04 - val_loss: 3.0557e-04\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.9746e-04 - val_loss: 3.0456e-04\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.8966e-04 - val_loss: 3.2878e-04\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.7795e-04 - val_loss: 3.2624e-04\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.7477e-04 - val_loss: 3.0709e-04\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.8609e-04 - val_loss: 3.2263e-04\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.7229e-04 - val_loss: 3.0556e-04\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.8141e-04 - val_loss: 3.0001e-04\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6403e-04 - val_loss: 2.9843e-04\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.5863e-04 - val_loss: 3.0702e-04\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6840e-04 - val_loss: 2.9715e-04\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6355e-04 - val_loss: 2.9591e-04\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6474e-04 - val_loss: 2.9754e-04\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.5604e-04 - val_loss: 2.9186e-04\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.5041e-04 - val_loss: 2.9891e-04\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.5518e-04 - val_loss: 3.0995e-04\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4531e-04 - val_loss: 2.9061e-04\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6088e-04 - val_loss: 2.9174e-04\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4152e-04 - val_loss: 2.8664e-04\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3752e-04 - val_loss: 3.0520e-04\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.5220e-04 - val_loss: 2.9336e-04\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.4489e-04 - val_loss: 2.8753e-04\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.4959e-04 - val_loss: 3.1367e-04\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3811e-04 - val_loss: 2.8785e-04\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2825e-04 - val_loss: 2.8196e-04\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.2169e-04 - val_loss: 2.8044e-04\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3263e-04 - val_loss: 2.8552e-04\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3594e-04 - val_loss: 2.8445e-04\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2012e-04 - val_loss: 3.0005e-04\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.5022e-04 - val_loss: 2.7638e-04\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2556e-04 - val_loss: 2.8227e-04\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.3097e-04 - val_loss: 3.5325e-04\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3934e-04 - val_loss: 3.1071e-04\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2376e-04 - val_loss: 2.8293e-04\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.1652e-04 - val_loss: 2.7811e-04\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.1546e-04 - val_loss: 2.7467e-04\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0568e-04 - val_loss: 2.7541e-04\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0738e-04 - val_loss: 2.7593e-04\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0995e-04 - val_loss: 3.2190e-04\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0966e-04 - val_loss: 2.8247e-04\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0180e-04 - val_loss: 2.8634e-04\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9732e-04 - val_loss: 2.6765e-04\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9834e-04 - val_loss: 2.7101e-04\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9395e-04 - val_loss: 3.2002e-04\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0374e-04 - val_loss: 2.7022e-04\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9458e-04 - val_loss: 2.7834e-04\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9176e-04 - val_loss: 2.6854e-04\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8923e-04 - val_loss: 3.2123e-04\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0192e-04 - val_loss: 2.6730e-04\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0219e-04 - val_loss: 2.6996e-04\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.1272e-04 - val_loss: 3.6534e-04\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0992e-04 - val_loss: 2.7146e-04\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9172e-04 - val_loss: 2.6069e-04\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9679e-04 - val_loss: 2.8463e-04\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9140e-04 - val_loss: 2.7429e-04\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8560e-04 - val_loss: 3.3322e-04\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8945e-04 - val_loss: 2.7696e-04\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8102e-04 - val_loss: 2.5983e-04\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8313e-04 - val_loss: 2.8201e-04\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8105e-04 - val_loss: 3.3250e-04\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9040e-04 - val_loss: 2.5691e-04\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7916e-04 - val_loss: 2.5487e-04\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9166e-04 - val_loss: 2.5428e-04\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7181e-04 - val_loss: 2.7983e-04\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.6911e-04 - val_loss: 2.6251e-04\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6868e-04 - val_loss: 2.6106e-04\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7155e-04 - val_loss: 2.6103e-04\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6654e-04 - val_loss: 2.8628e-04\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7227e-04 - val_loss: 2.5326e-04\n",
      "Epoch 131/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7077e-04 - val_loss: 2.5167e-04\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6631e-04 - val_loss: 2.8929e-04\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6181e-04 - val_loss: 2.6001e-04\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6684e-04 - val_loss: 2.7564e-04\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7187e-04 - val_loss: 2.5085e-04\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6267e-04 - val_loss: 2.4853e-04\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5599e-04 - val_loss: 2.4924e-04\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5373e-04 - val_loss: 2.6029e-04\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7529e-04 - val_loss: 2.4978e-04\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5144e-04 - val_loss: 2.6275e-04\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6530e-04 - val_loss: 2.4811e-04\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6022e-04 - val_loss: 3.3064e-04\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6167e-04 - val_loss: 2.4732e-04\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5280e-04 - val_loss: 2.5107e-04\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4928e-04 - val_loss: 2.5882e-04\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5226e-04 - val_loss: 2.4477e-04\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4399e-04 - val_loss: 2.6220e-04\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5045e-04 - val_loss: 2.4280e-04\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4992e-04 - val_loss: 2.7504e-04\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4526e-04 - val_loss: 2.4178e-04\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4551e-04 - val_loss: 2.4220e-04\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3732e-04 - val_loss: 2.4810e-04\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4173e-04 - val_loss: 2.4252e-04\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4047e-04 - val_loss: 2.4320e-04\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.5591e-04 - val_loss: 2.9125e-04\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4423e-04 - val_loss: 2.4706e-04\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4529e-04 - val_loss: 2.4332e-04\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5023e-04 - val_loss: 2.3866e-04\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4470e-04 - val_loss: 2.3838e-04\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3554e-04 - val_loss: 2.4044e-04\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3683e-04 - val_loss: 2.3826e-04\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3395e-04 - val_loss: 2.8925e-04\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6042e-04 - val_loss: 2.6021e-04\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.3544e-04 - val_loss: 2.8943e-04\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4303e-04 - val_loss: 2.4278e-04\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3581e-04 - val_loss: 2.4571e-04\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2993e-04 - val_loss: 2.4202e-04\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3480e-04 - val_loss: 2.6425e-04\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3204e-04 - val_loss: 2.3969e-04\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2973e-04 - val_loss: 2.4246e-04\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6949e-04 - val_loss: 2.7846e-04\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3646e-04 - val_loss: 2.6113e-04\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2565e-04 - val_loss: 2.6216e-04\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2325e-04 - val_loss: 2.6658e-04\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4113e-04 - val_loss: 2.3355e-04\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2545e-04 - val_loss: 2.3498e-04\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3644e-04 - val_loss: 2.4289e-04\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2915e-04 - val_loss: 2.7039e-04\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4492e-04 - val_loss: 2.3502e-04\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2197e-04 - val_loss: 2.3342e-04\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1761e-04 - val_loss: 2.3724e-04\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2970e-04 - val_loss: 2.3619e-04\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1916e-04 - val_loss: 2.6269e-04\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2123e-04 - val_loss: 2.5631e-04\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2097e-04 - val_loss: 2.3691e-04\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2053e-04 - val_loss: 2.5577e-04\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2821e-04 - val_loss: 2.5598e-04\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2326e-04 - val_loss: 2.4275e-04\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1653e-04 - val_loss: 2.3422e-04\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2801e-04 - val_loss: 2.4033e-04\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2322e-04 - val_loss: 2.3587e-04\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2652e-04 - val_loss: 2.8064e-04\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2703e-04 - val_loss: 2.5538e-04\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2685e-04 - val_loss: 2.3274e-04\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2157e-04 - val_loss: 2.3417e-04\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2078e-04 - val_loss: 2.3144e-04\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1716e-04 - val_loss: 2.4127e-04\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1981e-04 - val_loss: 2.3404e-04\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1312e-04 - val_loss: 2.4353e-04\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2080e-04 - val_loss: 2.3784e-04\n",
      "Thời gian huấn luyện:  20.145853281021118\n",
      "Model: \"sequential_117\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_29 (SimpleRNN)   (None, 5, 103)            10815     \n",
      "                                                                 \n",
      " flatten_117 (Flatten)       (None, 515)               0         \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 1)                 516       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,331\n",
      "Trainable params: 11,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 2s 16ms/step - loss: 0.0191 - val_loss: 5.6479e-04\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 4.4022e-04\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 4.7758e-04\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 5.2621e-04\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 4.9413e-04\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 4.6315e-04\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 4.6885e-04\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 4.7533e-04\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 4.7861e-04\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 4.9300e-04\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 5.1981e-04\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 4.9104e-04\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 4.7567e-04\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 4.8925e-04\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 4.7478e-04\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 4.7599e-04\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 4.7380e-04\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 4.7674e-04\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 5.1330e-04\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 4.7314e-04\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 4.7930e-04\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 4.7950e-04\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 4.7791e-04\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 4.6334e-04\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 4.6490e-04\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 4.8970e-04\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 4.6856e-04\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 4.5836e-04\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 4.5890e-04\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 4.5584e-04\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 4.5404e-04\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 4.5602e-04\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 4.5194e-04\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 4.5463e-04\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 4.4893e-04\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 4.4881e-04\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 4.6315e-04\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 4.5605e-04\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.9805e-04 - val_loss: 4.4458e-04\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.9127e-04 - val_loss: 4.4396e-04\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.9224e-04 - val_loss: 4.4110e-04\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8698e-04 - val_loss: 4.4602e-04\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8175e-04 - val_loss: 4.5403e-04\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.7504e-04 - val_loss: 4.6160e-04\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8393e-04 - val_loss: 4.6316e-04\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.7958e-04 - val_loss: 4.3763e-04\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.7193e-04 - val_loss: 4.7388e-04\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.6538e-04 - val_loss: 4.3530e-04\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.5618e-04 - val_loss: 4.3158e-04\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.5461e-04 - val_loss: 4.2842e-04\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.4749e-04 - val_loss: 4.3735e-04\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.4336e-04 - val_loss: 4.4253e-04\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.4191e-04 - val_loss: 4.2581e-04\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.3658e-04 - val_loss: 4.3907e-04\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.3363e-04 - val_loss: 4.2289e-04\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.3104e-04 - val_loss: 4.2811e-04\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.3409e-04 - val_loss: 4.2085e-04\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.2082e-04 - val_loss: 4.1589e-04\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.1786e-04 - val_loss: 4.2547e-04\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.0938e-04 - val_loss: 4.2793e-04\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.1683e-04 - val_loss: 4.1229e-04\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.0403e-04 - val_loss: 4.1239e-04\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.0131e-04 - val_loss: 4.0972e-04\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.9573e-04 - val_loss: 4.0701e-04\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.9606e-04 - val_loss: 4.3514e-04\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.8935e-04 - val_loss: 4.0465e-04\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.9246e-04 - val_loss: 4.0244e-04\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.7897e-04 - val_loss: 4.0042e-04\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.7463e-04 - val_loss: 4.0589e-04\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.7395e-04 - val_loss: 3.9788e-04\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.6747e-04 - val_loss: 3.9612e-04\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.6196e-04 - val_loss: 4.1220e-04\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.5534e-04 - val_loss: 3.9327e-04\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.5541e-04 - val_loss: 3.9809e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.5248e-04 - val_loss: 3.9333e-04\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.4222e-04 - val_loss: 3.9425e-04\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 8.4703e-04 - val_loss: 4.2234e-04\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.3238e-04 - val_loss: 3.9819e-04\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.4468e-04 - val_loss: 3.8647e-04\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.3410e-04 - val_loss: 3.8078e-04\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.2547e-04 - val_loss: 4.4611e-04\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.4595e-04 - val_loss: 3.8142e-04\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.1886e-04 - val_loss: 3.7720e-04\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.0812e-04 - val_loss: 3.9032e-04\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.0722e-04 - val_loss: 4.3095e-04\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.9912e-04 - val_loss: 3.7241e-04\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.9447e-04 - val_loss: 3.9309e-04\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.9203e-04 - val_loss: 3.7103e-04\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.8994e-04 - val_loss: 3.6699e-04\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.9034e-04 - val_loss: 3.6571e-04\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.8685e-04 - val_loss: 3.7677e-04\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.7274e-04 - val_loss: 3.7122e-04\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.8661e-04 - val_loss: 3.6672e-04\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.6054e-04 - val_loss: 3.6165e-04\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.6295e-04 - val_loss: 3.7868e-04\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6120e-04 - val_loss: 4.1945e-04\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.5630e-04 - val_loss: 3.5836e-04\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.4320e-04 - val_loss: 3.5444e-04\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.3603e-04 - val_loss: 3.5646e-04\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.4552e-04 - val_loss: 3.5800e-04\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.3040e-04 - val_loss: 3.8803e-04\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.2803e-04 - val_loss: 3.5028e-04\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.2380e-04 - val_loss: 3.4799e-04\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.1725e-04 - val_loss: 3.4622e-04\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.2606e-04 - val_loss: 3.4308e-04\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.0940e-04 - val_loss: 3.4233e-04\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.0429e-04 - val_loss: 3.4153e-04\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.0573e-04 - val_loss: 3.4526e-04\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.0244e-04 - val_loss: 3.3965e-04\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.0834e-04 - val_loss: 3.3754e-04\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.8940e-04 - val_loss: 3.3660e-04\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.8442e-04 - val_loss: 3.3541e-04\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.8902e-04 - val_loss: 3.4308e-04\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.7628e-04 - val_loss: 3.3825e-04\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.7855e-04 - val_loss: 3.3239e-04\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.7190e-04 - val_loss: 3.3135e-04\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.7404e-04 - val_loss: 3.3088e-04\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.7171e-04 - val_loss: 3.4224e-04\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.5986e-04 - val_loss: 3.5688e-04\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.6470e-04 - val_loss: 3.2743e-04\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.5319e-04 - val_loss: 3.4104e-04\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.5023e-04 - val_loss: 3.4471e-04\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.6056e-04 - val_loss: 3.2607e-04\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.5348e-04 - val_loss: 3.4202e-04\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.4383e-04 - val_loss: 3.2301e-04\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.4389e-04 - val_loss: 3.2265e-04\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.3837e-04 - val_loss: 3.2297e-04\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.3402e-04 - val_loss: 3.2054e-04\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.2897e-04 - val_loss: 3.2763e-04\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.3590e-04 - val_loss: 3.3005e-04\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.2517e-04 - val_loss: 3.2213e-04\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.2186e-04 - val_loss: 3.2081e-04\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.2306e-04 - val_loss: 3.3703e-04\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.2777e-04 - val_loss: 3.4501e-04\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.2154e-04 - val_loss: 3.1687e-04\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.1031e-04 - val_loss: 3.1665e-04\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.1571e-04 - val_loss: 3.1514e-04\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.1067e-04 - val_loss: 3.1997e-04\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.1077e-04 - val_loss: 3.2392e-04\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.0770e-04 - val_loss: 3.1374e-04\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.0698e-04 - val_loss: 3.1432e-04\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.0186e-04 - val_loss: 3.1320e-04\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.0560e-04 - val_loss: 3.2504e-04\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.1071e-04 - val_loss: 3.3209e-04\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.9929e-04 - val_loss: 3.1824e-04\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.1556e-04 - val_loss: 3.1156e-04\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.0123e-04 - val_loss: 3.2521e-04\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.9957e-04 - val_loss: 3.2465e-04\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.8987e-04 - val_loss: 3.2341e-04\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 5ms/step - loss: 5.9455e-04 - val_loss: 3.2519e-04\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.9155e-04 - val_loss: 3.1473e-04\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.9222e-04 - val_loss: 3.6180e-04\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.9544e-04 - val_loss: 3.0969e-04\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.8307e-04 - val_loss: 3.1296e-04\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.8043e-04 - val_loss: 3.0897e-04\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.8440e-04 - val_loss: 3.0964e-04\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.9110e-04 - val_loss: 3.1610e-04\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.9318e-04 - val_loss: 3.1026e-04\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.7686e-04 - val_loss: 3.0754e-04\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.8801e-04 - val_loss: 3.3890e-04\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.7645e-04 - val_loss: 3.0683e-04\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.7259e-04 - val_loss: 3.1733e-04\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.7251e-04 - val_loss: 3.1316e-04\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.7013e-04 - val_loss: 3.3191e-04\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.7366e-04 - val_loss: 3.1451e-04\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.8212e-04 - val_loss: 3.1030e-04\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.7655e-04 - val_loss: 3.0393e-04\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.7593e-04 - val_loss: 3.0423e-04\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.7190e-04 - val_loss: 3.0866e-04\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.6659e-04 - val_loss: 3.0422e-04\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.6774e-04 - val_loss: 3.1132e-04\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.6916e-04 - val_loss: 3.0158e-04\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.6186e-04 - val_loss: 3.0442e-04\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.6128e-04 - val_loss: 3.1070e-04\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.6641e-04 - val_loss: 3.4309e-04\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.6661e-04 - val_loss: 3.0586e-04\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.6122e-04 - val_loss: 3.0346e-04\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.7205e-04 - val_loss: 3.1845e-04\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.6670e-04 - val_loss: 3.0136e-04\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.7456e-04 - val_loss: 3.0731e-04\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.5760e-04 - val_loss: 3.0031e-04\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.5843e-04 - val_loss: 3.1270e-04\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.5611e-04 - val_loss: 2.9835e-04\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.5089e-04 - val_loss: 3.1534e-04\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.5022e-04 - val_loss: 2.9895e-04\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.5458e-04 - val_loss: 3.0452e-04\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.5256e-04 - val_loss: 2.9734e-04\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.5466e-04 - val_loss: 2.9566e-04\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.5286e-04 - val_loss: 3.0114e-04\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.8399e-04 - val_loss: 2.9874e-04\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.4715e-04 - val_loss: 3.2241e-04\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.4599e-04 - val_loss: 2.9609e-04\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.4511e-04 - val_loss: 2.9338e-04\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.4442e-04 - val_loss: 2.9329e-04\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.4513e-04 - val_loss: 2.9528e-04\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.4507e-04 - val_loss: 3.4126e-04\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.4292e-04 - val_loss: 2.9291e-04\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.5755e-04 - val_loss: 2.9219e-04\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.4103e-04 - val_loss: 2.9355e-04\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.3619e-04 - val_loss: 2.9128e-04\n",
      "Thời gian huấn luyện:  38.6162805557251\n",
      "Model: \"sequential_118\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_29 (LSTM)              (None, 5, 103)            43260     \n",
      "                                                                 \n",
      " flatten_118 (Flatten)       (None, 515)               0         \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 1)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,776\n",
      "Trainable params: 43,776\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 2s 13ms/step - loss: 0.0199 - val_loss: 7.6688e-04\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 4.5365e-04\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 4.1811e-04\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 4.2341e-04\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 4.3494e-04\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 4.4062e-04\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 4.4095e-04\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.9903e-04 - val_loss: 4.5872e-04\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.9137e-04 - val_loss: 4.5974e-04\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8867e-04 - val_loss: 4.6823e-04\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.9615e-04 - val_loss: 4.3345e-04\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.7358e-04 - val_loss: 4.3967e-04\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.7813e-04 - val_loss: 4.4778e-04\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.5711e-04 - val_loss: 4.3896e-04\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.5707e-04 - val_loss: 4.2686e-04\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.5155e-04 - val_loss: 4.2330e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.4158e-04 - val_loss: 4.3747e-04\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.3720e-04 - val_loss: 4.1909e-04\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.2993e-04 - val_loss: 4.1702e-04\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.2944e-04 - val_loss: 4.3130e-04\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.1989e-04 - val_loss: 4.1355e-04\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.1527e-04 - val_loss: 4.2682e-04\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.1205e-04 - val_loss: 4.0893e-04\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.0128e-04 - val_loss: 4.3811e-04\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.0039e-04 - val_loss: 4.0540e-04\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.9785e-04 - val_loss: 4.0633e-04\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.8450e-04 - val_loss: 4.0495e-04\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.7847e-04 - val_loss: 3.9696e-04\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.7400e-04 - val_loss: 3.9589e-04\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.6713e-04 - val_loss: 3.9265e-04\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.6411e-04 - val_loss: 3.9076e-04\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.5390e-04 - val_loss: 4.0259e-04\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.5086e-04 - val_loss: 4.0969e-04\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.4774e-04 - val_loss: 3.8945e-04\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.3624e-04 - val_loss: 3.8052e-04\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.3676e-04 - val_loss: 3.8547e-04\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.2425e-04 - val_loss: 3.7747e-04\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.1944e-04 - val_loss: 3.7477e-04\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.1205e-04 - val_loss: 3.7479e-04\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.0778e-04 - val_loss: 3.7975e-04\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.9823e-04 - val_loss: 3.6674e-04\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.9152e-04 - val_loss: 3.6535e-04\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.9093e-04 - val_loss: 3.8296e-04\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.8466e-04 - val_loss: 3.7341e-04\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.7113e-04 - val_loss: 3.5977e-04\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.7478e-04 - val_loss: 3.8003e-04\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.6168e-04 - val_loss: 3.6889e-04\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.5492e-04 - val_loss: 3.6502e-04\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.5138e-04 - val_loss: 3.5456e-04\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.4479e-04 - val_loss: 3.5796e-04\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.3466e-04 - val_loss: 3.4325e-04\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.2887e-04 - val_loss: 3.3992e-04\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.2295e-04 - val_loss: 3.3942e-04\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.1623e-04 - val_loss: 3.3614e-04\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.0920e-04 - val_loss: 3.3490e-04\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.0687e-04 - val_loss: 3.4046e-04\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.9790e-04 - val_loss: 3.3571e-04\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.8993e-04 - val_loss: 3.2808e-04\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.8401e-04 - val_loss: 3.3476e-04\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.7876e-04 - val_loss: 3.4305e-04\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.8026e-04 - val_loss: 3.2742e-04\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.7464e-04 - val_loss: 3.2012e-04\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.7267e-04 - val_loss: 3.5364e-04\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.5250e-04 - val_loss: 3.1672e-04\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.4854e-04 - val_loss: 3.1622e-04\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.4254e-04 - val_loss: 3.1953e-04\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.4366e-04 - val_loss: 3.2987e-04\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.2774e-04 - val_loss: 3.1383e-04\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.2760e-04 - val_loss: 3.0634e-04\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.2193e-04 - val_loss: 3.1223e-04\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.2162e-04 - val_loss: 3.0597e-04\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.1068e-04 - val_loss: 3.0093e-04\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.0521e-04 - val_loss: 3.1575e-04\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.1406e-04 - val_loss: 2.9822e-04\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.9376e-04 - val_loss: 3.1041e-04\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.9212e-04 - val_loss: 2.9788e-04\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.8942e-04 - val_loss: 2.9555e-04\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.8601e-04 - val_loss: 2.9780e-04\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.7839e-04 - val_loss: 2.9117e-04\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.8319e-04 - val_loss: 2.9673e-04\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.8399e-04 - val_loss: 2.9113e-04\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.6660e-04 - val_loss: 2.9057e-04\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.6578e-04 - val_loss: 2.9885e-04\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.5937e-04 - val_loss: 2.9430e-04\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.6816e-04 - val_loss: 2.8668e-04\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.5779e-04 - val_loss: 2.8429e-04\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.4953e-04 - val_loss: 2.9699e-04\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.5020e-04 - val_loss: 2.8582e-04\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.5341e-04 - val_loss: 2.8190e-04\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.4754e-04 - val_loss: 2.8412e-04\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.3858e-04 - val_loss: 2.8781e-04\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.3577e-04 - val_loss: 2.8870e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.3465e-04 - val_loss: 2.9218e-04\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.3511e-04 - val_loss: 2.9289e-04\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.3998e-04 - val_loss: 2.7732e-04\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.4099e-04 - val_loss: 3.0000e-04\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.4016e-04 - val_loss: 2.7628e-04\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.2275e-04 - val_loss: 2.7626e-04\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.3208e-04 - val_loss: 2.8853e-04\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.2295e-04 - val_loss: 2.7796e-04\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.2544e-04 - val_loss: 2.7882e-04\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.2674e-04 - val_loss: 2.8062e-04\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.1974e-04 - val_loss: 2.8559e-04\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.2393e-04 - val_loss: 2.7497e-04\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.1802e-04 - val_loss: 2.7403e-04\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.0964e-04 - val_loss: 2.7960e-04\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.1741e-04 - val_loss: 2.7198e-04\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.0879e-04 - val_loss: 2.7582e-04\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.1385e-04 - val_loss: 2.8724e-04\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.0910e-04 - val_loss: 2.7892e-04\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.0521e-04 - val_loss: 2.7601e-04\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.0392e-04 - val_loss: 2.7180e-04\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.0189e-04 - val_loss: 2.7001e-04\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.0107e-04 - val_loss: 2.8830e-04\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.0163e-04 - val_loss: 2.7000e-04\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.0045e-04 - val_loss: 2.7043e-04\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.9855e-04 - val_loss: 2.6892e-04\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.0293e-04 - val_loss: 2.6785e-04\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.9695e-04 - val_loss: 2.8425e-04\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.0269e-04 - val_loss: 2.6648e-04\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.9781e-04 - val_loss: 2.8259e-04\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.0743e-04 - val_loss: 2.8990e-04\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.9897e-04 - val_loss: 2.7577e-04\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.9774e-04 - val_loss: 2.7183e-04\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.9371e-04 - val_loss: 2.6459e-04\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.9540e-04 - val_loss: 2.7731e-04\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8399e-04 - val_loss: 2.7976e-04\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8366e-04 - val_loss: 2.6302e-04\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.7959e-04 - val_loss: 2.6885e-04\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.8654e-04 - val_loss: 2.9098e-04\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.8303e-04 - val_loss: 2.6230e-04\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.8265e-04 - val_loss: 2.6226e-04\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.8241e-04 - val_loss: 2.6021e-04\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.7907e-04 - val_loss: 2.5920e-04\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8170e-04 - val_loss: 2.6105e-04\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.7688e-04 - val_loss: 2.6444e-04\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.7749e-04 - val_loss: 2.7194e-04\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.9290e-04 - val_loss: 2.6998e-04\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.7771e-04 - val_loss: 2.5701e-04\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.7143e-04 - val_loss: 2.6234e-04\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.7685e-04 - val_loss: 2.5751e-04\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.7749e-04 - val_loss: 2.8074e-04\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.8299e-04 - val_loss: 2.6086e-04\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.6804e-04 - val_loss: 2.5541e-04\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.6470e-04 - val_loss: 2.7335e-04\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.6723e-04 - val_loss: 2.5414e-04\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.6728e-04 - val_loss: 2.6392e-04\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.7254e-04 - val_loss: 2.6279e-04\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.7505e-04 - val_loss: 2.6534e-04\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.6767e-04 - val_loss: 2.5259e-04\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.6090e-04 - val_loss: 2.6778e-04\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6440e-04 - val_loss: 2.5100e-04\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6060e-04 - val_loss: 2.5115e-04\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.6046e-04 - val_loss: 2.5034e-04\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6320e-04 - val_loss: 2.5490e-04\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6754e-04 - val_loss: 2.5253e-04\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.5880e-04 - val_loss: 2.5284e-04\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.5617e-04 - val_loss: 2.5146e-04\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.5315e-04 - val_loss: 2.4904e-04\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.5905e-04 - val_loss: 2.5121e-04\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.5770e-04 - val_loss: 2.4836e-04\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.5341e-04 - val_loss: 2.4707e-04\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4985e-04 - val_loss: 2.5095e-04\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.5898e-04 - val_loss: 2.4837e-04\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4940e-04 - val_loss: 2.4594e-04\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4982e-04 - val_loss: 2.4672e-04\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4654e-04 - val_loss: 2.4534e-04\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 5ms/step - loss: 4.5351e-04 - val_loss: 2.4591e-04\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6226e-04 - val_loss: 2.6014e-04\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4822e-04 - val_loss: 2.4449e-04\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4768e-04 - val_loss: 2.4595e-04\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.5109e-04 - val_loss: 2.4817e-04\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4158e-04 - val_loss: 2.4906e-04\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4691e-04 - val_loss: 2.4512e-04\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.7014e-04 - val_loss: 2.5090e-04\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.4402e-04 - val_loss: 2.6239e-04\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4529e-04 - val_loss: 2.4614e-04\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4759e-04 - val_loss: 2.4263e-04\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.5121e-04 - val_loss: 2.8403e-04\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4441e-04 - val_loss: 2.4577e-04\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4395e-04 - val_loss: 2.5399e-04\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4203e-04 - val_loss: 2.4061e-04\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3703e-04 - val_loss: 2.4865e-04\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4399e-04 - val_loss: 2.4811e-04\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3623e-04 - val_loss: 2.4013e-04\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3788e-04 - val_loss: 2.4973e-04\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4649e-04 - val_loss: 2.5271e-04\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4120e-04 - val_loss: 2.4201e-04\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3400e-04 - val_loss: 2.3899e-04\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3447e-04 - val_loss: 2.3944e-04\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3308e-04 - val_loss: 2.3920e-04\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3764e-04 - val_loss: 2.5423e-04\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3879e-04 - val_loss: 2.4144e-04\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3327e-04 - val_loss: 2.5308e-04\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4038e-04 - val_loss: 2.4746e-04\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3443e-04 - val_loss: 2.5690e-04\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4041e-04 - val_loss: 2.3838e-04\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3145e-04 - val_loss: 2.3733e-04\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3405e-04 - val_loss: 2.4173e-04\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3246e-04 - val_loss: 2.4024e-04\n",
      "Thời gian huấn luyện:  35.74664878845215\n",
      "Model: \"sequential_119\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_29 (GRU)                (None, 5, 103)            32754     \n",
      "                                                                 \n",
      " flatten_119 (Flatten)       (None, 515)               0         \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 1)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,270\n",
      "Trainable params: 33,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 37/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 200/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Thời gian huấn luyện:  13.664875984191895\n",
      "Model: \"sequential_120\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_150 (Dense)           (None, 10, 96)            192       \n",
      "                                                                 \n",
      " flatten_120 (Flatten)       (None, 960)               0         \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,153\n",
      "Trainable params: 1,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 999us/step\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 1s 7ms/step - loss: 0.0033 - val_loss: 8.1322e-04\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 4.6016e-04\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 4.6894e-04\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 9.5113e-04 - val_loss: 3.9704e-04\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.6763e-04 - val_loss: 3.9784e-04\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.5452e-04 - val_loss: 3.6677e-04\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.5156e-04 - val_loss: 3.5523e-04\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.2158e-04 - val_loss: 3.4982e-04\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.3172e-04 - val_loss: 3.4550e-04\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.7126e-04 - val_loss: 4.5427e-04\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.9485e-04 - val_loss: 4.4559e-04\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.7905e-04 - val_loss: 3.5072e-04\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.6782e-04 - val_loss: 3.5101e-04\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.6641e-04 - val_loss: 3.5610e-04\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.4283e-04 - val_loss: 3.1532e-04\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.4523e-04 - val_loss: 3.1467e-04\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.2058e-04 - val_loss: 3.1456e-04\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.4420e-04 - val_loss: 3.0557e-04\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.0309e-04 - val_loss: 3.0598e-04\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.9468e-04 - val_loss: 4.2225e-04\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.9572e-04 - val_loss: 3.1835e-04\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.8556e-04 - val_loss: 3.9752e-04\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.7570e-04 - val_loss: 3.0062e-04\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.1557e-04 - val_loss: 4.0687e-04\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.9836e-04 - val_loss: 2.8845e-04\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.7906e-04 - val_loss: 3.0049e-04\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.4952e-04 - val_loss: 2.9182e-04\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.4108e-04 - val_loss: 2.8577e-04\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.5582e-04 - val_loss: 2.8813e-04\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.4182e-04 - val_loss: 3.2343e-04\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.5756e-04 - val_loss: 2.7845e-04\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.3639e-04 - val_loss: 2.9411e-04\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.2616e-04 - val_loss: 2.8346e-04\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.3187e-04 - val_loss: 2.8984e-04\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.2113e-04 - val_loss: 2.7988e-04\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.1343e-04 - val_loss: 2.8898e-04\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.1997e-04 - val_loss: 3.0052e-04\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.1894e-04 - val_loss: 2.6869e-04\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.1255e-04 - val_loss: 2.6738e-04\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0589e-04 - val_loss: 2.7032e-04\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.2426e-04 - val_loss: 2.6520e-04\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.1319e-04 - val_loss: 2.7208e-04\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0341e-04 - val_loss: 2.6633e-04\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9922e-04 - val_loss: 2.6663e-04\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0253e-04 - val_loss: 2.6655e-04\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9854e-04 - val_loss: 2.6176e-04\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9712e-04 - val_loss: 2.5880e-04\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8440e-04 - val_loss: 2.6006e-04\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0054e-04 - val_loss: 2.5810e-04\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8124e-04 - val_loss: 2.5985e-04\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7733e-04 - val_loss: 2.6313e-04\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8176e-04 - val_loss: 2.8288e-04\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0109e-04 - val_loss: 2.6088e-04\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8212e-04 - val_loss: 2.5671e-04\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7742e-04 - val_loss: 2.6253e-04\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8439e-04 - val_loss: 2.8610e-04\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9242e-04 - val_loss: 2.6614e-04\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8254e-04 - val_loss: 2.5517e-04\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7242e-04 - val_loss: 2.5001e-04\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8201e-04 - val_loss: 2.6859e-04\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6638e-04 - val_loss: 2.5464e-04\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6472e-04 - val_loss: 2.5140e-04\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6622e-04 - val_loss: 2.9625e-04\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8743e-04 - val_loss: 2.9071e-04\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.2178e-04 - val_loss: 2.6042e-04\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6240e-04 - val_loss: 2.9532e-04\n",
      "Epoch 67/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5321e-04 - val_loss: 2.4544e-04\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5760e-04 - val_loss: 2.9085e-04\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5560e-04 - val_loss: 2.4737e-04\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5119e-04 - val_loss: 2.5954e-04\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5438e-04 - val_loss: 2.5593e-04\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5600e-04 - val_loss: 2.7187e-04\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6223e-04 - val_loss: 2.5380e-04\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4666e-04 - val_loss: 2.4605e-04\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4588e-04 - val_loss: 2.4136e-04\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4146e-04 - val_loss: 2.4143e-04\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3878e-04 - val_loss: 2.6682e-04\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5951e-04 - val_loss: 3.1144e-04\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5440e-04 - val_loss: 2.4030e-04\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4169e-04 - val_loss: 2.5270e-04\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5596e-04 - val_loss: 2.4097e-04\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4839e-04 - val_loss: 2.6969e-04\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5905e-04 - val_loss: 2.3968e-04\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5397e-04 - val_loss: 2.6294e-04\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4280e-04 - val_loss: 2.3929e-04\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5228e-04 - val_loss: 2.5819e-04\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.2581e-04 - val_loss: 2.9013e-04\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3921e-04 - val_loss: 2.5031e-04\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3115e-04 - val_loss: 2.5592e-04\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3202e-04 - val_loss: 3.0109e-04\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5544e-04 - val_loss: 2.3573e-04\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3340e-04 - val_loss: 2.3719e-04\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3740e-04 - val_loss: 2.3558e-04\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2762e-04 - val_loss: 2.3480e-04\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3347e-04 - val_loss: 2.5790e-04\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3597e-04 - val_loss: 2.7117e-04\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4870e-04 - val_loss: 2.4065e-04\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3120e-04 - val_loss: 2.3395e-04\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4162e-04 - val_loss: 2.4388e-04\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2796e-04 - val_loss: 2.3467e-04\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4338e-04 - val_loss: 2.5550e-04\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3139e-04 - val_loss: 2.3555e-04\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4050e-04 - val_loss: 2.4208e-04\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3238e-04 - val_loss: 2.3866e-04\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2762e-04 - val_loss: 2.3274e-04\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3130e-04 - val_loss: 2.4937e-04\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3741e-04 - val_loss: 2.4063e-04\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3161e-04 - val_loss: 2.3092e-04\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1999e-04 - val_loss: 2.4121e-04\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2348e-04 - val_loss: 2.3418e-04\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2148e-04 - val_loss: 2.6067e-04\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3112e-04 - val_loss: 2.7682e-04\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2870e-04 - val_loss: 2.5686e-04\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1505e-04 - val_loss: 2.3318e-04\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1917e-04 - val_loss: 2.4672e-04\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1626e-04 - val_loss: 2.3844e-04\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3899e-04 - val_loss: 2.3038e-04\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1927e-04 - val_loss: 2.3120e-04\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2009e-04 - val_loss: 2.4133e-04\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1852e-04 - val_loss: 2.4075e-04\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1462e-04 - val_loss: 2.5186e-04\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1689e-04 - val_loss: 2.4960e-04\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3197e-04 - val_loss: 2.5415e-04\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2186e-04 - val_loss: 2.3038e-04\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1360e-04 - val_loss: 2.2915e-04\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1916e-04 - val_loss: 2.4013e-04\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8557e-04 - val_loss: 2.3518e-04\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2070e-04 - val_loss: 2.2871e-04\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1379e-04 - val_loss: 2.2948e-04\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1469e-04 - val_loss: 2.8118e-04\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3479e-04 - val_loss: 2.7393e-04\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1968e-04 - val_loss: 3.1338e-04\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3068e-04 - val_loss: 2.4444e-04\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1426e-04 - val_loss: 2.3817e-04\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2489e-04 - val_loss: 2.8217e-04\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1962e-04 - val_loss: 2.3599e-04\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1078e-04 - val_loss: 2.5007e-04\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1751e-04 - val_loss: 2.4139e-04\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2390e-04 - val_loss: 2.4371e-04\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1069e-04 - val_loss: 2.2730e-04\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1639e-04 - val_loss: 2.4067e-04\n",
      "Epoch 142/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1211e-04 - val_loss: 2.6713e-04\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2033e-04 - val_loss: 2.3410e-04\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1209e-04 - val_loss: 2.3121e-04\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2712e-04 - val_loss: 2.2953e-04\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1074e-04 - val_loss: 2.9482e-04\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2046e-04 - val_loss: 2.2955e-04\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1249e-04 - val_loss: 2.4711e-04\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0508e-04 - val_loss: 2.3006e-04\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1534e-04 - val_loss: 2.8253e-04\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2418e-04 - val_loss: 2.3459e-04\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0636e-04 - val_loss: 2.5283e-04\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1520e-04 - val_loss: 2.4669e-04\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0778e-04 - val_loss: 2.3066e-04\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1298e-04 - val_loss: 2.3945e-04\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0978e-04 - val_loss: 2.2785e-04\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0494e-04 - val_loss: 2.2832e-04\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1161e-04 - val_loss: 2.3257e-04\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3478e-04 - val_loss: 4.1471e-04\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3000e-04 - val_loss: 2.2738e-04\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2762e-04 - val_loss: 2.4153e-04\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0285e-04 - val_loss: 2.2881e-04\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0576e-04 - val_loss: 2.2974e-04\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3516e-04 - val_loss: 2.2740e-04\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2205e-04 - val_loss: 3.0251e-04\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1575e-04 - val_loss: 2.5020e-04\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0609e-04 - val_loss: 2.3966e-04\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0572e-04 - val_loss: 2.2680e-04\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0618e-04 - val_loss: 2.4626e-04\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2169e-04 - val_loss: 2.2860e-04\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1010e-04 - val_loss: 2.6107e-04\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1561e-04 - val_loss: 2.4861e-04\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0383e-04 - val_loss: 2.3321e-04\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1053e-04 - val_loss: 2.3144e-04\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1395e-04 - val_loss: 2.4215e-04\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3146e-04 - val_loss: 2.5098e-04\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0607e-04 - val_loss: 2.4980e-04\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0574e-04 - val_loss: 2.3748e-04\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0444e-04 - val_loss: 2.3362e-04\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3359e-04 - val_loss: 2.6103e-04\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2068e-04 - val_loss: 2.7993e-04\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1658e-04 - val_loss: 2.2821e-04\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.4048e-04 - val_loss: 2.3039e-04\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.2845e-04 - val_loss: 2.6619e-04\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1419e-04 - val_loss: 2.4407e-04\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3346e-04 - val_loss: 3.6033e-04\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1955e-04 - val_loss: 2.7705e-04\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1351e-04 - val_loss: 2.2710e-04\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0620e-04 - val_loss: 2.3048e-04\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1702e-04 - val_loss: 2.2998e-04\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1101e-04 - val_loss: 2.4255e-04\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0892e-04 - val_loss: 2.2769e-04\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0839e-04 - val_loss: 2.5261e-04\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0523e-04 - val_loss: 2.3547e-04\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1081e-04 - val_loss: 2.2820e-04\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0801e-04 - val_loss: 2.3542e-04\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0853e-04 - val_loss: 2.4594e-04\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0726e-04 - val_loss: 2.2786e-04\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0824e-04 - val_loss: 2.3037e-04\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.0647e-04 - val_loss: 2.4657e-04\n",
      "Thời gian huấn luyện:  24.321216344833374\n",
      "Model: \"sequential_121\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_30 (SimpleRNN)   (None, 10, 103)           10815     \n",
      "                                                                 \n",
      " flatten_121 (Flatten)       (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,846\n",
      "Trainable params: 11,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 2s 16ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 91/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 172/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Thời gian huấn luyện:  54.23788261413574\n",
      "Model: \"sequential_122\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_30 (LSTM)              (None, 10, 103)           43260     \n",
      "                                                                 \n",
      " flatten_122 (Flatten)       (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,291\n",
      "Trainable params: 44,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 2s 15ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.1021\n",
      "Thời gian huấn luyện:  48.991272926330566\n",
      "Model: \"sequential_123\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_30 (GRU)                (None, 10, 103)           32754     \n",
      "                                                                 \n",
      " flatten_123 (Flatten)       (None, 1030)              0         \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 1)                 1031      \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Total params: 33,785\n",
      "Trainable params: 33,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0379 - val_loss: 0.0076\n",
      "Epoch 2/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0024\n",
      "Epoch 3/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 4/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 5/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 6/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 7/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 8/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 9/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 10/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 11/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 12/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 13/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 14/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 15/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 16/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 17/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 18/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 19/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 20/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 21/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 22/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 23/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 24/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 25/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 26/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 27/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 28/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 29/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 9.4716e-04\n",
      "Epoch 30/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 9.8144e-04\n",
      "Epoch 31/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 9.0573e-04\n",
      "Epoch 32/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 9.0678e-04\n",
      "Epoch 33/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 8.6672e-04\n",
      "Epoch 34/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 9.3045e-04\n",
      "Epoch 35/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.5996e-04\n",
      "Epoch 36/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.4355e-04\n",
      "Epoch 37/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 8.3507e-04\n",
      "Epoch 38/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.7610e-04\n",
      "Epoch 39/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.7101e-04\n",
      "Epoch 40/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.5580e-04\n",
      "Epoch 41/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.0431e-04\n",
      "Epoch 42/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.0082e-04\n",
      "Epoch 43/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.8776e-04\n",
      "Epoch 44/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.8670e-04\n",
      "Epoch 45/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.8038e-04\n",
      "Epoch 46/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.6866e-04\n",
      "Epoch 47/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.3458e-04\n",
      "Epoch 48/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.1915e-04\n",
      "Epoch 49/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.9548e-04\n",
      "Epoch 50/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.9837e-04\n",
      "Epoch 51/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.4534e-04\n",
      "Epoch 52/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.6525e-04\n",
      "Epoch 53/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.9712e-04\n",
      "Epoch 54/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.6084e-04\n",
      "Epoch 55/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.9100e-04 - val_loss: 5.6188e-04\n",
      "Epoch 56/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.7801e-04 - val_loss: 5.5723e-04\n",
      "Epoch 57/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.6984e-04 - val_loss: 5.5121e-04\n",
      "Epoch 58/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.5405e-04 - val_loss: 5.0623e-04\n",
      "Epoch 59/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.5468e-04 - val_loss: 4.9520e-04\n",
      "Epoch 60/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.3559e-04 - val_loss: 5.0543e-04\n",
      "Epoch 61/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.2915e-04 - val_loss: 5.6552e-04\n",
      "Epoch 62/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.1790e-04 - val_loss: 5.0117e-04\n",
      "Epoch 63/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.0907e-04 - val_loss: 4.8703e-04\n",
      "Epoch 64/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.9334e-04 - val_loss: 4.7612e-04\n",
      "Epoch 65/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.8550e-04 - val_loss: 4.6505e-04\n",
      "Epoch 66/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.7747e-04 - val_loss: 4.6903e-04\n",
      "Epoch 67/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.6780e-04 - val_loss: 4.6357e-04\n",
      "Epoch 68/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.5828e-04 - val_loss: 4.5437e-04\n",
      "Epoch 69/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.5696e-04 - val_loss: 4.4286e-04\n",
      "Epoch 70/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.4494e-04 - val_loss: 4.5074e-04\n",
      "Epoch 71/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.3967e-04 - val_loss: 4.8336e-04\n",
      "Epoch 72/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.3391e-04 - val_loss: 4.5741e-04\n",
      "Epoch 73/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.2595e-04 - val_loss: 4.2620e-04\n",
      "Epoch 74/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.1780e-04 - val_loss: 4.4007e-04\n",
      "Epoch 75/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.1437e-04 - val_loss: 4.3203e-04\n",
      "Epoch 76/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.0139e-04 - val_loss: 4.1048e-04\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step - loss: 8.0425e-04 - val_loss: 4.2406e-04\n",
      "Epoch 78/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.9297e-04 - val_loss: 4.0933e-04\n",
      "Epoch 79/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.9311e-04 - val_loss: 4.1009e-04\n",
      "Epoch 80/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.8793e-04 - val_loss: 4.0751e-04\n",
      "Epoch 81/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7552e-04 - val_loss: 3.9608e-04\n",
      "Epoch 82/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.8254e-04 - val_loss: 3.9671e-04\n",
      "Epoch 83/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7912e-04 - val_loss: 3.9714e-04\n",
      "Epoch 84/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6387e-04 - val_loss: 3.9647e-04\n",
      "Epoch 85/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5698e-04 - val_loss: 3.8995e-04\n",
      "Epoch 86/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5296e-04 - val_loss: 3.8253e-04\n",
      "Epoch 87/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5164e-04 - val_loss: 3.8149e-04\n",
      "Epoch 88/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.4716e-04 - val_loss: 3.7769e-04\n",
      "Epoch 89/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3806e-04 - val_loss: 3.8275e-04\n",
      "Epoch 90/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3701e-04 - val_loss: 3.7259e-04\n",
      "Epoch 91/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3658e-04 - val_loss: 3.9980e-04\n",
      "Epoch 92/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3244e-04 - val_loss: 3.8794e-04\n",
      "Epoch 93/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.2345e-04 - val_loss: 3.8051e-04\n",
      "Epoch 94/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.2135e-04 - val_loss: 4.1283e-04\n",
      "Epoch 95/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2160e-04 - val_loss: 3.7463e-04\n",
      "Epoch 96/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0840e-04 - val_loss: 3.6977e-04\n",
      "Epoch 97/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0699e-04 - val_loss: 3.8851e-04\n",
      "Epoch 98/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0248e-04 - val_loss: 3.7355e-04\n",
      "Epoch 99/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.9667e-04 - val_loss: 4.6286e-04\n",
      "Epoch 100/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0008e-04 - val_loss: 3.5631e-04\n",
      "Epoch 101/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.9173e-04 - val_loss: 3.5771e-04\n",
      "Epoch 102/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.9009e-04 - val_loss: 3.5474e-04\n",
      "Epoch 103/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.8811e-04 - val_loss: 3.4881e-04\n",
      "Epoch 104/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.8175e-04 - val_loss: 3.5091e-04\n",
      "Epoch 105/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.8042e-04 - val_loss: 3.8224e-04\n",
      "Epoch 106/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.7786e-04 - val_loss: 3.5543e-04\n",
      "Epoch 107/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.7046e-04 - val_loss: 3.4803e-04\n",
      "Epoch 108/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.6754e-04 - val_loss: 3.4719e-04\n",
      "Epoch 109/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.6033e-04 - val_loss: 3.4304e-04\n",
      "Epoch 110/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.5955e-04 - val_loss: 3.4159e-04\n",
      "Epoch 111/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.5530e-04 - val_loss: 3.5267e-04\n",
      "Epoch 112/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.5205e-04 - val_loss: 3.4737e-04\n",
      "Epoch 113/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.5189e-04 - val_loss: 3.4187e-04\n",
      "Epoch 114/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.4969e-04 - val_loss: 3.3379e-04\n",
      "Epoch 115/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.4537e-04 - val_loss: 3.3536e-04\n",
      "Epoch 116/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.4859e-04 - val_loss: 3.4559e-04\n",
      "Epoch 117/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.4554e-04 - val_loss: 3.3533e-04\n",
      "Epoch 118/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.3811e-04 - val_loss: 3.4031e-04\n",
      "Epoch 119/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.3189e-04 - val_loss: 3.3043e-04\n",
      "Epoch 120/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.3493e-04 - val_loss: 3.3546e-04\n",
      "Epoch 121/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.2656e-04 - val_loss: 3.2490e-04\n",
      "Epoch 122/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.2906e-04 - val_loss: 3.3585e-04\n",
      "Epoch 123/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.1875e-04 - val_loss: 3.3251e-04\n",
      "Epoch 124/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.2779e-04 - val_loss: 3.2347e-04\n",
      "Epoch 125/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.3252e-04 - val_loss: 3.6876e-04\n",
      "Epoch 126/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.2489e-04 - val_loss: 3.3849e-04\n",
      "Epoch 127/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.1178e-04 - val_loss: 3.2802e-04\n",
      "Epoch 128/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.0996e-04 - val_loss: 3.1802e-04\n",
      "Epoch 129/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.0745e-04 - val_loss: 3.5415e-04\n",
      "Epoch 130/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.0801e-04 - val_loss: 3.1623e-04\n",
      "Epoch 131/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.0258e-04 - val_loss: 3.1850e-04\n",
      "Epoch 132/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.0188e-04 - val_loss: 3.1373e-04\n",
      "Epoch 133/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.0640e-04 - val_loss: 3.2686e-04\n",
      "Epoch 134/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.9407e-04 - val_loss: 3.3409e-04\n",
      "Epoch 135/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.9795e-04 - val_loss: 3.1251e-04\n",
      "Epoch 136/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.9102e-04 - val_loss: 3.1378e-04\n",
      "Epoch 137/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.9852e-04 - val_loss: 3.5686e-04\n",
      "Epoch 138/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.9340e-04 - val_loss: 3.0880e-04\n",
      "Epoch 139/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.8859e-04 - val_loss: 3.2519e-04\n",
      "Epoch 140/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.8383e-04 - val_loss: 3.0937e-04\n",
      "Epoch 141/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.8201e-04 - val_loss: 3.0544e-04\n",
      "Epoch 142/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.7727e-04 - val_loss: 3.2078e-04\n",
      "Epoch 143/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.8064e-04 - val_loss: 3.0757e-04\n",
      "Epoch 144/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.7926e-04 - val_loss: 3.1351e-04\n",
      "Epoch 145/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.7526e-04 - val_loss: 3.0322e-04\n",
      "Epoch 146/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.7180e-04 - val_loss: 3.0638e-04\n",
      "Epoch 147/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.6894e-04 - val_loss: 3.2784e-04\n",
      "Epoch 148/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.7320e-04 - val_loss: 3.2344e-04\n",
      "Epoch 149/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.6557e-04 - val_loss: 3.0813e-04\n",
      "Epoch 150/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.6419e-04 - val_loss: 3.4149e-04\n",
      "Epoch 151/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.6339e-04 - val_loss: 2.9774e-04\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 3ms/step - loss: 5.6219e-04 - val_loss: 3.1907e-04\n",
      "Epoch 153/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.6801e-04 - val_loss: 3.2802e-04\n",
      "Epoch 154/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5784e-04 - val_loss: 2.9537e-04\n",
      "Epoch 155/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.6066e-04 - val_loss: 3.0218e-04\n",
      "Epoch 156/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5837e-04 - val_loss: 2.9756e-04\n",
      "Epoch 157/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5149e-04 - val_loss: 2.9617e-04\n",
      "Epoch 158/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5430e-04 - val_loss: 2.9372e-04\n",
      "Epoch 159/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5295e-04 - val_loss: 2.9381e-04\n",
      "Epoch 160/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5612e-04 - val_loss: 2.9559e-04\n",
      "Epoch 161/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.4956e-04 - val_loss: 3.0937e-04\n",
      "Epoch 162/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5709e-04 - val_loss: 2.9232e-04\n",
      "Epoch 163/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.4952e-04 - val_loss: 2.9213e-04\n",
      "Epoch 164/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.4438e-04 - val_loss: 2.9328e-04\n",
      "Epoch 165/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5377e-04 - val_loss: 2.9972e-04\n",
      "Epoch 166/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.4458e-04 - val_loss: 3.0939e-04\n",
      "Epoch 167/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3887e-04 - val_loss: 3.0858e-04\n",
      "Epoch 168/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3986e-04 - val_loss: 2.9392e-04\n",
      "Epoch 169/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3955e-04 - val_loss: 2.8704e-04\n",
      "Epoch 170/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3603e-04 - val_loss: 2.9156e-04\n",
      "Epoch 171/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3578e-04 - val_loss: 3.0442e-04\n",
      "Epoch 172/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3531e-04 - val_loss: 2.8501e-04\n",
      "Epoch 173/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.4560e-04 - val_loss: 2.8667e-04\n",
      "Epoch 174/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.4448e-04 - val_loss: 3.5661e-04\n",
      "Epoch 175/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.4516e-04 - val_loss: 2.8331e-04\n",
      "Epoch 176/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3791e-04 - val_loss: 3.0450e-04\n",
      "Epoch 177/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3358e-04 - val_loss: 2.8711e-04\n",
      "Epoch 178/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3122e-04 - val_loss: 2.8730e-04\n",
      "Epoch 179/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.2542e-04 - val_loss: 2.8475e-04\n",
      "Epoch 180/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.2702e-04 - val_loss: 2.9318e-04\n",
      "Epoch 181/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.2581e-04 - val_loss: 2.7987e-04\n",
      "Epoch 182/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3251e-04 - val_loss: 2.8059e-04\n",
      "Epoch 183/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.2704e-04 - val_loss: 3.0393e-04\n",
      "Epoch 184/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.2660e-04 - val_loss: 3.0064e-04\n",
      "Epoch 185/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.2418e-04 - val_loss: 2.8542e-04\n",
      "Epoch 186/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.2424e-04 - val_loss: 2.7991e-04\n",
      "Epoch 187/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.1812e-04 - val_loss: 2.8971e-04\n",
      "Epoch 188/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.2051e-04 - val_loss: 2.7724e-04\n",
      "Epoch 189/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.1449e-04 - val_loss: 2.9232e-04\n",
      "Epoch 190/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.1662e-04 - val_loss: 2.7763e-04\n",
      "Epoch 191/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.1636e-04 - val_loss: 2.7523e-04\n",
      "Epoch 192/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3516e-04 - val_loss: 3.1383e-04\n",
      "Epoch 193/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.1416e-04 - val_loss: 2.7789e-04\n",
      "Epoch 194/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.1088e-04 - val_loss: 2.7418e-04\n",
      "Epoch 195/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.1336e-04 - val_loss: 2.7342e-04\n",
      "Epoch 196/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.0918e-04 - val_loss: 2.7591e-04\n",
      "Epoch 197/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.0913e-04 - val_loss: 3.0824e-04\n",
      "Epoch 198/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.1693e-04 - val_loss: 3.0335e-04\n",
      "Epoch 199/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.1683e-04 - val_loss: 2.7423e-04\n",
      "Epoch 200/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.0766e-04 - val_loss: 2.7209e-04\n",
      "Thời gian huấn luyện:  13.985512733459473\n",
      "Model: \"sequential_124\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_155 (Dense)           (None, 20, 95)            190       \n",
      "                                                                 \n",
      " flatten_124 (Flatten)       (None, 1900)              0         \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 1)                 1901      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,091\n",
      "Trainable params: 2,091\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 1s 9ms/step - loss: 0.0077 - val_loss: 0.0012\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 7.3328e-04\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 6.2004e-04\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 5.7296e-04\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 6.9025e-04\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 5.9556e-04\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 4.9459e-04\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 6.4524e-04\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 4.8075e-04\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 4.7935e-04\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 4.5173e-04\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.9384e-04 - val_loss: 4.3862e-04\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.5531e-04 - val_loss: 5.0273e-04\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.5228e-04 - val_loss: 4.2618e-04\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.2825e-04 - val_loss: 4.2250e-04\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.0308e-04 - val_loss: 4.1914e-04\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.9526e-04 - val_loss: 4.2133e-04\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.6147e-04 - val_loss: 4.1191e-04\n",
      "Epoch 19/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 4ms/step - loss: 8.5019e-04 - val_loss: 4.2684e-04\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.7614e-04 - val_loss: 5.5524e-04\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.7318e-04 - val_loss: 4.8256e-04\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.2000e-04 - val_loss: 3.8433e-04\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.9996e-04 - val_loss: 3.8781e-04\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.9134e-04 - val_loss: 4.0465e-04\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.8928e-04 - val_loss: 3.7910e-04\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.7985e-04 - val_loss: 3.7481e-04\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.7340e-04 - val_loss: 4.7383e-04\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.6356e-04 - val_loss: 3.6541e-04\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.7834e-04 - val_loss: 3.7491e-04\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.4608e-04 - val_loss: 4.6168e-04\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.4826e-04 - val_loss: 3.9348e-04\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.6252e-04 - val_loss: 3.8821e-04\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.1314e-04 - val_loss: 3.9356e-04\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.2530e-04 - val_loss: 4.0516e-04\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.2122e-04 - val_loss: 3.4353e-04\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.5300e-04 - val_loss: 3.4433e-04\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.0179e-04 - val_loss: 3.3694e-04\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.8936e-04 - val_loss: 3.3456e-04\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.7728e-04 - val_loss: 3.8113e-04\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.1740e-04 - val_loss: 3.9886e-04\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.6671e-04 - val_loss: 4.3587e-04\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.7418e-04 - val_loss: 3.2618e-04\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.4875e-04 - val_loss: 3.2659e-04\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.4018e-04 - val_loss: 3.2255e-04\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.5064e-04 - val_loss: 3.2713e-04\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.4064e-04 - val_loss: 3.8638e-04\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.4915e-04 - val_loss: 3.4313e-04\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.4670e-04 - val_loss: 3.3800e-04\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.1546e-04 - val_loss: 3.1421e-04\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.1087e-04 - val_loss: 4.4935e-04\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.2995e-04 - val_loss: 3.1397e-04\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.0657e-04 - val_loss: 3.0875e-04\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.0500e-04 - val_loss: 3.4498e-04\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.1422e-04 - val_loss: 3.4202e-04\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.1993e-04 - val_loss: 3.0518e-04\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.9724e-04 - val_loss: 3.1382e-04\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.8899e-04 - val_loss: 2.9862e-04\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.7742e-04 - val_loss: 3.0446e-04\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.0003e-04 - val_loss: 3.0371e-04\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.8342e-04 - val_loss: 3.0477e-04\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.6544e-04 - val_loss: 2.9842e-04\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.8726e-04 - val_loss: 3.0734e-04\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.6613e-04 - val_loss: 3.5083e-04\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.7762e-04 - val_loss: 2.9054e-04\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.6312e-04 - val_loss: 3.1180e-04\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.6034e-04 - val_loss: 2.9092e-04\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.5812e-04 - val_loss: 3.5565e-04\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.6312e-04 - val_loss: 2.8557e-04\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.8725e-04 - val_loss: 2.9401e-04\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.8483e-04 - val_loss: 2.8284e-04\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.5735e-04 - val_loss: 2.9657e-04\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.5190e-04 - val_loss: 3.1208e-04\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.5443e-04 - val_loss: 3.0080e-04\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.2911e-04 - val_loss: 2.8960e-04\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.4679e-04 - val_loss: 3.7891e-04\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.4313e-04 - val_loss: 2.7920e-04\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.3021e-04 - val_loss: 2.9522e-04\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.2474e-04 - val_loss: 3.3334e-04\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.4897e-04 - val_loss: 2.7734e-04\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.2106e-04 - val_loss: 2.7322e-04\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.2140e-04 - val_loss: 2.9484e-04\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.2395e-04 - val_loss: 2.7252e-04\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.2269e-04 - val_loss: 2.7237e-04\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.2954e-04 - val_loss: 3.0321e-04\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.3906e-04 - val_loss: 2.9585e-04\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.0660e-04 - val_loss: 2.8015e-04\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.1982e-04 - val_loss: 2.8095e-04\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.0783e-04 - val_loss: 3.1207e-04\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.1532e-04 - val_loss: 3.8574e-04\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.1822e-04 - val_loss: 2.9577e-04\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.9576e-04 - val_loss: 2.7498e-04\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.0085e-04 - val_loss: 2.7732e-04\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.6311e-04 - val_loss: 2.6423e-04\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.7112e-04 - val_loss: 2.6727e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.9940e-04 - val_loss: 2.7123e-04\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8514e-04 - val_loss: 3.2585e-04\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.1584e-04 - val_loss: 3.4012e-04\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8775e-04 - val_loss: 2.6104e-04\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8081e-04 - val_loss: 3.1971e-04\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.9859e-04 - val_loss: 2.9908e-04\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.7994e-04 - val_loss: 3.3281e-04\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8381e-04 - val_loss: 2.8283e-04\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8821e-04 - val_loss: 2.8556e-04\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8618e-04 - val_loss: 2.5676e-04\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.7658e-04 - val_loss: 2.6695e-04\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.0761e-04 - val_loss: 2.6096e-04\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8199e-04 - val_loss: 3.6658e-04\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8513e-04 - val_loss: 2.5568e-04\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8327e-04 - val_loss: 2.7210e-04\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8293e-04 - val_loss: 3.3137e-04\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.7053e-04 - val_loss: 2.6769e-04\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6522e-04 - val_loss: 2.6877e-04\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.7493e-04 - val_loss: 2.7839e-04\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.0039e-04 - val_loss: 2.9548e-04\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.6717e-04 - val_loss: 2.5363e-04\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.5667e-04 - val_loss: 2.5239e-04\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6309e-04 - val_loss: 2.4904e-04\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.8343e-04 - val_loss: 2.6400e-04\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.7467e-04 - val_loss: 2.5018e-04\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.9891e-04 - val_loss: 2.5571e-04\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8121e-04 - val_loss: 2.5988e-04\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.5895e-04 - val_loss: 2.5758e-04\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.5203e-04 - val_loss: 2.7639e-04\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.9336e-04 - val_loss: 2.5159e-04\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.7357e-04 - val_loss: 2.5290e-04\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6466e-04 - val_loss: 2.9006e-04\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.6773e-04 - val_loss: 2.4585e-04\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.5232e-04 - val_loss: 2.4326e-04\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.5798e-04 - val_loss: 2.4527e-04\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.5002e-04 - val_loss: 2.4358e-04\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3986e-04 - val_loss: 2.4632e-04\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.4915e-04 - val_loss: 2.4567e-04\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.5772e-04 - val_loss: 2.9814e-04\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6673e-04 - val_loss: 2.4269e-04\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3627e-04 - val_loss: 2.7812e-04\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4397e-04 - val_loss: 2.4425e-04\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.4233e-04 - val_loss: 2.4008e-04\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3958e-04 - val_loss: 2.4518e-04\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3707e-04 - val_loss: 2.7809e-04\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3763e-04 - val_loss: 2.4094e-04\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4546e-04 - val_loss: 2.7484e-04\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3605e-04 - val_loss: 2.3858e-04\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6497e-04 - val_loss: 2.7451e-04\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.7456e-04 - val_loss: 3.1800e-04\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6154e-04 - val_loss: 2.7179e-04\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3717e-04 - val_loss: 2.4140e-04\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4810e-04 - val_loss: 2.3812e-04\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.4132e-04 - val_loss: 2.3698e-04\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3457e-04 - val_loss: 2.3624e-04\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3095e-04 - val_loss: 2.4550e-04\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4516e-04 - val_loss: 2.4570e-04\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.9275e-04 - val_loss: 3.0598e-04\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3613e-04 - val_loss: 2.5290e-04\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3347e-04 - val_loss: 2.3564e-04\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.2839e-04 - val_loss: 2.6324e-04\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2548e-04 - val_loss: 2.3653e-04\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.2993e-04 - val_loss: 2.3922e-04\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.2455e-04 - val_loss: 2.4447e-04\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.4771e-04 - val_loss: 2.6233e-04\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3565e-04 - val_loss: 2.4653e-04\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2486e-04 - val_loss: 2.3354e-04\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2277e-04 - val_loss: 2.4163e-04\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2596e-04 - val_loss: 2.6470e-04\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.5786e-04 - val_loss: 2.3947e-04\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.4630e-04 - val_loss: 2.6138e-04\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.2961e-04 - val_loss: 2.4197e-04\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3654e-04 - val_loss: 2.7039e-04\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.1746e-04 - val_loss: 2.3471e-04\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.2479e-04 - val_loss: 2.3634e-04\n",
      "Epoch 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 4ms/step - loss: 4.1915e-04 - val_loss: 2.3498e-04\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.1946e-04 - val_loss: 2.4505e-04\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.1576e-04 - val_loss: 2.8185e-04\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.2778e-04 - val_loss: 2.3760e-04\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.2047e-04 - val_loss: 2.3192e-04\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.1563e-04 - val_loss: 2.5983e-04\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4241e-04 - val_loss: 2.4157e-04\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2177e-04 - val_loss: 2.8062e-04\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.1614e-04 - val_loss: 2.3164e-04\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2510e-04 - val_loss: 2.8517e-04\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.1332e-04 - val_loss: 2.4381e-04\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3055e-04 - val_loss: 2.4498e-04\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2118e-04 - val_loss: 2.3065e-04\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.0911e-04 - val_loss: 2.3533e-04\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2062e-04 - val_loss: 2.3357e-04\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.2092e-04 - val_loss: 2.3678e-04\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.2699e-04 - val_loss: 2.5428e-04\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.1346e-04 - val_loss: 2.7571e-04\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.1487e-04 - val_loss: 2.3627e-04\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2642e-04 - val_loss: 2.3721e-04\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.1421e-04 - val_loss: 2.3017e-04\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.1168e-04 - val_loss: 2.3336e-04\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.0993e-04 - val_loss: 2.2928e-04\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.1167e-04 - val_loss: 2.3189e-04\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.0934e-04 - val_loss: 2.3036e-04\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.1268e-04 - val_loss: 2.2911e-04\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.1023e-04 - val_loss: 2.4671e-04\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.1957e-04 - val_loss: 2.7278e-04\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.1020e-04 - val_loss: 2.3599e-04\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2245e-04 - val_loss: 2.3005e-04\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2267e-04 - val_loss: 2.3355e-04\n",
      "Thời gian huấn luyện:  33.46095395088196\n",
      "Model: \"sequential_125\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_31 (SimpleRNN)   (None, 20, 102)           10608     \n",
      "                                                                 \n",
      " flatten_125 (Flatten)       (None, 2040)              0         \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 1)                 2041      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,649\n",
      "Trainable params: 12,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 3s 21ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 39/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Epoch 200/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0960 - val_loss: 0.1021\n",
      "Thời gian huấn luyện:  86.59562659263611\n",
      "Model: \"sequential_126\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_31 (LSTM)              (None, 20, 102)           42432     \n",
      "                                                                 \n",
      " flatten_126 (Flatten)       (None, 2040)              0         \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 1)                 2041      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,473\n",
      "Trainable params: 44,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 2s 19ms/step - loss: 0.0141 - val_loss: 8.1192e-04\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0025 - val_loss: 7.7496e-04\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 7.0279e-04\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 6.7558e-04\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 6.4694e-04\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 6.2589e-04\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 5.9679e-04\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 5.7616e-04\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 5.6063e-04\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 5.5616e-04\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 5.3111e-04\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 5.2699e-04\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 5.2343e-04\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 5.0562e-04\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 5.1407e-04\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 5.0255e-04\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 4.8134e-04\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 4.9182e-04\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 4.7806e-04\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 4.6442e-04\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 4.6935e-04\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 4.5146e-04\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 4.5577e-04\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 4.4505e-04\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 4.3501e-04\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 4.3521e-04\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 4.2541e-04\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 9.7978e-04 - val_loss: 4.2018e-04\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 9.6638e-04 - val_loss: 4.1710e-04\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 9.6528e-04 - val_loss: 4.1206e-04\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 9.3983e-04 - val_loss: 4.2002e-04\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 9.3146e-04 - val_loss: 4.0002e-04\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 9.0803e-04 - val_loss: 3.9728e-04\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 9.0641e-04 - val_loss: 3.9516e-04\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 8.9720e-04 - val_loss: 3.9486e-04\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.8014e-04 - val_loss: 3.8893e-04\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 8.6517e-04 - val_loss: 3.8538e-04\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.4816e-04 - val_loss: 3.8380e-04\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.4571e-04 - val_loss: 3.9302e-04\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.3526e-04 - val_loss: 3.7275e-04\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.2048e-04 - val_loss: 4.0180e-04\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.0609e-04 - val_loss: 3.6750e-04\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.9864e-04 - val_loss: 3.8806e-04\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.9875e-04 - val_loss: 3.6012e-04\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.9235e-04 - val_loss: 3.8826e-04\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 7.8283e-04 - val_loss: 3.5331e-04\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 7.6218e-04 - val_loss: 3.8124e-04\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.5370e-04 - val_loss: 3.5461e-04\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 7.5349e-04 - val_loss: 3.5312e-04\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 7.4563e-04 - val_loss: 3.4364e-04\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.3668e-04 - val_loss: 3.4520e-04\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.2963e-04 - val_loss: 3.4002e-04\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.1625e-04 - val_loss: 3.3846e-04\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.1744e-04 - val_loss: 3.3743e-04\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.1387e-04 - val_loss: 3.3860e-04\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.9946e-04 - val_loss: 3.3661e-04\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.9267e-04 - val_loss: 3.4983e-04\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 7.1483e-04 - val_loss: 3.2945e-04\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.7995e-04 - val_loss: 3.5855e-04\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 7.0170e-04 - val_loss: 3.9013e-04\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.9969e-04 - val_loss: 3.2568e-04\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.6271e-04 - val_loss: 3.2330e-04\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.7265e-04 - val_loss: 3.3241e-04\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.5350e-04 - val_loss: 3.2809e-04\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.5873e-04 - val_loss: 3.1897e-04\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.4345e-04 - val_loss: 3.1884e-04\n",
      "Epoch 67/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 10ms/step - loss: 6.5069e-04 - val_loss: 3.1823e-04\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.3286e-04 - val_loss: 3.2991e-04\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.6087e-04 - val_loss: 3.6004e-04\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.3317e-04 - val_loss: 3.2149e-04\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.2199e-04 - val_loss: 3.2676e-04\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.2847e-04 - val_loss: 3.1295e-04\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.2368e-04 - val_loss: 3.1023e-04\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.2246e-04 - val_loss: 3.1253e-04\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.0631e-04 - val_loss: 3.2125e-04\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.0913e-04 - val_loss: 3.2440e-04\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.2715e-04 - val_loss: 3.3373e-04\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.3150e-04 - val_loss: 3.5214e-04\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.0311e-04 - val_loss: 3.2297e-04\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.0023e-04 - val_loss: 3.1907e-04\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.1238e-04 - val_loss: 3.0553e-04\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.8851e-04 - val_loss: 3.1024e-04\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.8332e-04 - val_loss: 3.0148e-04\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.8006e-04 - val_loss: 3.0336e-04\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.9136e-04 - val_loss: 3.0050e-04\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.0171e-04 - val_loss: 2.9711e-04\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.7912e-04 - val_loss: 2.9631e-04\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.8794e-04 - val_loss: 2.9695e-04\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.6760e-04 - val_loss: 3.0884e-04\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.6371e-04 - val_loss: 2.9282e-04\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.6556e-04 - val_loss: 2.9401e-04\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.6818e-04 - val_loss: 3.3533e-04\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.7837e-04 - val_loss: 2.9487e-04\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.5952e-04 - val_loss: 2.9018e-04\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.6380e-04 - val_loss: 2.9259e-04\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.5795e-04 - val_loss: 3.2405e-04\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.5473e-04 - val_loss: 3.3754e-04\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.6575e-04 - val_loss: 2.8761e-04\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.4420e-04 - val_loss: 2.9738e-04\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.5350e-04 - val_loss: 2.8330e-04\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.3847e-04 - val_loss: 2.8301e-04\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.3967e-04 - val_loss: 2.8151e-04\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.4630e-04 - val_loss: 3.0348e-04\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.4176e-04 - val_loss: 3.3315e-04\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.2772e-04 - val_loss: 2.8072e-04\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.2890e-04 - val_loss: 2.7888e-04\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.2686e-04 - val_loss: 2.8052e-04\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.2490e-04 - val_loss: 3.5746e-04\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.5387e-04 - val_loss: 2.8673e-04\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.3305e-04 - val_loss: 2.7521e-04\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.2004e-04 - val_loss: 2.7696e-04\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.1816e-04 - val_loss: 2.9214e-04\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.3962e-04 - val_loss: 2.7402e-04\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.1858e-04 - val_loss: 2.7421e-04\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.2182e-04 - val_loss: 2.7517e-04\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.0804e-04 - val_loss: 2.7059e-04\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.1053e-04 - val_loss: 2.7975e-04\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.1542e-04 - val_loss: 2.7918e-04\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.0175e-04 - val_loss: 2.6862e-04\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.1078e-04 - val_loss: 2.7836e-04\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.9728e-04 - val_loss: 2.6995e-04\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.9742e-04 - val_loss: 2.7308e-04\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.0504e-04 - val_loss: 2.9278e-04\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.0709e-04 - val_loss: 2.8100e-04\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.0228e-04 - val_loss: 2.8127e-04\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.9034e-04 - val_loss: 2.6936e-04\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.9428e-04 - val_loss: 2.6717e-04\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.9648e-04 - val_loss: 2.7928e-04\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.9460e-04 - val_loss: 2.7667e-04\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.0848e-04 - val_loss: 2.7027e-04\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.8725e-04 - val_loss: 2.5864e-04\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.8115e-04 - val_loss: 2.6580e-04\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.8498e-04 - val_loss: 2.6320e-04\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.8090e-04 - val_loss: 2.6043e-04\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.7958e-04 - val_loss: 2.5857e-04\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.7415e-04 - val_loss: 2.6659e-04\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.7795e-04 - val_loss: 2.5695e-04\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.9264e-04 - val_loss: 2.5456e-04\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.7505e-04 - val_loss: 2.5808e-04\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.7943e-04 - val_loss: 2.6728e-04\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.8430e-04 - val_loss: 2.5314e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.6963e-04 - val_loss: 2.5390e-04\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.6858e-04 - val_loss: 2.7475e-04\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.7219e-04 - val_loss: 2.6404e-04\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.6247e-04 - val_loss: 2.5875e-04\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.7364e-04 - val_loss: 2.5456e-04\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.6171e-04 - val_loss: 2.6812e-04\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.6236e-04 - val_loss: 2.4902e-04\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.6615e-04 - val_loss: 2.5474e-04\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.5858e-04 - val_loss: 2.5002e-04\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.5419e-04 - val_loss: 2.4942e-04\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.6517e-04 - val_loss: 2.6094e-04\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.7301e-04 - val_loss: 2.8767e-04\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.5842e-04 - val_loss: 2.4665e-04\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.5543e-04 - val_loss: 2.8389e-04\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.5962e-04 - val_loss: 2.4464e-04\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.6524e-04 - val_loss: 2.5031e-04\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.5414e-04 - val_loss: 2.7204e-04\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.6488e-04 - val_loss: 2.5995e-04\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.6327e-04 - val_loss: 2.8529e-04\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.6653e-04 - val_loss: 2.5946e-04\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.5339e-04 - val_loss: 2.4425e-04\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.4839e-04 - val_loss: 2.5025e-04\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.4709e-04 - val_loss: 2.4466e-04\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.4076e-04 - val_loss: 2.7479e-04\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.4227e-04 - val_loss: 2.8144e-04\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.5887e-04 - val_loss: 2.4157e-04\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.4505e-04 - val_loss: 2.4134e-04\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.4266e-04 - val_loss: 2.4371e-04\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.3922e-04 - val_loss: 2.3891e-04\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.4404e-04 - val_loss: 2.7573e-04\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.4739e-04 - val_loss: 2.4153e-04\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.4192e-04 - val_loss: 2.4177e-04\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.3914e-04 - val_loss: 2.8225e-04\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.4792e-04 - val_loss: 2.5548e-04\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.3578e-04 - val_loss: 2.3684e-04\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.3739e-04 - val_loss: 2.9012e-04\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.6870e-04 - val_loss: 2.3624e-04\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.3365e-04 - val_loss: 2.4454e-04\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 4.3674e-04 - val_loss: 2.3636e-04\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.3122e-04 - val_loss: 2.3543e-04\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.3774e-04 - val_loss: 2.5790e-04\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.3322e-04 - val_loss: 2.3445e-04\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.3162e-04 - val_loss: 2.3649e-04\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.3440e-04 - val_loss: 2.4989e-04\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.5501e-04 - val_loss: 2.3597e-04\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.4561e-04 - val_loss: 2.4373e-04\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.3386e-04 - val_loss: 2.4222e-04\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.2997e-04 - val_loss: 2.4754e-04\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.3536e-04 - val_loss: 2.8935e-04\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.3167e-04 - val_loss: 2.3279e-04\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.2694e-04 - val_loss: 2.3329e-04\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.3068e-04 - val_loss: 2.3155e-04\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.2769e-04 - val_loss: 2.3221e-04\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.3378e-04 - val_loss: 2.3454e-04\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.2000e-04 - val_loss: 2.3147e-04\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.2857e-04 - val_loss: 2.4536e-04\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.3371e-04 - val_loss: 2.3810e-04\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 4.2481e-04 - val_loss: 2.5579e-04\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 4.1954e-04 - val_loss: 2.5008e-04\n",
      "Thời gian huấn luyện:  77.74484705924988\n",
      "Model: \"sequential_127\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_31 (GRU)                (None, 20, 102)           32130     \n",
      "                                                                 \n",
      " flatten_127 (Flatten)       (None, 2040)              0         \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 1)                 2041      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,171\n",
      "Trainable params: 34,171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 1s 3ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Epoch 1/200\n",
      "31/31 [==============================] - 1s 6ms/step - loss: 0.0280 - val_loss: 0.0062\n",
      "Epoch 2/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 3/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 4/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 5/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 6/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 7/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 8/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 9/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 10/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 11/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 12/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 13/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 14/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 15/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 16/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 17/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 18/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 19/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 20/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 21/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 22/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 23/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 24/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 25/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 26/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 27/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 28/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 29/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 30/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 31/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 9.4315e-04\n",
      "Epoch 32/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 9.7521e-04\n",
      "Epoch 33/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 9.3461e-04\n",
      "Epoch 34/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.5419e-04\n",
      "Epoch 35/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.9989e-04\n",
      "Epoch 36/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.8482e-04\n",
      "Epoch 37/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.9967e-04\n",
      "Epoch 38/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.7062e-04\n",
      "Epoch 39/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.3697e-04\n",
      "Epoch 40/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.3365e-04\n",
      "Epoch 41/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.2281e-04\n",
      "Epoch 42/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.0143e-04\n",
      "Epoch 43/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.0136e-04\n",
      "Epoch 44/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.5168e-04\n",
      "Epoch 45/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.8011e-04\n",
      "Epoch 46/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.0161e-04\n",
      "Epoch 47/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.0263e-04\n",
      "Epoch 48/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.2834e-04\n",
      "Epoch 49/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.5065e-04\n",
      "Epoch 50/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.8048e-04\n",
      "Epoch 51/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.8097e-04\n",
      "Epoch 52/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.7674e-04\n",
      "Epoch 53/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.5241e-04\n",
      "Epoch 54/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.5512e-04\n",
      "Epoch 55/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.6138e-04\n",
      "Epoch 56/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.9628e-04\n",
      "Epoch 57/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.9322e-04\n",
      "Epoch 58/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.3330e-04\n",
      "Epoch 59/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.9666e-04 - val_loss: 5.1744e-04\n",
      "Epoch 60/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 9.9524e-04 - val_loss: 5.1460e-04\n",
      "Epoch 61/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.7561e-04 - val_loss: 5.5588e-04\n",
      "Epoch 62/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.7021e-04 - val_loss: 4.8768e-04\n",
      "Epoch 63/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.7061e-04 - val_loss: 5.0088e-04\n",
      "Epoch 64/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.5815e-04 - val_loss: 5.1206e-04\n",
      "Epoch 65/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.4917e-04 - val_loss: 4.9333e-04\n",
      "Epoch 66/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.3498e-04 - val_loss: 4.7991e-04\n",
      "Epoch 67/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.2757e-04 - val_loss: 4.8527e-04\n",
      "Epoch 68/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.2007e-04 - val_loss: 5.0397e-04\n",
      "Epoch 69/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.1521e-04 - val_loss: 4.7931e-04\n",
      "Epoch 70/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.0640e-04 - val_loss: 4.9280e-04\n",
      "Epoch 71/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.9978e-04 - val_loss: 4.4955e-04\n",
      "Epoch 72/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.8975e-04 - val_loss: 4.6176e-04\n",
      "Epoch 73/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.8746e-04 - val_loss: 4.4385e-04\n",
      "Epoch 74/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.8606e-04 - val_loss: 4.4471e-04\n",
      "Epoch 75/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.6822e-04 - val_loss: 4.6798e-04\n",
      "Epoch 76/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 8.6162e-04 - val_loss: 4.9468e-04\n",
      "Epoch 77/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 8.5259e-04 - val_loss: 4.3328e-04\n",
      "Epoch 78/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.5199e-04 - val_loss: 4.4750e-04\n",
      "Epoch 79/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.4438e-04 - val_loss: 4.3845e-04\n",
      "Epoch 80/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 8.4152e-04 - val_loss: 4.2620e-04\n",
      "Epoch 81/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.2674e-04 - val_loss: 4.4754e-04\n",
      "Epoch 82/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.1993e-04 - val_loss: 4.6236e-04\n",
      "Epoch 83/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.1936e-04 - val_loss: 4.4748e-04\n",
      "Epoch 84/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.2861e-04 - val_loss: 4.1049e-04\n",
      "Epoch 85/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 8.0766e-04 - val_loss: 4.1862e-04\n",
      "Epoch 86/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step - loss: 7.9243e-04 - val_loss: 4.0340e-04\n",
      "Epoch 87/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.0133e-04 - val_loss: 4.0826e-04\n",
      "Epoch 88/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.8528e-04 - val_loss: 4.1094e-04\n",
      "Epoch 89/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7990e-04 - val_loss: 4.1954e-04\n",
      "Epoch 90/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.8484e-04 - val_loss: 3.9701e-04\n",
      "Epoch 91/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.7768e-04 - val_loss: 3.9470e-04\n",
      "Epoch 92/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6120e-04 - val_loss: 4.1141e-04\n",
      "Epoch 93/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6014e-04 - val_loss: 3.9360e-04\n",
      "Epoch 94/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6252e-04 - val_loss: 4.0854e-04\n",
      "Epoch 95/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6099e-04 - val_loss: 4.2039e-04\n",
      "Epoch 96/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.4736e-04 - val_loss: 3.9203e-04\n",
      "Epoch 97/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5188e-04 - val_loss: 3.8083e-04\n",
      "Epoch 98/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.4146e-04 - val_loss: 4.4821e-04\n",
      "Epoch 99/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3671e-04 - val_loss: 4.1198e-04\n",
      "Epoch 100/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2519e-04 - val_loss: 3.8641e-04\n",
      "Epoch 101/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2357e-04 - val_loss: 3.9504e-04\n",
      "Epoch 102/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2212e-04 - val_loss: 3.7192e-04\n",
      "Epoch 103/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.1072e-04 - val_loss: 3.7446e-04\n",
      "Epoch 104/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0869e-04 - val_loss: 4.0302e-04\n",
      "Epoch 105/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0709e-04 - val_loss: 3.6364e-04\n",
      "Epoch 106/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.1098e-04 - val_loss: 3.6163e-04\n",
      "Epoch 107/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0242e-04 - val_loss: 4.0538e-04\n",
      "Epoch 108/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.9474e-04 - val_loss: 3.6753e-04\n",
      "Epoch 109/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0779e-04 - val_loss: 3.6824e-04\n",
      "Epoch 110/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.8454e-04 - val_loss: 3.8699e-04\n",
      "Epoch 111/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.8684e-04 - val_loss: 3.5785e-04\n",
      "Epoch 112/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.7883e-04 - val_loss: 3.5491e-04\n",
      "Epoch 113/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.7964e-04 - val_loss: 3.8569e-04\n",
      "Epoch 114/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.7656e-04 - val_loss: 3.5960e-04\n",
      "Epoch 115/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.9568e-04 - val_loss: 3.9709e-04\n",
      "Epoch 116/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.7858e-04 - val_loss: 3.5208e-04\n",
      "Epoch 117/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.5874e-04 - val_loss: 3.8572e-04\n",
      "Epoch 118/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.6561e-04 - val_loss: 3.4870e-04\n",
      "Epoch 119/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.6136e-04 - val_loss: 3.4262e-04\n",
      "Epoch 120/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.6469e-04 - val_loss: 3.7667e-04\n",
      "Epoch 121/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.6049e-04 - val_loss: 3.5855e-04\n",
      "Epoch 122/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.4950e-04 - val_loss: 3.3779e-04\n",
      "Epoch 123/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.5594e-04 - val_loss: 3.3704e-04\n",
      "Epoch 124/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.4695e-04 - val_loss: 3.4049e-04\n",
      "Epoch 125/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.3646e-04 - val_loss: 3.5595e-04\n",
      "Epoch 126/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.4627e-04 - val_loss: 3.4810e-04\n",
      "Epoch 127/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.4128e-04 - val_loss: 3.5299e-04\n",
      "Epoch 128/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.3265e-04 - val_loss: 3.3164e-04\n",
      "Epoch 129/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.3274e-04 - val_loss: 3.9383e-04\n",
      "Epoch 130/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.3083e-04 - val_loss: 3.3489e-04\n",
      "Epoch 131/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.2084e-04 - val_loss: 3.3109e-04\n",
      "Epoch 132/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.2501e-04 - val_loss: 3.5135e-04\n",
      "Epoch 133/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.1836e-04 - val_loss: 3.2543e-04\n",
      "Epoch 134/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.2394e-04 - val_loss: 3.5526e-04\n",
      "Epoch 135/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.1943e-04 - val_loss: 3.2463e-04\n",
      "Epoch 136/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.1538e-04 - val_loss: 3.2273e-04\n",
      "Epoch 137/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.1058e-04 - val_loss: 3.3372e-04\n",
      "Epoch 138/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.1350e-04 - val_loss: 3.3746e-04\n",
      "Epoch 139/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.0466e-04 - val_loss: 3.3378e-04\n",
      "Epoch 140/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.0123e-04 - val_loss: 3.2030e-04\n",
      "Epoch 141/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.0556e-04 - val_loss: 3.3412e-04\n",
      "Epoch 142/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.9863e-04 - val_loss: 3.5973e-04\n",
      "Epoch 143/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.0442e-04 - val_loss: 3.1574e-04\n",
      "Epoch 144/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.9991e-04 - val_loss: 3.4418e-04\n",
      "Epoch 145/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.9544e-04 - val_loss: 3.1528e-04\n",
      "Epoch 146/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.8962e-04 - val_loss: 3.3769e-04\n",
      "Epoch 147/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.9460e-04 - val_loss: 3.1207e-04\n",
      "Epoch 148/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.9567e-04 - val_loss: 3.1343e-04\n",
      "Epoch 149/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.8371e-04 - val_loss: 3.3077e-04\n",
      "Epoch 150/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.8497e-04 - val_loss: 3.0947e-04\n",
      "Epoch 151/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.8257e-04 - val_loss: 3.2914e-04\n",
      "Epoch 152/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.7720e-04 - val_loss: 3.2056e-04\n",
      "Epoch 153/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.9227e-04 - val_loss: 3.2758e-04\n",
      "Epoch 154/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.8496e-04 - val_loss: 3.3127e-04\n",
      "Epoch 155/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.8308e-04 - val_loss: 3.4352e-04\n",
      "Epoch 156/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.7603e-04 - val_loss: 3.0737e-04\n",
      "Epoch 157/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.6749e-04 - val_loss: 3.4125e-04\n",
      "Epoch 158/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.7066e-04 - val_loss: 3.1042e-04\n",
      "Epoch 159/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.7077e-04 - val_loss: 3.1250e-04\n",
      "Epoch 160/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.6919e-04 - val_loss: 3.5545e-04\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step - loss: 5.6531e-04 - val_loss: 3.1168e-04\n",
      "Epoch 162/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.6377e-04 - val_loss: 3.0243e-04\n",
      "Epoch 163/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.6822e-04 - val_loss: 2.9982e-04\n",
      "Epoch 164/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.6228e-04 - val_loss: 2.9951e-04\n",
      "Epoch 165/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5872e-04 - val_loss: 3.1875e-04\n",
      "Epoch 166/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5889e-04 - val_loss: 2.9810e-04\n",
      "Epoch 167/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5959e-04 - val_loss: 2.9998e-04\n",
      "Epoch 168/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.6206e-04 - val_loss: 3.0409e-04\n",
      "Epoch 169/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5413e-04 - val_loss: 2.9613e-04\n",
      "Epoch 170/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5391e-04 - val_loss: 2.9562e-04\n",
      "Epoch 171/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5044e-04 - val_loss: 3.1044e-04\n",
      "Epoch 172/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5463e-04 - val_loss: 2.9415e-04\n",
      "Epoch 173/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5499e-04 - val_loss: 3.3600e-04\n",
      "Epoch 174/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5053e-04 - val_loss: 3.0761e-04\n",
      "Epoch 175/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.4630e-04 - val_loss: 2.9633e-04\n",
      "Epoch 176/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.4456e-04 - val_loss: 3.2960e-04\n",
      "Epoch 177/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.4108e-04 - val_loss: 2.9544e-04\n",
      "Epoch 178/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.4281e-04 - val_loss: 2.9766e-04\n",
      "Epoch 179/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5268e-04 - val_loss: 2.9607e-04\n",
      "Epoch 180/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5120e-04 - val_loss: 2.9302e-04\n",
      "Epoch 181/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.4499e-04 - val_loss: 3.4743e-04\n",
      "Epoch 182/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3946e-04 - val_loss: 2.9310e-04\n",
      "Epoch 183/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3502e-04 - val_loss: 2.9230e-04\n",
      "Epoch 184/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3750e-04 - val_loss: 3.1032e-04\n",
      "Epoch 185/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3701e-04 - val_loss: 2.8934e-04\n",
      "Epoch 186/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3317e-04 - val_loss: 2.8699e-04\n",
      "Epoch 187/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3173e-04 - val_loss: 2.8617e-04\n",
      "Epoch 188/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3263e-04 - val_loss: 2.8573e-04\n",
      "Epoch 189/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.2626e-04 - val_loss: 3.0403e-04\n",
      "Epoch 190/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3131e-04 - val_loss: 2.8698e-04\n",
      "Epoch 191/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3604e-04 - val_loss: 2.9874e-04\n",
      "Epoch 192/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3291e-04 - val_loss: 2.8374e-04\n",
      "Epoch 193/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.2664e-04 - val_loss: 2.8368e-04\n",
      "Epoch 194/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.2359e-04 - val_loss: 2.9020e-04\n",
      "Epoch 195/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.2665e-04 - val_loss: 2.8355e-04\n",
      "Epoch 196/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.2545e-04 - val_loss: 2.9028e-04\n",
      "Epoch 197/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.3040e-04 - val_loss: 3.0137e-04\n",
      "Epoch 198/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.1861e-04 - val_loss: 2.9508e-04\n",
      "Epoch 199/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.2376e-04 - val_loss: 2.8773e-04\n",
      "Epoch 200/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.1412e-04 - val_loss: 3.0877e-04\n",
      "Thời gian huấn luyện:  16.137869119644165\n",
      "Model: \"sequential_128\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_160 (Dense)           (None, 30, 95)            190       \n",
      "                                                                 \n",
      " flatten_128 (Flatten)       (None, 2850)              0         \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 1)                 2851      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,041\n",
      "Trainable params: 3,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 1s 11ms/step - loss: 0.0138 - val_loss: 8.4925e-04\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0028 - val_loss: 8.3263e-04\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 7.5688e-04\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 7.3928e-04\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 6.7369e-04\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 6.3590e-04\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 6.4556e-04\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 6.3559e-04\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.5703e-04\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 5.3230e-04\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 5.6267e-04\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.5549e-04\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 4.9280e-04\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.0986e-04\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 4.7732e-04\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.9712e-04\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 4.6863e-04\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 9.8613e-04 - val_loss: 4.6128e-04\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.4576e-04 - val_loss: 4.4663e-04\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.3985e-04 - val_loss: 4.5174e-04\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.1975e-04 - val_loss: 4.4027e-04\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 8.9983e-04 - val_loss: 4.4049e-04\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.1994e-04 - val_loss: 4.4723e-04\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 8.8472e-04 - val_loss: 4.5224e-04\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 8.8849e-04 - val_loss: 4.2151e-04\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 8.5011e-04 - val_loss: 4.6050e-04\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.4420e-04 - val_loss: 4.2813e-04\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 6ms/step - loss: 8.3299e-04 - val_loss: 4.1605e-04\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 8.8020e-04 - val_loss: 4.0389e-04\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 8.0059e-04 - val_loss: 5.7571e-04\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 8.0504e-04 - val_loss: 4.7149e-04\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.9195e-04 - val_loss: 4.0740e-04\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.7944e-04 - val_loss: 3.7955e-04\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.5582e-04 - val_loss: 3.8933e-04\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.3705e-04 - val_loss: 3.6936e-04\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.4050e-04 - val_loss: 3.6649e-04\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.2664e-04 - val_loss: 3.7262e-04\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.8139e-04 - val_loss: 6.3336e-04\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.4119e-04 - val_loss: 3.5710e-04\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.0128e-04 - val_loss: 3.5437e-04\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.0671e-04 - val_loss: 3.6033e-04\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.0218e-04 - val_loss: 3.8882e-04\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.8969e-04 - val_loss: 3.4639e-04\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.7569e-04 - val_loss: 3.4363e-04\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.8670e-04 - val_loss: 3.4192e-04\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.7899e-04 - val_loss: 3.8601e-04\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.7646e-04 - val_loss: 3.3115e-04\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.7000e-04 - val_loss: 3.7918e-04\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.4686e-04 - val_loss: 3.3770e-04\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.6203e-04 - val_loss: 3.5969e-04\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.4240e-04 - val_loss: 4.2880e-04\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.5788e-04 - val_loss: 4.2677e-04\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.6048e-04 - val_loss: 3.3113e-04\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.1661e-04 - val_loss: 3.5626e-04\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.3313e-04 - val_loss: 3.2150e-04\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.1424e-04 - val_loss: 3.8490e-04\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.2153e-04 - val_loss: 3.2565e-04\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.1002e-04 - val_loss: 3.2108e-04\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.1242e-04 - val_loss: 3.3583e-04\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.3868e-04 - val_loss: 3.4584e-04\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.1353e-04 - val_loss: 3.0874e-04\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.1508e-04 - val_loss: 3.2725e-04\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.0431e-04 - val_loss: 3.1109e-04\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.7987e-04 - val_loss: 3.2121e-04\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.9771e-04 - val_loss: 3.0375e-04\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.8494e-04 - val_loss: 2.9918e-04\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.7987e-04 - val_loss: 3.0440e-04\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.8041e-04 - val_loss: 3.8815e-04\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.3960e-04 - val_loss: 3.1284e-04\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.2027e-04 - val_loss: 3.0371e-04\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.5479e-04 - val_loss: 3.3914e-04\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.5804e-04 - val_loss: 2.9383e-04\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.7251e-04 - val_loss: 2.8729e-04\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.5585e-04 - val_loss: 2.8959e-04\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.4446e-04 - val_loss: 2.9815e-04\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.5044e-04 - val_loss: 2.8469e-04\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.4478e-04 - val_loss: 2.9717e-04\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.6031e-04 - val_loss: 3.0252e-04\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.5648e-04 - val_loss: 3.3307e-04\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.8713e-04 - val_loss: 3.5748e-04\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.4967e-04 - val_loss: 2.8357e-04\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.2521e-04 - val_loss: 3.3863e-04\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.2739e-04 - val_loss: 2.8187e-04\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 6.0195e-04 - val_loss: 4.1024e-04\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.7187e-04 - val_loss: 2.9034e-04\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.1174e-04 - val_loss: 2.8872e-04\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.2011e-04 - val_loss: 3.4511e-04\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.3216e-04 - val_loss: 3.3235e-04\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.3709e-04 - val_loss: 3.0805e-04\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.2274e-04 - val_loss: 2.7317e-04\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.1208e-04 - val_loss: 2.9131e-04\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.0478e-04 - val_loss: 2.8881e-04\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.1634e-04 - val_loss: 3.5660e-04\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.2214e-04 - val_loss: 2.6937e-04\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.1720e-04 - val_loss: 2.8469e-04\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.0936e-04 - val_loss: 2.9261e-04\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.9554e-04 - val_loss: 2.8743e-04\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.3615e-04 - val_loss: 2.6934e-04\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.0753e-04 - val_loss: 2.6975e-04\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.0808e-04 - val_loss: 3.0839e-04\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.0315e-04 - val_loss: 2.8700e-04\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.9122e-04 - val_loss: 2.6911e-04\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.8876e-04 - val_loss: 2.9909e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.1914e-04 - val_loss: 2.5936e-04\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.0845e-04 - val_loss: 2.5961e-04\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.9591e-04 - val_loss: 3.5879e-04\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.0293e-04 - val_loss: 2.5647e-04\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.7955e-04 - val_loss: 2.7287e-04\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.8327e-04 - val_loss: 2.8822e-04\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.7582e-04 - val_loss: 2.9324e-04\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.7817e-04 - val_loss: 2.7253e-04\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.9212e-04 - val_loss: 2.7820e-04\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.3392e-04 - val_loss: 3.5952e-04\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.4819e-04 - val_loss: 2.8070e-04\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.0314e-04 - val_loss: 3.7054e-04\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.9262e-04 - val_loss: 2.5850e-04\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.7815e-04 - val_loss: 2.8022e-04\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.6096e-04 - val_loss: 2.5958e-04\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.6988e-04 - val_loss: 2.6715e-04\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.6048e-04 - val_loss: 2.6747e-04\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.6175e-04 - val_loss: 2.8619e-04\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.0925e-04 - val_loss: 3.0112e-04\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.7091e-04 - val_loss: 2.8985e-04\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.6059e-04 - val_loss: 2.5582e-04\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.5105e-04 - val_loss: 2.5874e-04\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.6217e-04 - val_loss: 2.5274e-04\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.5550e-04 - val_loss: 2.5939e-04\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.7277e-04 - val_loss: 2.7212e-04\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.5731e-04 - val_loss: 2.6907e-04\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.5197e-04 - val_loss: 3.0287e-04\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.6276e-04 - val_loss: 2.5473e-04\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.4582e-04 - val_loss: 2.8911e-04\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.4285e-04 - val_loss: 2.6293e-04\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.4866e-04 - val_loss: 2.7334e-04\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.4915e-04 - val_loss: 2.5602e-04\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.6212e-04 - val_loss: 2.7196e-04\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.7725e-04 - val_loss: 2.4960e-04\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3860e-04 - val_loss: 2.4347e-04\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.4106e-04 - val_loss: 2.5092e-04\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.4167e-04 - val_loss: 2.6765e-04\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.5733e-04 - val_loss: 2.4732e-04\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.9296e-04 - val_loss: 2.5332e-04\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.4957e-04 - val_loss: 3.2825e-04\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.1572e-04 - val_loss: 2.6268e-04\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.4549e-04 - val_loss: 3.1102e-04\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.4233e-04 - val_loss: 2.5762e-04\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3946e-04 - val_loss: 2.4356e-04\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3696e-04 - val_loss: 3.0837e-04\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.5015e-04 - val_loss: 2.5539e-04\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.4360e-04 - val_loss: 3.1067e-04\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.6285e-04 - val_loss: 2.4067e-04\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.5085e-04 - val_loss: 2.4338e-04\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 4.4131e-04 - val_loss: 2.4995e-04\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.5611e-04 - val_loss: 2.5405e-04\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3849e-04 - val_loss: 2.7513e-04\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.4875e-04 - val_loss: 2.6228e-04\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2948e-04 - val_loss: 2.5417e-04\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2130e-04 - val_loss: 2.6192e-04\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2367e-04 - val_loss: 2.8971e-04\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.7386e-04 - val_loss: 4.0684e-04\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.6857e-04 - val_loss: 2.4096e-04\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.4034e-04 - val_loss: 2.4999e-04\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3922e-04 - val_loss: 2.4183e-04\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2999e-04 - val_loss: 2.3814e-04\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2020e-04 - val_loss: 2.3944e-04\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.1522e-04 - val_loss: 2.4782e-04\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2611e-04 - val_loss: 2.4440e-04\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3064e-04 - val_loss: 2.9859e-04\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3635e-04 - val_loss: 2.4262e-04\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2873e-04 - val_loss: 2.8756e-04\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2678e-04 - val_loss: 2.6741e-04\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2114e-04 - val_loss: 2.6691e-04\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3550e-04 - val_loss: 2.5485e-04\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.4672e-04 - val_loss: 2.6615e-04\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.5325e-04 - val_loss: 2.7374e-04\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2546e-04 - val_loss: 2.3893e-04\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2977e-04 - val_loss: 2.4587e-04\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2433e-04 - val_loss: 2.4081e-04\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 6ms/step - loss: 4.1528e-04 - val_loss: 2.4416e-04\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2297e-04 - val_loss: 2.3731e-04\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 4.1883e-04 - val_loss: 2.3863e-04\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.0921e-04 - val_loss: 2.5640e-04\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.1223e-04 - val_loss: 2.3746e-04\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.1232e-04 - val_loss: 2.3678e-04\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2084e-04 - val_loss: 2.3622e-04\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.1870e-04 - val_loss: 3.5547e-04\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2168e-04 - val_loss: 2.6713e-04\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.1945e-04 - val_loss: 2.6683e-04\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2239e-04 - val_loss: 2.3502e-04\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.1889e-04 - val_loss: 2.4656e-04\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3620e-04 - val_loss: 2.3494e-04\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.1998e-04 - val_loss: 2.4957e-04\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.1027e-04 - val_loss: 2.4029e-04\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.0999e-04 - val_loss: 3.0386e-04\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.1921e-04 - val_loss: 2.4653e-04\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.1145e-04 - val_loss: 2.5515e-04\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.3928e-04 - val_loss: 3.6895e-04\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2141e-04 - val_loss: 2.6006e-04\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.2519e-04 - val_loss: 2.3401e-04\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 4.0850e-04 - val_loss: 2.3689e-04\n",
      "Thời gian huấn luyện:  42.76766777038574\n",
      "Model: \"sequential_129\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_32 (SimpleRNN)   (None, 30, 102)           10608     \n",
      "                                                                 \n",
      " flatten_129 (Flatten)       (None, 3060)              0         \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 1)                 3061      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,669\n",
      "Trainable params: 13,669\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 2s 29ms/step - loss: 0.0183 - val_loss: 0.0014\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0037 - val_loss: 8.8130e-04\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0033 - val_loss: 8.4775e-04\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0030 - val_loss: 7.9216e-04\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0028 - val_loss: 7.6541e-04\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0026 - val_loss: 7.4546e-04\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0023 - val_loss: 7.8524e-04\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0022 - val_loss: 7.7069e-04\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0020 - val_loss: 7.3282e-04\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0019 - val_loss: 7.4132e-04\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0018 - val_loss: 7.6767e-04\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0018 - val_loss: 7.3030e-04\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.0017 - val_loss: 7.1933e-04\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.0017 - val_loss: 7.0671e-04\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.0017 - val_loss: 6.8835e-04\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0016 - val_loss: 6.8142e-04\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0016 - val_loss: 6.5975e-04\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0015 - val_loss: 6.4699e-04\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0016 - val_loss: 6.3688e-04\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0015 - val_loss: 6.4198e-04\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0015 - val_loss: 6.4116e-04\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0015 - val_loss: 6.0476e-04\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0014 - val_loss: 6.2734e-04\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0014 - val_loss: 6.1714e-04\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.0014 - val_loss: 5.7704e-04\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0014 - val_loss: 5.7126e-04\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0014 - val_loss: 5.6371e-04\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.0013 - val_loss: 5.8004e-04\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0013 - val_loss: 6.2678e-04\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.0013 - val_loss: 5.4378e-04\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0013 - val_loss: 5.5307e-04\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0013 - val_loss: 5.4304e-04\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0013 - val_loss: 5.2778e-04\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.0012 - val_loss: 5.3193e-04\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0012 - val_loss: 5.5154e-04\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0012 - val_loss: 5.3040e-04\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0012 - val_loss: 5.1682e-04\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0012 - val_loss: 5.3776e-04\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0012 - val_loss: 5.2998e-04\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0012 - val_loss: 5.2319e-04\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0011 - val_loss: 5.1013e-04\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0011 - val_loss: 5.0880e-04\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0011 - val_loss: 5.0296e-04\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0011 - val_loss: 6.6538e-04\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0011 - val_loss: 5.1834e-04\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0011 - val_loss: 4.9984e-04\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0011 - val_loss: 4.9181e-04\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0011 - val_loss: 5.1228e-04\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0011 - val_loss: 5.4521e-04\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0011 - val_loss: 5.5834e-04\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0011 - val_loss: 4.7794e-04\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0010 - val_loss: 4.9282e-04\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0010 - val_loss: 5.4761e-04\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0010 - val_loss: 4.7698e-04\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.0010 - val_loss: 4.6849e-04\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0010 - val_loss: 5.2116e-04\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0010 - val_loss: 4.7591e-04\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.0010 - val_loss: 6.0670e-04\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.0010 - val_loss: 4.7335e-04\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 9.7825e-04 - val_loss: 4.8476e-04\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 9.8065e-04 - val_loss: 4.6828e-04\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 9.6362e-04 - val_loss: 4.8499e-04\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 9.7487e-04 - val_loss: 4.5609e-04\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 9.5182e-04 - val_loss: 4.6147e-04\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 9.5449e-04 - val_loss: 6.0401e-04\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 9.6193e-04 - val_loss: 4.5001e-04\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 9.4626e-04 - val_loss: 4.4578e-04\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 9.4555e-04 - val_loss: 5.6871e-04\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 9.4207e-04 - val_loss: 4.6055e-04\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 9.2707e-04 - val_loss: 4.3256e-04\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 9.0496e-04 - val_loss: 4.3124e-04\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 8.9976e-04 - val_loss: 4.4502e-04\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 8.8777e-04 - val_loss: 4.3254e-04\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 8.8694e-04 - val_loss: 4.4971e-04\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 8.8169e-04 - val_loss: 4.3424e-04\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 8.7744e-04 - val_loss: 4.6998e-04\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.7381e-04 - val_loss: 4.1695e-04\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 8.7202e-04 - val_loss: 4.6219e-04\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 8.6886e-04 - val_loss: 4.1253e-04\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.7116e-04 - val_loss: 4.1436e-04\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.6881e-04 - val_loss: 4.3127e-04\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.3791e-04 - val_loss: 4.7024e-04\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.6015e-04 - val_loss: 4.6700e-04\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 8.6015e-04 - val_loss: 4.1253e-04\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 8.2027e-04 - val_loss: 4.2305e-04\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 8.5485e-04 - val_loss: 4.0691e-04\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.1687e-04 - val_loss: 3.9569e-04\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.0993e-04 - val_loss: 3.9293e-04\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 8.0515e-04 - val_loss: 4.0168e-04\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 8.1980e-04 - val_loss: 4.1064e-04\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.9372e-04 - val_loss: 4.4249e-04\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 8.0875e-04 - val_loss: 3.9629e-04\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 8.4310e-04 - val_loss: 3.8441e-04\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 8.0782e-04 - val_loss: 3.8406e-04\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.7392e-04 - val_loss: 3.9766e-04\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.2905e-04 - val_loss: 3.8971e-04\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.7650e-04 - val_loss: 3.7923e-04\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.6278e-04 - val_loss: 3.8397e-04\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 7.8795e-04 - val_loss: 3.7801e-04\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 7.7067e-04 - val_loss: 4.0524e-04\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.6941e-04 - val_loss: 4.3817e-04\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.7214e-04 - val_loss: 3.7618e-04\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 7.4336e-04 - val_loss: 3.7052e-04\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.4724e-04 - val_loss: 3.9247e-04\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.4216e-04 - val_loss: 4.5101e-04\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.5909e-04 - val_loss: 3.9798e-04\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.3851e-04 - val_loss: 4.5355e-04\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.6571e-04 - val_loss: 3.9938e-04\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.3324e-04 - val_loss: 3.7639e-04\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.3293e-04 - val_loss: 3.7080e-04\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 7.2846e-04 - val_loss: 4.3214e-04\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.2591e-04 - val_loss: 3.7292e-04\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.0473e-04 - val_loss: 3.8223e-04\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.1456e-04 - val_loss: 3.6501e-04\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.2795e-04 - val_loss: 3.6069e-04\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.0499e-04 - val_loss: 4.4824e-04\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.2753e-04 - val_loss: 3.8088e-04\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.1327e-04 - val_loss: 3.7485e-04\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 6.9881e-04 - val_loss: 3.5663e-04\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.8805e-04 - val_loss: 3.7648e-04\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 7.1232e-04 - val_loss: 4.0315e-04\n",
      "Epoch 122/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 17ms/step - loss: 6.8624e-04 - val_loss: 3.5360e-04\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 6.7235e-04 - val_loss: 3.9926e-04\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 6.9225e-04 - val_loss: 3.8277e-04\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 6.9237e-04 - val_loss: 3.8621e-04\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 6.8375e-04 - val_loss: 3.4632e-04\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 6.7135e-04 - val_loss: 3.5044e-04\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 6.8732e-04 - val_loss: 3.5494e-04\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 6.6303e-04 - val_loss: 3.5064e-04\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 6.5914e-04 - val_loss: 3.4984e-04\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.5687e-04 - val_loss: 3.4733e-04\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.6513e-04 - val_loss: 3.6043e-04\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.6002e-04 - val_loss: 3.7579e-04\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.6952e-04 - val_loss: 3.7224e-04\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.5716e-04 - val_loss: 4.5589e-04\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.5008e-04 - val_loss: 3.8392e-04\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.6286e-04 - val_loss: 3.4654e-04\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.4497e-04 - val_loss: 3.4183e-04\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.3189e-04 - val_loss: 3.4171e-04\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.3322e-04 - val_loss: 3.4544e-04\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 6.2768e-04 - val_loss: 3.6058e-04\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.3476e-04 - val_loss: 3.4719e-04\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.2412e-04 - val_loss: 3.7864e-04\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.2446e-04 - val_loss: 3.3713e-04\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.2242e-04 - val_loss: 3.5654e-04\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.1907e-04 - val_loss: 3.3378e-04\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.2306e-04 - val_loss: 3.3217e-04\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.1808e-04 - val_loss: 3.9134e-04\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.2385e-04 - val_loss: 3.3138e-04\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.2112e-04 - val_loss: 3.2713e-04\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.1073e-04 - val_loss: 3.5506e-04\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.1154e-04 - val_loss: 3.3878e-04\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.0952e-04 - val_loss: 3.2497e-04\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.0373e-04 - val_loss: 3.3899e-04\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 5.9138e-04 - val_loss: 3.2423e-04\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 5.9269e-04 - val_loss: 3.2292e-04\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 5.9120e-04 - val_loss: 3.3802e-04\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 5.9617e-04 - val_loss: 3.2105e-04\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 6.1941e-04 - val_loss: 3.3914e-04\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 6.0411e-04 - val_loss: 3.2471e-04\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 5.9536e-04 - val_loss: 3.3913e-04\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 5.8124e-04 - val_loss: 3.1743e-04\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 5.7962e-04 - val_loss: 3.7226e-04\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 6.0748e-04 - val_loss: 3.1849e-04\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 5.7350e-04 - val_loss: 3.1612e-04\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 5.7818e-04 - val_loss: 3.1619e-04\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 5.6841e-04 - val_loss: 3.1816e-04\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 5.6782e-04 - val_loss: 3.1948e-04\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 5.7893e-04 - val_loss: 3.0959e-04\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 5.7600e-04 - val_loss: 3.0891e-04\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 5.6330e-04 - val_loss: 3.2571e-04\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 5.6902e-04 - val_loss: 3.0715e-04\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.0804e-04 - val_loss: 3.5455e-04\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 5.8424e-04 - val_loss: 3.0850e-04\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 5.6484e-04 - val_loss: 3.0486e-04\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 5.4736e-04 - val_loss: 3.0514e-04\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 5.5833e-04 - val_loss: 3.3909e-04\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 5.6410e-04 - val_loss: 3.0089e-04\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 5.5341e-04 - val_loss: 3.0254e-04\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 5.5434e-04 - val_loss: 4.0886e-04\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 5.6692e-04 - val_loss: 2.9982e-04\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 5.7804e-04 - val_loss: 3.2075e-04\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 5.6809e-04 - val_loss: 3.6108e-04\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 5.5693e-04 - val_loss: 3.1568e-04\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 5.4240e-04 - val_loss: 2.9931e-04\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 5.3777e-04 - val_loss: 3.2865e-04\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 5.3619e-04 - val_loss: 3.0439e-04\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 5.3436e-04 - val_loss: 2.9570e-04\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 5.3083e-04 - val_loss: 3.3493e-04\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 5.4429e-04 - val_loss: 2.9546e-04\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 5.3897e-04 - val_loss: 3.4785e-04\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 5.5127e-04 - val_loss: 2.9439e-04\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 5.3834e-04 - val_loss: 2.9004e-04\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 5.2237e-04 - val_loss: 2.9031e-04\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 5.6748e-04 - val_loss: 2.8755e-04\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 16ms/step - loss: 5.2684e-04 - val_loss: 3.0229e-04\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 5.3767e-04 - val_loss: 3.0320e-04\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 5.4412e-04 - val_loss: 2.8778e-04\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 5.5583e-04 - val_loss: 3.1112e-04\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 5.2039e-04 - val_loss: 3.0294e-04\n",
      "Thời gian huấn luyện:  122.7958471775055\n",
      "Model: \"sequential_130\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_32 (LSTM)              (None, 30, 102)           42432     \n",
      "                                                                 \n",
      " flatten_130 (Flatten)       (None, 3060)              0         \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 1)                 3061      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,493\n",
      "Trainable params: 45,493\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 1s 5ms/step\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 2s 23ms/step - loss: 0.0138 - val_loss: 0.0013\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0028 - val_loss: 7.7668e-04\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0024 - val_loss: 6.8798e-04\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0022 - val_loss: 6.6858e-04\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0020 - val_loss: 6.5409e-04\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0019 - val_loss: 6.5062e-04\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0018 - val_loss: 7.6323e-04\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0017 - val_loss: 6.2911e-04\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0016 - val_loss: 6.2693e-04\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 6.1828e-04\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0015 - val_loss: 6.1328e-04\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0014 - val_loss: 5.9296e-04\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0014 - val_loss: 6.0060e-04\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0013 - val_loss: 5.8318e-04\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0013 - val_loss: 5.7523e-04\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0013 - val_loss: 5.8150e-04\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0012 - val_loss: 5.6019e-04\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0012 - val_loss: 5.4875e-04\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0012 - val_loss: 5.2485e-04\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0012 - val_loss: 5.0645e-04\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0011 - val_loss: 4.9846e-04\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0011 - val_loss: 4.8655e-04\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0011 - val_loss: 4.7741e-04\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0010 - val_loss: 4.8867e-04\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0010 - val_loss: 4.6142e-04\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0010 - val_loss: 4.7404e-04\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 9.9055e-04 - val_loss: 4.7090e-04\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 9.6538e-04 - val_loss: 4.4098e-04\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 9.4789e-04 - val_loss: 4.3677e-04\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 9.3892e-04 - val_loss: 4.2429e-04\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 9.2892e-04 - val_loss: 4.2110e-04\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 9.2627e-04 - val_loss: 4.1086e-04\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.8946e-04 - val_loss: 4.0692e-04\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.8083e-04 - val_loss: 4.0084e-04\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.6221e-04 - val_loss: 4.0026e-04\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.5322e-04 - val_loss: 3.9713e-04\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.4309e-04 - val_loss: 4.3560e-04\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 8.1410e-04 - val_loss: 4.0014e-04\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 8.1303e-04 - val_loss: 3.8288e-04\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.0026e-04 - val_loss: 3.8676e-04\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.0010e-04 - val_loss: 3.7481e-04\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.9783e-04 - val_loss: 4.1245e-04\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.0246e-04 - val_loss: 3.9867e-04\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 7.8256e-04 - val_loss: 3.7125e-04\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 7.4955e-04 - val_loss: 3.6544e-04\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.4331e-04 - val_loss: 4.4788e-04\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 7.5895e-04 - val_loss: 4.0332e-04\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.9076e-04 - val_loss: 4.3025e-04\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 7.2499e-04 - val_loss: 3.5640e-04\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 7.2354e-04 - val_loss: 3.5009e-04\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.4178e-04 - val_loss: 3.5820e-04\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.9654e-04 - val_loss: 3.4478e-04\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 6.9172e-04 - val_loss: 3.6823e-04\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 7.4116e-04 - val_loss: 3.7089e-04\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 6.9620e-04 - val_loss: 3.5605e-04\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 6.7418e-04 - val_loss: 3.5255e-04\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 6.6676e-04 - val_loss: 3.3521e-04\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 6.6825e-04 - val_loss: 3.4568e-04\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 6.7339e-04 - val_loss: 3.3227e-04\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 6.7054e-04 - val_loss: 3.3121e-04\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 6.5567e-04 - val_loss: 3.3651e-04\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 6.4426e-04 - val_loss: 3.6418e-04\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 16ms/step - loss: 6.5300e-04 - val_loss: 3.3650e-04\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 6.4198e-04 - val_loss: 3.4092e-04\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 6.2859e-04 - val_loss: 3.2227e-04\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.3218e-04 - val_loss: 3.8422e-04\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 6.3287e-04 - val_loss: 3.3729e-04\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.1215e-04 - val_loss: 3.2341e-04\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 6.1199e-04 - val_loss: 3.2608e-04\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 6.1034e-04 - val_loss: 3.3667e-04\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 6.1352e-04 - val_loss: 3.1978e-04\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 6.0651e-04 - val_loss: 3.3767e-04\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 5.9509e-04 - val_loss: 3.1584e-04\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 5.9103e-04 - val_loss: 3.1091e-04\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 5.8848e-04 - val_loss: 3.2014e-04\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 5.9755e-04 - val_loss: 3.1945e-04\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 5.9044e-04 - val_loss: 3.0605e-04\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 6.0361e-04 - val_loss: 3.5226e-04\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 6.0142e-04 - val_loss: 3.0383e-04\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 5.7537e-04 - val_loss: 3.3411e-04\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 5.9446e-04 - val_loss: 3.0625e-04\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 5.7709e-04 - val_loss: 3.0021e-04\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 5.7228e-04 - val_loss: 3.1446e-04\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 5.5709e-04 - val_loss: 3.0071e-04\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 5.5544e-04 - val_loss: 3.0950e-04\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 5.7490e-04 - val_loss: 3.0088e-04\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 5.5199e-04 - val_loss: 2.9622e-04\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 5.4647e-04 - val_loss: 3.0032e-04\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 5.5490e-04 - val_loss: 2.9281e-04\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 5.6699e-04 - val_loss: 3.1855e-04\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 5.3804e-04 - val_loss: 2.9211e-04\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 5.5205e-04 - val_loss: 3.3516e-04\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 5.4178e-04 - val_loss: 3.2407e-04\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 5.4776e-04 - val_loss: 3.0120e-04\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 5.4181e-04 - val_loss: 2.9768e-04\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 5.3303e-04 - val_loss: 3.0648e-04\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 5.3467e-04 - val_loss: 3.0276e-04\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 5.4674e-04 - val_loss: 3.2826e-04\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 5.4104e-04 - val_loss: 3.0773e-04\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 5.3177e-04 - val_loss: 2.8472e-04\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 5.4144e-04 - val_loss: 3.6189e-04\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 5.4640e-04 - val_loss: 3.1997e-04\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 5.2589e-04 - val_loss: 3.2523e-04\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 5.2490e-04 - val_loss: 2.8245e-04\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 5.0855e-04 - val_loss: 2.8543e-04\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 5.0795e-04 - val_loss: 2.8106e-04\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 5.1422e-04 - val_loss: 3.1824e-04\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 5.1368e-04 - val_loss: 3.3439e-04\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 5.0872e-04 - val_loss: 2.7759e-04\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.9946e-04 - val_loss: 2.9005e-04\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 5.1023e-04 - val_loss: 2.8421e-04\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.9871e-04 - val_loss: 2.7893e-04\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 5.0388e-04 - val_loss: 2.9327e-04\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 5.0041e-04 - val_loss: 2.7375e-04\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.9643e-04 - val_loss: 2.7326e-04\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 5.0349e-04 - val_loss: 3.0958e-04\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 4.8908e-04 - val_loss: 2.8933e-04\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 5.0642e-04 - val_loss: 2.7930e-04\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.8723e-04 - val_loss: 3.1399e-04\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.9623e-04 - val_loss: 2.8777e-04\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.9480e-04 - val_loss: 3.2617e-04\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 5.1484e-04 - val_loss: 2.6701e-04\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.7735e-04 - val_loss: 2.8890e-04\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.9184e-04 - val_loss: 2.6887e-04\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.8115e-04 - val_loss: 2.6565e-04\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.8934e-04 - val_loss: 2.6480e-04\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.7937e-04 - val_loss: 2.9223e-04\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.7157e-04 - val_loss: 2.6292e-04\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.7581e-04 - val_loss: 2.6973e-04\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.7827e-04 - val_loss: 2.6458e-04\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 5.0425e-04 - val_loss: 2.7818e-04\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.7327e-04 - val_loss: 2.7355e-04\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.7450e-04 - val_loss: 2.6434e-04\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.7153e-04 - val_loss: 2.7481e-04\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.7244e-04 - val_loss: 3.0115e-04\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.7204e-04 - val_loss: 2.5636e-04\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.7685e-04 - val_loss: 2.6245e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.7251e-04 - val_loss: 2.6446e-04\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.6032e-04 - val_loss: 3.1166e-04\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.8128e-04 - val_loss: 3.0760e-04\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.7108e-04 - val_loss: 2.6594e-04\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.5943e-04 - val_loss: 2.5746e-04\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.5643e-04 - val_loss: 2.5505e-04\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.7225e-04 - val_loss: 2.5439e-04\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.6118e-04 - val_loss: 2.6829e-04\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 4.5826e-04 - val_loss: 2.7472e-04\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.6700e-04 - val_loss: 2.7590e-04\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.5724e-04 - val_loss: 2.5346e-04\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 4.6052e-04 - val_loss: 2.5991e-04\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.4712e-04 - val_loss: 2.4920e-04\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.5022e-04 - val_loss: 2.5024e-04\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.4809e-04 - val_loss: 2.6006e-04\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.4399e-04 - val_loss: 3.0145e-04\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 4.5080e-04 - val_loss: 2.4811e-04\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.4875e-04 - val_loss: 2.5949e-04\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.4588e-04 - val_loss: 2.9048e-04\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 4.5780e-04 - val_loss: 2.5389e-04\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 4.3965e-04 - val_loss: 2.4717e-04\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 4.5972e-04 - val_loss: 2.6048e-04\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.4341e-04 - val_loss: 2.7166e-04\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.4638e-04 - val_loss: 2.6943e-04\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 4.4512e-04 - val_loss: 2.9475e-04\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.4094e-04 - val_loss: 2.4425e-04\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.5371e-04 - val_loss: 2.4408e-04\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.3357e-04 - val_loss: 2.4426e-04\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.3265e-04 - val_loss: 2.4393e-04\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.3383e-04 - val_loss: 2.4843e-04\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.3630e-04 - val_loss: 2.4844e-04\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.4537e-04 - val_loss: 2.4293e-04\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.3041e-04 - val_loss: 2.4344e-04\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.3870e-04 - val_loss: 2.4142e-04\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.2580e-04 - val_loss: 2.3971e-04\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.3869e-04 - val_loss: 2.5512e-04\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.3164e-04 - val_loss: 2.5575e-04\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.3351e-04 - val_loss: 2.4020e-04\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.3509e-04 - val_loss: 2.4560e-04\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 4.2280e-04 - val_loss: 2.4003e-04\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.3055e-04 - val_loss: 2.3908e-04\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.2131e-04 - val_loss: 2.5212e-04\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.2651e-04 - val_loss: 2.3837e-04\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.2529e-04 - val_loss: 2.5092e-04\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.2366e-04 - val_loss: 2.3729e-04\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.3243e-04 - val_loss: 2.4455e-04\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.1841e-04 - val_loss: 2.4091e-04\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.3261e-04 - val_loss: 2.4883e-04\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.2986e-04 - val_loss: 2.7910e-04\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.1752e-04 - val_loss: 2.3695e-04\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.2655e-04 - val_loss: 2.6269e-04\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.1391e-04 - val_loss: 2.3895e-04\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.3547e-04 - val_loss: 2.4577e-04\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.1930e-04 - val_loss: 2.5679e-04\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.3902e-04 - val_loss: 2.3561e-04\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.2081e-04 - val_loss: 2.3632e-04\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.1104e-04 - val_loss: 2.3488e-04\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.1360e-04 - val_loss: 2.5145e-04\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.1518e-04 - val_loss: 2.5433e-04\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.1995e-04 - val_loss: 2.7400e-04\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.1845e-04 - val_loss: 2.3903e-04\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.2288e-04 - val_loss: 2.3510e-04\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.2677e-04 - val_loss: 2.4793e-04\n",
      "Thời gian huấn luyện:  108.95765781402588\n",
      "Model: \"sequential_131\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_32 (GRU)                (None, 30, 102)           32130     \n",
      "                                                                 \n",
      " flatten_131 (Flatten)       (None, 3060)              0         \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 1)                 3061      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,191\n",
      "Trainable params: 35,191\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "rmse_bag = [] # Ex: rmse_bag[1] == [0.9, 0.8, 0.9, 0.9] --> FFNN, RNN, LSTM, GRU\n",
    "\n",
    "for look_back in [1, 3, 5, 10, 20, 30]:\n",
    "    FFNN_data, FFNN_params = prepare_best_params(information_FFNN_df,ds, look_back, opt)\n",
    "    FFNN_delta, FFNN_model = create_ffnn_model(*FFNN_params)\n",
    "    FFNN_mse, FFNN_mae, FFNN_mape, FFNN_rmse, FFNN_trainPredict, FFNN_testPredict = create_accuracy(FFNN_model, scaler, *FFNN_data)\n",
    "    \n",
    "    RNN_data, RNN_params = prepare_best_params(information_RNN_df,ds, look_back, opt)\n",
    "    RNN_delta, RNN_model = create_rnn_model(*RNN_params)\n",
    "    RNN_mse, RNN_mae, RNN_mape, RNN_rmse, RNN_trainPredict, RNN_testPredict = create_accuracy(RNN_model, scaler, *RNN_data)\n",
    "    \n",
    "    LSTM_data, LSTM_params = prepare_best_params(information_LSTM_df,ds, look_back, opt)\n",
    "    LSTM_delta, LSTM_model = create_lstm_model(*LSTM_params)\n",
    "    LSTM_mse, LSTM_mae, LSTM_mape, LSTM_rmse, LSTM_trainPredict, LSTM_testPredict = create_accuracy(LSTM_model, scaler, *LSTM_data)\n",
    "    \n",
    "    GRU_data, GRU_params = prepare_best_params(information_GRU_df,ds, look_back, opt)\n",
    "    GRU_delta, GRU_model = create_gru_model(*GRU_params)\n",
    "    GRU_mse, GRU_mae, GRU_mape, GRU_rmse, GRU_trainPredict, GRU_testPredict = create_accuracy(GRU_model, scaler, *GRU_data)\n",
    "    \n",
    "    # Lưu các RMSE\n",
    "    rmse_bag.append([FFNN_rmse, RNN_rmse, LSTM_rmse, GRU_rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7209307b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFNN</th>\n",
       "      <th>RNN</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>GRU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.317</td>\n",
       "      <td>0.276</td>\n",
       "      <td>4.329</td>\n",
       "      <td>0.277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.305</td>\n",
       "      <td>0.277</td>\n",
       "      <td>4.331</td>\n",
       "      <td>0.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.323</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.333</td>\n",
       "      <td>0.280</td>\n",
       "      <td>4.342</td>\n",
       "      <td>4.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.311</td>\n",
       "      <td>0.276</td>\n",
       "      <td>4.358</td>\n",
       "      <td>0.285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.315</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FFNN    RNN   LSTM    GRU\n",
       "1   4.317  0.276  4.329  0.277\n",
       "3   0.305  0.277  4.331  0.283\n",
       "5   0.323  0.279  0.316  0.283\n",
       "10  4.333  0.280  4.342  4.342\n",
       "20  0.311  0.276  4.358  0.285\n",
       "30  0.315  0.274  0.316  0.282"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_bag = pd.DataFrame(rmse_bag, index=[1, 3, 5, 10, 20, 30], columns=['FFNN', 'RNN', 'LSTM', 'GRU'])\n",
    "rmse_bag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bc3d79",
   "metadata": {},
   "source": [
    "### So the chosen look_back is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67a4d4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d18bca3",
   "metadata": {},
   "source": [
    "## Chose the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ceb9782",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_table = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13103ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0424 - val_loss: 0.0056\n",
      "Epoch 2/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0024\n",
      "Epoch 3/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 4/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 5/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 6/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 7/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 8/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 9/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 10/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 11/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 12/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 13/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 14/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 15/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 16/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 17/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 18/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 19/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 20/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 21/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 22/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 23/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 24/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 25/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 26/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 27/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 28/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 29/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 30/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 31/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 9.4515e-04\n",
      "Epoch 32/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 9.8975e-04\n",
      "Epoch 33/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 9.1533e-04\n",
      "Epoch 34/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 9.0805e-04\n",
      "Epoch 35/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 9.4347e-04\n",
      "Epoch 36/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.7383e-04\n",
      "Epoch 37/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.6730e-04\n",
      "Epoch 38/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.3131e-04\n",
      "Epoch 39/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 8.0457e-04\n",
      "Epoch 40/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 8.3719e-04\n",
      "Epoch 41/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 8.1568e-04\n",
      "Epoch 42/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 7.9378e-04\n",
      "Epoch 43/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.8480e-04\n",
      "Epoch 44/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.3960e-04\n",
      "Epoch 45/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.1792e-04\n",
      "Epoch 46/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.3205e-04\n",
      "Epoch 47/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.2003e-04\n",
      "Epoch 48/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.6774e-04\n",
      "Epoch 49/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.0955e-04\n",
      "Epoch 50/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.6546e-04\n",
      "Epoch 51/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.8173e-04\n",
      "Epoch 52/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.4289e-04\n",
      "Epoch 53/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.4501e-04\n",
      "Epoch 54/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.7028e-04\n",
      "Epoch 55/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.3035e-04\n",
      "Epoch 56/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.4350e-04\n",
      "Epoch 57/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.1280e-04\n",
      "Epoch 58/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.7640e-04\n",
      "Epoch 59/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.0004e-04\n",
      "Epoch 60/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 6.2291e-04\n",
      "Epoch 61/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.9050e-04\n",
      "Epoch 62/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.9637e-04\n",
      "Epoch 63/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.3999e-04\n",
      "Epoch 64/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 9.9387e-04 - val_loss: 5.4293e-04\n",
      "Epoch 65/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.8314e-04 - val_loss: 5.5545e-04\n",
      "Epoch 66/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.7740e-04 - val_loss: 5.2022e-04\n",
      "Epoch 67/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 9.6393e-04 - val_loss: 5.3061e-04\n",
      "Epoch 68/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 9.5254e-04 - val_loss: 5.2186e-04\n",
      "Epoch 69/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 9.4347e-04 - val_loss: 5.3356e-04\n",
      "Epoch 70/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.4175e-04 - val_loss: 5.0997e-04\n",
      "Epoch 71/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.2786e-04 - val_loss: 4.8561e-04\n",
      "Epoch 72/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.2592e-04 - val_loss: 5.2253e-04\n",
      "Epoch 73/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.1621e-04 - val_loss: 4.7536e-04\n",
      "Epoch 74/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.0764e-04 - val_loss: 4.9983e-04\n",
      "Epoch 75/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.0207e-04 - val_loss: 4.6863e-04\n",
      "Epoch 76/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 8.8866e-04 - val_loss: 4.9063e-04\n",
      "Epoch 77/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 8.8308e-04 - val_loss: 4.7296e-04\n",
      "Epoch 78/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.7524e-04 - val_loss: 4.5451e-04\n",
      "Epoch 79/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.7411e-04 - val_loss: 4.5427e-04\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step - loss: 8.6050e-04 - val_loss: 4.6953e-04\n",
      "Epoch 81/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 8.5639e-04 - val_loss: 4.5064e-04\n",
      "Epoch 82/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 8.4625e-04 - val_loss: 4.3979e-04\n",
      "Epoch 83/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.4416e-04 - val_loss: 4.3516e-04\n",
      "Epoch 84/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.4998e-04 - val_loss: 4.3462e-04\n",
      "Epoch 85/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.2782e-04 - val_loss: 4.4946e-04\n",
      "Epoch 86/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.2506e-04 - val_loss: 4.2922e-04\n",
      "Epoch 87/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.2891e-04 - val_loss: 4.2929e-04\n",
      "Epoch 88/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.2241e-04 - val_loss: 4.8223e-04\n",
      "Epoch 89/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.1253e-04 - val_loss: 4.2597e-04\n",
      "Epoch 90/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.1751e-04 - val_loss: 4.1592e-04\n",
      "Epoch 91/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.0248e-04 - val_loss: 4.1221e-04\n",
      "Epoch 92/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.9489e-04 - val_loss: 4.1390e-04\n",
      "Epoch 93/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.8932e-04 - val_loss: 4.3541e-04\n",
      "Epoch 94/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.8862e-04 - val_loss: 4.0751e-04\n",
      "Epoch 95/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.8851e-04 - val_loss: 4.0656e-04\n",
      "Epoch 96/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7763e-04 - val_loss: 4.0991e-04\n",
      "Epoch 97/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7580e-04 - val_loss: 3.9422e-04\n",
      "Epoch 98/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.7528e-04 - val_loss: 3.9918e-04\n",
      "Epoch 99/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.5994e-04 - val_loss: 3.9693e-04\n",
      "Epoch 100/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5472e-04 - val_loss: 4.4225e-04\n",
      "Epoch 101/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5487e-04 - val_loss: 4.2000e-04\n",
      "Epoch 102/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6496e-04 - val_loss: 4.1888e-04\n",
      "Epoch 103/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.4951e-04 - val_loss: 4.0037e-04\n",
      "Epoch 104/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3950e-04 - val_loss: 4.2731e-04\n",
      "Epoch 105/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3759e-04 - val_loss: 4.1469e-04\n",
      "Epoch 106/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3230e-04 - val_loss: 3.7950e-04\n",
      "Epoch 107/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3595e-04 - val_loss: 3.8065e-04\n",
      "Epoch 108/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3095e-04 - val_loss: 3.7216e-04\n",
      "Epoch 109/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2335e-04 - val_loss: 3.7399e-04\n",
      "Epoch 110/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.1636e-04 - val_loss: 3.8649e-04\n",
      "Epoch 111/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.1059e-04 - val_loss: 3.6691e-04\n",
      "Epoch 112/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0811e-04 - val_loss: 3.6476e-04\n",
      "Epoch 113/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0595e-04 - val_loss: 3.6331e-04\n",
      "Epoch 114/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.9918e-04 - val_loss: 3.8507e-04\n",
      "Epoch 115/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.9479e-04 - val_loss: 3.6575e-04\n",
      "Epoch 116/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0058e-04 - val_loss: 3.7657e-04\n",
      "Epoch 117/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.9043e-04 - val_loss: 3.9016e-04\n",
      "Epoch 118/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.8701e-04 - val_loss: 3.5862e-04\n",
      "Epoch 119/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0701e-04 - val_loss: 3.5392e-04\n",
      "Epoch 120/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.8205e-04 - val_loss: 3.6431e-04\n",
      "Epoch 121/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.7801e-04 - val_loss: 3.5453e-04\n",
      "Epoch 122/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.7776e-04 - val_loss: 3.4966e-04\n",
      "Epoch 123/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.6944e-04 - val_loss: 3.4822e-04\n",
      "Epoch 124/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.7293e-04 - val_loss: 3.8003e-04\n",
      "Epoch 125/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.6818e-04 - val_loss: 3.4797e-04\n",
      "Epoch 126/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.6469e-04 - val_loss: 3.4587e-04\n",
      "Epoch 127/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.6026e-04 - val_loss: 3.6100e-04\n",
      "Epoch 128/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.5915e-04 - val_loss: 3.7796e-04\n",
      "Epoch 129/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.5465e-04 - val_loss: 3.6059e-04\n",
      "Epoch 130/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.5029e-04 - val_loss: 3.5994e-04\n",
      "Epoch 131/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.5123e-04 - val_loss: 3.5176e-04\n",
      "Epoch 132/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.5045e-04 - val_loss: 3.4444e-04\n",
      "Epoch 133/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.4434e-04 - val_loss: 3.3568e-04\n",
      "Epoch 134/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.4817e-04 - val_loss: 3.5345e-04\n",
      "Epoch 135/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.3616e-04 - val_loss: 3.3319e-04\n",
      "Epoch 136/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.3985e-04 - val_loss: 3.5659e-04\n",
      "Epoch 137/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.3286e-04 - val_loss: 3.4082e-04\n",
      "Epoch 138/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.2649e-04 - val_loss: 3.3711e-04\n",
      "Epoch 139/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.2458e-04 - val_loss: 3.3035e-04\n",
      "Epoch 140/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.2804e-04 - val_loss: 3.2807e-04\n",
      "Epoch 141/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.2546e-04 - val_loss: 3.2947e-04\n",
      "Epoch 142/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.1682e-04 - val_loss: 3.5005e-04\n",
      "Epoch 143/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.1556e-04 - val_loss: 3.2609e-04\n",
      "Epoch 144/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.2179e-04 - val_loss: 3.5563e-04\n",
      "Epoch 145/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.1631e-04 - val_loss: 3.2470e-04\n",
      "Epoch 146/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.0858e-04 - val_loss: 3.4520e-04\n",
      "Epoch 147/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.1146e-04 - val_loss: 3.2658e-04\n",
      "Epoch 148/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.0645e-04 - val_loss: 3.2528e-04\n",
      "Epoch 149/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.0549e-04 - val_loss: 3.3088e-04\n",
      "Epoch 150/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.0967e-04 - val_loss: 3.2066e-04\n",
      "Epoch 151/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.0033e-04 - val_loss: 3.3474e-04\n",
      "Epoch 152/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.0077e-04 - val_loss: 3.2406e-04\n",
      "Epoch 153/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.9772e-04 - val_loss: 3.2122e-04\n",
      "Epoch 154/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.9186e-04 - val_loss: 3.1564e-04\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step - loss: 5.9193e-04 - val_loss: 3.1413e-04\n",
      "Epoch 156/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.9398e-04 - val_loss: 3.2560e-04\n",
      "Epoch 157/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.9473e-04 - val_loss: 3.2150e-04\n",
      "Epoch 158/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.8519e-04 - val_loss: 3.1137e-04\n",
      "Epoch 159/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.8770e-04 - val_loss: 3.1015e-04\n",
      "Epoch 160/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.8969e-04 - val_loss: 3.1069e-04\n",
      "Epoch 161/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.7865e-04 - val_loss: 3.1428e-04\n",
      "Epoch 162/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.7639e-04 - val_loss: 3.2461e-04\n",
      "Epoch 163/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.7542e-04 - val_loss: 3.1049e-04\n",
      "Epoch 164/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.7872e-04 - val_loss: 3.1521e-04\n",
      "Epoch 165/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.7844e-04 - val_loss: 3.1080e-04\n",
      "Epoch 166/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.7543e-04 - val_loss: 3.0611e-04\n",
      "Epoch 167/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.6874e-04 - val_loss: 3.0410e-04\n",
      "Epoch 168/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.6898e-04 - val_loss: 3.0646e-04\n",
      "Epoch 169/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.6807e-04 - val_loss: 3.1574e-04\n",
      "Epoch 170/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.6951e-04 - val_loss: 3.0221e-04\n",
      "Epoch 171/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.6669e-04 - val_loss: 3.1102e-04\n",
      "Epoch 172/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.6947e-04 - val_loss: 3.0632e-04\n",
      "Epoch 173/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.7547e-04 - val_loss: 3.3081e-04\n",
      "Epoch 174/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5889e-04 - val_loss: 3.0318e-04\n",
      "Epoch 175/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5606e-04 - val_loss: 2.9909e-04\n",
      "Epoch 176/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5291e-04 - val_loss: 3.2422e-04\n",
      "Epoch 177/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5507e-04 - val_loss: 3.0975e-04\n",
      "Epoch 178/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5912e-04 - val_loss: 3.4754e-04\n",
      "Epoch 179/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5679e-04 - val_loss: 3.0329e-04\n",
      "Epoch 180/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5010e-04 - val_loss: 3.0436e-04\n",
      "Epoch 181/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5373e-04 - val_loss: 3.1003e-04\n",
      "Epoch 182/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5393e-04 - val_loss: 2.9603e-04\n",
      "Epoch 183/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.4815e-04 - val_loss: 2.9409e-04\n",
      "Epoch 184/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.4662e-04 - val_loss: 2.9394e-04\n",
      "Epoch 185/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.4120e-04 - val_loss: 3.0891e-04\n",
      "Epoch 186/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5131e-04 - val_loss: 2.9199e-04\n",
      "Epoch 187/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3973e-04 - val_loss: 3.1722e-04\n",
      "Epoch 188/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.4414e-04 - val_loss: 2.9152e-04\n",
      "Epoch 189/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3791e-04 - val_loss: 2.9439e-04\n",
      "Epoch 190/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5379e-04 - val_loss: 3.0538e-04\n",
      "Epoch 191/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3944e-04 - val_loss: 2.9083e-04\n",
      "Epoch 192/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3617e-04 - val_loss: 2.8879e-04\n",
      "Epoch 193/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3397e-04 - val_loss: 3.2706e-04\n",
      "Epoch 194/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3727e-04 - val_loss: 2.9269e-04\n",
      "Epoch 195/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3129e-04 - val_loss: 3.0304e-04\n",
      "Epoch 196/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3115e-04 - val_loss: 2.9581e-04\n",
      "Epoch 197/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3242e-04 - val_loss: 3.0985e-04\n",
      "Epoch 198/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3011e-04 - val_loss: 3.1270e-04\n",
      "Epoch 199/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3528e-04 - val_loss: 2.8789e-04\n",
      "Epoch 200/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.2809e-04 - val_loss: 2.8726e-04\n",
      "Thời gian huấn luyện:  14.567809343338013\n",
      "Model: \"sequential_133\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_167 (Dense)           (None, 20, 95)            190       \n",
      "                                                                 \n",
      " flatten_133 (Flatten)       (None, 1900)              0         \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 1)                 1901      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,091\n",
      "Trainable params: 2,091\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 1s 9ms/step - loss: 0.0144 - val_loss: 0.0015\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 9.6667e-04\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 7.4465e-04\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 7.5073e-04\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 6.6562e-04\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 6.5175e-04\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 6.0388e-04\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 5.7562e-04\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 5.5936e-04\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 5.2786e-04\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 6.0697e-04\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 5.0576e-04\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 5.6819e-04\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 4.8487e-04\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 5.0657e-04\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 4.5351e-04\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 5.5200e-04\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.0423e-04\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 4.4667e-04\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8211e-04 - val_loss: 4.4777e-04\n",
      "Epoch 22/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8049e-04 - val_loss: 6.8967e-04\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.6330e-04 - val_loss: 4.7067e-04\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.4538e-04 - val_loss: 4.2334e-04\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.9917e-04 - val_loss: 4.0892e-04\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.3136e-04 - val_loss: 5.8404e-04\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.7703e-04 - val_loss: 4.0910e-04\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.6503e-04 - val_loss: 3.9021e-04\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.4072e-04 - val_loss: 4.0602e-04\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.2373e-04 - val_loss: 3.8321e-04\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.1377e-04 - val_loss: 4.0049e-04\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.3086e-04 - val_loss: 4.7037e-04\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.1421e-04 - val_loss: 3.6946e-04\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.8330e-04 - val_loss: 3.8465e-04\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.8075e-04 - val_loss: 4.7324e-04\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.9465e-04 - val_loss: 3.6607e-04\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.7460e-04 - val_loss: 4.6538e-04\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.6557e-04 - val_loss: 3.8028e-04\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.4235e-04 - val_loss: 3.5645e-04\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.4096e-04 - val_loss: 3.5969e-04\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.3241e-04 - val_loss: 5.1379e-04\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.2323e-04 - val_loss: 3.8517e-04\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.1494e-04 - val_loss: 3.7085e-04\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.0835e-04 - val_loss: 3.5018e-04\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.0755e-04 - val_loss: 3.4212e-04\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.0029e-04 - val_loss: 3.4495e-04\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.8334e-04 - val_loss: 4.0715e-04\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.9736e-04 - val_loss: 3.3503e-04\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.7162e-04 - val_loss: 3.5541e-04\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.7943e-04 - val_loss: 3.8813e-04\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.6373e-04 - val_loss: 3.2993e-04\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.9351e-04 - val_loss: 3.7180e-04\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.9464e-04 - val_loss: 3.2882e-04\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.5110e-04 - val_loss: 3.8186e-04\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.4629e-04 - val_loss: 3.5145e-04\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.5686e-04 - val_loss: 3.2185e-04\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.4116e-04 - val_loss: 3.8193e-04\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.4002e-04 - val_loss: 3.5129e-04\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.3395e-04 - val_loss: 3.2228e-04\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.3714e-04 - val_loss: 3.3313e-04\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.2002e-04 - val_loss: 3.8923e-04\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.6670e-04 - val_loss: 5.4036e-04\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.2522e-04 - val_loss: 3.4679e-04\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.1989e-04 - val_loss: 4.1609e-04\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.7531e-04 - val_loss: 4.5256e-04\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.1748e-04 - val_loss: 5.9081e-04\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.5073e-04 - val_loss: 3.0462e-04\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.9968e-04 - val_loss: 3.1221e-04\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.9057e-04 - val_loss: 4.2633e-04\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.8811e-04 - val_loss: 3.1364e-04\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.7999e-04 - val_loss: 2.9988e-04\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.7757e-04 - val_loss: 3.1703e-04\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.0797e-04 - val_loss: 2.9719e-04\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.7753e-04 - val_loss: 3.0001e-04\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.0622e-04 - val_loss: 4.5241e-04\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.7603e-04 - val_loss: 3.0451e-04\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.8675e-04 - val_loss: 3.7823e-04\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.7470e-04 - val_loss: 2.9057e-04\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.6580e-04 - val_loss: 3.0401e-04\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.6527e-04 - val_loss: 3.5649e-04\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.6297e-04 - val_loss: 2.8777e-04\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.4197e-04 - val_loss: 2.9679e-04\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.4773e-04 - val_loss: 2.9174e-04\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.5386e-04 - val_loss: 2.8646e-04\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.3343e-04 - val_loss: 2.9628e-04\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.4228e-04 - val_loss: 3.0199e-04\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.5113e-04 - val_loss: 3.1475e-04\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.4976e-04 - val_loss: 2.8725e-04\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.3519e-04 - val_loss: 4.3420e-04\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.4162e-04 - val_loss: 2.8820e-04\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.3481e-04 - val_loss: 2.8456e-04\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.3379e-04 - val_loss: 3.6280e-04\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.3982e-04 - val_loss: 2.7695e-04\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.2205e-04 - val_loss: 2.9890e-04\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.3704e-04 - val_loss: 2.8082e-04\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.2444e-04 - val_loss: 2.7513e-04\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.1929e-04 - val_loss: 2.9086e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.2460e-04 - val_loss: 2.7221e-04\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.1748e-04 - val_loss: 3.4343e-04\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.2765e-04 - val_loss: 2.7791e-04\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.1949e-04 - val_loss: 3.1968e-04\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.1694e-04 - val_loss: 3.5544e-04\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.1858e-04 - val_loss: 3.2025e-04\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.0991e-04 - val_loss: 2.7166e-04\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.2583e-04 - val_loss: 2.8640e-04\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.0521e-04 - val_loss: 2.6912e-04\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.0508e-04 - val_loss: 2.7909e-04\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.9973e-04 - val_loss: 2.7762e-04\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.0068e-04 - val_loss: 2.8142e-04\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.3668e-04 - val_loss: 2.6456e-04\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.9477e-04 - val_loss: 2.7941e-04\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.9616e-04 - val_loss: 2.6086e-04\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.1505e-04 - val_loss: 2.6817e-04\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.9705e-04 - val_loss: 4.1932e-04\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.9853e-04 - val_loss: 3.3196e-04\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.2109e-04 - val_loss: 2.9375e-04\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.9198e-04 - val_loss: 3.0105e-04\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.0302e-04 - val_loss: 2.9932e-04\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.0214e-04 - val_loss: 2.5677e-04\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.7133e-04 - val_loss: 2.5583e-04\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.7375e-04 - val_loss: 2.5879e-04\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.7481e-04 - val_loss: 2.7612e-04\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.6948e-04 - val_loss: 2.9599e-04\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.7342e-04 - val_loss: 2.5575e-04\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.6805e-04 - val_loss: 2.8133e-04\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.7229e-04 - val_loss: 3.5806e-04\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.0518e-04 - val_loss: 3.3650e-04\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6730e-04 - val_loss: 2.5132e-04\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.9613e-04 - val_loss: 2.5947e-04\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.7295e-04 - val_loss: 2.5996e-04\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.5979e-04 - val_loss: 2.5401e-04\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.6520e-04 - val_loss: 2.5049e-04\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.5936e-04 - val_loss: 3.1096e-04\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.6571e-04 - val_loss: 2.5449e-04\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.5997e-04 - val_loss: 2.4716e-04\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.5306e-04 - val_loss: 2.5202e-04\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.6154e-04 - val_loss: 2.6382e-04\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6734e-04 - val_loss: 2.4768e-04\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4932e-04 - val_loss: 2.7493e-04\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.6720e-04 - val_loss: 2.5773e-04\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8322e-04 - val_loss: 2.4780e-04\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.6131e-04 - val_loss: 2.4592e-04\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.5176e-04 - val_loss: 2.9161e-04\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.5032e-04 - val_loss: 2.7974e-04\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.7520e-04 - val_loss: 3.0877e-04\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.7737e-04 - val_loss: 2.4775e-04\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4098e-04 - val_loss: 2.4587e-04\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.5241e-04 - val_loss: 2.4441e-04\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3952e-04 - val_loss: 2.4204e-04\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.7799e-04 - val_loss: 3.0138e-04\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.5021e-04 - val_loss: 2.5193e-04\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3866e-04 - val_loss: 3.1684e-04\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.6132e-04 - val_loss: 2.6047e-04\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4145e-04 - val_loss: 2.6493e-04\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4467e-04 - val_loss: 2.6482e-04\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4235e-04 - val_loss: 2.5726e-04\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.5007e-04 - val_loss: 3.0000e-04\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.7968e-04 - val_loss: 2.8200e-04\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4409e-04 - val_loss: 2.7746e-04\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.4784e-04 - val_loss: 2.3909e-04\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3949e-04 - val_loss: 2.6681e-04\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3707e-04 - val_loss: 2.4112e-04\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3706e-04 - val_loss: 2.7847e-04\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3258e-04 - val_loss: 2.4333e-04\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.5676e-04 - val_loss: 2.5729e-04\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4140e-04 - val_loss: 2.3881e-04\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.4708e-04 - val_loss: 2.3675e-04\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3835e-04 - val_loss: 2.7123e-04\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2967e-04 - val_loss: 2.4484e-04\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.2958e-04 - val_loss: 2.4834e-04\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.2424e-04 - val_loss: 2.5316e-04\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2945e-04 - val_loss: 2.4067e-04\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3390e-04 - val_loss: 2.7254e-04\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3940e-04 - val_loss: 3.0475e-04\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6032e-04 - val_loss: 3.0010e-04\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2871e-04 - val_loss: 2.4600e-04\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.4323e-04 - val_loss: 3.1378e-04\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.4195e-04 - val_loss: 2.6019e-04\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.2687e-04 - val_loss: 2.3585e-04\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3685e-04 - val_loss: 2.7729e-04\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.1746e-04 - val_loss: 2.3937e-04\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.2043e-04 - val_loss: 2.3367e-04\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.2790e-04 - val_loss: 2.8642e-04\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3533e-04 - val_loss: 2.3788e-04\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3751e-04 - val_loss: 2.6838e-04\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3784e-04 - val_loss: 2.4006e-04\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.3720e-04 - val_loss: 2.3316e-04\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2144e-04 - val_loss: 2.3374e-04\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.2392e-04 - val_loss: 2.3833e-04\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.1772e-04 - val_loss: 2.3213e-04\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.2371e-04 - val_loss: 2.5002e-04\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2388e-04 - val_loss: 2.6211e-04\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.2082e-04 - val_loss: 2.3998e-04\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.6849e-04 - val_loss: 3.3252e-04\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.6023e-04 - val_loss: 2.3416e-04\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.2716e-04 - val_loss: 2.6262e-04\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.2761e-04 - val_loss: 2.3269e-04\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.2571e-04 - val_loss: 2.3957e-04\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.2402e-04 - val_loss: 2.3496e-04\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.1617e-04 - val_loss: 2.3118e-04\n",
      "Thời gian huấn luyện:  34.19559407234192\n",
      "Model: \"sequential_134\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_33 (SimpleRNN)   (None, 20, 102)           10608     \n",
      "                                                                 \n",
      " flatten_134 (Flatten)       (None, 2040)              0         \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 1)                 2041      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,649\n",
      "Trainable params: 12,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 2s 22ms/step - loss: 0.0095 - val_loss: 0.0011\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 8.1021e-04\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 7.7278e-04\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 7.3833e-04\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0022 - val_loss: 7.2808e-04\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 6.9911e-04\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 6.6708e-04\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 6.5231e-04\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 6.6165e-04\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 6.2500e-04\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 6.0459e-04\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 6.1823e-04\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 5.8657e-04\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 6.3420e-04\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 5.7308e-04\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 6.2152e-04\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 5.5927e-04\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 5.6795e-04\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 5.5269e-04\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 5.5624e-04\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 5.3500e-04\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 5.2739e-04\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 6.1971e-04\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 5.2381e-04\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 5.1728e-04\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 5.3447e-04\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 5.0487e-04\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 5.0993e-04\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 5.1645e-04\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 4.8281e-04\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 4.8388e-04\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 4.7509e-04\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 4.8711e-04\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 4.6782e-04\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 4.6155e-04\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 5.5765e-04\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.0011 - val_loss: 4.5869e-04\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 4.5094e-04\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 4.5235e-04\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 4.5372e-04\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 4.4283e-04\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 4.4143e-04\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 4.3570e-04\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 4.6136e-04\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 4.3777e-04\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 9.9932e-04 - val_loss: 4.2663e-04\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 9.9458e-04 - val_loss: 4.3276e-04\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 4.9688e-04\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 4.2525e-04\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 9.9267e-04 - val_loss: 4.7278e-04\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 9.9405e-04 - val_loss: 4.2708e-04\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 9.6772e-04 - val_loss: 4.5616e-04\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 9.6132e-04 - val_loss: 4.6243e-04\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 9.4365e-04 - val_loss: 4.0763e-04\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 9.3024e-04 - val_loss: 4.4153e-04\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 9.2459e-04 - val_loss: 4.1910e-04\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 9.1813e-04 - val_loss: 4.0371e-04\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 9.0272e-04 - val_loss: 4.0967e-04\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 9.0495e-04 - val_loss: 3.9689e-04\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 9.3211e-04 - val_loss: 4.2868e-04\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 8.8783e-04 - val_loss: 4.3346e-04\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 8.7571e-04 - val_loss: 3.9177e-04\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 8.6623e-04 - val_loss: 4.0499e-04\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 8.7192e-04 - val_loss: 3.8890e-04\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 8.6358e-04 - val_loss: 5.4509e-04\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 8.6354e-04 - val_loss: 4.4273e-04\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 8.5276e-04 - val_loss: 3.8700e-04\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 8.4814e-04 - val_loss: 4.4327e-04\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 8.4021e-04 - val_loss: 3.7964e-04\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 8.2564e-04 - val_loss: 3.9547e-04\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 8.2283e-04 - val_loss: 3.9585e-04\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 8.3009e-04 - val_loss: 3.7672e-04\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 8.0646e-04 - val_loss: 4.0920e-04\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 8.0517e-04 - val_loss: 3.7432e-04\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 8.0288e-04 - val_loss: 3.7739e-04\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.9161e-04 - val_loss: 3.8397e-04\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.9729e-04 - val_loss: 3.8249e-04\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.8149e-04 - val_loss: 3.6632e-04\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.7467e-04 - val_loss: 3.6501e-04\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.7332e-04 - val_loss: 4.1027e-04\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.8016e-04 - val_loss: 3.7991e-04\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.6824e-04 - val_loss: 3.6254e-04\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.6508e-04 - val_loss: 4.0135e-04\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.7456e-04 - val_loss: 3.5874e-04\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.6641e-04 - val_loss: 4.1489e-04\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.4312e-04 - val_loss: 3.8144e-04\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.3901e-04 - val_loss: 3.7005e-04\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.4299e-04 - val_loss: 3.5464e-04\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.3988e-04 - val_loss: 3.6826e-04\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.3597e-04 - val_loss: 3.5362e-04\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.2890e-04 - val_loss: 3.5660e-04\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.2776e-04 - val_loss: 3.5592e-04\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.2848e-04 - val_loss: 3.5324e-04\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.1959e-04 - val_loss: 3.5038e-04\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.1334e-04 - val_loss: 3.6233e-04\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.5039e-04 - val_loss: 3.5973e-04\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.1641e-04 - val_loss: 3.7029e-04\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.2316e-04 - val_loss: 3.8504e-04\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.2245e-04 - val_loss: 3.6508e-04\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.9059e-04 - val_loss: 3.8463e-04\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.4121e-04 - val_loss: 3.6334e-04\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.9271e-04 - val_loss: 3.4619e-04\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.8074e-04 - val_loss: 3.4154e-04\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.9250e-04 - val_loss: 3.9644e-04\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.0287e-04 - val_loss: 3.4336e-04\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.1459e-04 - val_loss: 3.3961e-04\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.9587e-04 - val_loss: 4.9675e-04\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.9904e-04 - val_loss: 3.6192e-04\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.7787e-04 - val_loss: 3.5785e-04\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 6.7169e-04 - val_loss: 3.5700e-04\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.6693e-04 - val_loss: 3.3189e-04\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.0135e-04 - val_loss: 3.7697e-04\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.6877e-04 - val_loss: 3.6152e-04\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.7226e-04 - val_loss: 3.3161e-04\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.5427e-04 - val_loss: 3.9931e-04\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 12ms/step - loss: 6.7360e-04 - val_loss: 3.3009e-04\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.4676e-04 - val_loss: 4.1621e-04\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.6756e-04 - val_loss: 3.2715e-04\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.6780e-04 - val_loss: 4.6504e-04\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.5951e-04 - val_loss: 3.5645e-04\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.7282e-04 - val_loss: 3.8206e-04\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.6906e-04 - val_loss: 3.2542e-04\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.4851e-04 - val_loss: 3.2442e-04\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.2864e-04 - val_loss: 3.2099e-04\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.3797e-04 - val_loss: 3.7627e-04\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.2392e-04 - val_loss: 3.3938e-04\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.4204e-04 - val_loss: 3.1729e-04\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.3008e-04 - val_loss: 3.4857e-04\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.1898e-04 - val_loss: 3.3854e-04\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.2324e-04 - val_loss: 3.2271e-04\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.1579e-04 - val_loss: 3.2200e-04\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.1235e-04 - val_loss: 3.1361e-04\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.3021e-04 - val_loss: 3.1274e-04\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.1189e-04 - val_loss: 3.1098e-04\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.0899e-04 - val_loss: 3.3148e-04\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.1744e-04 - val_loss: 3.2763e-04\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.0851e-04 - val_loss: 3.1255e-04\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.9653e-04 - val_loss: 3.4506e-04\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.2606e-04 - val_loss: 3.3855e-04\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.0563e-04 - val_loss: 3.0604e-04\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.0915e-04 - val_loss: 3.2227e-04\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.9275e-04 - val_loss: 3.0579e-04\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.9345e-04 - val_loss: 3.0653e-04\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.7761e-04 - val_loss: 3.0526e-04\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.8435e-04 - val_loss: 3.0945e-04\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.7753e-04 - val_loss: 3.0162e-04\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.8281e-04 - val_loss: 3.2226e-04\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.7219e-04 - val_loss: 3.0129e-04\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 5.6999e-04 - val_loss: 2.9814e-04\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.6381e-04 - val_loss: 3.3445e-04\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.8354e-04 - val_loss: 3.1352e-04\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.9444e-04 - val_loss: 3.1301e-04\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.7034e-04 - val_loss: 2.9310e-04\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.6877e-04 - val_loss: 3.2528e-04\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.6244e-04 - val_loss: 3.2601e-04\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.6021e-04 - val_loss: 2.9423e-04\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.5612e-04 - val_loss: 2.9565e-04\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.5336e-04 - val_loss: 2.9218e-04\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.6587e-04 - val_loss: 3.0317e-04\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.9203e-04 - val_loss: 3.7764e-04\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.7005e-04 - val_loss: 3.0651e-04\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.4607e-04 - val_loss: 2.8706e-04\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.4328e-04 - val_loss: 3.0870e-04\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.4774e-04 - val_loss: 3.4002e-04\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.6025e-04 - val_loss: 2.8417e-04\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.4061e-04 - val_loss: 2.9825e-04\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.4855e-04 - val_loss: 3.1714e-04\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.8352e-04 - val_loss: 3.1692e-04\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.6023e-04 - val_loss: 2.8321e-04\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.6128e-04 - val_loss: 2.8192e-04\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.3269e-04 - val_loss: 2.8031e-04\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.3356e-04 - val_loss: 2.8058e-04\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.2801e-04 - val_loss: 2.9248e-04\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.3040e-04 - val_loss: 2.9436e-04\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.3059e-04 - val_loss: 3.0999e-04\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.2458e-04 - val_loss: 2.7988e-04\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.2093e-04 - val_loss: 2.8059e-04\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.1649e-04 - val_loss: 2.7499e-04\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.1412e-04 - val_loss: 2.7770e-04\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.1363e-04 - val_loss: 4.0423e-04\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.9729e-04 - val_loss: 2.7685e-04\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.1880e-04 - val_loss: 2.7244e-04\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.1432e-04 - val_loss: 3.1248e-04\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.2158e-04 - val_loss: 3.0346e-04\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.2937e-04 - val_loss: 2.7790e-04\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.0796e-04 - val_loss: 2.7443e-04\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.0819e-04 - val_loss: 2.6841e-04\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.0621e-04 - val_loss: 2.9851e-04\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.2033e-04 - val_loss: 2.6831e-04\n",
      "Epoch 190/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 12ms/step - loss: 4.9836e-04 - val_loss: 3.0824e-04\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.0484e-04 - val_loss: 3.0176e-04\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.0080e-04 - val_loss: 2.6624e-04\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.1802e-04 - val_loss: 2.7664e-04\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 4.9649e-04 - val_loss: 2.6437e-04\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.0817e-04 - val_loss: 2.6420e-04\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.3343e-04 - val_loss: 3.1511e-04\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 4.9624e-04 - val_loss: 2.7097e-04\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 4.9056e-04 - val_loss: 2.8799e-04\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 4.9713e-04 - val_loss: 2.7807e-04\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 4.9196e-04 - val_loss: 2.8971e-04\n",
      "Thời gian huấn luyện:  88.55929350852966\n",
      "Model: \"sequential_135\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_33 (LSTM)              (None, 20, 102)           42432     \n",
      "                                                                 \n",
      " flatten_135 (Flatten)       (None, 2040)              0         \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 1)                 2041      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,473\n",
      "Trainable params: 44,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 2s 20ms/step - loss: 0.0145 - val_loss: 7.2305e-04\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 7.0538e-04\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 6.6333e-04\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 6.3581e-04\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 6.2453e-04\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 6.0480e-04\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 5.9469e-04\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 5.6783e-04\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 5.5445e-04\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 5.7128e-04\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 5.3752e-04\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 5.3458e-04\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 5.2099e-04\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 5.2521e-04\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 5.4636e-04\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 5.0379e-04\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 4.8098e-04\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 4.7300e-04\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 4.7299e-04\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 4.6348e-04\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 4.5181e-04\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 4.8825e-04\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 4.3908e-04\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 9.9658e-04 - val_loss: 4.3864e-04\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 9.8859e-04 - val_loss: 4.7082e-04\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 9.7347e-04 - val_loss: 4.2019e-04\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 9.6642e-04 - val_loss: 4.1566e-04\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 9.4202e-04 - val_loss: 4.1754e-04\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 9.2162e-04 - val_loss: 4.1201e-04\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 9.0488e-04 - val_loss: 4.1754e-04\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 8.9448e-04 - val_loss: 4.0939e-04\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 8.7479e-04 - val_loss: 3.9144e-04\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 8.6545e-04 - val_loss: 3.9203e-04\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 8.5216e-04 - val_loss: 3.9778e-04\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 8.3813e-04 - val_loss: 3.8066e-04\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 8.2952e-04 - val_loss: 3.8761e-04\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 8.2236e-04 - val_loss: 4.0178e-04\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 8.3581e-04 - val_loss: 3.7094e-04\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.9438e-04 - val_loss: 3.7256e-04\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.8658e-04 - val_loss: 3.8189e-04\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 7.8907e-04 - val_loss: 3.8587e-04\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 7.6526e-04 - val_loss: 3.6008e-04\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 7.6902e-04 - val_loss: 3.5923e-04\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 7.4316e-04 - val_loss: 3.7777e-04\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 7.4595e-04 - val_loss: 3.6293e-04\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 7.3626e-04 - val_loss: 3.5338e-04\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 7.4053e-04 - val_loss: 3.7990e-04\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 7.4024e-04 - val_loss: 3.5703e-04\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 7.1964e-04 - val_loss: 3.5329e-04\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 7.0478e-04 - val_loss: 3.4332e-04\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 7.0205e-04 - val_loss: 3.4242e-04\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 7.0621e-04 - val_loss: 3.3900e-04\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.8429e-04 - val_loss: 3.4785e-04\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.8856e-04 - val_loss: 3.5090e-04\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.9567e-04 - val_loss: 3.4589e-04\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.6879e-04 - val_loss: 3.4070e-04\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 11ms/step - loss: 6.7400e-04 - val_loss: 3.3296e-04\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.6284e-04 - val_loss: 3.3208e-04\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.6175e-04 - val_loss: 3.3266e-04\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.6275e-04 - val_loss: 3.3452e-04\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.4853e-04 - val_loss: 3.3283e-04\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.4208e-04 - val_loss: 3.2850e-04\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.3637e-04 - val_loss: 3.2337e-04\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.4186e-04 - val_loss: 3.2382e-04\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.3356e-04 - val_loss: 3.2156e-04\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.3580e-04 - val_loss: 3.3287e-04\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.3804e-04 - val_loss: 3.1995e-04\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.1767e-04 - val_loss: 3.3420e-04\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.2631e-04 - val_loss: 3.7847e-04\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.1500e-04 - val_loss: 3.1797e-04\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.0869e-04 - val_loss: 3.2882e-04\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.1871e-04 - val_loss: 3.1311e-04\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.0581e-04 - val_loss: 3.1158e-04\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.9894e-04 - val_loss: 3.1438e-04\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.9852e-04 - val_loss: 3.1967e-04\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.0544e-04 - val_loss: 3.0946e-04\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.0866e-04 - val_loss: 3.1313e-04\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.9488e-04 - val_loss: 3.0723e-04\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.8693e-04 - val_loss: 3.1420e-04\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.8359e-04 - val_loss: 3.0527e-04\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.7683e-04 - val_loss: 3.0363e-04\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.7195e-04 - val_loss: 3.0334e-04\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.7942e-04 - val_loss: 3.0439e-04\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.8677e-04 - val_loss: 3.3126e-04\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.7734e-04 - val_loss: 3.1882e-04\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.0611e-04 - val_loss: 3.1273e-04\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.6056e-04 - val_loss: 3.0027e-04\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.6126e-04 - val_loss: 3.3330e-04\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.5923e-04 - val_loss: 3.0086e-04\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.5260e-04 - val_loss: 2.9786e-04\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.6195e-04 - val_loss: 2.9392e-04\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.5098e-04 - val_loss: 3.0195e-04\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.5375e-04 - val_loss: 3.6521e-04\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.5489e-04 - val_loss: 2.9996e-04\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.5811e-04 - val_loss: 3.0227e-04\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.5110e-04 - val_loss: 2.9758e-04\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.4210e-04 - val_loss: 2.8805e-04\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.3351e-04 - val_loss: 2.9700e-04\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.3192e-04 - val_loss: 2.8773e-04\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.4607e-04 - val_loss: 3.0297e-04\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.3834e-04 - val_loss: 2.8447e-04\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.2640e-04 - val_loss: 3.2219e-04\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.3918e-04 - val_loss: 2.9259e-04\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.3038e-04 - val_loss: 2.8398e-04\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.2130e-04 - val_loss: 3.4824e-04\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.3928e-04 - val_loss: 2.7984e-04\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.2686e-04 - val_loss: 2.8117e-04\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.3254e-04 - val_loss: 3.1694e-04\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.1720e-04 - val_loss: 2.7833e-04\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.0870e-04 - val_loss: 2.8228e-04\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.2003e-04 - val_loss: 2.8911e-04\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.0564e-04 - val_loss: 3.0728e-04\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.2684e-04 - val_loss: 2.8283e-04\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.1818e-04 - val_loss: 2.8912e-04\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.0206e-04 - val_loss: 2.7745e-04\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.1107e-04 - val_loss: 2.7503e-04\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.0508e-04 - val_loss: 2.7863e-04\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.0223e-04 - val_loss: 2.7700e-04\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.9688e-04 - val_loss: 2.6953e-04\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.9413e-04 - val_loss: 2.7149e-04\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.9123e-04 - val_loss: 2.6876e-04\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.0179e-04 - val_loss: 2.6717e-04\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.9012e-04 - val_loss: 2.6740e-04\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.9172e-04 - val_loss: 2.6576e-04\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.9098e-04 - val_loss: 2.7886e-04\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.8351e-04 - val_loss: 2.6871e-04\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.8728e-04 - val_loss: 2.6456e-04\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.7974e-04 - val_loss: 2.6258e-04\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.8188e-04 - val_loss: 2.7845e-04\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.9571e-04 - val_loss: 3.1267e-04\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.0979e-04 - val_loss: 2.6331e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.7919e-04 - val_loss: 2.6046e-04\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.8180e-04 - val_loss: 2.7355e-04\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.7744e-04 - val_loss: 2.6681e-04\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 5.0512e-04 - val_loss: 2.6438e-04\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.7746e-04 - val_loss: 2.6286e-04\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.7163e-04 - val_loss: 2.7275e-04\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.9963e-04 - val_loss: 2.8583e-04\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.6857e-04 - val_loss: 2.5857e-04\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.7912e-04 - val_loss: 4.5824e-04\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.8896e-04 - val_loss: 2.7592e-04\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.6702e-04 - val_loss: 2.6780e-04\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.6609e-04 - val_loss: 2.6002e-04\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 4.8006e-04 - val_loss: 2.6408e-04\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 4.6758e-04 - val_loss: 2.6514e-04\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.6615e-04 - val_loss: 2.9446e-04\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.5713e-04 - val_loss: 2.5430e-04\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.6471e-04 - val_loss: 2.7304e-04\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.6225e-04 - val_loss: 2.5874e-04\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.5406e-04 - val_loss: 2.5925e-04\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.5342e-04 - val_loss: 2.5850e-04\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.5075e-04 - val_loss: 2.4833e-04\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.4893e-04 - val_loss: 2.5720e-04\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.4851e-04 - val_loss: 2.4735e-04\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.5688e-04 - val_loss: 2.4974e-04\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.5665e-04 - val_loss: 2.4653e-04\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.5124e-04 - val_loss: 2.6342e-04\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.5942e-04 - val_loss: 2.5588e-04\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.4232e-04 - val_loss: 2.5253e-04\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.5239e-04 - val_loss: 2.8367e-04\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.4847e-04 - val_loss: 2.4693e-04\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.5275e-04 - val_loss: 2.4344e-04\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.4205e-04 - val_loss: 2.4372e-04\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.3934e-04 - val_loss: 2.4808e-04\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.4634e-04 - val_loss: 2.7502e-04\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.5028e-04 - val_loss: 2.5129e-04\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.4806e-04 - val_loss: 2.8073e-04\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.3935e-04 - val_loss: 2.5392e-04\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.5399e-04 - val_loss: 2.5998e-04\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.3849e-04 - val_loss: 2.4566e-04\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.3316e-04 - val_loss: 2.4093e-04\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.3524e-04 - val_loss: 2.4123e-04\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.3455e-04 - val_loss: 2.4285e-04\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.2792e-04 - val_loss: 2.7490e-04\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.3115e-04 - val_loss: 2.5055e-04\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.3635e-04 - val_loss: 2.3849e-04\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.3120e-04 - val_loss: 3.0846e-04\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.3450e-04 - val_loss: 2.3754e-04\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.2804e-04 - val_loss: 2.3714e-04\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.2981e-04 - val_loss: 2.3741e-04\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.2823e-04 - val_loss: 2.4256e-04\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.5558e-04 - val_loss: 2.3700e-04\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.2434e-04 - val_loss: 2.3872e-04\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.3046e-04 - val_loss: 2.6049e-04\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.3472e-04 - val_loss: 2.4451e-04\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.1828e-04 - val_loss: 3.0273e-04\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 4.3488e-04 - val_loss: 2.9880e-04\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.5413e-04 - val_loss: 2.6236e-04\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.1995e-04 - val_loss: 2.3439e-04\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 4.2289e-04 - val_loss: 2.6760e-04\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.3015e-04 - val_loss: 2.4455e-04\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.2698e-04 - val_loss: 2.3684e-04\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.2102e-04 - val_loss: 2.3345e-04\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.1836e-04 - val_loss: 2.3725e-04\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.2214e-04 - val_loss: 2.4283e-04\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.2207e-04 - val_loss: 2.3318e-04\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.1858e-04 - val_loss: 2.3352e-04\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.2830e-04 - val_loss: 2.3241e-04\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.2686e-04 - val_loss: 2.8224e-04\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.2915e-04 - val_loss: 2.3346e-04\n",
      "Thời gian huấn luyện:  80.53283381462097\n",
      "Model: \"sequential_136\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_33 (GRU)                (None, 20, 102)           32130     \n",
      "                                                                 \n",
      " flatten_136 (Flatten)       (None, 2040)              0         \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 1)                 2041      \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Total params: 34,171\n",
      "Trainable params: 34,171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "FFNN_data, FFNN_params = prepare_best_params(information_FFNN_df,ds, look_back, opt)\n",
    "FFNN_delta, FFNN_model = create_ffnn_model(*FFNN_params)\n",
    "FFNN_mse, FFNN_mae, FFNN_mape, FFNN_rmse, FFNN_trainPredict, FFNN_testPredict = create_accuracy(FFNN_model, scaler, *FFNN_data)\n",
    "compare_table.append([FFNN_mse, FFNN_mae, FFNN_mape, FFNN_rmse, FFNN_delta])\n",
    "    \n",
    "RNN_data, RNN_params = prepare_best_params(information_RNN_df,ds, look_back, opt)\n",
    "RNN_delta, RNN_model = create_rnn_model(*RNN_params)\n",
    "RNN_mse, RNN_mae, RNN_mape, RNN_rmse, RNN_trainPredict, RNN_testPredict = create_accuracy(RNN_model, scaler, *RNN_data)\n",
    "compare_table.append([RNN_mse, RNN_mae, RNN_mape, RNN_rmse, RNN_delta])\n",
    "    \n",
    "LSTM_data, LSTM_params = prepare_best_params(information_LSTM_df,ds, look_back, opt)\n",
    "LSTM_delta, LSTM_model = create_lstm_model(*LSTM_params)\n",
    "LSTM_mse, LSTM_mae, LSTM_mape, LSTM_rmse, LSTM_trainPredict, LSTM_testPredict = create_accuracy(LSTM_model, scaler, *LSTM_data)\n",
    "compare_table.append([LSTM_mse, LSTM_mae, LSTM_mape, LSTM_rmse, LSTM_delta])\n",
    "    \n",
    "GRU_data, GRU_params = prepare_best_params(information_GRU_df,ds, look_back, opt)\n",
    "GRU_delta, GRU_model = create_gru_model(*GRU_params)\n",
    "GRU_mse, GRU_mae, GRU_mape, GRU_rmse, GRU_trainPredict, GRU_testPredict = create_accuracy(GRU_model, scaler, *GRU_data)\n",
    "compare_table.append([GRU_mse, GRU_mae, GRU_mape, GRU_rmse, GRU_delta])\n",
    "\n",
    "#Save models\n",
    "FFNN_model.save('ffnn_model.h5')\n",
    "RNN_model.save('rnn_model.h5')\n",
    "LSTM_model.save('lstm_model.h5')\n",
    "GRU_model.save('gru_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "911fde1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FFNN</th>\n",
       "      <td>0.098</td>\n",
       "      <td>0.223</td>\n",
       "      <td>1.372</td>\n",
       "      <td>0.313</td>\n",
       "      <td>14.577812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RNN</th>\n",
       "      <td>0.076</td>\n",
       "      <td>0.194</td>\n",
       "      <td>1.193</td>\n",
       "      <td>0.276</td>\n",
       "      <td>34.203597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>0.095</td>\n",
       "      <td>0.218</td>\n",
       "      <td>1.333</td>\n",
       "      <td>0.308</td>\n",
       "      <td>88.566298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU</th>\n",
       "      <td>0.077</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.197</td>\n",
       "      <td>0.278</td>\n",
       "      <td>80.541833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MSE    MAE   MAPE   RMSE  Training Time\n",
       "FFNN  0.098  0.223  1.372  0.313      14.577812\n",
       "RNN   0.076  0.194  1.193  0.276      34.203597\n",
       "LSTM  0.095  0.218  1.333  0.308      88.566298\n",
       "GRU   0.077  0.195  1.197  0.278      80.541833"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_table = pd.DataFrame(compare_table, index=[\"FFNN\", \"RNN\", \"LSTM\", \"GRU\"], columns=[\"MSE\", \"MAE\", \"MAPE\", \"RMSE\", \"Training Time\"])\n",
    "compare_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f283c24",
   "metadata": {},
   "source": [
    "### So best params are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18ff8be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "look_back, opt, epochs, batch_size, validation\n",
      "FFNN [30, <keras.optimizers.optimizer_v2.adam.Adam object at 0x00000198C4687A30>, 200, 32, 0.2]\n",
      "RNN [30, <keras.optimizers.optimizer_v2.adam.Adam object at 0x00000198C4687A30>, 200, 32, 0.15]\n",
      "LSTM [30, <keras.optimizers.optimizer_v2.adam.Adam object at 0x00000198C4687A30>, 200, 32, 0.2]\n",
      "GRU [30, <keras.optimizers.optimizer_v2.adam.Adam object at 0x00000198C4687A30>, 200, 32, 0.1]\n"
     ]
    }
   ],
   "source": [
    "print(\"look_back, opt, epochs, batch_size, validation\")\n",
    "print(\"FFNN\", FFNN_params[2:])\n",
    "print(\"RNN\", RNN_params[2:])\n",
    "print(\"LSTM\", LSTM_params[2:])\n",
    "print(\"GRU\", GRU_params[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439069e2",
   "metadata": {},
   "source": [
    "## So the best model in this case is RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da7f1900",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RNN_model\n",
    "trainPredict = RNN_trainPredict\n",
    "testPredict = RNN_testPredict\n",
    "model_name = \"RNN\"\n",
    "mse, mae, mape, rmse = LSTM_mse, LSTM_mae, LSTM_mape, LSTM_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e64dbe3",
   "metadata": {},
   "source": [
    "## Trực quan hóa kết quả dự đoán của best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51247994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1430x770 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RNN</th>\n",
       "      <td>20.577</td>\n",
       "      <td>2.701</td>\n",
       "      <td>2.033</td>\n",
       "      <td>4.536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MSE    MAE   MAPE   RMSE\n",
       "RNN  20.577  2.701  2.033  4.536"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_plot(ds, trainPredict, testPredict, scaler, look_back, model_name, stock_name)\n",
    "pd.DataFrame([[mse, mae, mape, rmse]], index=[model_name], columns=[\"MSE\", \"MAE\", \"MAPE\", \"RMSE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92685df7",
   "metadata": {},
   "source": [
    "## Remake model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1945ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_best_params(info_df, ds, look_back, opt):\n",
    "    index = info_df.MSE.argmin()\n",
    "    ratio = info_df.iloc[index, 1]\n",
    "    epochs = info_df.iloc[index, 2]\n",
    "    batch_size = info_df.iloc[index, 3]\n",
    "    validation = info_df.iloc[index, 4]\n",
    "    \n",
    "    train_size = int(len(ds) * ratio)\n",
    "    test_size = len(ds) - train_size\n",
    "    train, test = ds[0:train_size,:], ds[train_size:len(ds)+1,:]\n",
    "    trainX, trainY, testX, testY = create_train_test_data(train, test, look_back)\n",
    "    \n",
    "    return [trainX, trainY, testX, testY], [trainX, trainY, look_back, opt, epochs, batch_size, validation]\n",
    "\n",
    "look_back = 30\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "epochs = 200\n",
    "batch_size = 32 \n",
    "validation_split = 0.2\n",
    "\n",
    "train_size = int(len(ds) * ratio)\n",
    "    test_size = len(ds) - train_size\n",
    "    train, test = ds[0:train_size,:], ds[train_size:len(ds)+1,:]\n",
    "    trainX, trainY, testX, testY = create_train_test_data(train, test, look_back)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
