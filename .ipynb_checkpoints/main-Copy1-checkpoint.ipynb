{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d05ab8a",
   "metadata": {},
   "source": [
    "# Load thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd15c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from tabulate import tabulate\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import SimpleRNN\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import pandas_datareader.data as web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62625b21",
   "metadata": {},
   "source": [
    "# Chuẩn bị dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b91ce7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_name = \"MANU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc88cf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = web.DataReader(stock_name,data_source=\"yahoo\",start=\"01/01/2005\",end=\"01/01/2019\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c874f93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1607.000000</td>\n",
       "      <td>1607.000000</td>\n",
       "      <td>1607.000000</td>\n",
       "      <td>1607.000000</td>\n",
       "      <td>1.607000e+03</td>\n",
       "      <td>1607.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.324294</td>\n",
       "      <td>16.875924</td>\n",
       "      <td>17.102620</td>\n",
       "      <td>17.084941</td>\n",
       "      <td>9.891637e+04</td>\n",
       "      <td>16.007120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.256755</td>\n",
       "      <td>2.174038</td>\n",
       "      <td>2.217825</td>\n",
       "      <td>2.216720</td>\n",
       "      <td>8.117236e+05</td>\n",
       "      <td>2.213693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.350000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.060000</td>\n",
       "      <td>12.180000</td>\n",
       "      <td>1.600000e+03</td>\n",
       "      <td>11.291115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.035001</td>\n",
       "      <td>15.700000</td>\n",
       "      <td>15.860000</td>\n",
       "      <td>15.850000</td>\n",
       "      <td>2.165000e+04</td>\n",
       "      <td>14.762630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.070000</td>\n",
       "      <td>16.650000</td>\n",
       "      <td>16.870001</td>\n",
       "      <td>16.850000</td>\n",
       "      <td>3.780000e+04</td>\n",
       "      <td>15.713005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.299999</td>\n",
       "      <td>17.835000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>18.070000</td>\n",
       "      <td>7.050000e+04</td>\n",
       "      <td>16.856253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27.700001</td>\n",
       "      <td>25.780001</td>\n",
       "      <td>26.049999</td>\n",
       "      <td>26.200001</td>\n",
       "      <td>3.184620e+07</td>\n",
       "      <td>25.054594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              High          Low         Open        Close        Volume  \\\n",
       "count  1607.000000  1607.000000  1607.000000  1607.000000  1.607000e+03   \n",
       "mean     17.324294    16.875924    17.102620    17.084941  9.891637e+04   \n",
       "std       2.256755     2.174038     2.217825     2.216720  8.117236e+05   \n",
       "min      12.350000    12.000000    12.060000    12.180000  1.600000e+03   \n",
       "25%      16.035001    15.700000    15.860000    15.850000  2.165000e+04   \n",
       "50%      17.070000    16.650000    16.870001    16.850000  3.780000e+04   \n",
       "75%      18.299999    17.835000    18.100000    18.070000  7.050000e+04   \n",
       "max      27.700001    25.780001    26.049999    26.200001  3.184620e+07   \n",
       "\n",
       "         Adj Close  \n",
       "count  1607.000000  \n",
       "mean     16.007120  \n",
       "std       2.213693  \n",
       "min      11.291115  \n",
       "25%      14.762630  \n",
       "50%      15.713005  \n",
       "75%      16.856253  \n",
       "max      25.054594  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27453666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1607, 1)             Close\n",
      "Date             \n",
      "2012-08-10  14.00\n",
      "2012-08-13  14.15\n",
      "2012-08-14  14.20\n",
      "2012-08-15  14.05\n",
      "2012-08-16  13.77\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = raw_data.dropna()\n",
    "df = df[['Close']]\n",
    "first_price = df.Close.iloc[0]\n",
    "print(df.shape, df.head())\n",
    "\n",
    "df.Close.plot()\n",
    "def create_ds(ds, look_back):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(ds)-look_back-1): \n",
    "        data = ds[i:(i+look_back), 0]      \n",
    "        dataX.append(data)\n",
    "        dataY.append(ds[i + look_back, 0]) \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "ds = df.values\n",
    "ds = ds.astype('float32')\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "ds = scaler.fit_transform(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90a229de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Chia tập train và tập test theo ty lệ 0.85, 0.15\n",
    "# train_size = int(len(ds) * 0.85)\n",
    "# test_size = len(ds) - train_size\n",
    "# train, test = ds[0:train_size,:], ds[train_size:len(ds)+1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560617e4",
   "metadata": {},
   "source": [
    "# outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6323037",
   "metadata": {},
   "source": [
    "#### 1:\n",
    "#### Đầu vào: train, test, look_back, opt, epochs, batch_size, validation_split\n",
    "#### Đầu ra: Trained model\n",
    "#### 2:\n",
    "#### Đầu vào: 4 trained models\n",
    "#### Đầu ra: 4 plots + bảng so sánh độ chính xác"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865ea794",
   "metadata": {},
   "source": [
    "# Xây dựng models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1f28081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_data(train, test, look_back):\n",
    "    trainX, trainY = create_ds(train, look_back)\n",
    "    testX, testY = create_ds(test, look_back)\n",
    "\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "    testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21a7835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainX, trainY, testX, testY = create_train_test_data(train, test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c4a1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_nodes = math.sqrt(len(trainX) * 3) + 2 * math.sqrt(len(trainX) / 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b7e608",
   "metadata": {},
   "source": [
    "## FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2713269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ffnn_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split):\n",
    "    # create model\n",
    "    hidden_nodes = int(math.sqrt(len(trainX) * 3) + 2 * math.sqrt(len(trainX) / 3))\n",
    "    model_ffnn = Sequential()\n",
    "    model_ffnn.add(Dense(hidden_nodes, input_shape = (trainX.shape[1],trainX.shape[2]), activation = 'relu', kernel_initializer='uniform'))\n",
    "#     model_ffnn.add(Dropout(0.4))\n",
    "#     model_ffnn.add(Dense(400, activation = 'relu', kernel_initializer='uniform' ))\n",
    "#     model_ffnn.add(Dropout(0.3))\n",
    "#     model_ffnn.add(Dense(150, activation = 'relu' ))\n",
    "#     model_ffnn.add(Dropout(0.3))\n",
    "#     model_ffnn.add(Dense(100, activation = 'hard_sigmoid' ))\n",
    "#     model_ffnn.add(Dropout(0.2))\n",
    "#     model_ffnn.add(Dense(50, activation = 'relu' ))\n",
    "#     model_ffnn.add(Dropout(0.1))\n",
    "#     model_ffnn.add(Dense(10, activation = 'relu' ))\n",
    "    model_ffnn.add(Flatten())\n",
    "    model_ffnn.add(Dense(1, activation = 'relu'))\n",
    "    # train created model\n",
    "    model_ffnn.compile(optimizer= opt, loss = \"mean_squared_error\")\n",
    "    start = time.time()\n",
    "    history = model_ffnn.fit(trainX, trainY, epochs = epochs , batch_size= batch_size, shuffle=True ,validation_split = validation_split)\n",
    "    print('Thời gian huấn luyện: ', time.time() - start)\n",
    "    model_ffnn.summary()\n",
    "    delta = time.time() - start\n",
    "    return delta, model_ffnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb585959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6feb7f00",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3b056c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split):\n",
    "    # create model\n",
    "    hidden_nodes = int(math.sqrt(len(trainX) * 3) + 2 * math.sqrt(len(trainX) / 3))\n",
    "    model_rnn = Sequential()\n",
    "    model_rnn.add(SimpleRNN(units = hidden_nodes, activation = \"tanh\", return_sequences = True, input_shape = (look_back,1)))\n",
    "#     model_rnn.add(Dropout(0.3))\n",
    "#     model_rnn.add(SimpleRNN(units = 50, activation = \"tanh\", return_sequences = True))\n",
    "#     model_rnn.add(Dropout(0.2))\n",
    "#     model_rnn.add(SimpleRNN(units = 50, activation = \"tanh\", return_sequences = True))\n",
    "#     model_rnn.add(Dropout(0.1))\n",
    "#     model_rnn.add(SimpleRNN(units = 50))\n",
    "    model_rnn.add(Flatten())\n",
    "    model_rnn.add(Dense(units = 1))\n",
    "    # train created model\n",
    "    model_rnn.compile(optimizer= opt, loss = \"mean_squared_error\")\n",
    "    start = time.time()\n",
    "    history = model_rnn.fit(trainX, trainY, epochs = epochs , batch_size= batch_size, shuffle=True ,validation_split = validation_split)\n",
    "    print('Thời gian huấn luyện: ', time.time() - start)\n",
    "    model_rnn.summary()\n",
    "    delta = time.time() - start\n",
    "    return delta, model_rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdadcde",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c306e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split):\n",
    "    # create model\n",
    "    hidden_nodes = int(math.sqrt(len(trainX) * 3) + 2 * math.sqrt(len(trainX) / 3))\n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(LSTM(hidden_nodes, activation = 'tanh', input_shape=(look_back,1),return_sequences=True))\n",
    "    model_lstm.add(Flatten())\n",
    "    model_lstm.add(Dense(1, activation = 'relu'))\n",
    "    # train created model\n",
    "    model_lstm.compile(optimizer= opt, loss = \"mean_squared_error\")\n",
    "    start = time.time()\n",
    "    history = model_lstm.fit(trainX, trainY, epochs = epochs , batch_size= batch_size, shuffle=True ,validation_split = validation_split)\n",
    "    print('Thời gian huấn luyện: ', time.time() - start)\n",
    "    model_lstm.summary()\n",
    "    delta = time.time() - start\n",
    "    return delta, model_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b222798",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fbf25ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gru_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split):\n",
    "    # create model\n",
    "    hidden_nodes = int(math.sqrt(len(trainX) * 3) + 2 * math.sqrt(len(trainX) / 3))\n",
    "    model_gru = Sequential()\n",
    "    model_gru.add(GRU(hidden_nodes, activation='tanh', recurrent_activation='sigmoid', input_shape=(look_back,1), return_sequences=True)) \n",
    "    model_gru.add(Flatten())\n",
    "    model_gru.add(Dense(1, activation = 'relu'))\n",
    "    # train created model\n",
    "    model_gru.compile(optimizer= opt, loss = \"mean_squared_error\")\n",
    "    start = time.time()\n",
    "    history = model_gru.fit(trainX, trainY, epochs = epochs , batch_size= batch_size, shuffle=True ,validation_split = validation_split)\n",
    "    print('Thời gian huấn luyện: ', time.time() - start)\n",
    "    model_gru.summary()\n",
    "    delta = time.time() - start\n",
    "    return delta, model_gru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0acfa5",
   "metadata": {},
   "source": [
    "# Trực quan hóa, so sánh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb06f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def calculate_performance(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    return round(mse, 3), round(mae, 3), round(mape, 3), round(rmse, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a2452ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_accuracy(trained_model, scaler, trainX, trainY, testX, testY):\n",
    "    trainPredict = trained_model.predict(trainX)\n",
    "    testPredict = trained_model.predict(testX)\n",
    "\n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform([trainY])\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY = scaler.inverse_transform([testY])\n",
    "\n",
    "    mse, mae, mape, rmse = calculate_performance(trainY[0],trainPredict[:, 0])\n",
    "    return mse, mae, mape, rmse, trainPredict, testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9eefe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(ds, trainPredict, testPredict, scaler, look_back, model_name, stock_name):\n",
    "    trainPredictPlot = np.empty_like(ds)\n",
    "    trainPredictPlot[:, :] = np.nan\n",
    "    trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "    testPredictPlot = np.empty_like(ds)\n",
    "    testPredictPlot[:, :] = np.nan\n",
    "    testPredictPlot[len(trainPredict)+(look_back*2)+1:len(ds)-1, :] = testPredict\n",
    "\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure(figsize=(13,7), dpi=110)\n",
    "    plt.grid(color='grey', linestyle='dashed')\n",
    "    plt.xlabel(\"{0} result\".format(model_name))\n",
    "    plt.ylabel('{0}'.format(stock_name),rotation=90)\n",
    "    plt.plot(scaler.inverse_transform(ds), label = 'Actual Closing Prices', linewidth = 1.2, color = 'c')\n",
    "    plt.plot(trainPredictPlot, label = 'A.I. Train Data Price Predictions_After fit', linewidth = 0.9, color = 'k')\n",
    "    plt.plot(testPredictPlot, label = 'A.I. Test Data Price Predictions', linewidth = 0.9, color = 'r')\n",
    "    legend = plt.legend(fontsize = 12,frameon = True)\n",
    "    legend.get_frame().set_edgecolor('b')\n",
    "    legend.get_frame().set_linewidth(0.4)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116dbf09",
   "metadata": {},
   "source": [
    "# Thực nghiệm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6f7494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 10\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "import itertools\n",
    "def get_combinations(parameters):\n",
    "    return list(itertools.product(*parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74ce315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27/27 [==============================] - 1s 9ms/step - loss: 0.0804 - val_loss: 0.0379\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0621 - val_loss: 0.0272\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0449 - val_loss: 0.0175\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0294 - val_loss: 0.0101\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0174 - val_loss: 0.0058\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0046\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0058\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0062\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0063\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0063\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0062\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0061\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0060\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0058\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0058\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0055\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Thời gian huấn luyện:  4.193561792373657\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10, 89)            178       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 890)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069\n",
      "Trainable params: 1,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "27/27 [==============================] - 1s 13ms/step - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.6866e-04 - val_loss: 0.0015\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.2992e-04 - val_loss: 0.0015\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.9258e-04 - val_loss: 0.0015\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.5290e-04 - val_loss: 0.0014\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.6541e-04 - val_loss: 0.0013\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.1899e-04 - val_loss: 0.0014\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.0836e-04 - val_loss: 0.0012\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.3404e-04 - val_loss: 0.0012\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.6284e-04 - val_loss: 0.0012\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.6049e-04 - val_loss: 0.0012\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.4657e-04 - val_loss: 0.0012\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.3731e-04 - val_loss: 0.0011\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.6440e-04 - val_loss: 0.0011\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.2562e-04 - val_loss: 0.0011\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.0101e-04 - val_loss: 0.0011\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.2875e-04 - val_loss: 0.0011\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 6.9114e-04 - val_loss: 0.0011\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.6850e-04 - val_loss: 0.0010\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 3ms/step - loss: 6.8665e-04 - val_loss: 0.0010\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.6029e-04 - val_loss: 9.9642e-04\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.9780e-04 - val_loss: 0.0010\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.8486e-04 - val_loss: 9.9598e-04\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.8424e-04 - val_loss: 9.5530e-04\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.5023e-04 - val_loss: 9.4626e-04\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.2913e-04 - val_loss: 9.3819e-04\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.5507e-04 - val_loss: 9.5791e-04\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.3287e-04 - val_loss: 9.5141e-04\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.4102e-04 - val_loss: 9.0894e-04\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.7583e-04 - val_loss: 9.3305e-04\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 6.8019e-04 - val_loss: 9.6279e-04\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 6.1139e-04 - val_loss: 8.9303e-04\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.9908e-04 - val_loss: 8.7608e-04\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.9471e-04 - val_loss: 8.7434e-04\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.8873e-04 - val_loss: 8.7180e-04\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.8110e-04 - val_loss: 8.6851e-04\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0227e-04 - val_loss: 8.7636e-04\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.7861e-04 - val_loss: 8.4967e-04\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.8932e-04 - val_loss: 8.4716e-04\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.6953e-04 - val_loss: 8.8622e-04\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.4745e-04 - val_loss: 8.5136e-04\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.2452e-04 - val_loss: 8.3921e-04\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.7906e-04 - val_loss: 8.1595e-04\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.6756e-04 - val_loss: 8.1514e-04\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.7726e-04 - val_loss: 8.2062e-04\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5465e-04 - val_loss: 8.0166e-04\n",
      "Thời gian huấn luyện:  5.395712375640869\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 10, 89)            8099      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 890)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,990\n",
      "Trainable params: 8,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "27/27 [==============================] - 2s 20ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Thời gian huấn luyện:  10.01625108718872\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 10, 89)            32396     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 890)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,287\n",
      "Trainable params: 33,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "27/27 [==============================] - 2s 19ms/step - loss: 0.0217 - val_loss: 0.0034\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 9.9411e-04 - val_loss: 0.0017\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 9.7693e-04 - val_loss: 0.0017\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 9.6954e-04 - val_loss: 0.0016\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 9.8351e-04 - val_loss: 0.0017\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 9.7244e-04 - val_loss: 0.0016\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 9.3127e-04 - val_loss: 0.0016\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 9.3535e-04 - val_loss: 0.0016\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 9.0329e-04 - val_loss: 0.0016\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 8.9548e-04 - val_loss: 0.0015\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 8.8714e-04 - val_loss: 0.0015\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 8.8276e-04 - val_loss: 0.0015\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 8.6609e-04 - val_loss: 0.0015\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 8.5761e-04 - val_loss: 0.0015\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.5660e-04 - val_loss: 0.0014\n",
      "Thời gian huấn luyện:  9.52461314201355\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 10, 89)            24564     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 890)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,455\n",
      "Trainable params: 25,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "30/30 [==============================] - 0s 1000us/step\n",
      "20/20 [==============================] - 0s 948us/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0664 - val_loss: 0.0231\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0077\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0066\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0061\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0059\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 13/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 14/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 15/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 16/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 17/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 18/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 19/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 20/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 21/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 22/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 23/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 24/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 25/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 26/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 27/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 28/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 29/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 30/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 31/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 32/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 33/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 34/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 35/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 36/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 37/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 38/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 39/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 40/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 41/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 42/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 43/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 44/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 45/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 46/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 47/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 48/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 49/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 50/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Thời gian huấn luyện:  3.4003400802612305\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 10, 89)            178       \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 890)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069\n",
      "Trainable params: 1,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "26/26 [==============================] - 1s 9ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 9.6222e-04 - val_loss: 0.0015\n",
      "Epoch 7/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.4615e-04 - val_loss: 0.0015\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.0382e-04 - val_loss: 0.0014\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 8.8950e-04 - val_loss: 0.0013\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 8.7695e-04 - val_loss: 0.0013\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.2272e-04 - val_loss: 0.0015\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 9.0018e-04 - val_loss: 0.0015\n",
      "Epoch 13/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 8.5469e-04 - val_loss: 0.0013\n",
      "Epoch 14/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.2086e-04 - val_loss: 0.0012\n",
      "Epoch 15/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.8216e-04 - val_loss: 0.0013\n",
      "Epoch 16/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.8250e-04 - val_loss: 0.0012\n",
      "Epoch 17/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.8766e-04 - val_loss: 0.0011\n",
      "Epoch 18/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.5465e-04 - val_loss: 0.0013\n",
      "Epoch 19/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.5931e-04 - val_loss: 0.0011\n",
      "Epoch 20/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.6359e-04 - val_loss: 0.0011\n",
      "Epoch 21/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.4461e-04 - val_loss: 0.0011\n",
      "Epoch 22/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1105e-04 - val_loss: 0.0012\n",
      "Epoch 23/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.0390e-04 - val_loss: 0.0011\n",
      "Epoch 24/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9926e-04 - val_loss: 9.9665e-04\n",
      "Epoch 25/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1652e-04 - val_loss: 9.9169e-04\n",
      "Epoch 26/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.2018e-04 - val_loss: 0.0010\n",
      "Epoch 27/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8410e-04 - val_loss: 0.0011\n",
      "Epoch 28/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.2372e-04 - val_loss: 0.0010\n",
      "Epoch 29/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.8411e-04 - val_loss: 9.5556e-04\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6491e-04 - val_loss: 9.2838e-04\n",
      "Epoch 31/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6715e-04 - val_loss: 9.8867e-04\n",
      "Epoch 32/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.6226e-04 - val_loss: 9.9147e-04\n",
      "Epoch 33/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5714e-04 - val_loss: 9.3018e-04\n",
      "Epoch 34/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3404e-04 - val_loss: 9.1229e-04\n",
      "Epoch 35/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4514e-04 - val_loss: 9.2228e-04\n",
      "Epoch 36/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.4389e-04 - val_loss: 8.8275e-04\n",
      "Epoch 37/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.4452e-04 - val_loss: 9.2161e-04\n",
      "Epoch 38/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5999e-04 - val_loss: 8.7330e-04\n",
      "Epoch 39/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1434e-04 - val_loss: 8.6427e-04\n",
      "Epoch 40/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4285e-04 - val_loss: 8.6475e-04\n",
      "Epoch 41/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.3672e-04 - val_loss: 8.4911e-04\n",
      "Epoch 42/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4736e-04 - val_loss: 8.4565e-04\n",
      "Epoch 43/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9853e-04 - val_loss: 8.4555e-04\n",
      "Epoch 44/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9561e-04 - val_loss: 8.3151e-04\n",
      "Epoch 45/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2310e-04 - val_loss: 8.2768e-04\n",
      "Epoch 46/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9074e-04 - val_loss: 8.3526e-04\n",
      "Epoch 47/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.9647e-04 - val_loss: 8.2956e-04\n",
      "Epoch 48/50\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.8907e-04 - val_loss: 8.0685e-04\n",
      "Epoch 49/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9099e-04 - val_loss: 8.0070e-04\n",
      "Epoch 50/50\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8413e-04 - val_loss: 8.2044e-04\n",
      "Thời gian huấn luyện:  5.257981777191162\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_1 (SimpleRNN)    (None, 10, 89)            8099      \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 890)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,990\n",
      "Trainable params: 8,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "26/26 [==============================] - 2s 20ms/step - loss: 0.0300 - val_loss: 0.0062\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 7/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 13/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 14/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 15/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 16/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 17/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 18/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 19/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 20/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 21/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 22/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 23/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 24/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 25/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 26/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 27/50\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 28/50\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 29/50\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 30/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 31/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 32/50\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 33/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 34/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 35/50\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 36/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 37/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 38/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 39/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 40/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 41/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 42/50\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 43/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 44/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 45/50\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 46/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 47/50\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 48/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 49/50\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 50/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Thời gian huấn luyện:  9.782893180847168\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 10, 89)            32396     \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 890)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,287\n",
      "Trainable params: 33,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "26/26 [==============================] - 2s 19ms/step - loss: 0.0180 - val_loss: 0.0030\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 7/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 13/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 14/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 15/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 16/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 17/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 18/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 19/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 20/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 21/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 22/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 23/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 24/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 25/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 26/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 27/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 28/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 29/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 30/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 31/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 32/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 33/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 34/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 35/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 36/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 37/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 38/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 39/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 40/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.8894e-04 - val_loss: 0.0017\n",
      "Epoch 41/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.6507e-04 - val_loss: 0.0016\n",
      "Epoch 42/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.5909e-04 - val_loss: 0.0016\n",
      "Epoch 43/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.4876e-04 - val_loss: 0.0016\n",
      "Epoch 44/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.3850e-04 - val_loss: 0.0015\n",
      "Epoch 45/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.4437e-04 - val_loss: 0.0016\n",
      "Epoch 46/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.1956e-04 - val_loss: 0.0015\n",
      "Epoch 47/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.2615e-04 - val_loss: 0.0014\n",
      "Epoch 48/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.0484e-04 - val_loss: 0.0015\n",
      "Epoch 49/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.9283e-04 - val_loss: 0.0014\n",
      "Epoch 50/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.8476e-04 - val_loss: 0.0014\n",
      "Thời gian huấn luyện:  9.30380654335022\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_1 (GRU)                 (None, 10, 89)            24564     \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 890)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,455\n",
      "Trainable params: 25,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0475 - val_loss: 0.0119\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Thời gian huấn luyện:  3.2871880531311035\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 10, 89)            178       \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 890)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069\n",
      "Trainable params: 1,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 1s 10ms/step - loss: 0.0191 - val_loss: 0.0053\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.9525e-04 - val_loss: 0.0014\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.6871e-04 - val_loss: 0.0014\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.8498e-04 - val_loss: 0.0013\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.8735e-04 - val_loss: 0.0012\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.2781e-04 - val_loss: 0.0012\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.1715e-04 - val_loss: 0.0012\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.0553e-04 - val_loss: 0.0012\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.0518e-04 - val_loss: 0.0011\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.8970e-04 - val_loss: 0.0012\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.8720e-04 - val_loss: 0.0011\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.7083e-04 - val_loss: 0.0011\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.6378e-04 - val_loss: 0.0011\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.5592e-04 - val_loss: 0.0011\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step - loss: 8.5311e-04 - val_loss: 0.0011\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.6585e-04 - val_loss: 0.0012\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.3841e-04 - val_loss: 0.0010\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.3447e-04 - val_loss: 0.0011\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.5517e-04 - val_loss: 0.0011\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.5914e-04 - val_loss: 0.0010\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.9742e-04 - val_loss: 0.0010\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.0900e-04 - val_loss: 9.9840e-04\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.1820e-04 - val_loss: 9.9867e-04\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.2085e-04 - val_loss: 9.9001e-04\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.1984e-04 - val_loss: 0.0010\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.8583e-04 - val_loss: 9.7359e-04\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.7520e-04 - val_loss: 9.6453e-04\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.7007e-04 - val_loss: 9.6129e-04\n",
      "Thời gian huấn luyện:  5.317591190338135\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_2 (SimpleRNN)    (None, 10, 89)            8099      \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 890)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,990\n",
      "Trainable params: 8,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 2s 21ms/step - loss: 0.0324 - val_loss: 0.0065\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Thời gian huấn luyện:  9.814332246780396\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 10, 89)            32396     \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,287\n",
      "Trainable params: 33,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 2s 19ms/step - loss: 0.0171 - val_loss: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 9.9497e-04 - val_loss: 0.0013\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 9.8424e-04 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 9.7094e-04 - val_loss: 0.0013\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 9.6454e-04 - val_loss: 0.0012\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 9.4414e-04 - val_loss: 0.0012\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 9.3323e-04 - val_loss: 0.0012\n",
      "Thời gian huấn luyện:  9.16268515586853\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_2 (GRU)                 (None, 10, 89)            24564     \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,455\n",
      "Trainable params: 25,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "30/30 [==============================] - 0s 931us/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 49/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 58/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 59/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 73/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 95/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 96/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 97/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 98/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Thời gian huấn luyện:  5.877689838409424\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_15 (Dense)            (None, 10, 89)            178       \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069\n",
      "Trainable params: 1,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "27/27 [==============================] - 1s 8ms/step - loss: 0.0089 - val_loss: 0.0037\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.8143e-04 - val_loss: 0.0016\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.7445e-04 - val_loss: 0.0016\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.2318e-04 - val_loss: 0.0016\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.0639e-04 - val_loss: 0.0015\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.9197e-04 - val_loss: 0.0015\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.8140e-04 - val_loss: 0.0015\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.5863e-04 - val_loss: 0.0014\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.5402e-04 - val_loss: 0.0014\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.3092e-04 - val_loss: 0.0014\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.3526e-04 - val_loss: 0.0013\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.2737e-04 - val_loss: 0.0013\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.0100e-04 - val_loss: 0.0013\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.9245e-04 - val_loss: 0.0013\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.0880e-04 - val_loss: 0.0013\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.7790e-04 - val_loss: 0.0012\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.7400e-04 - val_loss: 0.0012\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.5376e-04 - val_loss: 0.0013\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.5196e-04 - val_loss: 0.0012\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.6412e-04 - val_loss: 0.0012\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.2809e-04 - val_loss: 0.0012\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.4151e-04 - val_loss: 0.0011\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.2170e-04 - val_loss: 0.0012\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.2716e-04 - val_loss: 0.0011\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.0406e-04 - val_loss: 0.0011\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.0162e-04 - val_loss: 0.0011\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.1203e-04 - val_loss: 0.0011\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.9496e-04 - val_loss: 0.0011\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.1937e-04 - val_loss: 0.0011\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.9118e-04 - val_loss: 0.0011\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.8588e-04 - val_loss: 0.0010\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.5990e-04 - val_loss: 0.0011\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.6864e-04 - val_loss: 0.0011\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.6637e-04 - val_loss: 0.0011\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.5350e-04 - val_loss: 0.0010\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.4624e-04 - val_loss: 9.9071e-04\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.4725e-04 - val_loss: 9.8140e-04\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.7616e-04 - val_loss: 9.8254e-04\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.3531e-04 - val_loss: 9.7639e-04\n",
      "Epoch 49/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.1995e-04 - val_loss: 0.0010\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.3289e-04 - val_loss: 9.5154e-04\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.7353e-04 - val_loss: 9.7199e-04\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.1677e-04 - val_loss: 0.0010\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.4638e-04 - val_loss: 0.0010\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0871e-04 - val_loss: 9.2415e-04\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0995e-04 - val_loss: 9.3876e-04\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.2281e-04 - val_loss: 9.2361e-04\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0054e-04 - val_loss: 9.1097e-04\n",
      "Epoch 58/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.9222e-04 - val_loss: 9.0727e-04\n",
      "Epoch 59/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.9206e-04 - val_loss: 9.0014e-04\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.9893e-04 - val_loss: 9.0550e-04\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.9562e-04 - val_loss: 8.8875e-04\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.8659e-04 - val_loss: 9.0212e-04\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0286e-04 - val_loss: 8.7182e-04\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.9274e-04 - val_loss: 9.0925e-04\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.9557e-04 - val_loss: 8.8069e-04\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0172e-04 - val_loss: 8.7751e-04\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.9063e-04 - val_loss: 8.7294e-04\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.7388e-04 - val_loss: 9.2598e-04\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.7885e-04 - val_loss: 8.4203e-04\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.7445e-04 - val_loss: 8.4469e-04\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.7897e-04 - val_loss: 8.7039e-04\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 5.6193e-04 - val_loss: 8.3056e-04\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 3ms/step - loss: 5.6324e-04 - val_loss: 8.2369e-04\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.6372e-04 - val_loss: 9.0276e-04\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.1103e-04 - val_loss: 8.3444e-04\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.4819e-04 - val_loss: 8.5297e-04\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.6043e-04 - val_loss: 8.9164e-04\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5401e-04 - val_loss: 8.0094e-04\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5535e-04 - val_loss: 7.9751e-04\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.6124e-04 - val_loss: 7.9382e-04\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3786e-04 - val_loss: 7.9328e-04\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5584e-04 - val_loss: 8.2989e-04\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3357e-04 - val_loss: 8.0658e-04\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.4647e-04 - val_loss: 7.8450e-04\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.4915e-04 - val_loss: 7.9395e-04\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2994e-04 - val_loss: 7.7227e-04\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3833e-04 - val_loss: 7.6664e-04\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3077e-04 - val_loss: 7.7219e-04\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3876e-04 - val_loss: 7.5957e-04\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2656e-04 - val_loss: 7.5702e-04\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3548e-04 - val_loss: 7.6842e-04\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2865e-04 - val_loss: 7.6376e-04\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3391e-04 - val_loss: 8.2054e-04\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2579e-04 - val_loss: 7.4280e-04\n",
      "Epoch 95/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2404e-04 - val_loss: 7.4383e-04\n",
      "Epoch 96/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.1038e-04 - val_loss: 7.3712e-04\n",
      "Epoch 97/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.4986e-04 - val_loss: 7.3486e-04\n",
      "Epoch 98/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2069e-04 - val_loss: 7.3816e-04\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2157e-04 - val_loss: 7.6869e-04\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2621e-04 - val_loss: 7.9180e-04\n",
      "Thời gian huấn luyện:  9.265209436416626\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_3 (SimpleRNN)    (None, 10, 89)            8099      \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,990\n",
      "Trainable params: 8,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "27/27 [==============================] - 2s 18ms/step - loss: 0.0320 - val_loss: 0.0057\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 49/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 58/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 59/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 73/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 9.9931e-04 - val_loss: 0.0019\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 9.9472e-04 - val_loss: 0.0018\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.8646e-04 - val_loss: 0.0018\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.7604e-04 - val_loss: 0.0018\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.8601e-04 - val_loss: 0.0018\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.7045e-04 - val_loss: 0.0018\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.7287e-04 - val_loss: 0.0018\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.5586e-04 - val_loss: 0.0018\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.6269e-04 - val_loss: 0.0017\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.7595e-04 - val_loss: 0.0018\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.7671e-04 - val_loss: 0.0018\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.4193e-04 - val_loss: 0.0017\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.6228e-04 - val_loss: 0.0018\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.3514e-04 - val_loss: 0.0017\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.3622e-04 - val_loss: 0.0017\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.3788e-04 - val_loss: 0.0018\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.4115e-04 - val_loss: 0.0017\n",
      "Epoch 95/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.4903e-04 - val_loss: 0.0017\n",
      "Epoch 96/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.2023e-04 - val_loss: 0.0018\n",
      "Epoch 97/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.5732e-04 - val_loss: 0.0017\n",
      "Epoch 98/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 9.2839e-04 - val_loss: 0.0017\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.2459e-04 - val_loss: 0.0017\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.3211e-04 - val_loss: 0.0017\n",
      "Thời gian huấn luyện:  17.721712827682495\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 10, 89)            32396     \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,287\n",
      "Trainable params: 33,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "27/27 [==============================] - 2s 18ms/step - loss: 0.0196 - val_loss: 0.0034\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.9040e-04 - val_loss: 0.0017\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.7510e-04 - val_loss: 0.0016\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.6235e-04 - val_loss: 0.0016\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.6232e-04 - val_loss: 0.0016\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.3353e-04 - val_loss: 0.0016\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.3069e-04 - val_loss: 0.0015\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.1658e-04 - val_loss: 0.0015\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.2206e-04 - val_loss: 0.0015\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.9754e-04 - val_loss: 0.0015\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.8688e-04 - val_loss: 0.0015\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.6352e-04 - val_loss: 0.0015\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.8506e-04 - val_loss: 0.0015\n",
      "Epoch 49/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.4335e-04 - val_loss: 0.0014\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.3136e-04 - val_loss: 0.0014\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.2052e-04 - val_loss: 0.0014\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.1849e-04 - val_loss: 0.0014\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.2093e-04 - val_loss: 0.0014\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.0942e-04 - val_loss: 0.0013\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.8836e-04 - val_loss: 0.0013\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.7946e-04 - val_loss: 0.0013\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.7425e-04 - val_loss: 0.0013\n",
      "Epoch 58/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.8343e-04 - val_loss: 0.0013\n",
      "Epoch 59/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.7295e-04 - val_loss: 0.0013\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.6084e-04 - val_loss: 0.0013\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.5437e-04 - val_loss: 0.0013\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.5242e-04 - val_loss: 0.0012\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.4834e-04 - val_loss: 0.0013\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.6189e-04 - val_loss: 0.0013\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.3408e-04 - val_loss: 0.0012\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.3265e-04 - val_loss: 0.0012\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.1900e-04 - val_loss: 0.0012\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.1645e-04 - val_loss: 0.0012\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.2126e-04 - val_loss: 0.0012\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.2991e-04 - val_loss: 0.0012\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.4286e-04 - val_loss: 0.0012\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.2202e-04 - val_loss: 0.0012\n",
      "Epoch 73/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 6.9190e-04 - val_loss: 0.0012\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.9780e-04 - val_loss: 0.0012\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.9159e-04 - val_loss: 0.0012\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.0312e-04 - val_loss: 0.0011\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.8643e-04 - val_loss: 0.0012\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.7977e-04 - val_loss: 0.0011\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.0371e-04 - val_loss: 0.0011\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.7508e-04 - val_loss: 0.0011\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.8734e-04 - val_loss: 0.0011\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.7773e-04 - val_loss: 0.0011\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.6984e-04 - val_loss: 0.0011\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.6625e-04 - val_loss: 0.0011\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.5758e-04 - val_loss: 0.0011\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.5692e-04 - val_loss: 0.0011\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.5276e-04 - val_loss: 0.0011\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.4912e-04 - val_loss: 0.0011\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.5029e-04 - val_loss: 0.0011\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.4294e-04 - val_loss: 0.0011\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.4030e-04 - val_loss: 0.0010\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.4120e-04 - val_loss: 0.0010\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.5273e-04 - val_loss: 0.0011\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.3535e-04 - val_loss: 0.0010\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 6ms/step - loss: 6.3199e-04 - val_loss: 0.0010\n",
      "Epoch 96/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.5046e-04 - val_loss: 0.0010\n",
      "Epoch 97/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.4002e-04 - val_loss: 0.0010\n",
      "Epoch 98/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2194e-04 - val_loss: 0.0010\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2558e-04 - val_loss: 9.9860e-04\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.1520e-04 - val_loss: 9.9623e-04\n",
      "Thời gian huấn luyện:  18.105236768722534\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_3 (GRU)                 (None, 10, 89)            24564     \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,455\n",
      "Trainable params: 25,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "30/30 [==============================] - 0s 897us/step\n",
      "20/20 [==============================] - 0s 948us/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0686 - val_loss: 0.0210\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0089\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0065\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0062\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0059\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0055\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.9178e-04 - val_loss: 0.0017\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.8653e-04 - val_loss: 0.0017\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.8268e-04 - val_loss: 0.0017\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.7888e-04 - val_loss: 0.0017\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.6995e-04 - val_loss: 0.0016\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 2ms/step - loss: 9.6673e-04 - val_loss: 0.0016\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.5768e-04 - val_loss: 0.0016\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.5101e-04 - val_loss: 0.0016\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.4326e-04 - val_loss: 0.0016\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.4103e-04 - val_loss: 0.0016\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.3144e-04 - val_loss: 0.0016\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.3466e-04 - val_loss: 0.0015\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 9.1789e-04 - val_loss: 0.0016\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.1787e-04 - val_loss: 0.0015\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.0828e-04 - val_loss: 0.0015\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.0212e-04 - val_loss: 0.0015\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.9631e-04 - val_loss: 0.0015\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.9093e-04 - val_loss: 0.0015\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.8481e-04 - val_loss: 0.0015\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.7962e-04 - val_loss: 0.0015\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.7499e-04 - val_loss: 0.0014\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.6914e-04 - val_loss: 0.0014\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.6336e-04 - val_loss: 0.0014\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.5337e-04 - val_loss: 0.0014\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.5148e-04 - val_loss: 0.0014\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.4479e-04 - val_loss: 0.0014\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.3690e-04 - val_loss: 0.0014\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.3527e-04 - val_loss: 0.0014\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.3733e-04 - val_loss: 0.0014\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.1975e-04 - val_loss: 0.0013\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.2020e-04 - val_loss: 0.0013\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.1101e-04 - val_loss: 0.0013\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.0405e-04 - val_loss: 0.0013\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.0259e-04 - val_loss: 0.0013\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7.9436e-04 - val_loss: 0.0013\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7.9048e-04 - val_loss: 0.0013\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7.8755e-04 - val_loss: 0.0013\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7.7637e-04 - val_loss: 0.0013\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7.7429e-04 - val_loss: 0.0012\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7.7434e-04 - val_loss: 0.0013\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7.6401e-04 - val_loss: 0.0012\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7.5704e-04 - val_loss: 0.0012\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7.5300e-04 - val_loss: 0.0012\n",
      "Thời gian huấn luyện:  6.457669973373413\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 10, 89)            178       \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069\n",
      "Trainable params: 1,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "26/26 [==============================] - 1s 9ms/step - loss: 0.0155 - val_loss: 0.0082\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 9.9672e-04 - val_loss: 0.0016\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.9257e-04 - val_loss: 0.0017\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.7007e-04 - val_loss: 0.0015\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.6043e-04 - val_loss: 0.0015\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.5391e-04 - val_loss: 0.0015\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.3708e-04 - val_loss: 0.0014\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.0215e-04 - val_loss: 0.0015\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.1990e-04 - val_loss: 0.0014\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.3458e-04 - val_loss: 0.0015\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.9425e-04 - val_loss: 0.0014\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.1903e-04 - val_loss: 0.0013\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.5494e-04 - val_loss: 0.0013\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.3898e-04 - val_loss: 0.0013\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.2344e-04 - val_loss: 0.0013\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.2120e-04 - val_loss: 0.0014\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.2814e-04 - val_loss: 0.0014\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 3ms/step - loss: 8.1795e-04 - val_loss: 0.0013\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.8984e-04 - val_loss: 0.0012\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.1183e-04 - val_loss: 0.0013\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.0596e-04 - val_loss: 0.0013\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.8974e-04 - val_loss: 0.0012\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.7508e-04 - val_loss: 0.0013\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.6974e-04 - val_loss: 0.0011\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.7033e-04 - val_loss: 0.0012\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 8.0146e-04 - val_loss: 0.0011\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.4990e-04 - val_loss: 0.0011\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.6153e-04 - val_loss: 0.0012\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.8362e-04 - val_loss: 0.0011\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.4844e-04 - val_loss: 0.0011\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.4479e-04 - val_loss: 0.0011\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.3276e-04 - val_loss: 0.0011\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1884e-04 - val_loss: 0.0011\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.2051e-04 - val_loss: 0.0011\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9993e-04 - val_loss: 0.0011\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.3274e-04 - val_loss: 0.0010\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.1256e-04 - val_loss: 0.0010\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1763e-04 - val_loss: 0.0011\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9704e-04 - val_loss: 0.0010\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9534e-04 - val_loss: 0.0010\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9199e-04 - val_loss: 9.9617e-04\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8976e-04 - val_loss: 0.0010\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8347e-04 - val_loss: 0.0010\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.7854e-04 - val_loss: 9.9006e-04\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6897e-04 - val_loss: 9.6833e-04\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1602e-04 - val_loss: 9.8863e-04\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.7799e-04 - val_loss: 9.7484e-04\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6143e-04 - val_loss: 9.4961e-04\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.6940e-04 - val_loss: 9.4286e-04\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.8351e-04 - val_loss: 9.8852e-04\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.7946e-04 - val_loss: 9.5920e-04\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.5898e-04 - val_loss: 9.5718e-04\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.6296e-04 - val_loss: 9.4215e-04\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.4822e-04 - val_loss: 9.1585e-04\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5982e-04 - val_loss: 9.2383e-04\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4551e-04 - val_loss: 9.5967e-04\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3913e-04 - val_loss: 9.0577e-04\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3371e-04 - val_loss: 0.0010\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4374e-04 - val_loss: 9.0510e-04\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3592e-04 - val_loss: 9.1727e-04\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3777e-04 - val_loss: 9.2421e-04\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3439e-04 - val_loss: 8.8209e-04\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3389e-04 - val_loss: 8.7416e-04\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4568e-04 - val_loss: 9.0550e-04\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.3413e-04 - val_loss: 8.6749e-04\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6658e-04 - val_loss: 9.5167e-04\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0730e-04 - val_loss: 8.7611e-04\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1499e-04 - val_loss: 9.4059e-04\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2519e-04 - val_loss: 8.7165e-04\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1202e-04 - val_loss: 9.1587e-04\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1725e-04 - val_loss: 9.2329e-04\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0559e-04 - val_loss: 8.4157e-04\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9723e-04 - val_loss: 9.2749e-04\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9218e-04 - val_loss: 8.3234e-04\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0638e-04 - val_loss: 8.4798e-04\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9495e-04 - val_loss: 8.2419e-04\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0805e-04 - val_loss: 8.4345e-04\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1984e-04 - val_loss: 8.2132e-04\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0005e-04 - val_loss: 9.1927e-04\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6128e-04 - val_loss: 8.1004e-04\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0797e-04 - val_loss: 8.1173e-04\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9153e-04 - val_loss: 8.1151e-04\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2263e-04 - val_loss: 0.0011\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4954e-04 - val_loss: 9.5393e-04\n",
      "Thời gian huấn luyện:  9.796491622924805\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_4 (SimpleRNN)    (None, 10, 89)            8099      \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,990\n",
      "Trainable params: 8,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "26/26 [==============================] - 2s 20ms/step - loss: 0.0287 - val_loss: 0.0054\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 9.9857e-04 - val_loss: 0.0017\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 9.9104e-04 - val_loss: 0.0017\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.8125e-04 - val_loss: 0.0017\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.7199e-04 - val_loss: 0.0016\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.7361e-04 - val_loss: 0.0016\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.6617e-04 - val_loss: 0.0017\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.5778e-04 - val_loss: 0.0016\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.3995e-04 - val_loss: 0.0016\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.3818e-04 - val_loss: 0.0016\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.3305e-04 - val_loss: 0.0016\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.2728e-04 - val_loss: 0.0016\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.1571e-04 - val_loss: 0.0015\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.0897e-04 - val_loss: 0.0016\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.9626e-04 - val_loss: 0.0016\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 9.1922e-04 - val_loss: 0.0015\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.0172e-04 - val_loss: 0.0015\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.9784e-04 - val_loss: 0.0015\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 6ms/step - loss: 8.8251e-04 - val_loss: 0.0015\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.8920e-04 - val_loss: 0.0015\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.1142e-04 - val_loss: 0.0015\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.5543e-04 - val_loss: 0.0016\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.9843e-04 - val_loss: 0.0014\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.7006e-04 - val_loss: 0.0014\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.7597e-04 - val_loss: 0.0014\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.6708e-04 - val_loss: 0.0014\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.7574e-04 - val_loss: 0.0015\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.5390e-04 - val_loss: 0.0014\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.4706e-04 - val_loss: 0.0015\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.5948e-04 - val_loss: 0.0014\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.5124e-04 - val_loss: 0.0014\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.5245e-04 - val_loss: 0.0014\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.4882e-04 - val_loss: 0.0014\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.5294e-04 - val_loss: 0.0014\n",
      "Thời gian huấn luyện:  18.168768882751465\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 10, 89)            32396     \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,287\n",
      "Trainable params: 33,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "26/26 [==============================] - 2s 18ms/step - loss: 0.0226 - val_loss: 0.0036\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.9172e-04 - val_loss: 0.0016\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.7304e-04 - val_loss: 0.0017\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.7148e-04 - val_loss: 0.0016\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.6191e-04 - val_loss: 0.0017\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.5410e-04 - val_loss: 0.0016\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.3734e-04 - val_loss: 0.0015\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.3984e-04 - val_loss: 0.0015\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.2596e-04 - val_loss: 0.0015\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.0963e-04 - val_loss: 0.0015\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.0031e-04 - val_loss: 0.0014\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.9862e-04 - val_loss: 0.0014\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.8236e-04 - val_loss: 0.0014\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.8767e-04 - val_loss: 0.0014\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.6715e-04 - val_loss: 0.0014\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.6088e-04 - val_loss: 0.0014\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.5933e-04 - val_loss: 0.0013\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.4795e-04 - val_loss: 0.0013\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.3478e-04 - val_loss: 0.0013\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.2781e-04 - val_loss: 0.0013\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.2551e-04 - val_loss: 0.0013\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 6ms/step - loss: 8.2098e-04 - val_loss: 0.0013\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.0885e-04 - val_loss: 0.0013\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.2314e-04 - val_loss: 0.0013\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.9841e-04 - val_loss: 0.0012\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.8817e-04 - val_loss: 0.0013\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.8916e-04 - val_loss: 0.0012\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.8071e-04 - val_loss: 0.0012\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.7649e-04 - val_loss: 0.0012\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.7549e-04 - val_loss: 0.0012\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.6928e-04 - val_loss: 0.0012\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.7227e-04 - val_loss: 0.0011\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.5420e-04 - val_loss: 0.0012\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 7.5020e-04 - val_loss: 0.0011\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 7.4890e-04 - val_loss: 0.0011\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.4280e-04 - val_loss: 0.0011\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.5432e-04 - val_loss: 0.0011\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.4757e-04 - val_loss: 0.0011\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.2970e-04 - val_loss: 0.0011\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.2618e-04 - val_loss: 0.0011\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.2239e-04 - val_loss: 0.0011\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.1876e-04 - val_loss: 0.0011\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.1561e-04 - val_loss: 0.0011\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.1025e-04 - val_loss: 0.0011\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.0910e-04 - val_loss: 0.0011\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.0958e-04 - val_loss: 0.0011\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.1336e-04 - val_loss: 0.0010\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.9951e-04 - val_loss: 0.0011\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.9955e-04 - val_loss: 0.0011\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.9254e-04 - val_loss: 0.0010\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.9738e-04 - val_loss: 0.0010\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.0138e-04 - val_loss: 0.0010\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.8400e-04 - val_loss: 0.0010\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.8053e-04 - val_loss: 9.9667e-04\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.7693e-04 - val_loss: 9.9264e-04\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.7343e-04 - val_loss: 0.0010\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.6881e-04 - val_loss: 0.0010\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.6450e-04 - val_loss: 9.7714e-04\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.6579e-04 - val_loss: 0.0010\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.5945e-04 - val_loss: 0.0010\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.8363e-04 - val_loss: 9.7177e-04\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.5636e-04 - val_loss: 9.7338e-04\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.5604e-04 - val_loss: 9.4817e-04\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.6795e-04 - val_loss: 9.9453e-04\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.4655e-04 - val_loss: 9.4587e-04\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.4556e-04 - val_loss: 9.4764e-04\n",
      "Thời gian huấn luyện:  17.205350399017334\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_4 (GRU)                 (None, 10, 89)            24564     \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,455\n",
      "Trainable params: 25,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "30/30 [==============================] - 0s 931us/step\n",
      "20/20 [==============================] - 0s 894us/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 1s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 58/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 59/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 61/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 62/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 63/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 64/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 65/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 66/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 67/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 69/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 70/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 72/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 73/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 74/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 75/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 76/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 78/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 79/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 80/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 81/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 82/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 83/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 84/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 85/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 86/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 87/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 88/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 89/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 90/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 91/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 92/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 93/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 94/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 95/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 96/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 97/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 98/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 99/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 100/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Thời gian huấn luyện:  6.391704082489014\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_25 (Dense)            (None, 10, 89)            178       \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 890)               0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069\n",
      "Trainable params: 1,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 1s 10ms/step - loss: 0.0304 - val_loss: 0.0041\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.9462e-04 - val_loss: 0.0013\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.9280e-04 - val_loss: 0.0013\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.7327e-04 - val_loss: 0.0012\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.7389e-04 - val_loss: 0.0012\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.6103e-04 - val_loss: 0.0012\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.6147e-04 - val_loss: 0.0013\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.4687e-04 - val_loss: 0.0012\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.1902e-04 - val_loss: 0.0012\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.0543e-04 - val_loss: 0.0012\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.9632e-04 - val_loss: 0.0011\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.8795e-04 - val_loss: 0.0011\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.7537e-04 - val_loss: 0.0011\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.7174e-04 - val_loss: 0.0011\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.6327e-04 - val_loss: 0.0011\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.6271e-04 - val_loss: 0.0011\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.7998e-04 - val_loss: 0.0011\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.4056e-04 - val_loss: 0.0011\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.5902e-04 - val_loss: 0.0011\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.5224e-04 - val_loss: 0.0011\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.7115e-04 - val_loss: 0.0010\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.2511e-04 - val_loss: 0.0010\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.2759e-04 - val_loss: 0.0010\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.1199e-04 - val_loss: 0.0010\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.1252e-04 - val_loss: 9.9988e-04\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.1326e-04 - val_loss: 9.8953e-04\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.8905e-04 - val_loss: 9.8139e-04\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.8767e-04 - val_loss: 9.8029e-04\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.6617e-04 - val_loss: 9.7730e-04\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.7290e-04 - val_loss: 9.9546e-04\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.8802e-04 - val_loss: 9.5281e-04\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.8135e-04 - val_loss: 9.6052e-04\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.6195e-04 - val_loss: 9.4545e-04\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.4973e-04 - val_loss: 9.4124e-04\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.7745e-04 - val_loss: 9.2805e-04\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.5755e-04 - val_loss: 9.2057e-04\n",
      "Epoch 58/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.6897e-04 - val_loss: 9.4903e-04\n",
      "Epoch 59/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.7041e-04 - val_loss: 9.1401e-04\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.2859e-04 - val_loss: 9.1548e-04\n",
      "Epoch 61/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.2885e-04 - val_loss: 8.9719e-04\n",
      "Epoch 62/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.3205e-04 - val_loss: 8.9135e-04\n",
      "Epoch 63/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.2228e-04 - val_loss: 9.0784e-04\n",
      "Epoch 64/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.2906e-04 - val_loss: 8.8823e-04\n",
      "Epoch 65/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.1572e-04 - val_loss: 9.0383e-04\n",
      "Epoch 66/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.3849e-04 - val_loss: 8.9409e-04\n",
      "Epoch 67/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.1347e-04 - val_loss: 8.9922e-04\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.0197e-04 - val_loss: 8.5949e-04\n",
      "Epoch 69/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.9806e-04 - val_loss: 8.5492e-04\n",
      "Epoch 70/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.9567e-04 - val_loss: 8.5074e-04\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.0577e-04 - val_loss: 8.7645e-04\n",
      "Epoch 72/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.3263e-04 - val_loss: 9.8052e-04\n",
      "Epoch 73/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.9908e-04 - val_loss: 8.5455e-04\n",
      "Epoch 74/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7660e-04 - val_loss: 8.3672e-04\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7933e-04 - val_loss: 8.2917e-04\n",
      "Epoch 76/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7542e-04 - val_loss: 8.2059e-04\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.8914e-04 - val_loss: 8.7484e-04\n",
      "Epoch 78/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.0828e-04 - val_loss: 8.8826e-04\n",
      "Epoch 79/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7264e-04 - val_loss: 8.1959e-04\n",
      "Epoch 80/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7142e-04 - val_loss: 8.0378e-04\n",
      "Epoch 81/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.5329e-04 - val_loss: 8.7112e-04\n",
      "Epoch 82/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7103e-04 - val_loss: 8.0835e-04\n",
      "Epoch 83/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.1526e-04 - val_loss: 8.6629e-04\n",
      "Epoch 84/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.6716e-04 - val_loss: 7.8843e-04\n",
      "Epoch 85/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.5986e-04 - val_loss: 8.0140e-04\n",
      "Epoch 86/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.4354e-04 - val_loss: 7.8155e-04\n",
      "Epoch 87/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.5613e-04 - val_loss: 7.7951e-04\n",
      "Epoch 88/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3580e-04 - val_loss: 7.8007e-04\n",
      "Epoch 89/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.4322e-04 - val_loss: 7.8211e-04\n",
      "Epoch 90/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.4129e-04 - val_loss: 7.7856e-04\n",
      "Epoch 91/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.2827e-04 - val_loss: 7.6392e-04\n",
      "Epoch 92/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3664e-04 - val_loss: 7.6623e-04\n",
      "Epoch 93/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3585e-04 - val_loss: 7.5353e-04\n",
      "Epoch 94/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3680e-04 - val_loss: 7.5343e-04\n",
      "Epoch 95/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.2628e-04 - val_loss: 7.4667e-04\n",
      "Epoch 96/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.2890e-04 - val_loss: 7.4267e-04\n",
      "Epoch 97/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3689e-04 - val_loss: 7.4436e-04\n",
      "Epoch 98/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.1153e-04 - val_loss: 7.7707e-04\n",
      "Epoch 99/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.1208e-04 - val_loss: 7.5048e-04\n",
      "Epoch 100/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.2280e-04 - val_loss: 7.3690e-04\n",
      "Thời gian huấn luyện:  9.849021434783936\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_5 (SimpleRNN)    (None, 10, 89)            8099      \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,990\n",
      "Trainable params: 8,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 2s 23ms/step - loss: 0.0362 - val_loss: 0.0075\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 58/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 59/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 61/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 62/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 63/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 64/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 65/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 66/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 67/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 69/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 70/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 72/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 73/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 74/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 75/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 76/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 78/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 79/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 80/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 81/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 82/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 83/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 84/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 85/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.8826e-04 - val_loss: 0.0013\n",
      "Epoch 86/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.8361e-04 - val_loss: 0.0013\n",
      "Epoch 87/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.8613e-04 - val_loss: 0.0014\n",
      "Epoch 88/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.7813e-04 - val_loss: 0.0013\n",
      "Epoch 89/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.8194e-04 - val_loss: 0.0013\n",
      "Epoch 90/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.9331e-04 - val_loss: 0.0013\n",
      "Epoch 91/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.6843e-04 - val_loss: 0.0013\n",
      "Epoch 92/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.6741e-04 - val_loss: 0.0013\n",
      "Epoch 93/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.6594e-04 - val_loss: 0.0013\n",
      "Epoch 94/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.6445e-04 - val_loss: 0.0013\n",
      "Epoch 95/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.4691e-04 - val_loss: 0.0013\n",
      "Epoch 96/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.6631e-04 - val_loss: 0.0013\n",
      "Epoch 97/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.4221e-04 - val_loss: 0.0014\n",
      "Epoch 98/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.6646e-04 - val_loss: 0.0014\n",
      "Epoch 99/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.6293e-04 - val_loss: 0.0013\n",
      "Epoch 100/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 9.3031e-04 - val_loss: 0.0013\n",
      "Thời gian huấn luyện:  20.567808866500854\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_5 (LSTM)               (None, 10, 89)            32396     \n",
      "                                                                 \n",
      " flatten_22 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,287\n",
      "Trainable params: 33,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 2s 20ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 58/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 59/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 61/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 62/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 63/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 64/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 65/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 66/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 67/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 69/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 70/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 72/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 73/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 74/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 75/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 76/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 78/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 79/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 80/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 81/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 82/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 83/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 84/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 85/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 86/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 87/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 88/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 89/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 90/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 91/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 92/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 93/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 94/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 95/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 96/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 97/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 98/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 99/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 100/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thời gian huấn luyện:  18.30964231491089\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_5 (GRU)                 (None, 10, 89)            24564     \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,455\n",
      "Trainable params: 25,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "30/30 [==============================] - 0s 931us/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0707 - val_loss: 0.0121\n",
      "Epoch 2/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 3/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0074\n",
      "Epoch 4/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0071\n",
      "Epoch 5/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0069\n",
      "Epoch 6/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0065\n",
      "Epoch 7/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0062\n",
      "Epoch 8/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0057\n",
      "Epoch 9/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 10/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 11/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 12/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 13/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 14/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 15/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 16/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 17/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 18/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 19/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 20/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 21/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 22/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 23/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 24/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 25/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 26/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 27/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 28/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 29/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 30/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 31/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 32/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 33/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 34/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 35/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 36/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 37/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 38/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 39/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 40/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 41/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 42/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 43/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 44/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 45/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 46/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 47/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 48/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 49/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 50/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 51/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 52/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 53/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 54/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 55/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 56/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 57/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 58/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 59/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 60/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 61/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 62/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 63/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 64/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 65/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 66/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 67/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 68/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 69/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 70/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 71/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 72/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 73/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 74/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 75/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 76/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.9857e-04 - val_loss: 0.0017\n",
      "Epoch 77/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 78/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.8379e-04 - val_loss: 0.0016\n",
      "Epoch 79/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.8804e-04 - val_loss: 0.0016\n",
      "Epoch 80/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.7231e-04 - val_loss: 0.0016\n",
      "Epoch 81/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.6462e-04 - val_loss: 0.0016\n",
      "Epoch 82/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.6174e-04 - val_loss: 0.0016\n",
      "Epoch 83/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.5658e-04 - val_loss: 0.0016\n",
      "Epoch 84/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.5029e-04 - val_loss: 0.0015\n",
      "Epoch 85/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.4511e-04 - val_loss: 0.0015\n",
      "Epoch 86/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.3287e-04 - val_loss: 0.0015\n",
      "Epoch 87/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.2577e-04 - val_loss: 0.0015\n",
      "Epoch 88/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.1675e-04 - val_loss: 0.0015\n",
      "Epoch 89/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.0899e-04 - val_loss: 0.0015\n",
      "Epoch 90/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.0420e-04 - val_loss: 0.0015\n",
      "Epoch 91/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.9679e-04 - val_loss: 0.0015\n",
      "Epoch 92/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.9274e-04 - val_loss: 0.0015\n",
      "Epoch 93/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.8684e-04 - val_loss: 0.0014\n",
      "Epoch 94/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.8153e-04 - val_loss: 0.0014\n",
      "Epoch 95/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.7289e-04 - val_loss: 0.0014\n",
      "Epoch 96/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.7153e-04 - val_loss: 0.0014\n",
      "Epoch 97/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.6656e-04 - val_loss: 0.0014\n",
      "Epoch 98/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.5429e-04 - val_loss: 0.0014\n",
      "Epoch 99/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.4481e-04 - val_loss: 0.0014\n",
      "Epoch 100/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.3982e-04 - val_loss: 0.0014\n",
      "Epoch 101/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.3291e-04 - val_loss: 0.0014\n",
      "Epoch 102/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.2913e-04 - val_loss: 0.0013\n",
      "Epoch 103/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.3086e-04 - val_loss: 0.0013\n",
      "Epoch 104/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.1647e-04 - val_loss: 0.0013\n",
      "Epoch 105/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.0953e-04 - val_loss: 0.0013\n",
      "Epoch 106/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.0305e-04 - val_loss: 0.0013\n",
      "Epoch 107/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.0087e-04 - val_loss: 0.0013\n",
      "Epoch 108/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.9449e-04 - val_loss: 0.0013\n",
      "Epoch 109/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.9084e-04 - val_loss: 0.0013\n",
      "Epoch 110/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.8582e-04 - val_loss: 0.0013\n",
      "Epoch 111/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.8040e-04 - val_loss: 0.0012\n",
      "Epoch 112/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.7317e-04 - val_loss: 0.0012\n",
      "Epoch 113/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.6780e-04 - val_loss: 0.0012\n",
      "Epoch 114/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.6391e-04 - val_loss: 0.0012\n",
      "Epoch 115/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.5794e-04 - val_loss: 0.0012\n",
      "Epoch 116/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.5262e-04 - val_loss: 0.0012\n",
      "Epoch 117/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.4810e-04 - val_loss: 0.0012\n",
      "Epoch 118/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.4039e-04 - val_loss: 0.0012\n",
      "Epoch 119/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.3672e-04 - val_loss: 0.0012\n",
      "Epoch 120/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.3146e-04 - val_loss: 0.0012\n",
      "Epoch 121/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.2361e-04 - val_loss: 0.0012\n",
      "Epoch 122/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.3150e-04 - val_loss: 0.0011\n",
      "Epoch 123/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.2072e-04 - val_loss: 0.0011\n",
      "Epoch 124/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.1076e-04 - val_loss: 0.0011\n",
      "Epoch 125/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.0710e-04 - val_loss: 0.0011\n",
      "Epoch 126/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.0352e-04 - val_loss: 0.0011\n",
      "Epoch 127/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.9948e-04 - val_loss: 0.0011\n",
      "Epoch 128/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.9684e-04 - val_loss: 0.0011\n",
      "Epoch 129/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.9019e-04 - val_loss: 0.0011\n",
      "Epoch 130/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.8761e-04 - val_loss: 0.0011\n",
      "Epoch 131/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.8976e-04 - val_loss: 0.0011\n",
      "Epoch 132/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.7797e-04 - val_loss: 0.0011\n",
      "Epoch 133/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.7251e-04 - val_loss: 0.0011\n",
      "Epoch 134/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.7076e-04 - val_loss: 0.0010\n",
      "Epoch 135/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.6403e-04 - val_loss: 0.0010\n",
      "Epoch 136/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.6412e-04 - val_loss: 0.0010\n",
      "Epoch 137/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.5739e-04 - val_loss: 0.0010\n",
      "Epoch 138/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.6144e-04 - val_loss: 0.0010\n",
      "Epoch 139/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.5077e-04 - val_loss: 0.0010\n",
      "Epoch 140/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.4743e-04 - val_loss: 0.0010\n",
      "Epoch 141/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.4909e-04 - val_loss: 0.0010\n",
      "Epoch 142/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.4293e-04 - val_loss: 9.9818e-04\n",
      "Epoch 143/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.3938e-04 - val_loss: 9.8839e-04\n",
      "Epoch 144/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.3606e-04 - val_loss: 9.8412e-04\n",
      "Epoch 145/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.3825e-04 - val_loss: 9.8235e-04\n",
      "Epoch 146/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.3842e-04 - val_loss: 9.6909e-04\n",
      "Epoch 147/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.2696e-04 - val_loss: 9.7727e-04\n",
      "Epoch 148/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 2ms/step - loss: 6.2577e-04 - val_loss: 9.6305e-04\n",
      "Epoch 149/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.1996e-04 - val_loss: 9.5332e-04\n",
      "Epoch 150/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.2092e-04 - val_loss: 9.4899e-04\n",
      "Epoch 151/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.1435e-04 - val_loss: 9.4286e-04\n",
      "Epoch 152/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.1090e-04 - val_loss: 9.3858e-04\n",
      "Epoch 153/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.1336e-04 - val_loss: 9.4065e-04\n",
      "Epoch 154/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.0487e-04 - val_loss: 9.2727e-04\n",
      "Epoch 155/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.0398e-04 - val_loss: 9.2275e-04\n",
      "Epoch 156/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.0425e-04 - val_loss: 9.1931e-04\n",
      "Epoch 157/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.9893e-04 - val_loss: 9.1327e-04\n",
      "Epoch 158/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.9500e-04 - val_loss: 9.1329e-04\n",
      "Epoch 159/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.9464e-04 - val_loss: 9.0679e-04\n",
      "Epoch 160/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.9329e-04 - val_loss: 9.0268e-04\n",
      "Epoch 161/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.0181e-04 - val_loss: 8.9875e-04\n",
      "Epoch 162/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.9647e-04 - val_loss: 8.9454e-04\n",
      "Epoch 163/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.8591e-04 - val_loss: 8.8771e-04\n",
      "Epoch 164/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.8178e-04 - val_loss: 8.9332e-04\n",
      "Epoch 165/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.8209e-04 - val_loss: 8.8624e-04\n",
      "Epoch 166/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.8097e-04 - val_loss: 8.8002e-04\n",
      "Epoch 167/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.8121e-04 - val_loss: 8.9027e-04\n",
      "Epoch 168/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.7973e-04 - val_loss: 8.6889e-04\n",
      "Epoch 169/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.7393e-04 - val_loss: 8.6486e-04\n",
      "Epoch 170/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.7156e-04 - val_loss: 8.6107e-04\n",
      "Epoch 171/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.7389e-04 - val_loss: 8.5943e-04\n",
      "Epoch 172/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.7450e-04 - val_loss: 8.5498e-04\n",
      "Epoch 173/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.7675e-04 - val_loss: 8.5201e-04\n",
      "Epoch 174/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.6334e-04 - val_loss: 8.4846e-04\n",
      "Epoch 175/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.7841e-04 - val_loss: 8.8078e-04\n",
      "Epoch 176/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.6260e-04 - val_loss: 8.4638e-04\n",
      "Epoch 177/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.6868e-04 - val_loss: 8.3849e-04\n",
      "Epoch 178/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.6139e-04 - val_loss: 8.4002e-04\n",
      "Epoch 179/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.5683e-04 - val_loss: 8.3303e-04\n",
      "Epoch 180/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.5717e-04 - val_loss: 8.3198e-04\n",
      "Epoch 181/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.6295e-04 - val_loss: 8.2694e-04\n",
      "Epoch 182/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.5159e-04 - val_loss: 8.2892e-04\n",
      "Epoch 183/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.5772e-04 - val_loss: 8.2305e-04\n",
      "Epoch 184/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.5322e-04 - val_loss: 8.2254e-04\n",
      "Epoch 185/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.5067e-04 - val_loss: 8.1919e-04\n",
      "Epoch 186/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.5027e-04 - val_loss: 8.1471e-04\n",
      "Epoch 187/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.4838e-04 - val_loss: 8.1222e-04\n",
      "Epoch 188/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.4741e-04 - val_loss: 8.1417e-04\n",
      "Epoch 189/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.4412e-04 - val_loss: 8.1489e-04\n",
      "Epoch 190/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.4600e-04 - val_loss: 8.1640e-04\n",
      "Epoch 191/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.4441e-04 - val_loss: 8.0918e-04\n",
      "Epoch 192/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.4073e-04 - val_loss: 7.9979e-04\n",
      "Epoch 193/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.4056e-04 - val_loss: 8.0655e-04\n",
      "Epoch 194/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.3989e-04 - val_loss: 7.9816e-04\n",
      "Epoch 195/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.3769e-04 - val_loss: 7.9559e-04\n",
      "Epoch 196/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.3908e-04 - val_loss: 7.9077e-04\n",
      "Epoch 197/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.4008e-04 - val_loss: 7.8990e-04\n",
      "Epoch 198/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.3830e-04 - val_loss: 7.8675e-04\n",
      "Epoch 199/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.4033e-04 - val_loss: 7.8835e-04\n",
      "Epoch 200/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.3262e-04 - val_loss: 7.8206e-04\n",
      "Thời gian huấn luyện:  12.304442167282104\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 10, 89)            178       \n",
      "                                                                 \n",
      " flatten_24 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069\n",
      "Trainable params: 1,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "27/27 [==============================] - 1s 10ms/step - loss: 0.0185 - val_loss: 0.0052\n",
      "Epoch 2/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 3/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 4/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 5/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 6/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 7/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 8/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 9/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 10/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 11/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 12/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 13/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 14/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 15/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 16/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 18/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 19/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 20/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 21/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 22/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 23/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 24/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 25/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.9982e-04 - val_loss: 0.0017\n",
      "Epoch 26/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 27/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.7568e-04 - val_loss: 0.0017\n",
      "Epoch 28/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 9.7308e-04 - val_loss: 0.0016\n",
      "Epoch 29/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.5442e-04 - val_loss: 0.0017\n",
      "Epoch 30/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.6667e-04 - val_loss: 0.0016\n",
      "Epoch 31/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.8159e-04 - val_loss: 0.0016\n",
      "Epoch 32/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.2330e-04 - val_loss: 0.0016\n",
      "Epoch 33/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 9.3896e-04 - val_loss: 0.0015\n",
      "Epoch 34/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.1374e-04 - val_loss: 0.0015\n",
      "Epoch 35/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.9855e-04 - val_loss: 0.0015\n",
      "Epoch 36/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.8579e-04 - val_loss: 0.0015\n",
      "Epoch 37/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.7946e-04 - val_loss: 0.0015\n",
      "Epoch 38/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 8.7484e-04 - val_loss: 0.0015\n",
      "Epoch 39/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.7999e-04 - val_loss: 0.0014\n",
      "Epoch 40/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.7744e-04 - val_loss: 0.0014\n",
      "Epoch 41/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.9513e-04 - val_loss: 0.0015\n",
      "Epoch 42/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.5296e-04 - val_loss: 0.0014\n",
      "Epoch 43/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.4879e-04 - val_loss: 0.0014\n",
      "Epoch 44/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.3356e-04 - val_loss: 0.0014\n",
      "Epoch 45/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.3228e-04 - val_loss: 0.0014\n",
      "Epoch 46/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.2345e-04 - val_loss: 0.0014\n",
      "Epoch 47/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.0905e-04 - val_loss: 0.0014\n",
      "Epoch 48/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.7439e-04 - val_loss: 0.0013\n",
      "Epoch 49/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.7291e-04 - val_loss: 0.0013\n",
      "Epoch 50/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.1971e-04 - val_loss: 0.0013\n",
      "Epoch 51/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 8.1677e-04 - val_loss: 0.0013\n",
      "Epoch 52/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 7.8379e-04 - val_loss: 0.0014\n",
      "Epoch 53/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 7.8782e-04 - val_loss: 0.0013\n",
      "Epoch 54/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.8249e-04 - val_loss: 0.0013\n",
      "Epoch 55/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.7288e-04 - val_loss: 0.0012\n",
      "Epoch 56/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.8255e-04 - val_loss: 0.0012\n",
      "Epoch 57/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.1185e-04 - val_loss: 0.0012\n",
      "Epoch 58/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.7521e-04 - val_loss: 0.0012\n",
      "Epoch 59/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.7222e-04 - val_loss: 0.0013\n",
      "Epoch 60/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.6903e-04 - val_loss: 0.0013\n",
      "Epoch 61/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.8029e-04 - val_loss: 0.0012\n",
      "Epoch 62/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 7.3692e-04 - val_loss: 0.0012\n",
      "Epoch 63/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 7.8282e-04 - val_loss: 0.0012\n",
      "Epoch 64/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.4050e-04 - val_loss: 0.0012\n",
      "Epoch 65/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.2683e-04 - val_loss: 0.0011\n",
      "Epoch 66/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.1941e-04 - val_loss: 0.0012\n",
      "Epoch 67/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.2367e-04 - val_loss: 0.0011\n",
      "Epoch 68/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.4024e-04 - val_loss: 0.0011\n",
      "Epoch 69/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.5389e-04 - val_loss: 0.0011\n",
      "Epoch 70/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.1328e-04 - val_loss: 0.0011\n",
      "Epoch 71/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.0590e-04 - val_loss: 0.0011\n",
      "Epoch 72/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.0006e-04 - val_loss: 0.0011\n",
      "Epoch 73/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.9256e-04 - val_loss: 0.0011\n",
      "Epoch 74/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.9913e-04 - val_loss: 0.0011\n",
      "Epoch 75/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.9374e-04 - val_loss: 0.0011\n",
      "Epoch 76/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.9979e-04 - val_loss: 0.0011\n",
      "Epoch 77/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 7.0884e-04 - val_loss: 0.0011\n",
      "Epoch 78/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.8705e-04 - val_loss: 0.0011\n",
      "Epoch 79/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.7552e-04 - val_loss: 0.0011\n",
      "Epoch 80/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.1549e-04 - val_loss: 0.0011\n",
      "Epoch 81/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.9020e-04 - val_loss: 0.0011\n",
      "Epoch 82/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.5842e-04 - val_loss: 0.0010\n",
      "Epoch 83/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.5985e-04 - val_loss: 0.0010\n",
      "Epoch 84/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.5308e-04 - val_loss: 0.0010\n",
      "Epoch 85/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.8460e-04 - val_loss: 0.0010\n",
      "Epoch 86/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.5287e-04 - val_loss: 0.0010\n",
      "Epoch 87/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.7477e-04 - val_loss: 9.9660e-04\n",
      "Epoch 88/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.6240e-04 - val_loss: 9.9130e-04\n",
      "Epoch 89/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.6192e-04 - val_loss: 9.8963e-04\n",
      "Epoch 90/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.5435e-04 - val_loss: 9.9396e-04\n",
      "Epoch 91/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.4501e-04 - val_loss: 9.7712e-04\n",
      "Epoch 92/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.3960e-04 - val_loss: 9.7666e-04\n",
      "Epoch 93/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 6.8371e-04 - val_loss: 9.6471e-04\n",
      "Epoch 94/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 6.2722e-04 - val_loss: 0.0010\n",
      "Epoch 95/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.2671e-04 - val_loss: 9.5356e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.2563e-04 - val_loss: 9.8229e-04\n",
      "Epoch 97/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.2619e-04 - val_loss: 9.5143e-04\n",
      "Epoch 98/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.2691e-04 - val_loss: 9.3982e-04\n",
      "Epoch 99/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.1851e-04 - val_loss: 9.3251e-04\n",
      "Epoch 100/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.1607e-04 - val_loss: 9.2727e-04\n",
      "Epoch 101/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0881e-04 - val_loss: 9.6496e-04\n",
      "Epoch 102/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0935e-04 - val_loss: 9.5968e-04\n",
      "Epoch 103/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.9955e-04 - val_loss: 9.1245e-04\n",
      "Epoch 104/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.1214e-04 - val_loss: 9.2589e-04\n",
      "Epoch 105/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0473e-04 - val_loss: 9.0650e-04\n",
      "Epoch 106/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.1398e-04 - val_loss: 9.2131e-04\n",
      "Epoch 107/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.9566e-04 - val_loss: 8.9432e-04\n",
      "Epoch 108/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 5.9403e-04 - val_loss: 8.8976e-04\n",
      "Epoch 109/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.8880e-04 - val_loss: 8.8554e-04\n",
      "Epoch 110/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.8893e-04 - val_loss: 8.8969e-04\n",
      "Epoch 111/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.8516e-04 - val_loss: 8.7552e-04\n",
      "Epoch 112/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0152e-04 - val_loss: 8.7231e-04\n",
      "Epoch 113/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0602e-04 - val_loss: 9.0726e-04\n",
      "Epoch 114/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.7860e-04 - val_loss: 8.6315e-04\n",
      "Epoch 115/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.8836e-04 - val_loss: 8.8607e-04\n",
      "Epoch 116/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.8150e-04 - val_loss: 8.7309e-04\n",
      "Epoch 117/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.6948e-04 - val_loss: 8.5729e-04\n",
      "Epoch 118/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.0629e-04 - val_loss: 8.6472e-04\n",
      "Epoch 119/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 5.8327e-04 - val_loss: 8.9104e-04\n",
      "Epoch 120/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.8488e-04 - val_loss: 9.3222e-04\n",
      "Epoch 121/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.6533e-04 - val_loss: 8.8034e-04\n",
      "Epoch 122/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 6.1337e-04 - val_loss: 8.7519e-04\n",
      "Epoch 123/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5948e-04 - val_loss: 8.3492e-04\n",
      "Epoch 124/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.6406e-04 - val_loss: 8.2475e-04\n",
      "Epoch 125/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.7056e-04 - val_loss: 8.4790e-04\n",
      "Epoch 126/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5344e-04 - val_loss: 8.2865e-04\n",
      "Epoch 127/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.7029e-04 - val_loss: 8.2496e-04\n",
      "Epoch 128/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5736e-04 - val_loss: 8.1017e-04\n",
      "Epoch 129/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5205e-04 - val_loss: 8.0783e-04\n",
      "Epoch 130/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.6160e-04 - val_loss: 8.0942e-04\n",
      "Epoch 131/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5849e-04 - val_loss: 8.4426e-04\n",
      "Epoch 132/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5649e-04 - val_loss: 7.9671e-04\n",
      "Epoch 133/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.6405e-04 - val_loss: 8.1813e-04\n",
      "Epoch 134/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5427e-04 - val_loss: 8.5481e-04\n",
      "Epoch 135/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.4924e-04 - val_loss: 7.9001e-04\n",
      "Epoch 136/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.4413e-04 - val_loss: 8.7812e-04\n",
      "Epoch 137/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 5.7531e-04 - val_loss: 7.8176e-04\n",
      "Epoch 138/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.8742e-04 - val_loss: 7.8638e-04\n",
      "Epoch 139/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.4517e-04 - val_loss: 7.7604e-04\n",
      "Epoch 140/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3439e-04 - val_loss: 7.7700e-04\n",
      "Epoch 141/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.4919e-04 - val_loss: 7.6943e-04\n",
      "Epoch 142/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3970e-04 - val_loss: 8.0378e-04\n",
      "Epoch 143/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3802e-04 - val_loss: 8.2644e-04\n",
      "Epoch 144/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5431e-04 - val_loss: 7.6207e-04\n",
      "Epoch 145/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5521e-04 - val_loss: 8.7690e-04\n",
      "Epoch 146/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.5540e-04 - val_loss: 7.6906e-04\n",
      "Epoch 147/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.1970e-04 - val_loss: 7.7181e-04\n",
      "Epoch 148/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.4640e-04 - val_loss: 8.2602e-04\n",
      "Epoch 149/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3961e-04 - val_loss: 7.6044e-04\n",
      "Epoch 150/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.1882e-04 - val_loss: 7.5264e-04\n",
      "Epoch 151/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2291e-04 - val_loss: 7.7843e-04\n",
      "Epoch 152/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2507e-04 - val_loss: 7.6687e-04\n",
      "Epoch 153/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2434e-04 - val_loss: 7.5151e-04\n",
      "Epoch 154/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.1140e-04 - val_loss: 7.6006e-04\n",
      "Epoch 155/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.0945e-04 - val_loss: 7.8784e-04\n",
      "Epoch 156/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.3014e-04 - val_loss: 7.2842e-04\n",
      "Epoch 157/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.0600e-04 - val_loss: 7.2700e-04\n",
      "Epoch 158/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.1387e-04 - val_loss: 7.2520e-04\n",
      "Epoch 159/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.1810e-04 - val_loss: 7.4438e-04\n",
      "Epoch 160/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 5.2289e-04 - val_loss: 7.3247e-04\n",
      "Epoch 161/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.1413e-04 - val_loss: 7.6193e-04\n",
      "Epoch 162/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.1589e-04 - val_loss: 7.1493e-04\n",
      "Epoch 163/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.0304e-04 - val_loss: 7.2608e-04\n",
      "Epoch 164/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.1288e-04 - val_loss: 7.1468e-04\n",
      "Epoch 165/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2400e-04 - val_loss: 7.1538e-04\n",
      "Epoch 166/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2793e-04 - val_loss: 7.0466e-04\n",
      "Epoch 167/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.2242e-04 - val_loss: 7.5062e-04\n",
      "Epoch 168/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.1108e-04 - val_loss: 7.0043e-04\n",
      "Epoch 169/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.9888e-04 - val_loss: 7.0108e-04\n",
      "Epoch 170/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.9549e-04 - val_loss: 6.9415e-04\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 3ms/step - loss: 5.0233e-04 - val_loss: 7.0190e-04\n",
      "Epoch 172/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.0133e-04 - val_loss: 6.8982e-04\n",
      "Epoch 173/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.9581e-04 - val_loss: 6.9973e-04\n",
      "Epoch 174/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.8943e-04 - val_loss: 7.0345e-04\n",
      "Epoch 175/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.8781e-04 - val_loss: 6.8062e-04\n",
      "Epoch 176/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.9181e-04 - val_loss: 6.9184e-04\n",
      "Epoch 177/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.9296e-04 - val_loss: 6.7664e-04\n",
      "Epoch 178/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.0028e-04 - val_loss: 6.8428e-04\n",
      "Epoch 179/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.9511e-04 - val_loss: 6.7373e-04\n",
      "Epoch 180/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.0830e-04 - val_loss: 7.2598e-04\n",
      "Epoch 181/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.8562e-04 - val_loss: 7.1555e-04\n",
      "Epoch 182/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.8542e-04 - val_loss: 6.9273e-04\n",
      "Epoch 183/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.0431e-04 - val_loss: 6.7015e-04\n",
      "Epoch 184/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 5.0077e-04 - val_loss: 6.6440e-04\n",
      "Epoch 185/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.7960e-04 - val_loss: 7.6433e-04\n",
      "Epoch 186/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.1653e-04 - val_loss: 6.6664e-04\n",
      "Epoch 187/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.9135e-04 - val_loss: 6.8032e-04\n",
      "Epoch 188/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.7994e-04 - val_loss: 6.6281e-04\n",
      "Epoch 189/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.8995e-04 - val_loss: 6.5600e-04\n",
      "Epoch 190/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.8277e-04 - val_loss: 6.5875e-04\n",
      "Epoch 191/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.8863e-04 - val_loss: 6.6420e-04\n",
      "Epoch 192/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.9088e-04 - val_loss: 6.6531e-04\n",
      "Epoch 193/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.6720e-04 - val_loss: 6.4904e-04\n",
      "Epoch 194/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.9247e-04 - val_loss: 6.5277e-04\n",
      "Epoch 195/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.8515e-04 - val_loss: 6.9592e-04\n",
      "Epoch 196/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.0334e-04 - val_loss: 6.4376e-04\n",
      "Epoch 197/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.8362e-04 - val_loss: 6.4343e-04\n",
      "Epoch 198/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.8470e-04 - val_loss: 6.4332e-04\n",
      "Epoch 199/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.7472e-04 - val_loss: 6.7060e-04\n",
      "Epoch 200/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.7452e-04 - val_loss: 6.3620e-04\n",
      "Thời gian huấn luyện:  19.156447887420654\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_6 (SimpleRNN)    (None, 10, 89)            8099      \n",
      "                                                                 \n",
      " flatten_25 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,990\n",
      "Trainable params: 8,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "27/27 [==============================] - 2s 20ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 2/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 3/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 4/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 5/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 6/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 7/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 8/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 9/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 10/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 11/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 12/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 13/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 14/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 15/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 16/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 17/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 18/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 19/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 20/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 21/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 22/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 23/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 24/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 25/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 26/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 27/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 28/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 29/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 30/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 31/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 32/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 33/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 34/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 35/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 36/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 37/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 38/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 39/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 40/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 41/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 43/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 44/200\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 45/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 46/200\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 47/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 48/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 49/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 50/200\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 51/200\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 52/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 53/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 54/200\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 55/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 56/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 57/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 58/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 59/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 60/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 61/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 62/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 63/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 64/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 65/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 66/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 67/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 68/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 69/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 70/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 71/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 72/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 73/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 74/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 75/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 76/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 77/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 78/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 79/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 80/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 81/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 82/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 83/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 84/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 85/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 86/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 87/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 88/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 89/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 90/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 91/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 92/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 93/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 94/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 95/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 96/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 97/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 98/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 99/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 100/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 101/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 102/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 103/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 104/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 105/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 106/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 107/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 108/200\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 109/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 110/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 111/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 112/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 113/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 114/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 115/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 116/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 117/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 118/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 119/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 120/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 121/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 122/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 123/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 124/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 125/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 126/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 127/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 128/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 129/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 130/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 131/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 132/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 133/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 134/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 135/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 136/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 137/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 138/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 139/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 140/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 141/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 142/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 143/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 144/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 145/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 146/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 147/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 148/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 149/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 150/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 151/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 152/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 153/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 154/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 155/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 156/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 157/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 158/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 159/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 160/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 161/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 162/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 163/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 164/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 165/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 166/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 167/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 168/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 169/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 170/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 171/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 172/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 173/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 174/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 175/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 176/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 177/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 178/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 179/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 180/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 181/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 182/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 183/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 184/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 185/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 186/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 187/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 188/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 189/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 190/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 191/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 192/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 193/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 194/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 195/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 196/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 197/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 198/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 199/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Epoch 200/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0572\n",
      "Thời gian huấn luyện:  39.320109844207764\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 10, 89)            32396     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " flatten_26 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,287\n",
      "Trainable params: 33,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "27/27 [==============================] - 2s 18ms/step - loss: 0.0233 - val_loss: 0.0036\n",
      "Epoch 2/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 3/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 4/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 5/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 6/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 7/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 8/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 9/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 10/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 11/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 12/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 13/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 14/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 15/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 16/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 17/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 18/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 19/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 20/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 21/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 22/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 23/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 24/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 25/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 26/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 27/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 28/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 29/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 30/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 31/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 32/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.8591e-04 - val_loss: 0.0016\n",
      "Epoch 33/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.5933e-04 - val_loss: 0.0016\n",
      "Epoch 34/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.5330e-04 - val_loss: 0.0016\n",
      "Epoch 35/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.3814e-04 - val_loss: 0.0016\n",
      "Epoch 36/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.3745e-04 - val_loss: 0.0016\n",
      "Epoch 37/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.1580e-04 - val_loss: 0.0015\n",
      "Epoch 38/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.0572e-04 - val_loss: 0.0015\n",
      "Epoch 39/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9.0301e-04 - val_loss: 0.0015\n",
      "Epoch 40/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.8289e-04 - val_loss: 0.0015\n",
      "Epoch 41/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.8744e-04 - val_loss: 0.0015\n",
      "Epoch 42/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.7156e-04 - val_loss: 0.0015\n",
      "Epoch 43/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.6033e-04 - val_loss: 0.0014\n",
      "Epoch 44/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.5062e-04 - val_loss: 0.0014\n",
      "Epoch 45/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.4100e-04 - val_loss: 0.0014\n",
      "Epoch 46/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.4325e-04 - val_loss: 0.0014\n",
      "Epoch 47/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.3673e-04 - val_loss: 0.0014\n",
      "Epoch 48/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.2214e-04 - val_loss: 0.0014\n",
      "Epoch 49/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.1575e-04 - val_loss: 0.0014\n",
      "Epoch 50/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.1038e-04 - val_loss: 0.0014\n",
      "Epoch 51/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.0450e-04 - val_loss: 0.0013\n",
      "Epoch 52/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.9769e-04 - val_loss: 0.0014\n",
      "Epoch 53/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.9775e-04 - val_loss: 0.0013\n",
      "Epoch 54/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.8553e-04 - val_loss: 0.0013\n",
      "Epoch 55/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.7771e-04 - val_loss: 0.0013\n",
      "Epoch 56/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.7445e-04 - val_loss: 0.0013\n",
      "Epoch 57/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.7465e-04 - val_loss: 0.0013\n",
      "Epoch 58/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.6719e-04 - val_loss: 0.0013\n",
      "Epoch 59/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.6058e-04 - val_loss: 0.0013\n",
      "Epoch 60/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.5556e-04 - val_loss: 0.0013\n",
      "Epoch 61/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.5067e-04 - val_loss: 0.0013\n",
      "Epoch 62/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.5110e-04 - val_loss: 0.0013\n",
      "Epoch 63/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.4946e-04 - val_loss: 0.0012\n",
      "Epoch 64/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.4971e-04 - val_loss: 0.0012\n",
      "Epoch 65/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.3947e-04 - val_loss: 0.0012\n",
      "Epoch 66/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.5334e-04 - val_loss: 0.0012\n",
      "Epoch 67/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.4462e-04 - val_loss: 0.0012\n",
      "Epoch 68/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.3409e-04 - val_loss: 0.0012\n",
      "Epoch 69/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.4366e-04 - val_loss: 0.0012\n",
      "Epoch 70/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.2171e-04 - val_loss: 0.0012\n",
      "Epoch 71/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.1071e-04 - val_loss: 0.0012\n",
      "Epoch 72/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.1805e-04 - val_loss: 0.0012\n",
      "Epoch 73/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.1700e-04 - val_loss: 0.0012\n",
      "Epoch 74/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.1195e-04 - val_loss: 0.0012\n",
      "Epoch 75/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 7.1177e-04 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.9759e-04 - val_loss: 0.0012\n",
      "Epoch 77/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.9704e-04 - val_loss: 0.0011\n",
      "Epoch 78/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.9320e-04 - val_loss: 0.0011\n",
      "Epoch 79/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.8656e-04 - val_loss: 0.0011\n",
      "Epoch 80/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.9884e-04 - val_loss: 0.0011\n",
      "Epoch 81/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.8247e-04 - val_loss: 0.0011\n",
      "Epoch 82/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.7829e-04 - val_loss: 0.0011\n",
      "Epoch 83/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.8262e-04 - val_loss: 0.0011\n",
      "Epoch 84/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.7442e-04 - val_loss: 0.0011\n",
      "Epoch 85/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.7235e-04 - val_loss: 0.0011\n",
      "Epoch 86/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.7514e-04 - val_loss: 0.0011\n",
      "Epoch 87/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.6512e-04 - val_loss: 0.0011\n",
      "Epoch 88/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.6663e-04 - val_loss: 0.0011\n",
      "Epoch 89/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.6244e-04 - val_loss: 0.0011\n",
      "Epoch 90/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.6314e-04 - val_loss: 0.0011\n",
      "Epoch 91/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.5402e-04 - val_loss: 0.0011\n",
      "Epoch 92/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.5000e-04 - val_loss: 0.0011\n",
      "Epoch 93/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.5697e-04 - val_loss: 0.0011\n",
      "Epoch 94/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.4833e-04 - val_loss: 0.0010\n",
      "Epoch 95/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.4637e-04 - val_loss: 0.0010\n",
      "Epoch 96/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.5222e-04 - val_loss: 0.0011\n",
      "Epoch 97/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.4300e-04 - val_loss: 0.0011\n",
      "Epoch 98/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.5784e-04 - val_loss: 0.0010\n",
      "Epoch 99/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.3764e-04 - val_loss: 0.0010\n",
      "Epoch 100/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.4199e-04 - val_loss: 0.0010\n",
      "Epoch 101/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2954e-04 - val_loss: 0.0010\n",
      "Epoch 102/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.4278e-04 - val_loss: 0.0010\n",
      "Epoch 103/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.3817e-04 - val_loss: 0.0010\n",
      "Epoch 104/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2342e-04 - val_loss: 0.0010\n",
      "Epoch 105/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2685e-04 - val_loss: 9.9169e-04\n",
      "Epoch 106/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2611e-04 - val_loss: 0.0010\n",
      "Epoch 107/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2174e-04 - val_loss: 9.7891e-04\n",
      "Epoch 108/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2280e-04 - val_loss: 9.8186e-04\n",
      "Epoch 109/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2249e-04 - val_loss: 9.6952e-04\n",
      "Epoch 110/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2391e-04 - val_loss: 9.6682e-04\n",
      "Epoch 111/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2017e-04 - val_loss: 9.9090e-04\n",
      "Epoch 112/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.0664e-04 - val_loss: 9.7068e-04\n",
      "Epoch 113/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.0393e-04 - val_loss: 9.7679e-04\n",
      "Epoch 114/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.2032e-04 - val_loss: 9.4386e-04\n",
      "Epoch 115/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.9853e-04 - val_loss: 9.4490e-04\n",
      "Epoch 116/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.0312e-04 - val_loss: 9.4026e-04\n",
      "Epoch 117/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.0341e-04 - val_loss: 9.3266e-04\n",
      "Epoch 118/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.9743e-04 - val_loss: 9.4285e-04\n",
      "Epoch 119/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.0338e-04 - val_loss: 9.7494e-04\n",
      "Epoch 120/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6.0973e-04 - val_loss: 9.2651e-04\n",
      "Epoch 121/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.9635e-04 - val_loss: 9.5159e-04\n",
      "Epoch 122/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.8882e-04 - val_loss: 9.1231e-04\n",
      "Epoch 123/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.8085e-04 - val_loss: 9.1208e-04\n",
      "Epoch 124/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.8187e-04 - val_loss: 9.1244e-04\n",
      "Epoch 125/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.8225e-04 - val_loss: 9.0744e-04\n",
      "Epoch 126/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.8058e-04 - val_loss: 9.0388e-04\n",
      "Epoch 127/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.7368e-04 - val_loss: 9.1168e-04\n",
      "Epoch 128/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.7274e-04 - val_loss: 9.2376e-04\n",
      "Epoch 129/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.7564e-04 - val_loss: 8.8894e-04\n",
      "Epoch 130/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.7131e-04 - val_loss: 8.8770e-04\n",
      "Epoch 131/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.7410e-04 - val_loss: 8.8073e-04\n",
      "Epoch 132/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.6691e-04 - val_loss: 8.7209e-04\n",
      "Epoch 133/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.6639e-04 - val_loss: 8.9929e-04\n",
      "Epoch 134/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.7764e-04 - val_loss: 8.6542e-04\n",
      "Epoch 135/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.6797e-04 - val_loss: 8.6427e-04\n",
      "Epoch 136/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.6019e-04 - val_loss: 8.5945e-04\n",
      "Epoch 137/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.5758e-04 - val_loss: 8.6457e-04\n",
      "Epoch 138/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.5658e-04 - val_loss: 8.5216e-04\n",
      "Epoch 139/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.5468e-04 - val_loss: 8.4844e-04\n",
      "Epoch 140/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.6139e-04 - val_loss: 8.4561e-04\n",
      "Epoch 141/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.6068e-04 - val_loss: 8.5741e-04\n",
      "Epoch 142/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.6401e-04 - val_loss: 8.3876e-04\n",
      "Epoch 143/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.5960e-04 - val_loss: 8.4357e-04\n",
      "Epoch 144/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.4907e-04 - val_loss: 8.4675e-04\n",
      "Epoch 145/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.4223e-04 - val_loss: 8.3368e-04\n",
      "Epoch 146/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.4068e-04 - val_loss: 8.2529e-04\n",
      "Epoch 147/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.6252e-04 - val_loss: 8.2652e-04\n",
      "Epoch 148/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.4818e-04 - val_loss: 8.1834e-04\n",
      "Epoch 149/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.4524e-04 - val_loss: 8.4498e-04\n",
      "Epoch 150/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.4038e-04 - val_loss: 8.1482e-04\n",
      "Epoch 151/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.3759e-04 - val_loss: 8.0977e-04\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 6ms/step - loss: 5.5776e-04 - val_loss: 8.1257e-04\n",
      "Epoch 153/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.3919e-04 - val_loss: 8.0331e-04\n",
      "Epoch 154/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.3488e-04 - val_loss: 8.0423e-04\n",
      "Epoch 155/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.3021e-04 - val_loss: 8.1065e-04\n",
      "Epoch 156/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.2898e-04 - val_loss: 7.9633e-04\n",
      "Epoch 157/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.4205e-04 - val_loss: 8.3166e-04\n",
      "Epoch 158/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.4339e-04 - val_loss: 7.9612e-04\n",
      "Epoch 159/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.3782e-04 - val_loss: 7.8790e-04\n",
      "Epoch 160/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.2676e-04 - val_loss: 7.8311e-04\n",
      "Epoch 161/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.2682e-04 - val_loss: 7.8505e-04\n",
      "Epoch 162/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.2253e-04 - val_loss: 7.8098e-04\n",
      "Epoch 163/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.2319e-04 - val_loss: 7.7637e-04\n",
      "Epoch 164/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.2447e-04 - val_loss: 7.8999e-04\n",
      "Epoch 165/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.2177e-04 - val_loss: 7.7213e-04\n",
      "Epoch 166/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.2036e-04 - val_loss: 7.7199e-04\n",
      "Epoch 167/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.3362e-04 - val_loss: 7.8898e-04\n",
      "Epoch 168/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.7400e-04 - val_loss: 7.6214e-04\n",
      "Epoch 169/200\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 5.2834e-04 - val_loss: 7.6518e-04\n",
      "Epoch 170/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.2139e-04 - val_loss: 7.5951e-04\n",
      "Epoch 171/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.2190e-04 - val_loss: 7.8309e-04\n",
      "Epoch 172/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.1370e-04 - val_loss: 7.8046e-04\n",
      "Epoch 173/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.0670e-04 - val_loss: 7.5229e-04\n",
      "Epoch 174/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.0960e-04 - val_loss: 7.6697e-04\n",
      "Epoch 175/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.1230e-04 - val_loss: 7.4643e-04\n",
      "Epoch 176/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.1001e-04 - val_loss: 7.8417e-04\n",
      "Epoch 177/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.0390e-04 - val_loss: 7.4184e-04\n",
      "Epoch 178/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.0665e-04 - val_loss: 7.4163e-04\n",
      "Epoch 179/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.0439e-04 - val_loss: 7.6353e-04\n",
      "Epoch 180/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.0948e-04 - val_loss: 7.4563e-04\n",
      "Epoch 181/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.0627e-04 - val_loss: 7.6187e-04\n",
      "Epoch 182/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.0663e-04 - val_loss: 7.8473e-04\n",
      "Epoch 183/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.0936e-04 - val_loss: 7.7185e-04\n",
      "Epoch 184/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.4101e-04 - val_loss: 7.5617e-04\n",
      "Epoch 185/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.3773e-04 - val_loss: 7.4285e-04\n",
      "Epoch 186/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.2117e-04 - val_loss: 7.2343e-04\n",
      "Epoch 187/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.1556e-04 - val_loss: 7.2559e-04\n",
      "Epoch 188/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.9667e-04 - val_loss: 7.3961e-04\n",
      "Epoch 189/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.9967e-04 - val_loss: 7.3407e-04\n",
      "Epoch 190/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.9869e-04 - val_loss: 7.1530e-04\n",
      "Epoch 191/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.9300e-04 - val_loss: 7.1345e-04\n",
      "Epoch 192/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.9459e-04 - val_loss: 7.1725e-04\n",
      "Epoch 193/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.9755e-04 - val_loss: 7.1050e-04\n",
      "Epoch 194/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.8871e-04 - val_loss: 7.3071e-04\n",
      "Epoch 195/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5.0017e-04 - val_loss: 7.0338e-04\n",
      "Epoch 196/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.9322e-04 - val_loss: 7.4176e-04\n",
      "Epoch 197/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.9362e-04 - val_loss: 7.1504e-04\n",
      "Epoch 198/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.8425e-04 - val_loss: 7.0107e-04\n",
      "Epoch 199/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.9838e-04 - val_loss: 7.1131e-04\n",
      "Epoch 200/200\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4.8684e-04 - val_loss: 6.9650e-04\n",
      "Thời gian huấn luyện:  35.96290373802185\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_6 (GRU)                 (None, 10, 89)            24564     \n",
      "                                                                 \n",
      " flatten_27 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,455\n",
      "Trainable params: 25,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "30/30 [==============================] - 0s 931us/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 24/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 29/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 32/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 42/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 44/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 49/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 50/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 51/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 52/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 53/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 54/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 55/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 56/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 57/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 58/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 59/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 60/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 61/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 62/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 63/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 64/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 65/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 66/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 67/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 68/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 69/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 70/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 71/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 72/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 73/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 74/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 75/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 76/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 77/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 78/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 79/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 80/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 81/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 82/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 83/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 84/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 85/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 86/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 87/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 88/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 89/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 90/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 91/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 92/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 93/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 94/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 95/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 96/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 97/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 98/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 100/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 101/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 102/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 103/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 104/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 105/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 106/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 107/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 108/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 109/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 110/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 111/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 112/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 113/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 114/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 115/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 116/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 117/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 118/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 119/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 120/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 121/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 122/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 123/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 124/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 125/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 126/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 127/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 128/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 129/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 130/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 131/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 132/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 133/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 134/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 135/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 136/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 137/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 138/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 139/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 140/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 141/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 142/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 143/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 144/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 145/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 146/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 147/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 148/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 149/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 150/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 151/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 152/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 153/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 154/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 155/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 156/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 157/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 158/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 159/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 160/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 161/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 162/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 163/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 164/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 165/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 166/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 167/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 168/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 169/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 170/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 171/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 172/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 173/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 174/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 175/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 176/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 177/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 178/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 179/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 180/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 181/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 182/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 183/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 184/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 185/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 186/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 187/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 188/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 189/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 190/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 191/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 192/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 193/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 194/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 195/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 196/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 197/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 198/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 199/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 200/200\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Thời gian huấn luyện:  12.718680381774902\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_35 (Dense)            (None, 10, 89)            178       \n",
      "                                                                 \n",
      " flatten_28 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069\n",
      "Trainable params: 1,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "26/26 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.0062\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.6260e-04 - val_loss: 0.0016\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.3805e-04 - val_loss: 0.0015\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 9.6674e-04 - val_loss: 0.0014\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 8.8455e-04 - val_loss: 0.0014\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.6465e-04 - val_loss: 0.0014\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 8.4996e-04 - val_loss: 0.0013\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 8.4174e-04 - val_loss: 0.0014\n",
      "Epoch 17/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 8.4676e-04 - val_loss: 0.0012\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.1168e-04 - val_loss: 0.0012\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.0377e-04 - val_loss: 0.0012\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 8.1760e-04 - val_loss: 0.0012\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 8.0519e-04 - val_loss: 0.0012\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.8563e-04 - val_loss: 0.0012\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.8413e-04 - val_loss: 0.0011\n",
      "Epoch 24/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.0141e-04 - val_loss: 0.0012\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.7508e-04 - val_loss: 0.0012\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.5288e-04 - val_loss: 0.0011\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.5382e-04 - val_loss: 0.0011\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.4755e-04 - val_loss: 0.0011\n",
      "Epoch 29/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.4360e-04 - val_loss: 0.0011\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.4675e-04 - val_loss: 0.0011\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.3909e-04 - val_loss: 0.0010\n",
      "Epoch 32/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.2650e-04 - val_loss: 0.0010\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.1320e-04 - val_loss: 0.0010\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 7.1432e-04 - val_loss: 0.0010\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.0451e-04 - val_loss: 0.0010\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.9841e-04 - val_loss: 9.9877e-04\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9575e-04 - val_loss: 9.8369e-04\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.9329e-04 - val_loss: 9.7693e-04\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.9772e-04 - val_loss: 0.0010\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8516e-04 - val_loss: 9.6641e-04\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8147e-04 - val_loss: 9.5222e-04\n",
      "Epoch 42/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8556e-04 - val_loss: 9.8572e-04\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8734e-04 - val_loss: 0.0010\n",
      "Epoch 44/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.9518e-04 - val_loss: 9.6939e-04\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8261e-04 - val_loss: 9.7239e-04\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9580e-04 - val_loss: 9.7402e-04\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.6887e-04 - val_loss: 9.1912e-04\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.6274e-04 - val_loss: 9.8932e-04\n",
      "Epoch 49/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1931e-04 - val_loss: 9.5197e-04\n",
      "Epoch 50/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6695e-04 - val_loss: 9.0902e-04\n",
      "Epoch 51/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 4ms/step - loss: 7.3908e-04 - val_loss: 9.2478e-04\n",
      "Epoch 52/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.6858e-04 - val_loss: 9.1006e-04\n",
      "Epoch 53/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4115e-04 - val_loss: 8.9313e-04\n",
      "Epoch 54/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3589e-04 - val_loss: 8.9081e-04\n",
      "Epoch 55/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4544e-04 - val_loss: 8.8478e-04\n",
      "Epoch 56/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3664e-04 - val_loss: 9.5064e-04\n",
      "Epoch 57/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.7962e-04 - val_loss: 8.8050e-04\n",
      "Epoch 58/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.6345e-04 - val_loss: 8.6535e-04\n",
      "Epoch 59/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.2958e-04 - val_loss: 8.7547e-04\n",
      "Epoch 60/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.2622e-04 - val_loss: 8.7004e-04\n",
      "Epoch 61/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.3477e-04 - val_loss: 8.5393e-04\n",
      "Epoch 62/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6590e-04 - val_loss: 8.5216e-04\n",
      "Epoch 63/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.2286e-04 - val_loss: 9.0474e-04\n",
      "Epoch 64/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.3223e-04 - val_loss: 8.5383e-04\n",
      "Epoch 65/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2341e-04 - val_loss: 8.6658e-04\n",
      "Epoch 66/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.1613e-04 - val_loss: 8.4142e-04\n",
      "Epoch 67/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1281e-04 - val_loss: 9.2952e-04\n",
      "Epoch 68/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3306e-04 - val_loss: 8.2741e-04\n",
      "Epoch 69/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.1971e-04 - val_loss: 8.4170e-04\n",
      "Epoch 70/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.1542e-04 - val_loss: 8.8444e-04\n",
      "Epoch 71/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3299e-04 - val_loss: 8.2604e-04\n",
      "Epoch 72/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.0832e-04 - val_loss: 8.1085e-04\n",
      "Epoch 73/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.9786e-04 - val_loss: 8.0978e-04\n",
      "Epoch 74/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.9366e-04 - val_loss: 8.0916e-04\n",
      "Epoch 75/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3326e-04 - val_loss: 8.0234e-04\n",
      "Epoch 76/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9356e-04 - val_loss: 8.6991e-04\n",
      "Epoch 77/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.0841e-04 - val_loss: 8.0416e-04\n",
      "Epoch 78/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8788e-04 - val_loss: 7.9693e-04\n",
      "Epoch 79/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.8930e-04 - val_loss: 8.2279e-04\n",
      "Epoch 80/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.9233e-04 - val_loss: 8.3388e-04\n",
      "Epoch 81/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2543e-04 - val_loss: 9.5202e-04\n",
      "Epoch 82/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.0532e-04 - val_loss: 8.3759e-04\n",
      "Epoch 83/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.9989e-04 - val_loss: 8.5460e-04\n",
      "Epoch 84/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9312e-04 - val_loss: 7.9545e-04\n",
      "Epoch 85/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1688e-04 - val_loss: 8.0539e-04\n",
      "Epoch 86/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.8809e-04 - val_loss: 8.9561e-04\n",
      "Epoch 87/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9428e-04 - val_loss: 8.3965e-04\n",
      "Epoch 88/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.7819e-04 - val_loss: 8.4056e-04\n",
      "Epoch 89/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8840e-04 - val_loss: 7.6197e-04\n",
      "Epoch 90/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.7326e-04 - val_loss: 7.6084e-04\n",
      "Epoch 91/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.5480e-04 - val_loss: 7.6035e-04\n",
      "Epoch 92/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.6591e-04 - val_loss: 8.7275e-04\n",
      "Epoch 93/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9442e-04 - val_loss: 8.2830e-04\n",
      "Epoch 94/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.6729e-04 - val_loss: 8.3499e-04\n",
      "Epoch 95/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8181e-04 - val_loss: 9.0589e-04\n",
      "Epoch 96/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8149e-04 - val_loss: 7.4017e-04\n",
      "Epoch 97/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.6095e-04 - val_loss: 7.9730e-04\n",
      "Epoch 98/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3740e-04 - val_loss: 7.3996e-04\n",
      "Epoch 99/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.6654e-04 - val_loss: 7.4171e-04\n",
      "Epoch 100/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.5363e-04 - val_loss: 7.7451e-04\n",
      "Epoch 101/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.7897e-04 - val_loss: 7.5864e-04\n",
      "Epoch 102/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.5678e-04 - val_loss: 7.5051e-04\n",
      "Epoch 103/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.7413e-04 - val_loss: 7.8776e-04\n",
      "Epoch 104/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.5166e-04 - val_loss: 8.0252e-04\n",
      "Epoch 105/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.8881e-04 - val_loss: 8.7707e-04\n",
      "Epoch 106/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.6212e-04 - val_loss: 7.1681e-04\n",
      "Epoch 107/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.4558e-04 - val_loss: 7.2349e-04\n",
      "Epoch 108/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.3755e-04 - val_loss: 7.1142e-04\n",
      "Epoch 109/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.4350e-04 - val_loss: 7.1626e-04\n",
      "Epoch 110/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8738e-04 - val_loss: 7.1097e-04\n",
      "Epoch 111/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.5414e-04 - val_loss: 7.0670e-04\n",
      "Epoch 112/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.3402e-04 - val_loss: 7.4188e-04\n",
      "Epoch 113/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.3738e-04 - val_loss: 7.0051e-04\n",
      "Epoch 114/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8092e-04 - val_loss: 7.4544e-04\n",
      "Epoch 115/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1881e-04 - val_loss: 7.0721e-04\n",
      "Epoch 116/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.3433e-04 - val_loss: 6.9516e-04\n",
      "Epoch 117/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.3524e-04 - val_loss: 6.9527e-04\n",
      "Epoch 118/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.3680e-04 - val_loss: 7.0036e-04\n",
      "Epoch 119/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.4340e-04 - val_loss: 7.7476e-04\n",
      "Epoch 120/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.4554e-04 - val_loss: 6.9300e-04\n",
      "Epoch 121/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.5249e-04 - val_loss: 6.8666e-04\n",
      "Epoch 122/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.2323e-04 - val_loss: 6.9047e-04\n",
      "Epoch 123/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.2194e-04 - val_loss: 7.1642e-04\n",
      "Epoch 124/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.6817e-04 - val_loss: 6.8568e-04\n",
      "Epoch 125/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.2382e-04 - val_loss: 6.9975e-04\n",
      "Epoch 126/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 4ms/step - loss: 5.2381e-04 - val_loss: 7.2389e-04\n",
      "Epoch 127/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.4974e-04 - val_loss: 6.9482e-04\n",
      "Epoch 128/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.4557e-04 - val_loss: 7.2914e-04\n",
      "Epoch 129/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.3179e-04 - val_loss: 6.9214e-04\n",
      "Epoch 130/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.1822e-04 - val_loss: 7.2393e-04\n",
      "Epoch 131/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.1770e-04 - val_loss: 6.7983e-04\n",
      "Epoch 132/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.2013e-04 - val_loss: 6.6581e-04\n",
      "Epoch 133/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.3123e-04 - val_loss: 6.6200e-04\n",
      "Epoch 134/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.3519e-04 - val_loss: 6.6886e-04\n",
      "Epoch 135/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.5607e-04 - val_loss: 6.9961e-04\n",
      "Epoch 136/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.3711e-04 - val_loss: 6.5574e-04\n",
      "Epoch 137/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.5233e-04 - val_loss: 6.5658e-04\n",
      "Epoch 138/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.5192e-04 - val_loss: 6.8320e-04\n",
      "Epoch 139/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.3152e-04 - val_loss: 7.7007e-04\n",
      "Epoch 140/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.2579e-04 - val_loss: 6.9060e-04\n",
      "Epoch 141/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.2502e-04 - val_loss: 7.2492e-04\n",
      "Epoch 142/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.6292e-04 - val_loss: 6.7956e-04\n",
      "Epoch 143/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.3258e-04 - val_loss: 6.4514e-04\n",
      "Epoch 144/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.0606e-04 - val_loss: 6.9417e-04\n",
      "Epoch 145/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.1493e-04 - val_loss: 7.3101e-04\n",
      "Epoch 146/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.1782e-04 - val_loss: 6.5609e-04\n",
      "Epoch 147/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.1872e-04 - val_loss: 6.3640e-04\n",
      "Epoch 148/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.2496e-04 - val_loss: 6.3971e-04\n",
      "Epoch 149/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.0845e-04 - val_loss: 6.7181e-04\n",
      "Epoch 150/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.9593e-04 - val_loss: 6.4721e-04\n",
      "Epoch 151/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.0333e-04 - val_loss: 6.3256e-04\n",
      "Epoch 152/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.9895e-04 - val_loss: 6.4238e-04\n",
      "Epoch 153/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.0916e-04 - val_loss: 6.7686e-04\n",
      "Epoch 154/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.9643e-04 - val_loss: 6.3425e-04\n",
      "Epoch 155/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.9877e-04 - val_loss: 6.2841e-04\n",
      "Epoch 156/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.0400e-04 - val_loss: 6.3341e-04\n",
      "Epoch 157/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.0151e-04 - val_loss: 6.1903e-04\n",
      "Epoch 158/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.0180e-04 - val_loss: 7.4340e-04\n",
      "Epoch 159/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.9986e-04 - val_loss: 6.9590e-04\n",
      "Epoch 160/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.3588e-04 - val_loss: 7.0413e-04\n",
      "Epoch 161/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.9959e-04 - val_loss: 8.7849e-04\n",
      "Epoch 162/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.3393e-04 - val_loss: 7.8543e-04\n",
      "Epoch 163/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.2804e-04 - val_loss: 6.1499e-04\n",
      "Epoch 164/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.8986e-04 - val_loss: 6.1827e-04\n",
      "Epoch 165/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.0360e-04 - val_loss: 6.4125e-04\n",
      "Epoch 166/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.0932e-04 - val_loss: 6.4508e-04\n",
      "Epoch 167/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.9389e-04 - val_loss: 6.0825e-04\n",
      "Epoch 168/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.9099e-04 - val_loss: 6.0445e-04\n",
      "Epoch 169/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.1213e-04 - val_loss: 6.5157e-04\n",
      "Epoch 170/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.9329e-04 - val_loss: 6.0220e-04\n",
      "Epoch 171/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.8169e-04 - val_loss: 6.0269e-04\n",
      "Epoch 172/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.8385e-04 - val_loss: 6.4793e-04\n",
      "Epoch 173/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.8242e-04 - val_loss: 6.2362e-04\n",
      "Epoch 174/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.7567e-04 - val_loss: 6.0615e-04\n",
      "Epoch 175/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.8139e-04 - val_loss: 6.0110e-04\n",
      "Epoch 176/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.8201e-04 - val_loss: 6.3336e-04\n",
      "Epoch 177/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.9584e-04 - val_loss: 6.0676e-04\n",
      "Epoch 178/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.3918e-04 - val_loss: 6.9622e-04\n",
      "Epoch 179/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.9008e-04 - val_loss: 6.3196e-04\n",
      "Epoch 180/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.7350e-04 - val_loss: 5.9061e-04\n",
      "Epoch 181/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.7312e-04 - val_loss: 5.9437e-04\n",
      "Epoch 182/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.1832e-04 - val_loss: 5.8885e-04\n",
      "Epoch 183/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.9768e-04 - val_loss: 6.1593e-04\n",
      "Epoch 184/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.9418e-04 - val_loss: 6.3299e-04\n",
      "Epoch 185/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.7806e-04 - val_loss: 8.0223e-04\n",
      "Epoch 186/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.3678e-04 - val_loss: 6.6533e-04\n",
      "Epoch 187/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.9386e-04 - val_loss: 6.0460e-04\n",
      "Epoch 188/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.7557e-04 - val_loss: 5.8131e-04\n",
      "Epoch 189/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.6601e-04 - val_loss: 5.8856e-04\n",
      "Epoch 190/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.7584e-04 - val_loss: 6.3688e-04\n",
      "Epoch 191/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.6875e-04 - val_loss: 5.9942e-04\n",
      "Epoch 192/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.8279e-04 - val_loss: 5.8155e-04\n",
      "Epoch 193/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.7067e-04 - val_loss: 5.7329e-04\n",
      "Epoch 194/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.7283e-04 - val_loss: 5.8816e-04\n",
      "Epoch 195/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.6630e-04 - val_loss: 5.8072e-04\n",
      "Epoch 196/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.6924e-04 - val_loss: 6.1646e-04\n",
      "Epoch 197/200\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.6504e-04 - val_loss: 5.8366e-04\n",
      "Epoch 198/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.7770e-04 - val_loss: 5.8463e-04\n",
      "Epoch 199/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.8673e-04 - val_loss: 5.6886e-04\n",
      "Epoch 200/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.7152e-04 - val_loss: 5.6660e-04\n",
      "Thời gian huấn luyện:  19.293518781661987\n",
      "Model: \"sequential_29\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_7 (SimpleRNN)    (None, 10, 89)            8099      \n",
      "                                                                 \n",
      " flatten_29 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,990\n",
      "Trainable params: 8,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "26/26 [==============================] - 2s 20ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 17/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 24/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 29/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 32/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 42/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 44/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 49/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 50/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 51/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 52/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 53/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 54/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 55/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 56/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 57/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 58/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 59/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 60/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 61/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 62/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 63/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 64/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 65/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 66/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 67/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 68/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 69/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 70/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 71/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 72/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 73/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 74/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 75/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 76/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 77/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 78/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 79/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 80/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 81/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 82/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 83/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 84/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 85/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 86/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 87/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 88/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 89/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 90/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 91/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 92/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 93/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 94/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 95/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 96/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 97/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 98/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 99/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 100/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 101/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 102/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 103/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 104/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 105/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 106/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 107/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 108/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 109/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 110/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 111/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 112/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 113/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 114/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 115/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 116/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 117/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 118/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 119/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 120/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 121/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 122/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 123/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 124/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 125/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 126/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 127/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 128/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 129/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 130/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 131/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 132/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 133/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 134/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 135/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 136/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 137/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 138/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 139/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 140/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 141/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 142/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 143/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 144/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 145/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 146/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 147/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 148/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 149/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 150/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 151/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 152/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 153/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 154/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 155/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 157/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 158/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 159/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 160/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 161/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 162/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 163/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 164/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 165/200\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 166/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 167/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 168/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 169/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 170/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 171/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 172/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 173/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 174/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 175/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 176/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 177/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 178/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 179/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 180/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 181/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 182/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 183/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 184/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 185/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 186/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 187/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 188/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 189/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 190/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 191/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 192/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 193/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 194/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 195/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 196/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 197/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 198/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 199/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Epoch 200/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0907\n",
      "Thời gian huấn luyện:  39.17798829078674\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_7 (LSTM)               (None, 10, 89)            32396     \n",
      "                                                                 \n",
      " flatten_30 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,287\n",
      "Trainable params: 33,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "26/26 [==============================] - 2s 18ms/step - loss: 0.0191 - val_loss: 0.0032\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 17/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 24/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 32/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.9533e-04 - val_loss: 0.0017\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.7962e-04 - val_loss: 0.0016\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.6770e-04 - val_loss: 0.0017\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.4968e-04 - val_loss: 0.0017\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.6102e-04 - val_loss: 0.0016\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.3356e-04 - val_loss: 0.0015\n",
      "Epoch 42/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.2744e-04 - val_loss: 0.0015\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 9.0753e-04 - val_loss: 0.0015\n",
      "Epoch 44/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 8.9948e-04 - val_loss: 0.0015\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.9264e-04 - val_loss: 0.0014\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.7890e-04 - val_loss: 0.0014\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.7208e-04 - val_loss: 0.0015\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.6394e-04 - val_loss: 0.0014\n",
      "Epoch 49/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.5255e-04 - val_loss: 0.0013\n",
      "Epoch 50/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.6722e-04 - val_loss: 0.0013\n",
      "Epoch 51/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.3861e-04 - val_loss: 0.0013\n",
      "Epoch 52/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.3276e-04 - val_loss: 0.0013\n",
      "Epoch 53/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.3124e-04 - val_loss: 0.0013\n",
      "Epoch 54/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.1529e-04 - val_loss: 0.0013\n",
      "Epoch 55/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.1006e-04 - val_loss: 0.0012\n",
      "Epoch 56/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.9837e-04 - val_loss: 0.0014\n",
      "Epoch 57/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.1620e-04 - val_loss: 0.0013\n",
      "Epoch 58/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 8.0317e-04 - val_loss: 0.0012\n",
      "Epoch 59/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.9066e-04 - val_loss: 0.0012\n",
      "Epoch 60/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.7771e-04 - val_loss: 0.0013\n",
      "Epoch 61/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.7496e-04 - val_loss: 0.0012\n",
      "Epoch 62/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.7927e-04 - val_loss: 0.0012\n",
      "Epoch 63/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.7417e-04 - val_loss: 0.0012\n",
      "Epoch 64/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.6690e-04 - val_loss: 0.0012\n",
      "Epoch 65/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.7070e-04 - val_loss: 0.0012\n",
      "Epoch 66/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.5589e-04 - val_loss: 0.0011\n",
      "Epoch 67/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.6040e-04 - val_loss: 0.0011\n",
      "Epoch 68/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.5674e-04 - val_loss: 0.0011\n",
      "Epoch 69/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 7.8259e-04 - val_loss: 0.0011\n",
      "Epoch 70/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.6390e-04 - val_loss: 0.0012\n",
      "Epoch 71/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.4966e-04 - val_loss: 0.0011\n",
      "Epoch 72/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.4314e-04 - val_loss: 0.0011\n",
      "Epoch 73/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 7.2906e-04 - val_loss: 0.0011\n",
      "Epoch 74/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.2709e-04 - val_loss: 0.0011\n",
      "Epoch 75/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 7.2220e-04 - val_loss: 0.0011\n",
      "Epoch 76/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 7.3601e-04 - val_loss: 0.0011\n",
      "Epoch 77/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.2226e-04 - val_loss: 0.0011\n",
      "Epoch 78/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 7.1792e-04 - val_loss: 0.0011\n",
      "Epoch 79/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.2210e-04 - val_loss: 0.0011\n",
      "Epoch 80/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.0577e-04 - val_loss: 0.0011\n",
      "Epoch 81/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.1807e-04 - val_loss: 0.0011\n",
      "Epoch 82/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.1059e-04 - val_loss: 0.0010\n",
      "Epoch 83/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.9803e-04 - val_loss: 0.0010\n",
      "Epoch 84/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.9820e-04 - val_loss: 0.0010\n",
      "Epoch 85/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.9151e-04 - val_loss: 0.0010\n",
      "Epoch 86/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.8698e-04 - val_loss: 0.0011\n",
      "Epoch 87/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.8575e-04 - val_loss: 0.0011\n",
      "Epoch 88/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.8866e-04 - val_loss: 0.0010\n",
      "Epoch 89/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.8111e-04 - val_loss: 9.9715e-04\n",
      "Epoch 90/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.7656e-04 - val_loss: 0.0010\n",
      "Epoch 91/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.6987e-04 - val_loss: 0.0010\n",
      "Epoch 92/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.7331e-04 - val_loss: 9.8283e-04\n",
      "Epoch 93/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.6853e-04 - val_loss: 9.8139e-04\n",
      "Epoch 94/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.7980e-04 - val_loss: 9.7249e-04\n",
      "Epoch 95/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.8612e-04 - val_loss: 0.0010\n",
      "Epoch 96/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 6.7001e-04 - val_loss: 9.8740e-04\n",
      "Epoch 97/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.5651e-04 - val_loss: 9.6555e-04\n",
      "Epoch 98/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 6.6176e-04 - val_loss: 9.7716e-04\n",
      "Epoch 99/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.5320e-04 - val_loss: 9.8489e-04\n",
      "Epoch 100/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.4669e-04 - val_loss: 0.0010\n",
      "Epoch 101/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.7252e-04 - val_loss: 9.8938e-04\n",
      "Epoch 102/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.5114e-04 - val_loss: 9.6407e-04\n",
      "Epoch 103/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.4310e-04 - val_loss: 9.8390e-04\n",
      "Epoch 104/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.6076e-04 - val_loss: 9.2832e-04\n",
      "Epoch 105/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.5070e-04 - val_loss: 9.4136e-04\n",
      "Epoch 106/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 6.4006e-04 - val_loss: 9.2194e-04\n",
      "Epoch 107/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 6ms/step - loss: 6.3239e-04 - val_loss: 9.1578e-04\n",
      "Epoch 108/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.3867e-04 - val_loss: 9.2806e-04\n",
      "Epoch 109/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.2996e-04 - val_loss: 9.0575e-04\n",
      "Epoch 110/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.3263e-04 - val_loss: 9.1873e-04\n",
      "Epoch 111/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.2525e-04 - val_loss: 9.2269e-04\n",
      "Epoch 112/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.2638e-04 - val_loss: 9.5398e-04\n",
      "Epoch 113/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.2256e-04 - val_loss: 8.8411e-04\n",
      "Epoch 114/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.1750e-04 - val_loss: 8.9118e-04\n",
      "Epoch 115/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.2045e-04 - val_loss: 9.3150e-04\n",
      "Epoch 116/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.1230e-04 - val_loss: 8.7591e-04\n",
      "Epoch 117/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.2520e-04 - val_loss: 8.7068e-04\n",
      "Epoch 118/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.0789e-04 - val_loss: 8.9347e-04\n",
      "Epoch 119/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.1022e-04 - val_loss: 8.6455e-04\n",
      "Epoch 120/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.1265e-04 - val_loss: 9.0015e-04\n",
      "Epoch 121/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 6.0579e-04 - val_loss: 8.5722e-04\n",
      "Epoch 122/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.0507e-04 - val_loss: 8.7134e-04\n",
      "Epoch 123/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.1292e-04 - val_loss: 8.4451e-04\n",
      "Epoch 124/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.0070e-04 - val_loss: 8.4826e-04\n",
      "Epoch 125/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.9594e-04 - val_loss: 8.3641e-04\n",
      "Epoch 126/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.1126e-04 - val_loss: 8.3182e-04\n",
      "Epoch 127/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 6.0819e-04 - val_loss: 8.3901e-04\n",
      "Epoch 128/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.9074e-04 - val_loss: 8.2610e-04\n",
      "Epoch 129/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.9685e-04 - val_loss: 8.4481e-04\n",
      "Epoch 130/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 5.9418e-04 - val_loss: 8.3941e-04\n",
      "Epoch 131/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.8810e-04 - val_loss: 8.5240e-04\n",
      "Epoch 132/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.8216e-04 - val_loss: 8.1144e-04\n",
      "Epoch 133/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.7817e-04 - val_loss: 8.2143e-04\n",
      "Epoch 134/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.8055e-04 - val_loss: 8.1771e-04\n",
      "Epoch 135/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.8198e-04 - val_loss: 8.1281e-04\n",
      "Epoch 136/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.7735e-04 - val_loss: 7.9893e-04\n",
      "Epoch 137/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.8635e-04 - val_loss: 8.2402e-04\n",
      "Epoch 138/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 5.7321e-04 - val_loss: 7.9262e-04\n",
      "Epoch 139/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.7543e-04 - val_loss: 8.7328e-04\n",
      "Epoch 140/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.8689e-04 - val_loss: 8.1784e-04\n",
      "Epoch 141/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.6887e-04 - val_loss: 7.8728e-04\n",
      "Epoch 142/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.7135e-04 - val_loss: 8.1080e-04\n",
      "Epoch 143/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.6840e-04 - val_loss: 7.7736e-04\n",
      "Epoch 144/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.6790e-04 - val_loss: 7.7463e-04\n",
      "Epoch 145/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.6810e-04 - val_loss: 7.7134e-04\n",
      "Epoch 146/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.6402e-04 - val_loss: 8.4807e-04\n",
      "Epoch 147/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.7299e-04 - val_loss: 7.6606e-04\n",
      "Epoch 148/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.6360e-04 - val_loss: 8.5783e-04\n",
      "Epoch 149/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.6541e-04 - val_loss: 7.6442e-04\n",
      "Epoch 150/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.5895e-04 - val_loss: 7.6396e-04\n",
      "Epoch 151/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.5663e-04 - val_loss: 7.6508e-04\n",
      "Epoch 152/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.4738e-04 - val_loss: 7.5320e-04\n",
      "Epoch 153/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.5387e-04 - val_loss: 7.6708e-04\n",
      "Epoch 154/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.4367e-04 - val_loss: 7.4412e-04\n",
      "Epoch 155/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.4877e-04 - val_loss: 7.4600e-04\n",
      "Epoch 156/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.4953e-04 - val_loss: 8.4311e-04\n",
      "Epoch 157/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 5.5920e-04 - val_loss: 7.4172e-04\n",
      "Epoch 158/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3965e-04 - val_loss: 7.4296e-04\n",
      "Epoch 159/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 5.4886e-04 - val_loss: 7.3842e-04\n",
      "Epoch 160/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3846e-04 - val_loss: 7.3379e-04\n",
      "Epoch 161/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3648e-04 - val_loss: 7.2933e-04\n",
      "Epoch 162/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3972e-04 - val_loss: 7.7184e-04\n",
      "Epoch 163/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3944e-04 - val_loss: 7.4633e-04\n",
      "Epoch 164/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3838e-04 - val_loss: 7.2037e-04\n",
      "Epoch 165/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3910e-04 - val_loss: 7.2966e-04\n",
      "Epoch 166/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.4565e-04 - val_loss: 7.2429e-04\n",
      "Epoch 167/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.2922e-04 - val_loss: 7.2933e-04\n",
      "Epoch 168/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3632e-04 - val_loss: 7.3323e-04\n",
      "Epoch 169/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.2972e-04 - val_loss: 7.0755e-04\n",
      "Epoch 170/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3059e-04 - val_loss: 7.5034e-04\n",
      "Epoch 171/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3058e-04 - val_loss: 7.3310e-04\n",
      "Epoch 172/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.2429e-04 - val_loss: 7.0851e-04\n",
      "Epoch 173/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.2079e-04 - val_loss: 7.0643e-04\n",
      "Epoch 174/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.2146e-04 - val_loss: 7.1847e-04\n",
      "Epoch 175/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3384e-04 - val_loss: 6.9508e-04\n",
      "Epoch 176/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.1718e-04 - val_loss: 7.1577e-04\n",
      "Epoch 177/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3452e-04 - val_loss: 6.9110e-04\n",
      "Epoch 178/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.1917e-04 - val_loss: 6.9246e-04\n",
      "Epoch 179/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.1895e-04 - val_loss: 6.8598e-04\n",
      "Epoch 180/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.1915e-04 - val_loss: 7.2033e-04\n",
      "Epoch 181/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.1665e-04 - val_loss: 6.8462e-04\n",
      "Epoch 182/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 6ms/step - loss: 5.1031e-04 - val_loss: 7.1422e-04\n",
      "Epoch 183/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.1647e-04 - val_loss: 6.7911e-04\n",
      "Epoch 184/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.3035e-04 - val_loss: 6.7582e-04\n",
      "Epoch 185/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.0836e-04 - val_loss: 6.9552e-04\n",
      "Epoch 186/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.1500e-04 - val_loss: 6.7613e-04\n",
      "Epoch 187/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.0792e-04 - val_loss: 6.7124e-04\n",
      "Epoch 188/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.0544e-04 - val_loss: 6.7021e-04\n",
      "Epoch 189/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.0288e-04 - val_loss: 6.8472e-04\n",
      "Epoch 190/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.0426e-04 - val_loss: 6.7035e-04\n",
      "Epoch 191/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.0163e-04 - val_loss: 6.7436e-04\n",
      "Epoch 192/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.0654e-04 - val_loss: 6.6447e-04\n",
      "Epoch 193/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.1442e-04 - val_loss: 6.6206e-04\n",
      "Epoch 194/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.0050e-04 - val_loss: 6.7088e-04\n",
      "Epoch 195/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 4.9889e-04 - val_loss: 6.6226e-04\n",
      "Epoch 196/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.0007e-04 - val_loss: 6.5817e-04\n",
      "Epoch 197/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.0746e-04 - val_loss: 6.5677e-04\n",
      "Epoch 198/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.0336e-04 - val_loss: 6.6301e-04\n",
      "Epoch 199/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 4.9739e-04 - val_loss: 6.4667e-04\n",
      "Epoch 200/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 4.9427e-04 - val_loss: 6.5678e-04\n",
      "Thời gian huấn luyện:  35.321553468704224\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_7 (GRU)                 (None, 10, 89)            24564     \n",
      "                                                                 \n",
      " flatten_31 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,455\n",
      "Trainable params: 25,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 1s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0559 - val_loss: 0.0212\n",
      "Epoch 2/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0065\n",
      "Epoch 3/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 4/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 5/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 6/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 7/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 8/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 9/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 10/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 11/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 12/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 13/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 14/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 15/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 16/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 17/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 18/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 19/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 20/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 21/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 22/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 23/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 24/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 25/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 26/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 27/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 28/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 29/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 30/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 31/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 32/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 33/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 34/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 35/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 36/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 37/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 38/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 39/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 40/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 41/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 42/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 43/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 44/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 45/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 46/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 47/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 48/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 50/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 51/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 52/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 53/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 54/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 55/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 56/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 57/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 58/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 59/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 60/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 61/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 62/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 63/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 64/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 65/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 66/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 67/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 68/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 69/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 70/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 71/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.9276e-04 - val_loss: 0.0013\n",
      "Epoch 72/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.8931e-04 - val_loss: 0.0013\n",
      "Epoch 73/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.8514e-04 - val_loss: 0.0013\n",
      "Epoch 74/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.7826e-04 - val_loss: 0.0013\n",
      "Epoch 75/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.7763e-04 - val_loss: 0.0013\n",
      "Epoch 76/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.6918e-04 - val_loss: 0.0013\n",
      "Epoch 77/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.6571e-04 - val_loss: 0.0013\n",
      "Epoch 78/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.5925e-04 - val_loss: 0.0012\n",
      "Epoch 79/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.5884e-04 - val_loss: 0.0012\n",
      "Epoch 80/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.4764e-04 - val_loss: 0.0012\n",
      "Epoch 81/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.4196e-04 - val_loss: 0.0012\n",
      "Epoch 82/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.3992e-04 - val_loss: 0.0012\n",
      "Epoch 83/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.4644e-04 - val_loss: 0.0012\n",
      "Epoch 84/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.3065e-04 - val_loss: 0.0012\n",
      "Epoch 85/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 9.3009e-04 - val_loss: 0.0012\n",
      "Epoch 86/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.2896e-04 - val_loss: 0.0012\n",
      "Epoch 87/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.1298e-04 - val_loss: 0.0012\n",
      "Epoch 88/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.1066e-04 - val_loss: 0.0012\n",
      "Epoch 89/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 9.0459e-04 - val_loss: 0.0012\n",
      "Epoch 90/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.9952e-04 - val_loss: 0.0012\n",
      "Epoch 91/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.9735e-04 - val_loss: 0.0012\n",
      "Epoch 92/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.9043e-04 - val_loss: 0.0012\n",
      "Epoch 93/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.8633e-04 - val_loss: 0.0011\n",
      "Epoch 94/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.8242e-04 - val_loss: 0.0011\n",
      "Epoch 95/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.7929e-04 - val_loss: 0.0011\n",
      "Epoch 96/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.7265e-04 - val_loss: 0.0011\n",
      "Epoch 97/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.6688e-04 - val_loss: 0.0011\n",
      "Epoch 98/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.6569e-04 - val_loss: 0.0011\n",
      "Epoch 99/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.6072e-04 - val_loss: 0.0011\n",
      "Epoch 100/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.5443e-04 - val_loss: 0.0011\n",
      "Epoch 101/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.4802e-04 - val_loss: 0.0011\n",
      "Epoch 102/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.4302e-04 - val_loss: 0.0011\n",
      "Epoch 103/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.3842e-04 - val_loss: 0.0011\n",
      "Epoch 104/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.3589e-04 - val_loss: 0.0011\n",
      "Epoch 105/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.3144e-04 - val_loss: 0.0011\n",
      "Epoch 106/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.2599e-04 - val_loss: 0.0011\n",
      "Epoch 107/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.2263e-04 - val_loss: 0.0010\n",
      "Epoch 108/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.1689e-04 - val_loss: 0.0011\n",
      "Epoch 109/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.1503e-04 - val_loss: 0.0010\n",
      "Epoch 110/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.1108e-04 - val_loss: 0.0010\n",
      "Epoch 111/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.1074e-04 - val_loss: 0.0010\n",
      "Epoch 112/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 8.0121e-04 - val_loss: 0.0010\n",
      "Epoch 113/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.9854e-04 - val_loss: 0.0010\n",
      "Epoch 114/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.9271e-04 - val_loss: 0.0010\n",
      "Epoch 115/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.9522e-04 - val_loss: 9.9522e-04\n",
      "Epoch 116/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.9181e-04 - val_loss: 9.8670e-04\n",
      "Epoch 117/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.8309e-04 - val_loss: 9.8059e-04\n",
      "Epoch 118/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.7928e-04 - val_loss: 9.7638e-04\n",
      "Epoch 119/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.7219e-04 - val_loss: 9.6806e-04\n",
      "Epoch 120/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.6843e-04 - val_loss: 9.6309e-04\n",
      "Epoch 121/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.6547e-04 - val_loss: 9.5914e-04\n",
      "Epoch 122/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.6105e-04 - val_loss: 9.6743e-04\n",
      "Epoch 123/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.6119e-04 - val_loss: 9.4956e-04\n",
      "Epoch 124/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.5244e-04 - val_loss: 9.4246e-04\n",
      "Epoch 125/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.4868e-04 - val_loss: 9.3488e-04\n",
      "Epoch 126/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.4604e-04 - val_loss: 9.2782e-04\n",
      "Epoch 127/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.4523e-04 - val_loss: 9.2248e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.3917e-04 - val_loss: 9.2022e-04\n",
      "Epoch 129/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.4454e-04 - val_loss: 9.6728e-04\n",
      "Epoch 130/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.4223e-04 - val_loss: 9.0633e-04\n",
      "Epoch 131/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.3091e-04 - val_loss: 9.0062e-04\n",
      "Epoch 132/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.3323e-04 - val_loss: 9.0288e-04\n",
      "Epoch 133/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.3411e-04 - val_loss: 9.0019e-04\n",
      "Epoch 134/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.2327e-04 - val_loss: 9.0022e-04\n",
      "Epoch 135/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.1342e-04 - val_loss: 8.8171e-04\n",
      "Epoch 136/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.1147e-04 - val_loss: 8.7881e-04\n",
      "Epoch 137/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.1256e-04 - val_loss: 8.7053e-04\n",
      "Epoch 138/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.0375e-04 - val_loss: 8.6511e-04\n",
      "Epoch 139/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.0264e-04 - val_loss: 8.7629e-04\n",
      "Epoch 140/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.9919e-04 - val_loss: 8.5619e-04\n",
      "Epoch 141/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.9955e-04 - val_loss: 8.6408e-04\n",
      "Epoch 142/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.0074e-04 - val_loss: 8.4671e-04\n",
      "Epoch 143/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.9012e-04 - val_loss: 8.4205e-04\n",
      "Epoch 144/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.8636e-04 - val_loss: 8.4668e-04\n",
      "Epoch 145/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.8280e-04 - val_loss: 8.3310e-04\n",
      "Epoch 146/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.8076e-04 - val_loss: 8.3129e-04\n",
      "Epoch 147/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.8112e-04 - val_loss: 8.2407e-04\n",
      "Epoch 148/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.7723e-04 - val_loss: 8.1991e-04\n",
      "Epoch 149/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.7102e-04 - val_loss: 8.2407e-04\n",
      "Epoch 150/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.7191e-04 - val_loss: 8.1247e-04\n",
      "Epoch 151/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.6645e-04 - val_loss: 8.1593e-04\n",
      "Epoch 152/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.6327e-04 - val_loss: 8.0659e-04\n",
      "Epoch 153/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.6567e-04 - val_loss: 8.0741e-04\n",
      "Epoch 154/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.6996e-04 - val_loss: 8.1233e-04\n",
      "Epoch 155/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.6284e-04 - val_loss: 7.9788e-04\n",
      "Epoch 156/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.5285e-04 - val_loss: 7.8943e-04\n",
      "Epoch 157/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.5033e-04 - val_loss: 7.8446e-04\n",
      "Epoch 158/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.5599e-04 - val_loss: 7.8056e-04\n",
      "Epoch 159/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.4967e-04 - val_loss: 7.7575e-04\n",
      "Epoch 160/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.4683e-04 - val_loss: 7.8204e-04\n",
      "Epoch 161/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.4249e-04 - val_loss: 7.6889e-04\n",
      "Epoch 162/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.4399e-04 - val_loss: 7.6529e-04\n",
      "Epoch 163/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.3702e-04 - val_loss: 7.6319e-04\n",
      "Epoch 164/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.3280e-04 - val_loss: 7.5821e-04\n",
      "Epoch 165/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.3271e-04 - val_loss: 7.6029e-04\n",
      "Epoch 166/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.3465e-04 - val_loss: 7.5802e-04\n",
      "Epoch 167/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.2846e-04 - val_loss: 7.4855e-04\n",
      "Epoch 168/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.2363e-04 - val_loss: 7.5249e-04\n",
      "Epoch 169/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.3655e-04 - val_loss: 7.8465e-04\n",
      "Epoch 170/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.3027e-04 - val_loss: 7.3815e-04\n",
      "Epoch 171/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.2127e-04 - val_loss: 7.4769e-04\n",
      "Epoch 172/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.1578e-04 - val_loss: 7.3644e-04\n",
      "Epoch 173/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.1910e-04 - val_loss: 7.2937e-04\n",
      "Epoch 174/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.1919e-04 - val_loss: 7.3280e-04\n",
      "Epoch 175/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.2103e-04 - val_loss: 7.5220e-04\n",
      "Epoch 176/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.1106e-04 - val_loss: 7.2061e-04\n",
      "Epoch 177/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.0866e-04 - val_loss: 7.1894e-04\n",
      "Epoch 178/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.0685e-04 - val_loss: 7.1738e-04\n",
      "Epoch 179/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.0454e-04 - val_loss: 7.1226e-04\n",
      "Epoch 180/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.0468e-04 - val_loss: 7.1290e-04\n",
      "Epoch 181/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.0401e-04 - val_loss: 7.1471e-04\n",
      "Epoch 182/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.0155e-04 - val_loss: 7.0430e-04\n",
      "Epoch 183/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.9885e-04 - val_loss: 7.0162e-04\n",
      "Epoch 184/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.9951e-04 - val_loss: 7.0002e-04\n",
      "Epoch 185/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.9751e-04 - val_loss: 6.9783e-04\n",
      "Epoch 186/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.9399e-04 - val_loss: 6.9784e-04\n",
      "Epoch 187/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.9328e-04 - val_loss: 6.9924e-04\n",
      "Epoch 188/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.9829e-04 - val_loss: 6.8947e-04\n",
      "Epoch 189/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.9180e-04 - val_loss: 6.9125e-04\n",
      "Epoch 190/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.9228e-04 - val_loss: 6.9785e-04\n",
      "Epoch 191/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.8545e-04 - val_loss: 6.8237e-04\n",
      "Epoch 192/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.8462e-04 - val_loss: 6.7998e-04\n",
      "Epoch 193/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.8357e-04 - val_loss: 6.8246e-04\n",
      "Epoch 194/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.8168e-04 - val_loss: 6.7997e-04\n",
      "Epoch 195/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.8137e-04 - val_loss: 6.7339e-04\n",
      "Epoch 196/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.7647e-04 - val_loss: 6.7230e-04\n",
      "Epoch 197/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.7809e-04 - val_loss: 6.6918e-04\n",
      "Epoch 198/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.7815e-04 - val_loss: 6.6738e-04\n",
      "Epoch 199/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.7379e-04 - val_loss: 6.6651e-04\n",
      "Epoch 200/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.7683e-04 - val_loss: 6.6312e-04\n",
      "Thời gian huấn luyện:  12.227001428604126\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_40 (Dense)            (None, 10, 89)            178       \n",
      "                                                                 \n",
      " flatten_32 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069\n",
      "Trainable params: 1,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "24/24 [==============================] - 1s 10ms/step - loss: 0.0189 - val_loss: 0.0025\n",
      "Epoch 2/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 3/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 4/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 5/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 6/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 7/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 8/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 9/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 10/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 11/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 12/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 13/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 14/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 15/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 16/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 17/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 18/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 19/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 20/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 21/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 22/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 23/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 24/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.9138e-04 - val_loss: 0.0012\n",
      "Epoch 25/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 26/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.7989e-04 - val_loss: 0.0012\n",
      "Epoch 27/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.9268e-04 - val_loss: 0.0012\n",
      "Epoch 28/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.5718e-04 - val_loss: 0.0012\n",
      "Epoch 29/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.4589e-04 - val_loss: 0.0012\n",
      "Epoch 30/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.4670e-04 - val_loss: 0.0012\n",
      "Epoch 31/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.3197e-04 - val_loss: 0.0012\n",
      "Epoch 32/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.7293e-04 - val_loss: 0.0012\n",
      "Epoch 33/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.5719e-04 - val_loss: 0.0011\n",
      "Epoch 34/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.2597e-04 - val_loss: 0.0011\n",
      "Epoch 35/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.9993e-04 - val_loss: 0.0011\n",
      "Epoch 36/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.0446e-04 - val_loss: 0.0011\n",
      "Epoch 37/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.0263e-04 - val_loss: 0.0012\n",
      "Epoch 38/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.0013e-04 - val_loss: 0.0011\n",
      "Epoch 39/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.7617e-04 - val_loss: 0.0011\n",
      "Epoch 40/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.7212e-04 - val_loss: 0.0011\n",
      "Epoch 41/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.5782e-04 - val_loss: 0.0011\n",
      "Epoch 42/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.6651e-04 - val_loss: 0.0010\n",
      "Epoch 43/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.5131e-04 - val_loss: 0.0010\n",
      "Epoch 44/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.4666e-04 - val_loss: 0.0010\n",
      "Epoch 45/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.4082e-04 - val_loss: 0.0010\n",
      "Epoch 46/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.3799e-04 - val_loss: 0.0010\n",
      "Epoch 47/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.4374e-04 - val_loss: 0.0010\n",
      "Epoch 48/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.4089e-04 - val_loss: 9.9612e-04\n",
      "Epoch 49/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.1647e-04 - val_loss: 9.8878e-04\n",
      "Epoch 50/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.0848e-04 - val_loss: 9.9870e-04\n",
      "Epoch 51/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.0786e-04 - val_loss: 9.9302e-04\n",
      "Epoch 52/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.5547e-04 - val_loss: 9.7122e-04\n",
      "Epoch 53/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.9854e-04 - val_loss: 9.6123e-04\n",
      "Epoch 54/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.8835e-04 - val_loss: 9.6561e-04\n",
      "Epoch 55/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.9528e-04 - val_loss: 9.4864e-04\n",
      "Epoch 56/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.8434e-04 - val_loss: 9.5278e-04\n",
      "Epoch 57/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.8591e-04 - val_loss: 9.4172e-04\n",
      "Epoch 58/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.7401e-04 - val_loss: 9.3893e-04\n",
      "Epoch 59/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.1763e-04 - val_loss: 9.2159e-04\n",
      "Epoch 60/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.7194e-04 - val_loss: 9.7698e-04\n",
      "Epoch 61/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.8352e-04 - val_loss: 9.3099e-04\n",
      "Epoch 62/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.6406e-04 - val_loss: 9.0377e-04\n",
      "Epoch 63/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.5726e-04 - val_loss: 8.9945e-04\n",
      "Epoch 64/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.6217e-04 - val_loss: 8.9335e-04\n",
      "Epoch 65/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.5317e-04 - val_loss: 9.0667e-04\n",
      "Epoch 66/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.6621e-04 - val_loss: 9.6184e-04\n",
      "Epoch 67/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.3824e-04 - val_loss: 8.8024e-04\n",
      "Epoch 68/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.5032e-04 - val_loss: 9.0449e-04\n",
      "Epoch 69/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.2742e-04 - val_loss: 9.0020e-04\n",
      "Epoch 70/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.2499e-04 - val_loss: 8.6516e-04\n",
      "Epoch 71/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.2242e-04 - val_loss: 8.6537e-04\n",
      "Epoch 72/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.1926e-04 - val_loss: 8.5631e-04\n",
      "Epoch 73/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.1719e-04 - val_loss: 8.4660e-04\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step - loss: 7.1219e-04 - val_loss: 8.4313e-04\n",
      "Epoch 75/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.3176e-04 - val_loss: 9.1186e-04\n",
      "Epoch 76/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.0956e-04 - val_loss: 8.4302e-04\n",
      "Epoch 77/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.0806e-04 - val_loss: 8.2831e-04\n",
      "Epoch 78/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.0376e-04 - val_loss: 8.3252e-04\n",
      "Epoch 79/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.9804e-04 - val_loss: 8.1825e-04\n",
      "Epoch 80/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.9020e-04 - val_loss: 8.1850e-04\n",
      "Epoch 81/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.0111e-04 - val_loss: 8.2369e-04\n",
      "Epoch 82/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7873e-04 - val_loss: 8.3295e-04\n",
      "Epoch 83/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.8774e-04 - val_loss: 8.1378e-04\n",
      "Epoch 84/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7436e-04 - val_loss: 8.0679e-04\n",
      "Epoch 85/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7507e-04 - val_loss: 7.8946e-04\n",
      "Epoch 86/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7921e-04 - val_loss: 7.9813e-04\n",
      "Epoch 87/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7778e-04 - val_loss: 8.5950e-04\n",
      "Epoch 88/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.4751e-04 - val_loss: 7.8965e-04\n",
      "Epoch 89/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7750e-04 - val_loss: 7.7876e-04\n",
      "Epoch 90/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7507e-04 - val_loss: 8.3886e-04\n",
      "Epoch 91/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.8358e-04 - val_loss: 7.6838e-04\n",
      "Epoch 92/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.5140e-04 - val_loss: 7.6297e-04\n",
      "Epoch 93/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.6110e-04 - val_loss: 7.6942e-04\n",
      "Epoch 94/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.6661e-04 - val_loss: 7.7050e-04\n",
      "Epoch 95/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.6921e-04 - val_loss: 7.5490e-04\n",
      "Epoch 96/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.4822e-04 - val_loss: 7.4794e-04\n",
      "Epoch 97/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.4144e-04 - val_loss: 7.6419e-04\n",
      "Epoch 98/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3527e-04 - val_loss: 7.3999e-04\n",
      "Epoch 99/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3592e-04 - val_loss: 7.3827e-04\n",
      "Epoch 100/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3351e-04 - val_loss: 7.3438e-04\n",
      "Epoch 101/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3067e-04 - val_loss: 7.9930e-04\n",
      "Epoch 102/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3873e-04 - val_loss: 7.3160e-04\n",
      "Epoch 103/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.5363e-04 - val_loss: 7.2655e-04\n",
      "Epoch 104/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.4068e-04 - val_loss: 7.3254e-04\n",
      "Epoch 105/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3195e-04 - val_loss: 7.1615e-04\n",
      "Epoch 106/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.2424e-04 - val_loss: 8.1374e-04\n",
      "Epoch 107/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3637e-04 - val_loss: 7.4509e-04\n",
      "Epoch 108/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.0539e-04 - val_loss: 7.2183e-04\n",
      "Epoch 109/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.1304e-04 - val_loss: 7.0915e-04\n",
      "Epoch 110/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.1196e-04 - val_loss: 7.0064e-04\n",
      "Epoch 111/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.6135e-04 - val_loss: 7.0791e-04\n",
      "Epoch 112/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.1175e-04 - val_loss: 6.9521e-04\n",
      "Epoch 113/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.0521e-04 - val_loss: 7.2686e-04\n",
      "Epoch 114/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3591e-04 - val_loss: 7.3640e-04\n",
      "Epoch 115/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.9694e-04 - val_loss: 6.9719e-04\n",
      "Epoch 116/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.9912e-04 - val_loss: 6.8203e-04\n",
      "Epoch 117/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.9482e-04 - val_loss: 6.8390e-04\n",
      "Epoch 118/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.8390e-04 - val_loss: 7.7385e-04\n",
      "Epoch 119/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.2693e-04 - val_loss: 6.7329e-04\n",
      "Epoch 120/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.9974e-04 - val_loss: 7.1759e-04\n",
      "Epoch 121/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.0886e-04 - val_loss: 6.7460e-04\n",
      "Epoch 122/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.8257e-04 - val_loss: 6.6971e-04\n",
      "Epoch 123/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.8666e-04 - val_loss: 6.6979e-04\n",
      "Epoch 124/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.8290e-04 - val_loss: 7.0372e-04\n",
      "Epoch 125/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.1188e-04 - val_loss: 7.3130e-04\n",
      "Epoch 126/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.4819e-04 - val_loss: 7.8840e-04\n",
      "Epoch 127/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.8919e-04 - val_loss: 6.5343e-04\n",
      "Epoch 128/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.6978e-04 - val_loss: 6.5207e-04\n",
      "Epoch 129/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.7903e-04 - val_loss: 7.2006e-04\n",
      "Epoch 130/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.8130e-04 - val_loss: 6.6979e-04\n",
      "Epoch 131/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.7117e-04 - val_loss: 6.5206e-04\n",
      "Epoch 132/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.8023e-04 - val_loss: 6.5550e-04\n",
      "Epoch 133/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.7362e-04 - val_loss: 6.3984e-04\n",
      "Epoch 134/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.6487e-04 - val_loss: 6.4404e-04\n",
      "Epoch 135/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.6865e-04 - val_loss: 6.4042e-04\n",
      "Epoch 136/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.8911e-04 - val_loss: 6.3734e-04\n",
      "Epoch 137/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.6228e-04 - val_loss: 6.6973e-04\n",
      "Epoch 138/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.7569e-04 - val_loss: 7.8170e-04\n",
      "Epoch 139/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.1604e-04 - val_loss: 6.3235e-04\n",
      "Epoch 140/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.5571e-04 - val_loss: 6.2192e-04\n",
      "Epoch 141/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.4772e-04 - val_loss: 6.2152e-04\n",
      "Epoch 142/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.5918e-04 - val_loss: 6.2426e-04\n",
      "Epoch 143/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.5511e-04 - val_loss: 6.1778e-04\n",
      "Epoch 144/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.5006e-04 - val_loss: 6.2903e-04\n",
      "Epoch 145/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.5537e-04 - val_loss: 6.2694e-04\n",
      "Epoch 146/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.4626e-04 - val_loss: 6.6988e-04\n",
      "Epoch 147/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.4603e-04 - val_loss: 6.2484e-04\n",
      "Epoch 148/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.6469e-04 - val_loss: 6.3010e-04\n",
      "Epoch 149/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step - loss: 5.4214e-04 - val_loss: 6.3820e-04\n",
      "Epoch 150/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.7625e-04 - val_loss: 6.1464e-04\n",
      "Epoch 151/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.5827e-04 - val_loss: 6.2751e-04\n",
      "Epoch 152/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.4643e-04 - val_loss: 7.0839e-04\n",
      "Epoch 153/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.3890e-04 - val_loss: 5.9546e-04\n",
      "Epoch 154/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.4611e-04 - val_loss: 6.3842e-04\n",
      "Epoch 155/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.3431e-04 - val_loss: 5.9140e-04\n",
      "Epoch 156/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.3835e-04 - val_loss: 6.0587e-04\n",
      "Epoch 157/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.2950e-04 - val_loss: 6.1282e-04\n",
      "Epoch 158/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.4052e-04 - val_loss: 5.8959e-04\n",
      "Epoch 159/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.2437e-04 - val_loss: 5.8352e-04\n",
      "Epoch 160/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.2213e-04 - val_loss: 5.8138e-04\n",
      "Epoch 161/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.3000e-04 - val_loss: 5.9621e-04\n",
      "Epoch 162/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.2865e-04 - val_loss: 5.8608e-04\n",
      "Epoch 163/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.2984e-04 - val_loss: 6.0158e-04\n",
      "Epoch 164/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.4562e-04 - val_loss: 5.8543e-04\n",
      "Epoch 165/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.3106e-04 - val_loss: 5.9336e-04\n",
      "Epoch 166/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.3619e-04 - val_loss: 6.5123e-04\n",
      "Epoch 167/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.1501e-04 - val_loss: 5.7009e-04\n",
      "Epoch 168/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.2395e-04 - val_loss: 5.6770e-04\n",
      "Epoch 169/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.2025e-04 - val_loss: 6.0318e-04\n",
      "Epoch 170/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.1534e-04 - val_loss: 5.7509e-04\n",
      "Epoch 171/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.1545e-04 - val_loss: 5.6504e-04\n",
      "Epoch 172/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.1974e-04 - val_loss: 5.6138e-04\n",
      "Epoch 173/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.5537e-04 - val_loss: 5.6317e-04\n",
      "Epoch 174/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.2027e-04 - val_loss: 5.6184e-04\n",
      "Epoch 175/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.2740e-04 - val_loss: 5.7645e-04\n",
      "Epoch 176/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.3004e-04 - val_loss: 5.6831e-04\n",
      "Epoch 177/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.0123e-04 - val_loss: 5.7223e-04\n",
      "Epoch 178/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.2066e-04 - val_loss: 5.5598e-04\n",
      "Epoch 179/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.0023e-04 - val_loss: 5.7922e-04\n",
      "Epoch 180/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.0359e-04 - val_loss: 5.5795e-04\n",
      "Epoch 181/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.2004e-04 - val_loss: 7.2620e-04\n",
      "Epoch 182/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.4698e-04 - val_loss: 5.4945e-04\n",
      "Epoch 183/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.9684e-04 - val_loss: 5.8077e-04\n",
      "Epoch 184/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.1613e-04 - val_loss: 5.8080e-04\n",
      "Epoch 185/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.9560e-04 - val_loss: 5.4388e-04\n",
      "Epoch 186/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.1312e-04 - val_loss: 5.4294e-04\n",
      "Epoch 187/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.9831e-04 - val_loss: 5.4487e-04\n",
      "Epoch 188/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.9994e-04 - val_loss: 5.5135e-04\n",
      "Epoch 189/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.0032e-04 - val_loss: 5.3906e-04\n",
      "Epoch 190/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.9824e-04 - val_loss: 5.3486e-04\n",
      "Epoch 191/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.9313e-04 - val_loss: 5.3325e-04\n",
      "Epoch 192/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.9497e-04 - val_loss: 5.4150e-04\n",
      "Epoch 193/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.0681e-04 - val_loss: 5.3424e-04\n",
      "Epoch 194/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.0388e-04 - val_loss: 5.3038e-04\n",
      "Epoch 195/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.0012e-04 - val_loss: 5.5218e-04\n",
      "Epoch 196/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.0155e-04 - val_loss: 5.2871e-04\n",
      "Epoch 197/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.9162e-04 - val_loss: 5.2615e-04\n",
      "Epoch 198/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.8704e-04 - val_loss: 5.2745e-04\n",
      "Epoch 199/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.9331e-04 - val_loss: 5.2567e-04\n",
      "Epoch 200/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.8881e-04 - val_loss: 5.2498e-04\n",
      "Thời gian huấn luyện:  18.64842462539673\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_8 (SimpleRNN)    (None, 10, 89)            8099      \n",
      "                                                                 \n",
      " flatten_33 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,990\n",
      "Trainable params: 8,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "24/24 [==============================] - 2s 22ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 2/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 3/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 4/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 5/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 6/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 7/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 8/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 9/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 10/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 11/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 12/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 13/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 14/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 15/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 16/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 17/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 19/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 20/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 21/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 22/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 23/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 24/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 25/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 26/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 27/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 28/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 29/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 30/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 31/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 32/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 33/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 34/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 35/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 36/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 37/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 38/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 39/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 40/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 41/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 42/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 43/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 44/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 45/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 46/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 47/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 48/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 49/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 50/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 51/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 52/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 53/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 54/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 55/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 56/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 57/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 58/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 59/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 60/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 61/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 62/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 63/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 64/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 65/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 66/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 67/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 68/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 69/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 70/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 71/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 72/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 73/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 74/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 75/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 76/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 77/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 78/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 79/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 80/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 81/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 82/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 83/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 84/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 85/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 86/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 87/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 88/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 89/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 90/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 91/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 92/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 93/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 94/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 95/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 96/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 97/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 98/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 99/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 101/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 102/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 103/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 104/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 105/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 106/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 107/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 108/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 109/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 110/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 111/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 112/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 113/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 114/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 115/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 116/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 117/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 118/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 119/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 120/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 121/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 122/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 123/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 124/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 125/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 126/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 127/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 128/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 129/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 130/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 131/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 132/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 133/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 134/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 135/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 136/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 137/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 138/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 139/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 140/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 141/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 142/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 143/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 144/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 145/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 146/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 147/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 148/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 149/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 150/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 151/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 152/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 153/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 154/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 155/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 156/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 157/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 158/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 159/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 160/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 161/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 162/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 163/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 164/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 165/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 166/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 167/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 168/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 169/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 170/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 171/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 172/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 173/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 174/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 175/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 176/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 177/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 178/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 179/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 180/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 182/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 183/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 184/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 185/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 186/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 187/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 188/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 189/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 190/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 191/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 192/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 193/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 194/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 195/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 196/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 197/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 198/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 199/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Epoch 200/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.1095\n",
      "Thời gian huấn luyện:  37.9913535118103\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 10, 89)            32396     \n",
      "                                                                 \n",
      " flatten_34 (Flatten)        (None, 890)               0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,287\n",
      "Trainable params: 33,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "24/24 [==============================] - 2s 20ms/step - loss: 0.0208 - val_loss: 0.0030\n",
      "Epoch 2/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 3/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 4/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 5/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 6/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 7/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 8/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 9/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 10/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 11/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 12/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 13/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 14/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 15/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 16/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 17/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 18/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 19/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 20/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 21/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 22/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 23/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 24/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 25/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 26/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 27/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 28/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 29/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 30/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 31/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 32/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 33/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 34/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 35/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 36/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 37/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 38/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 39/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 40/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 9.9778e-04 - val_loss: 0.0013\n",
      "Epoch 41/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 9.8212e-04 - val_loss: 0.0013\n",
      "Epoch 42/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 9.7278e-04 - val_loss: 0.0013\n",
      "Epoch 43/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 9.5875e-04 - val_loss: 0.0012\n",
      "Epoch 44/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 9.4974e-04 - val_loss: 0.0012\n",
      "Epoch 45/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 9.5316e-04 - val_loss: 0.0012\n",
      "Epoch 46/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 9.2035e-04 - val_loss: 0.0012\n",
      "Epoch 47/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 9.1577e-04 - val_loss: 0.0012\n",
      "Epoch 48/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.9880e-04 - val_loss: 0.0012\n",
      "Epoch 49/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.8737e-04 - val_loss: 0.0011\n",
      "Epoch 50/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.7694e-04 - val_loss: 0.0011\n",
      "Epoch 51/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.7325e-04 - val_loss: 0.0011\n",
      "Epoch 52/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.6025e-04 - val_loss: 0.0011\n",
      "Epoch 53/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.5035e-04 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.5210e-04 - val_loss: 0.0011\n",
      "Epoch 55/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.4331e-04 - val_loss: 0.0011\n",
      "Epoch 56/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.2550e-04 - val_loss: 0.0011\n",
      "Epoch 57/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.3956e-04 - val_loss: 0.0011\n",
      "Epoch 58/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.2551e-04 - val_loss: 0.0010\n",
      "Epoch 59/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.0509e-04 - val_loss: 0.0010\n",
      "Epoch 60/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.0233e-04 - val_loss: 0.0010\n",
      "Epoch 61/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.9217e-04 - val_loss: 9.9407e-04\n",
      "Epoch 62/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.9420e-04 - val_loss: 9.8685e-04\n",
      "Epoch 63/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.0664e-04 - val_loss: 9.7785e-04\n",
      "Epoch 64/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.7551e-04 - val_loss: 9.6755e-04\n",
      "Epoch 65/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.7089e-04 - val_loss: 9.9353e-04\n",
      "Epoch 66/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 8.0213e-04 - val_loss: 9.8395e-04\n",
      "Epoch 67/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.7967e-04 - val_loss: 9.5178e-04\n",
      "Epoch 68/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.5800e-04 - val_loss: 9.4177e-04\n",
      "Epoch 69/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.4968e-04 - val_loss: 9.3102e-04\n",
      "Epoch 70/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.4176e-04 - val_loss: 9.2459e-04\n",
      "Epoch 71/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.4508e-04 - val_loss: 9.3843e-04\n",
      "Epoch 72/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.5557e-04 - val_loss: 9.3839e-04\n",
      "Epoch 73/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.3114e-04 - val_loss: 9.1746e-04\n",
      "Epoch 74/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.2285e-04 - val_loss: 9.0322e-04\n",
      "Epoch 75/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.2338e-04 - val_loss: 9.0541e-04\n",
      "Epoch 76/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.1959e-04 - val_loss: 8.8860e-04\n",
      "Epoch 77/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.2179e-04 - val_loss: 9.0350e-04\n",
      "Epoch 78/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.1350e-04 - val_loss: 8.8816e-04\n",
      "Epoch 79/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.1967e-04 - val_loss: 8.8468e-04\n",
      "Epoch 80/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.0652e-04 - val_loss: 8.6749e-04\n",
      "Epoch 81/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.9759e-04 - val_loss: 8.6552e-04\n",
      "Epoch 82/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.9594e-04 - val_loss: 8.5859e-04\n",
      "Epoch 83/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.9572e-04 - val_loss: 8.5399e-04\n",
      "Epoch 84/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.9457e-04 - val_loss: 8.5313e-04\n",
      "Epoch 85/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.8902e-04 - val_loss: 8.4437e-04\n",
      "Epoch 86/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.9013e-04 - val_loss: 8.4714e-04\n",
      "Epoch 87/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.8546e-04 - val_loss: 8.6708e-04\n",
      "Epoch 88/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.8247e-04 - val_loss: 8.3177e-04\n",
      "Epoch 89/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.8082e-04 - val_loss: 8.5382e-04\n",
      "Epoch 90/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.7155e-04 - val_loss: 8.2108e-04\n",
      "Epoch 91/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.6825e-04 - val_loss: 8.1872e-04\n",
      "Epoch 92/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.6720e-04 - val_loss: 8.2839e-04\n",
      "Epoch 93/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.6778e-04 - val_loss: 8.2613e-04\n",
      "Epoch 94/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.7040e-04 - val_loss: 8.6436e-04\n",
      "Epoch 95/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.7168e-04 - val_loss: 8.0072e-04\n",
      "Epoch 96/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.5940e-04 - val_loss: 7.9605e-04\n",
      "Epoch 97/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.5050e-04 - val_loss: 8.0385e-04\n",
      "Epoch 98/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.4756e-04 - val_loss: 7.8847e-04\n",
      "Epoch 99/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.4786e-04 - val_loss: 7.9522e-04\n",
      "Epoch 100/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.4946e-04 - val_loss: 7.8203e-04\n",
      "Epoch 101/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.4433e-04 - val_loss: 7.8427e-04\n",
      "Epoch 102/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.5316e-04 - val_loss: 7.7427e-04\n",
      "Epoch 103/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.3533e-04 - val_loss: 7.7639e-04\n",
      "Epoch 104/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.4168e-04 - val_loss: 7.8203e-04\n",
      "Epoch 105/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.5481e-04 - val_loss: 7.6304e-04\n",
      "Epoch 106/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.4709e-04 - val_loss: 8.2074e-04\n",
      "Epoch 107/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.3458e-04 - val_loss: 7.5972e-04\n",
      "Epoch 108/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.2282e-04 - val_loss: 7.5520e-04\n",
      "Epoch 109/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.2253e-04 - val_loss: 7.5784e-04\n",
      "Epoch 110/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.2227e-04 - val_loss: 7.6281e-04\n",
      "Epoch 111/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.2216e-04 - val_loss: 7.4300e-04\n",
      "Epoch 112/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.1523e-04 - val_loss: 7.3921e-04\n",
      "Epoch 113/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.1013e-04 - val_loss: 7.3634e-04\n",
      "Epoch 114/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.0618e-04 - val_loss: 7.3652e-04\n",
      "Epoch 115/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.1506e-04 - val_loss: 7.3306e-04\n",
      "Epoch 116/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.0568e-04 - val_loss: 7.2641e-04\n",
      "Epoch 117/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.0234e-04 - val_loss: 7.2637e-04\n",
      "Epoch 118/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.9989e-04 - val_loss: 7.2285e-04\n",
      "Epoch 119/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.9685e-04 - val_loss: 7.2123e-04\n",
      "Epoch 120/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.9432e-04 - val_loss: 7.1445e-04\n",
      "Epoch 121/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.9518e-04 - val_loss: 7.1143e-04\n",
      "Epoch 122/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6.0346e-04 - val_loss: 7.1183e-04\n",
      "Epoch 123/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.9069e-04 - val_loss: 7.6118e-04\n",
      "Epoch 124/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.9621e-04 - val_loss: 7.1271e-04\n",
      "Epoch 125/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.9921e-04 - val_loss: 7.0384e-04\n",
      "Epoch 126/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.8845e-04 - val_loss: 6.9851e-04\n",
      "Epoch 127/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.7965e-04 - val_loss: 6.9772e-04\n",
      "Epoch 128/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.7770e-04 - val_loss: 7.0154e-04\n",
      "Epoch 129/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.8045e-04 - val_loss: 6.8933e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.7787e-04 - val_loss: 6.9163e-04\n",
      "Epoch 131/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.7502e-04 - val_loss: 6.8434e-04\n",
      "Epoch 132/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6937e-04 - val_loss: 6.9974e-04\n",
      "Epoch 133/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.7753e-04 - val_loss: 6.7835e-04\n",
      "Epoch 134/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6990e-04 - val_loss: 6.8079e-04\n",
      "Epoch 135/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6741e-04 - val_loss: 6.7711e-04\n",
      "Epoch 136/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6694e-04 - val_loss: 6.7644e-04\n",
      "Epoch 137/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6687e-04 - val_loss: 6.6897e-04\n",
      "Epoch 138/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6485e-04 - val_loss: 6.6611e-04\n",
      "Epoch 139/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6459e-04 - val_loss: 6.6449e-04\n",
      "Epoch 140/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6078e-04 - val_loss: 6.6810e-04\n",
      "Epoch 141/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6898e-04 - val_loss: 6.6036e-04\n",
      "Epoch 142/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6023e-04 - val_loss: 6.6318e-04\n",
      "Epoch 143/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6117e-04 - val_loss: 6.6489e-04\n",
      "Epoch 144/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.5793e-04 - val_loss: 6.5899e-04\n",
      "Epoch 145/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.5328e-04 - val_loss: 6.8688e-04\n",
      "Epoch 146/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.5465e-04 - val_loss: 6.4856e-04\n",
      "Epoch 147/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6101e-04 - val_loss: 6.5068e-04\n",
      "Epoch 148/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4996e-04 - val_loss: 6.4545e-04\n",
      "Epoch 149/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4512e-04 - val_loss: 6.4166e-04\n",
      "Epoch 150/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4894e-04 - val_loss: 6.5859e-04\n",
      "Epoch 151/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.9161e-04 - val_loss: 6.6295e-04\n",
      "Epoch 152/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6600e-04 - val_loss: 6.5156e-04\n",
      "Epoch 153/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4290e-04 - val_loss: 6.3630e-04\n",
      "Epoch 154/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.5380e-04 - val_loss: 6.4703e-04\n",
      "Epoch 155/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4164e-04 - val_loss: 6.3703e-04\n",
      "Epoch 156/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4410e-04 - val_loss: 6.2948e-04\n",
      "Epoch 157/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4328e-04 - val_loss: 6.3081e-04\n",
      "Epoch 158/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.3674e-04 - val_loss: 6.2533e-04\n",
      "Epoch 159/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.5116e-04 - val_loss: 6.2393e-04\n",
      "Epoch 160/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4793e-04 - val_loss: 6.6404e-04\n",
      "Epoch 161/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.3218e-04 - val_loss: 6.2123e-04\n",
      "Epoch 162/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4660e-04 - val_loss: 6.2777e-04\n",
      "Epoch 163/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.3587e-04 - val_loss: 6.1907e-04\n",
      "Epoch 164/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.2759e-04 - val_loss: 6.1881e-04\n",
      "Epoch 165/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.3086e-04 - val_loss: 6.3024e-04\n",
      "Epoch 166/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4118e-04 - val_loss: 6.9996e-04\n",
      "Epoch 167/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4474e-04 - val_loss: 6.1041e-04\n",
      "Epoch 168/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.2257e-04 - val_loss: 6.0800e-04\n",
      "Epoch 169/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.2512e-04 - val_loss: 6.0844e-04\n",
      "Epoch 170/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1953e-04 - val_loss: 6.1006e-04\n",
      "Epoch 171/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.2391e-04 - val_loss: 6.0737e-04\n",
      "Epoch 172/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1883e-04 - val_loss: 6.0127e-04\n",
      "Epoch 173/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.2306e-04 - val_loss: 6.0025e-04\n",
      "Epoch 174/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1992e-04 - val_loss: 5.9886e-04\n",
      "Epoch 175/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.3945e-04 - val_loss: 6.1436e-04\n",
      "Epoch 176/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.2013e-04 - val_loss: 6.1639e-04\n",
      "Epoch 177/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4657e-04 - val_loss: 7.2605e-04\n",
      "Epoch 178/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.6219e-04 - val_loss: 5.9598e-04\n",
      "Epoch 179/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1363e-04 - val_loss: 6.0206e-04\n",
      "Epoch 180/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1679e-04 - val_loss: 6.5860e-04\n",
      "Epoch 181/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.3768e-04 - val_loss: 5.8861e-04\n",
      "Epoch 182/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1219e-04 - val_loss: 5.8976e-04\n",
      "Epoch 183/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.2014e-04 - val_loss: 5.8747e-04\n",
      "Epoch 184/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.0886e-04 - val_loss: 5.9142e-04\n",
      "Epoch 185/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.0674e-04 - val_loss: 5.8470e-04\n",
      "Epoch 186/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1678e-04 - val_loss: 5.8514e-04\n",
      "Epoch 187/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1682e-04 - val_loss: 5.8072e-04\n",
      "Epoch 188/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.0983e-04 - val_loss: 5.8002e-04\n",
      "Epoch 189/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1008e-04 - val_loss: 6.2202e-04\n",
      "Epoch 190/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1474e-04 - val_loss: 5.7609e-04\n",
      "Epoch 191/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.0837e-04 - val_loss: 5.7889e-04\n",
      "Epoch 192/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.0668e-04 - val_loss: 5.8453e-04\n",
      "Epoch 193/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.0774e-04 - val_loss: 5.7182e-04\n",
      "Epoch 194/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1771e-04 - val_loss: 6.1387e-04\n",
      "Epoch 195/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.1771e-04 - val_loss: 5.7618e-04\n",
      "Epoch 196/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 4.9479e-04 - val_loss: 5.7293e-04\n",
      "Epoch 197/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 4.9702e-04 - val_loss: 5.6753e-04\n",
      "Epoch 198/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 4.9585e-04 - val_loss: 5.7261e-04\n",
      "Epoch 199/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 4.9840e-04 - val_loss: 5.6588e-04\n",
      "Epoch 200/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 4.9657e-04 - val_loss: 5.6499e-04\n",
      "Thời gian huấn luyện:  34.16022968292236\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_8 (GRU)                 (None, 10, 89)            24564     \n",
      "                                                                 \n",
      " flatten_35 (Flatten)        (None, 890)               0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1)                 891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,455\n",
      "Trainable params: 25,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0525 - val_loss: 0.0027\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0032\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0025\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 9.4395e-04\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 9.6398e-04\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 9.2435e-04\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 8.7858e-04\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 8.7916e-04\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 8.3303e-04\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.0231e-04\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.7518e-04\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.2493e-04\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.1013e-04\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.6861e-04\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.3363e-04\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.2766e-04\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.1383e-04\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.1845e-04\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.0398e-04\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.6750e-04\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.4158e-04\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.9549e-04\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.8898e-04\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.9204e-04\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.1014e-04\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.0496e-04\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.7311e-04\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.7958e-04\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.6749e-04\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.7255e-04\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.5577e-04\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.6337e-04\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.3817e-04\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.8437e-04\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.2312e-04\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.4007e-04\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.2664e-04\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.2281e-04\n",
      "Thời gian huấn luyện:  3.7412447929382324\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_45 (Dense)            (None, 10, 96)            192       \n",
      "                                                                 \n",
      " flatten_36 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,153\n",
      "Trainable params: 1,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 1s 8ms/step - loss: 0.0225 - val_loss: 0.0038\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 9.0934e-04\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 8.4271e-04\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 7.7946e-04\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 7.7605e-04\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 7.0914e-04\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.5566e-04\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.8866e-04\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.3729e-04\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.0480e-04\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.2153e-04\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.3669e-04\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.6381e-04\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.7126e-04\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.8776e-04 - val_loss: 5.8172e-04\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.8948e-04 - val_loss: 7.4749e-04\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.6422e-04 - val_loss: 5.9866e-04\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.3719e-04 - val_loss: 5.1756e-04\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.3645e-04 - val_loss: 5.0434e-04\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.2163e-04 - val_loss: 5.0291e-04\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.9737e-04 - val_loss: 5.4059e-04\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.8536e-04 - val_loss: 5.0310e-04\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.8540e-04 - val_loss: 5.0573e-04\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.6001e-04 - val_loss: 4.8976e-04\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.9151e-04 - val_loss: 4.6843e-04\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.3798e-04 - val_loss: 4.7093e-04\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.3498e-04 - val_loss: 4.7774e-04\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.1376e-04 - val_loss: 4.5431e-04\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.4452e-04 - val_loss: 4.4845e-04\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.1087e-04 - val_loss: 4.4449e-04\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.1178e-04 - val_loss: 4.3874e-04\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.9462e-04 - val_loss: 4.3496e-04\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.9186e-04 - val_loss: 4.3795e-04\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.7276e-04 - val_loss: 4.3558e-04\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.0654e-04 - val_loss: 4.2224e-04\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.0522e-04 - val_loss: 4.4255e-04\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.5808e-04 - val_loss: 4.1974e-04\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.6719e-04 - val_loss: 4.1486e-04\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.4336e-04 - val_loss: 4.0880e-04\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.3939e-04 - val_loss: 4.0304e-04\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.4133e-04 - val_loss: 4.5614e-04\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2445e-04 - val_loss: 3.9917e-04\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1902e-04 - val_loss: 3.9323e-04\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.1563e-04 - val_loss: 4.3718e-04\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.0796e-04 - val_loss: 3.8804e-04\n",
      "Thời gian huấn luyện:  6.031972408294678\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_9 (SimpleRNN)    (None, 10, 96)            9408      \n",
      "                                                                 \n",
      " flatten_37 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,369\n",
      "Trainable params: 10,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 2s 18ms/step - loss: 0.0186 - val_loss: 0.0015\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 9.9844e-04\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 9.7138e-04\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 9.3383e-04\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 9.3350e-04\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 9.6860e-04\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 9.6303e-04\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.9959e-04\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 9.9979e-04\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 8.8254e-04\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 9.2480e-04\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 8.7495e-04\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 8.2800e-04\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 8.4547e-04\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.1591e-04\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.1841e-04\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 8.3998e-04\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.0195e-04\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.2581e-04\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.7356e-04\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 8.3645e-04\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.6223e-04\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.4879e-04\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 7.9167e-04\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 7.5673e-04\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.6821e-04\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.5769e-04\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 7.3128e-04\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 7.0667e-04\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.9462e-04\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 7.1415e-04\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 7.2299e-04\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 7.3406e-04\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.7512e-04\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.8911e-04\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.6622e-04\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 6.8729e-04\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 7.2882e-04\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.3345e-04\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.2711e-04\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 6.6163e-04\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 6.2085e-04\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 6.2338e-04\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 6.6088e-04\n",
      "Thời gian huấn luyện:  12.855132341384888\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_9 (LSTM)               (None, 10, 96)            37632     \n",
      "                                                                 \n",
      " flatten_38 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,593\n",
      "Trainable params: 38,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 2s 16ms/step - loss: 0.0184 - val_loss: 0.0016\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 9.3136e-04\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 9.0136e-04\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.6503e-04\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.3063e-04\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.1289e-04\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.2968e-04\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 7.8035e-04\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 7.7657e-04\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.4416e-04\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.2759e-04\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 7.2143e-04\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 7.2357e-04\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.9220e-04\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.8537e-04\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.9890e-04\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 7.1836e-04\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.9630e-04\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.7190e-04\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.3039e-04\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.5159e-04\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.0394e-04\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.1972e-04\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.1613e-04\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.7069e-04\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.7810e-04\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 6.1088e-04\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 6.3302e-04\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.9424e-04 - val_loss: 5.7998e-04\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.6535e-04 - val_loss: 5.3302e-04\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.4288e-04 - val_loss: 5.2033e-04\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.2888e-04 - val_loss: 5.0001e-04\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.2021e-04 - val_loss: 4.9460e-04\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.9620e-04 - val_loss: 5.4022e-04\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.9331e-04 - val_loss: 4.7988e-04\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.9406e-04 - val_loss: 4.7336e-04\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.5869e-04 - val_loss: 4.6674e-04\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.5802e-04 - val_loss: 5.1198e-04\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.4457e-04 - val_loss: 4.7832e-04\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.2989e-04 - val_loss: 4.7327e-04\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.2164e-04 - val_loss: 4.6680e-04\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.0494e-04 - val_loss: 5.1233e-04\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.2376e-04 - val_loss: 4.3702e-04\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.9112e-04 - val_loss: 4.5930e-04\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.8792e-04 - val_loss: 4.8361e-04\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.7799e-04 - val_loss: 4.2451e-04\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.8096e-04 - val_loss: 4.7428e-04\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.6356e-04 - val_loss: 4.2159e-04\n",
      "Thời gian huấn luyện:  12.046826839447021\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_9 (GRU)                 (None, 10, 96)            28512     \n",
      "                                                                 \n",
      " flatten_39 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_49 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,473\n",
      "Trainable params: 29,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.0565 - val_loss: 0.0062\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0034\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0018\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0020\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0018\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0016\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 9.2051e-04\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 8.0783e-04\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 8.3363e-04\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 7.7062e-04\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 7.8502e-04\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 7.3707e-04\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.0177e-04\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 6.9923e-04\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 6.9459e-04\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.8912e-04\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.3647e-04\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.1821e-04\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.6125e-04\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.5689e-04\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.4527e-04\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.9785e-04\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.4987e-04\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.1157e-04\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.1570e-04\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.8130e-04\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.0835e-04\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.7157e-04\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.7187e-04\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.8057e-04\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.7298e-04\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.7120e-04\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.6194e-04\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.4346e-04\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.5350e-04\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.5617e-04\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.4976e-04\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.3969e-04\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.4086e-04\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.3663e-04\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.2342e-04\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.3744e-04\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.1366e-04\n",
      "Thời gian huấn luyện:  3.7267298698425293\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_50 (Dense)            (None, 10, 96)            192       \n",
      "                                                                 \n",
      " flatten_40 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,153\n",
      "Trainable params: 1,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "30/30 [==============================] - 1s 8ms/step - loss: 0.0374 - val_loss: 0.0031\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0014\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 9.8916e-04\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 9.5495e-04\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 8.8152e-04\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 8.5692e-04\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 7.5870e-04\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 7.6105e-04\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 7.0218e-04\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 7.2408e-04\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 7.1938e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 6.9328e-04\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 7.7918e-04\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 6.4399e-04\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 7.4058e-04\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.0324e-04\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.1903e-04\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.6984e-04\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 5.6890e-04\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.9748e-04\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.5061e-04\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.2218e-04\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.7660e-04\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.4737e-04\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 5.3762e-04\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.2392e-04\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 6.4799e-04\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.4533e-04\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.0818e-04\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.9598e-04 - val_loss: 5.0864e-04\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.8123e-04 - val_loss: 5.1491e-04\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.8892e-04 - val_loss: 5.4320e-04\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.9553e-04 - val_loss: 5.1424e-04\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.5000e-04 - val_loss: 4.9476e-04\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.4059e-04 - val_loss: 5.1590e-04\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.4666e-04 - val_loss: 4.9741e-04\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.3853e-04 - val_loss: 4.9963e-04\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.1595e-04 - val_loss: 5.2152e-04\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.0886e-04 - val_loss: 4.6897e-04\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.4277e-04 - val_loss: 5.1645e-04\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.8582e-04 - val_loss: 4.8833e-04\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.8637e-04 - val_loss: 4.9495e-04\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.8096e-04 - val_loss: 4.6348e-04\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.8576e-04 - val_loss: 4.5756e-04\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.6078e-04 - val_loss: 4.7347e-04\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.5371e-04 - val_loss: 4.4891e-04\n",
      "Thời gian huấn luyện:  5.902420282363892\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_10 (SimpleRNN)   (None, 10, 96)            9408      \n",
      "                                                                 \n",
      " flatten_41 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,369\n",
      "Trainable params: 10,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "30/30 [==============================] - 2s 18ms/step - loss: 0.0202 - val_loss: 0.0012\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 9.4658e-04\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 9.8314e-04\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 9.5979e-04\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 9.3326e-04\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 9.4289e-04\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 9.3458e-04\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 9.3363e-04\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 9.0619e-04\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 9.0690e-04\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 9.5601e-04\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 8.6832e-04\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 8.4208e-04\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 8.5063e-04\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 8.2993e-04\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 8.2622e-04\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.2789e-04\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.3883e-04\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 9.0720e-04\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 8.5033e-04\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 7.9262e-04\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.1921e-04\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 8.0151e-04\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.6260e-04\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.4516e-04\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.9147e-04\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.6236e-04\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.4117e-04\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.9896e-04\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.7998e-04\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.4442e-04\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 6.8644e-04\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.5786e-04\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.8883e-04\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 6.5807e-04\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 6.8463e-04\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 6.5857e-04\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 6.5351e-04\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.5559e-04\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.3202e-04\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.7990e-04\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.3073e-04\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.8959e-04\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 6.6740e-04\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 5.7436e-04\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.7095e-04\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.6109e-04\n",
      "Thời gian huấn luyện:  11.96903133392334\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 10, 96)            37632     \n",
      "                                                                 \n",
      " flatten_42 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,593\n",
      "Trainable params: 38,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "30/30 [==============================] - 2s 17ms/step - loss: 0.0159 - val_loss: 0.0015\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 9.2499e-04\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 8.3093e-04\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 8.3462e-04\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 8.0131e-04\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 7.3582e-04\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 7.7979e-04\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 7.6560e-04\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 7.3280e-04\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 7.2271e-04\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 6.8815e-04\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 7.6766e-04\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 7.7482e-04\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 6.5746e-04\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 6.6624e-04\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.5950e-04\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.7781e-04\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.4419e-04\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.7426e-04\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.6717e-04\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.2913e-04\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 5.9178e-04\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.2635e-04\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.1809e-04\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 5.8452e-04\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.6622e-04\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.6869e-04\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.4279e-04\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.3597e-04\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.4974e-04\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.2398e-04\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.2271e-04\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.1156e-04\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.2255e-04\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.0981e-04\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 4.9789e-04\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.2338e-04\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.7899e-04 - val_loss: 4.9160e-04\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.6793e-04 - val_loss: 4.8445e-04\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.5776e-04 - val_loss: 4.8328e-04\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.4912e-04 - val_loss: 5.0870e-04\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.6632e-04 - val_loss: 5.4066e-04\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.2640e-04 - val_loss: 5.1905e-04\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.1736e-04 - val_loss: 4.6324e-04\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.1852e-04 - val_loss: 4.6051e-04\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.0326e-04 - val_loss: 4.5266e-04\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.0598e-04 - val_loss: 5.0832e-04\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.0111e-04 - val_loss: 4.7692e-04\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.8229e-04 - val_loss: 4.4302e-04\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.7646e-04 - val_loss: 4.8965e-04\n",
      "Thời gian huấn luyện:  11.284602642059326\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_10 (GRU)                (None, 10, 96)            28512     \n",
      "                                                                 \n",
      " flatten_43 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Total params: 29,473\n",
      "Trainable params: 29,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "35/35 [==============================] - 0s 971us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 1s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0693 - val_loss: 0.0133\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0059\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0032\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 19/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 31/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 32/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 33/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 34/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 35/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 36/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 37/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 38/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 39/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 40/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 41/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 42/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 43/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 44/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 45/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 46/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 47/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 48/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 49/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 50/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Thời gian huấn luyện:  3.6277551651000977\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_55 (Dense)            (None, 10, 96)            192       \n",
      "                                                                 \n",
      " flatten_44 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,153\n",
      "Trainable params: 1,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "28/28 [==============================] - 1s 9ms/step - loss: 0.0168 - val_loss: 0.0025\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 9.8564e-04\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 9.3323e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 9.5157e-04\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 8.9796e-04\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 9.9242e-04 - val_loss: 9.5735e-04\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 9.8025e-04 - val_loss: 8.9322e-04\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 9.5884e-04 - val_loss: 9.6199e-04\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.5191e-04 - val_loss: 8.3681e-04\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 9.0941e-04 - val_loss: 8.7678e-04\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 9.4801e-04 - val_loss: 9.0772e-04\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.6897e-04 - val_loss: 8.1455e-04\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.8830e-04 - val_loss: 7.8927e-04\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.7119e-04 - val_loss: 7.8307e-04\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.9255e-04 - val_loss: 8.2616e-04\n",
      "Epoch 31/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 8.4619e-04 - val_loss: 7.9994e-04\n",
      "Epoch 32/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 8.3797e-04 - val_loss: 7.4638e-04\n",
      "Epoch 33/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.1477e-04 - val_loss: 7.4001e-04\n",
      "Epoch 34/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.3553e-04 - val_loss: 7.2944e-04\n",
      "Epoch 35/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.2442e-04 - val_loss: 7.5384e-04\n",
      "Epoch 36/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.9871e-04 - val_loss: 7.1800e-04\n",
      "Epoch 37/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.6737e-04 - val_loss: 7.2073e-04\n",
      "Epoch 38/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.2664e-04 - val_loss: 7.1002e-04\n",
      "Epoch 39/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.9012e-04 - val_loss: 7.7189e-04\n",
      "Epoch 40/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.7005e-04 - val_loss: 6.8375e-04\n",
      "Epoch 41/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.7183e-04 - val_loss: 6.8107e-04\n",
      "Epoch 42/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.7721e-04 - val_loss: 6.7187e-04\n",
      "Epoch 43/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.6670e-04 - val_loss: 6.6782e-04\n",
      "Epoch 44/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.3855e-04 - val_loss: 6.9846e-04\n",
      "Epoch 45/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.3575e-04 - val_loss: 6.7652e-04\n",
      "Epoch 46/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.5761e-04 - val_loss: 7.1796e-04\n",
      "Epoch 47/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.3931e-04 - val_loss: 6.5012e-04\n",
      "Epoch 48/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.5509e-04 - val_loss: 6.4278e-04\n",
      "Epoch 49/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.3324e-04 - val_loss: 6.3844e-04\n",
      "Epoch 50/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.0483e-04 - val_loss: 6.3226e-04\n",
      "Thời gian huấn luyện:  5.750639915466309\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_11 (SimpleRNN)   (None, 10, 96)            9408      \n",
      "                                                                 \n",
      " flatten_45 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,369\n",
      "Trainable params: 10,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "28/28 [==============================] - 2s 19ms/step - loss: 0.0211 - val_loss: 0.0018\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 19/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 31/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 32/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 33/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 34/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 35/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 38/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 39/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 41/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 42/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 43/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 44/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 45/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 46/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 47/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 48/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 49/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 50/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Thời gian huấn luyện:  11.949188709259033\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_11 (LSTM)              (None, 10, 96)            37632     \n",
      "                                                                 \n",
      " flatten_46 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,593\n",
      "Trainable params: 38,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "28/28 [==============================] - 2s 18ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 19/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 31/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 32/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 33/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 34/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 35/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 36/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 37/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 38/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 39/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 40/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 41/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 42/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 43/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 44/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 45/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 46/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 47/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 48/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 49/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Epoch 50/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0728\n",
      "Thời gian huấn luyện:  11.289196252822876\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_11 (GRU)                (None, 10, 96)            28512     \n",
      "                                                                 \n",
      " flatten_47 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,473\n",
      "Trainable params: 29,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0505 - val_loss: 0.0024\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 9.6152e-04\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 9.4355e-04\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 8.6026e-04\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 8.1862e-04\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 8.5891e-04\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 8.1884e-04\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.7337e-04\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.6389e-04\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.0452e-04\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.5587e-04\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.6438e-04\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.6414e-04\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.4678e-04\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.2944e-04\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.0727e-04\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.1661e-04\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.2116e-04\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.0888e-04\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.8999e-04\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.8486e-04\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.9901e-04\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.9215e-04\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.6879e-04\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.5169e-04\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.6126e-04\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.3872e-04\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.6847e-04\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.4129e-04\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.5695e-04\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.2086e-04\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.5069e-04\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.1847e-04\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.0054e-04\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.0535e-04\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.2590e-04\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.8817e-04\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.7798e-04\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.1527e-04\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.9608e-04\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.6198e-04\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.6131e-04\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.5043e-04\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.8200e-04\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.9415e-04\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.9141e-04 - val_loss: 5.3843e-04\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.7933e-04 - val_loss: 5.4937e-04\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.6974e-04 - val_loss: 5.2955e-04\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.5933e-04 - val_loss: 5.4407e-04\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.5595e-04 - val_loss: 5.4762e-04\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.3949e-04 - val_loss: 5.1286e-04\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.2976e-04 - val_loss: 5.5665e-04\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.2910e-04 - val_loss: 5.3216e-04\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.1406e-04 - val_loss: 4.9678e-04\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.1247e-04 - val_loss: 4.8827e-04\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.9832e-04 - val_loss: 4.8539e-04\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.8701e-04 - val_loss: 4.9064e-04\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.7837e-04 - val_loss: 4.7740e-04\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.6782e-04 - val_loss: 4.7208e-04\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.6023e-04 - val_loss: 4.7447e-04\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.5341e-04 - val_loss: 4.6261e-04\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.4393e-04 - val_loss: 4.5746e-04\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.3331e-04 - val_loss: 4.8139e-04\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.2814e-04 - val_loss: 4.7029e-04\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.2570e-04 - val_loss: 4.4942e-04\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.1214e-04 - val_loss: 4.4305e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.0185e-04 - val_loss: 4.4479e-04\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.0368e-04 - val_loss: 4.3858e-04\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.8486e-04 - val_loss: 4.5424e-04\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.8812e-04 - val_loss: 4.3239e-04\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.7875e-04 - val_loss: 4.1583e-04\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.6461e-04 - val_loss: 4.1918e-04\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.5913e-04 - val_loss: 4.1813e-04\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.5105e-04 - val_loss: 4.0576e-04\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.4678e-04 - val_loss: 3.9986e-04\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.4240e-04 - val_loss: 3.9608e-04\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.3186e-04 - val_loss: 3.9684e-04\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.2497e-04 - val_loss: 4.0016e-04\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.1757e-04 - val_loss: 3.9584e-04\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.1253e-04 - val_loss: 4.1490e-04\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.0755e-04 - val_loss: 3.8447e-04\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.0051e-04 - val_loss: 3.7602e-04\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.0228e-04 - val_loss: 3.7215e-04\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.9170e-04 - val_loss: 3.7024e-04\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.8145e-04 - val_loss: 3.7747e-04\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.7801e-04 - val_loss: 3.6496e-04\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.7362e-04 - val_loss: 3.6029e-04\n",
      "Thời gian huấn luyện:  6.997787952423096\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_60 (Dense)            (None, 10, 96)            192       \n",
      "                                                                 \n",
      " flatten_48 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,153\n",
      "Trainable params: 1,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 1s 8ms/step - loss: 0.0126 - val_loss: 0.0011\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 9.0352e-04\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 8.0942e-04\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 8.0306e-04\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 7.3732e-04\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 7.8746e-04\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 7.6488e-04\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 6.9143e-04\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 7.0739e-04\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.3021e-04\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.3247e-04\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.4358e-04\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.1913e-04\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.7998e-04\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.9551e-04\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.5689e-04\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 6.0170e-04\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 6.3731e-04\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.9326e-04\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.6791e-04 - val_loss: 5.2930e-04\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.5560e-04 - val_loss: 5.1639e-04\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.3441e-04 - val_loss: 5.4740e-04\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.2191e-04 - val_loss: 5.0422e-04\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.9932e-04 - val_loss: 5.4451e-04\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.9293e-04 - val_loss: 5.1133e-04\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.8388e-04 - val_loss: 4.9875e-04\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.8554e-04 - val_loss: 4.7572e-04\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.8002e-04 - val_loss: 4.9279e-04\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.9422e-04 - val_loss: 4.6711e-04\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.0108e-04 - val_loss: 4.6681e-04\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.9372e-04 - val_loss: 4.8955e-04\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.3422e-04 - val_loss: 4.5066e-04\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.3591e-04 - val_loss: 4.4981e-04\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.2253e-04 - val_loss: 4.4491e-04\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.0086e-04 - val_loss: 4.8426e-04\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.0925e-04 - val_loss: 4.8246e-04\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.0300e-04 - val_loss: 4.5423e-04\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.7376e-04 - val_loss: 4.6512e-04\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.6082e-04 - val_loss: 5.1664e-04\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.6923e-04 - val_loss: 4.1723e-04\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.5653e-04 - val_loss: 4.6992e-04\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.7914e-04 - val_loss: 4.4677e-04\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.5280e-04 - val_loss: 4.1148e-04\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2814e-04 - val_loss: 4.4076e-04\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.3939e-04 - val_loss: 4.4755e-04\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.5667e-04 - val_loss: 3.9660e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.3398e-04 - val_loss: 3.9369e-04\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.0773e-04 - val_loss: 3.9476e-04\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.0214e-04 - val_loss: 3.8910e-04\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.0831e-04 - val_loss: 4.3773e-04\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.9470e-04 - val_loss: 3.8260e-04\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8829e-04 - val_loss: 4.5788e-04\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.9485e-04 - val_loss: 4.0063e-04\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8262e-04 - val_loss: 3.7473e-04\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.7335e-04 - val_loss: 3.9315e-04\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.9785e-04 - val_loss: 3.7967e-04\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8361e-04 - val_loss: 4.0477e-04\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5800e-04 - val_loss: 3.6406e-04\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6448e-04 - val_loss: 3.6359e-04\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6199e-04 - val_loss: 3.7054e-04\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6253e-04 - val_loss: 3.7382e-04\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5226e-04 - val_loss: 3.5617e-04\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5577e-04 - val_loss: 4.1705e-04\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3555e-04 - val_loss: 3.7757e-04\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4174e-04 - val_loss: 4.2970e-04\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4710e-04 - val_loss: 3.4754e-04\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4099e-04 - val_loss: 3.9510e-04\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5043e-04 - val_loss: 3.4707e-04\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2877e-04 - val_loss: 3.6013e-04\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1498e-04 - val_loss: 3.5602e-04\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1466e-04 - val_loss: 3.8218e-04\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2525e-04 - val_loss: 3.5672e-04\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6768e-04 - val_loss: 3.8527e-04\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0435e-04 - val_loss: 3.4222e-04\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9858e-04 - val_loss: 3.4547e-04\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2821e-04 - val_loss: 4.6466e-04\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5791e-04 - val_loss: 3.2742e-04\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9408e-04 - val_loss: 3.5073e-04\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0377e-04 - val_loss: 3.2859e-04\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0261e-04 - val_loss: 3.2117e-04\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9706e-04 - val_loss: 3.3224e-04\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9020e-04 - val_loss: 3.2271e-04\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8305e-04 - val_loss: 3.4259e-04\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9014e-04 - val_loss: 3.3203e-04\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0272e-04 - val_loss: 3.3898e-04\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7337e-04 - val_loss: 3.1716e-04\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7761e-04 - val_loss: 3.0996e-04\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6780e-04 - val_loss: 3.0890e-04\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6534e-04 - val_loss: 3.1291e-04\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5764e-04 - val_loss: 3.0583e-04\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5900e-04 - val_loss: 3.3294e-04\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7152e-04 - val_loss: 3.0602e-04\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6229e-04 - val_loss: 3.0355e-04\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6271e-04 - val_loss: 3.2407e-04\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4951e-04 - val_loss: 3.4842e-04\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5138e-04 - val_loss: 3.0872e-04\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4579e-04 - val_loss: 2.9636e-04\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6696e-04 - val_loss: 2.9543e-04\n",
      "Thời gian huấn luyện:  11.238847970962524\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_12 (SimpleRNN)   (None, 10, 96)            9408      \n",
      "                                                                 \n",
      " flatten_49 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,369\n",
      "Trainable params: 10,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 2s 30ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Thời gian huấn luyện:  24.05993628501892\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 10, 96)            37632     \n",
      "                                                                 \n",
      " flatten_50 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,593\n",
      "Trainable params: 38,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 2s 16ms/step - loss: 0.0152 - val_loss: 0.0013\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 9.1411e-04\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 8.8378e-04\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.5471e-04\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 8.7168e-04\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.7447e-04\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 8.1964e-04\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 7.8798e-04\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 7.2910e-04\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 7.1024e-04\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.9264e-04\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 7.1616e-04\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.8094e-04\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 7.2186e-04\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.5383e-04\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.3426e-04\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.4417e-04\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.0629e-04\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.3951e-04\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.0890e-04\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.8397e-04\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.7586e-04\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 5.9003e-04\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.5111e-04\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.9847e-04 - val_loss: 5.4649e-04\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.8325e-04 - val_loss: 5.4447e-04\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.6767e-04 - val_loss: 5.6160e-04\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.5348e-04 - val_loss: 5.6719e-04\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.5604e-04 - val_loss: 5.6711e-04\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.3970e-04 - val_loss: 5.0608e-04\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.1630e-04 - val_loss: 4.9991e-04\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.1123e-04 - val_loss: 5.2941e-04\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.9639e-04 - val_loss: 4.9404e-04\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.8072e-04 - val_loss: 5.2615e-04\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.7757e-04 - val_loss: 5.3880e-04\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.7669e-04 - val_loss: 4.8043e-04\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.6371e-04 - val_loss: 4.7978e-04\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.4498e-04 - val_loss: 4.9309e-04\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.5015e-04 - val_loss: 5.2235e-04\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.3457e-04 - val_loss: 4.6067e-04\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.2514e-04 - val_loss: 4.6199e-04\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.1587e-04 - val_loss: 4.6832e-04\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.1392e-04 - val_loss: 4.4224e-04\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.1034e-04 - val_loss: 4.7592e-04\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.9559e-04 - val_loss: 4.5389e-04\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.8760e-04 - val_loss: 4.3223e-04\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.8374e-04 - val_loss: 4.3593e-04\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.9011e-04 - val_loss: 4.3102e-04\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.9878e-04 - val_loss: 4.3870e-04\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.7799e-04 - val_loss: 4.2131e-04\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.7993e-04 - val_loss: 4.2232e-04\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.6844e-04 - val_loss: 4.2482e-04\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.5626e-04 - val_loss: 4.6047e-04\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.4331e-04 - val_loss: 4.1319e-04\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.4033e-04 - val_loss: 4.2984e-04\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.3753e-04 - val_loss: 4.2828e-04\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.3532e-04 - val_loss: 4.2562e-04\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.2778e-04 - val_loss: 4.4830e-04\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.2162e-04 - val_loss: 4.2299e-04\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.2482e-04 - val_loss: 3.9620e-04\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.1624e-04 - val_loss: 4.3669e-04\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.0859e-04 - val_loss: 3.9848e-04\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.0635e-04 - val_loss: 4.0124e-04\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.9564e-04 - val_loss: 4.2646e-04\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.9807e-04 - val_loss: 3.9428e-04\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.9871e-04 - val_loss: 4.2599e-04\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.9663e-04 - val_loss: 4.0156e-04\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.8278e-04 - val_loss: 3.9527e-04\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 6.8381e-04 - val_loss: 4.0379e-04\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.7596e-04 - val_loss: 4.2889e-04\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.7753e-04 - val_loss: 3.9154e-04\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.6929e-04 - val_loss: 3.8039e-04\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.7630e-04 - val_loss: 3.6870e-04\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.6152e-04 - val_loss: 3.6983e-04\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.5696e-04 - val_loss: 3.8084e-04\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.6150e-04 - val_loss: 3.8093e-04\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.5273e-04 - val_loss: 3.7870e-04\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.3816e-04 - val_loss: 4.9388e-04\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.5892e-04 - val_loss: 3.5780e-04\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.4644e-04 - val_loss: 4.0846e-04\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.3842e-04 - val_loss: 3.5916e-04\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.3245e-04 - val_loss: 3.8906e-04\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.3171e-04 - val_loss: 3.6545e-04\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.2789e-04 - val_loss: 3.7520e-04\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.2216e-04 - val_loss: 3.4768e-04\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.3248e-04 - val_loss: 3.8154e-04\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.1231e-04 - val_loss: 3.5338e-04\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.0992e-04 - val_loss: 4.0878e-04\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.1114e-04 - val_loss: 3.5010e-04\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.1043e-04 - val_loss: 3.5503e-04\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.0568e-04 - val_loss: 3.4157e-04\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.1253e-04 - val_loss: 3.4357e-04\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.9848e-04 - val_loss: 3.4692e-04\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.1670e-04 - val_loss: 3.3494e-04\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.9405e-04 - val_loss: 3.5171e-04\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.0145e-04 - val_loss: 3.3432e-04\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.9032e-04 - val_loss: 3.6414e-04\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.8675e-04 - val_loss: 3.2794e-04\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.8431e-04 - val_loss: 3.4628e-04\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.8665e-04 - val_loss: 3.6377e-04\n",
      "Thời gian huấn luyện:  22.47052812576294\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_12 (GRU)                (None, 10, 96)            28512     \n",
      "                                                                 \n",
      " flatten_51 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,473\n",
      "Trainable params: 29,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.0509 - val_loss: 0.0029\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0029\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0018\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0018\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0016\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 9.2993e-04\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 8.6738e-04\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 8.2345e-04\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 8.0500e-04\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 7.9507e-04\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 7.5137e-04\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 7.3831e-04\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 7.5771e-04\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.0603e-04\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 6.9689e-04\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 6.8434e-04\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.0720e-04\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 6.5964e-04\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 6.9027e-04\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.5502e-04\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.3913e-04\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.6773e-04\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.3135e-04\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.7406e-04\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.4731e-04\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.4761e-04\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.1245e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.5909e-04\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.1176e-04\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.9189e-04\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.1592e-04\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.8978e-04\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.8573e-04\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.9891e-04\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.8410e-04\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.7237e-04\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.6991e-04\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.6459e-04\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.9227e-04\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.5136e-04\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.7765e-04\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.4861e-04\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.4353e-04\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.5628e-04\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.4380e-04\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.3156e-04\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.2369e-04\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.3634e-04\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.2614e-04\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.5567e-04\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.1479e-04\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.1540e-04\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.0526e-04\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.2344e-04\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.9392e-04 - val_loss: 4.9855e-04\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.8962e-04 - val_loss: 4.8630e-04\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.7624e-04 - val_loss: 5.5060e-04\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.6952e-04 - val_loss: 4.7310e-04\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.6351e-04 - val_loss: 4.8326e-04\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.5321e-04 - val_loss: 5.0244e-04\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.4162e-04 - val_loss: 4.6871e-04\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.3590e-04 - val_loss: 4.6515e-04\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.2467e-04 - val_loss: 4.7510e-04\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.1896e-04 - val_loss: 4.5042e-04\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.0940e-04 - val_loss: 4.7332e-04\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.0229e-04 - val_loss: 4.4734e-04\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.9249e-04 - val_loss: 4.6569e-04\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.9840e-04 - val_loss: 4.3640e-04\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.8920e-04 - val_loss: 4.3189e-04\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.7632e-04 - val_loss: 4.3198e-04\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.6613e-04 - val_loss: 4.4371e-04\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.5448e-04 - val_loss: 4.2879e-04\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.4867e-04 - val_loss: 4.2240e-04\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.3953e-04 - val_loss: 4.2774e-04\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.4166e-04 - val_loss: 4.2193e-04\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.2771e-04 - val_loss: 4.3164e-04\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.3146e-04 - val_loss: 4.0825e-04\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.1468e-04 - val_loss: 4.1864e-04\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.0588e-04 - val_loss: 4.0394e-04\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.0405e-04 - val_loss: 4.1733e-04\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.9411e-04 - val_loss: 4.1494e-04\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.8714e-04 - val_loss: 4.1126e-04\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.8135e-04 - val_loss: 4.0254e-04\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.7779e-04 - val_loss: 4.0014e-04\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.6955e-04 - val_loss: 4.1766e-04\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.6254e-04 - val_loss: 3.9160e-04\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.5966e-04 - val_loss: 4.2955e-04\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.5961e-04 - val_loss: 4.0329e-04\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.4550e-04 - val_loss: 3.8982e-04\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.3789e-04 - val_loss: 3.7790e-04\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.3449e-04 - val_loss: 3.7310e-04\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.2837e-04 - val_loss: 3.7442e-04\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.2413e-04 - val_loss: 3.6509e-04\n",
      "Thời gian huấn luyện:  7.043416976928711\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_65 (Dense)            (None, 10, 96)            192       \n",
      "                                                                 \n",
      " flatten_52 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,153\n",
      "Trainable params: 1,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "30/30 [==============================] - 1s 8ms/step - loss: 0.0163 - val_loss: 0.0020\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 8.3034e-04\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 7.7959e-04\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 6.9951e-04\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 6.7737e-04\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 6.7248e-04\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 5.8994e-04\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.8151e-04\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.5192e-04\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.4363e-04\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.1838e-04\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.6563e-04\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.3945e-04\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.7941e-04 - val_loss: 5.0833e-04\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.4318e-04 - val_loss: 4.9322e-04\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.2195e-04 - val_loss: 4.7709e-04\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.0475e-04 - val_loss: 4.6721e-04\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.9517e-04 - val_loss: 4.7025e-04\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.7183e-04 - val_loss: 4.4555e-04\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.5334e-04 - val_loss: 4.5612e-04\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.5308e-04 - val_loss: 4.6015e-04\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.5612e-04 - val_loss: 4.1759e-04\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.1412e-04 - val_loss: 4.8020e-04\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.0806e-04 - val_loss: 4.5518e-04\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.1090e-04 - val_loss: 4.1471e-04\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.8334e-04 - val_loss: 4.0294e-04\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.8694e-04 - val_loss: 4.3359e-04\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.9148e-04 - val_loss: 4.7317e-04\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.7168e-04 - val_loss: 3.9730e-04\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.5379e-04 - val_loss: 4.0160e-04\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.4262e-04 - val_loss: 3.8280e-04\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.4941e-04 - val_loss: 3.8345e-04\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.5755e-04 - val_loss: 3.8561e-04\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.2543e-04 - val_loss: 3.8145e-04\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.2048e-04 - val_loss: 3.7763e-04\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.9945e-04 - val_loss: 5.1050e-04\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.0358e-04 - val_loss: 3.6517e-04\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.1328e-04 - val_loss: 5.5404e-04\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.0184e-04 - val_loss: 3.6500e-04\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.9899e-04 - val_loss: 4.0994e-04\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.7917e-04 - val_loss: 3.5810e-04\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.7130e-04 - val_loss: 3.5522e-04\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.6499e-04 - val_loss: 3.6619e-04\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.5832e-04 - val_loss: 3.7240e-04\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.5294e-04 - val_loss: 3.5389e-04\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.9192e-04 - val_loss: 3.4451e-04\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.5624e-04 - val_loss: 3.7315e-04\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.4932e-04 - val_loss: 3.4930e-04\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.3977e-04 - val_loss: 3.3683e-04\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.3776e-04 - val_loss: 4.1818e-04\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.2768e-04 - val_loss: 3.8556e-04\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.3159e-04 - val_loss: 3.6282e-04\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.2351e-04 - val_loss: 3.4715e-04\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.1635e-04 - val_loss: 3.3118e-04\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.2516e-04 - val_loss: 3.2653e-04\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.1603e-04 - val_loss: 3.7023e-04\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.1653e-04 - val_loss: 3.5065e-04\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.0333e-04 - val_loss: 3.5397e-04\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.9635e-04 - val_loss: 4.3784e-04\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.1139e-04 - val_loss: 5.2166e-04\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.2641e-04 - val_loss: 3.2350e-04\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 6.0631e-04 - val_loss: 3.6620e-04\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 5.9951e-04 - val_loss: 3.5287e-04\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.8906e-04 - val_loss: 4.1868e-04\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.8717e-04 - val_loss: 3.1412e-04\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.7775e-04 - val_loss: 3.3784e-04\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.7860e-04 - val_loss: 3.1758e-04\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 5.9876e-04 - val_loss: 3.3358e-04\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.7126e-04 - val_loss: 3.5471e-04\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.7447e-04 - val_loss: 3.1273e-04\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.8399e-04 - val_loss: 3.0373e-04\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.7485e-04 - val_loss: 3.1218e-04\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 5.6757e-04 - val_loss: 3.1250e-04\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.5676e-04 - val_loss: 3.0112e-04\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.6815e-04 - val_loss: 3.0327e-04\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.5415e-04 - val_loss: 3.0081e-04\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.5390e-04 - val_loss: 3.4127e-04\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.8622e-04 - val_loss: 4.8419e-04\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.8999e-04 - val_loss: 3.4409e-04\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 3ms/step - loss: 5.4780e-04 - val_loss: 3.3832e-04\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.4537e-04 - val_loss: 3.0317e-04\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.5819e-04 - val_loss: 2.9033e-04\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.4261e-04 - val_loss: 2.8996e-04\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.6210e-04 - val_loss: 3.6191e-04\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.7823e-04 - val_loss: 2.9996e-04\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.4120e-04 - val_loss: 2.8695e-04\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.0806e-04 - val_loss: 3.6751e-04\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.5247e-04 - val_loss: 2.8473e-04\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.2666e-04 - val_loss: 2.8952e-04\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.3144e-04 - val_loss: 2.8647e-04\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.3103e-04 - val_loss: 2.8287e-04\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.3016e-04 - val_loss: 3.3413e-04\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.2781e-04 - val_loss: 2.8582e-04\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.2704e-04 - val_loss: 3.0289e-04\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.3703e-04 - val_loss: 3.1686e-04\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.3472e-04 - val_loss: 2.8326e-04\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.3980e-04 - val_loss: 2.8022e-04\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.1875e-04 - val_loss: 2.9179e-04\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 5.2632e-04 - val_loss: 2.9117e-04\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.1389e-04 - val_loss: 2.7528e-04\n",
      "Thời gian huấn luyện:  10.990137338638306\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_13 (SimpleRNN)   (None, 10, 96)            9408      \n",
      "                                                                 \n",
      " flatten_53 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,369\n",
      "Trainable params: 10,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "30/30 [==============================] - 2s 18ms/step - loss: 0.0232 - val_loss: 0.0011\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 9.5392e-04\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 9.7008e-04\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 9.7099e-04\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 9.8123e-04\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 9.0156e-04\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 9.1991e-04\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 9.1200e-04\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 9.2123e-04\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 8.6696e-04\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 8.8307e-04\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 8.6901e-04\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.7301e-04\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.5500e-04\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.1642e-04\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.9297e-04\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.6645e-04\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.4149e-04\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 8.0800e-04\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 7.8647e-04\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 8.3260e-04\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.6888e-04\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.6574e-04\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.9288e-04\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.6497e-04\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.3365e-04\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.4954e-04\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.3957e-04\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.3710e-04\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.0828e-04\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.0310e-04\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 6.9405e-04\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.0278e-04\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.1926e-04\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 7.2730e-04\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 6.7685e-04\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 7.0064e-04\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 7.0671e-04\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 6.7718e-04\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 6.6792e-04\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 7.0757e-04\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.3092e-04\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 7.2211e-04\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.2483e-04\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.4786e-04\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 7.5051e-04\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.1126e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.3398e-04\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 6.5114e-04\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 6.3551e-04\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 6.2571e-04\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 6.5474e-04\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 6.8103e-04\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.7705e-04\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.5994e-04\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 6.3606e-04\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.4906e-04\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.5174e-04\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.5346e-04\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.6647e-04\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 6.1537e-04\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.3003e-04\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.3462e-04\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.5125e-04\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.4563e-04\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.2790e-04\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 5.2275e-04\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 5.2424e-04\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 6.3100e-04\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.1862e-04\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 5.7187e-04\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 5.0406e-04\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 6.7747e-04\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 5.3315e-04\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 9.9752e-04 - val_loss: 5.7851e-04\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 9.9420e-04 - val_loss: 5.2461e-04\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 6.6662e-04\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 5.0296e-04\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.8191e-04 - val_loss: 5.6312e-04\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 5.1920e-04\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.9642e-04 - val_loss: 5.3391e-04\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.8032e-04 - val_loss: 6.2891e-04\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.7402e-04 - val_loss: 5.1412e-04\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 9.6354e-04 - val_loss: 5.4611e-04\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.8408e-04 - val_loss: 5.1675e-04\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.6720e-04 - val_loss: 4.9383e-04\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 9.6849e-04 - val_loss: 5.8053e-04\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.4690e-04 - val_loss: 5.0933e-04\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.5180e-04 - val_loss: 4.8184e-04\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.5043e-04 - val_loss: 5.3062e-04\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.4256e-04 - val_loss: 5.5193e-04\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.5184e-04 - val_loss: 4.7685e-04\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.4289e-04 - val_loss: 4.7391e-04\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.5612e-04 - val_loss: 5.1477e-04\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.2409e-04 - val_loss: 4.8808e-04\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.2114e-04 - val_loss: 5.1194e-04\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.1778e-04 - val_loss: 5.1858e-04\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 9.0574e-04 - val_loss: 4.7942e-04\n",
      "Thời gian huấn luyện:  23.246170043945312\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_13 (LSTM)              (None, 10, 96)            37632     \n",
      "                                                                 \n",
      " flatten_54 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,593\n",
      "Trainable params: 38,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "30/30 [==============================] - 2s 17ms/step - loss: 0.0206 - val_loss: 0.0017\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 8.0687e-04\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 8.2083e-04\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 7.5676e-04\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 7.8632e-04\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 7.1664e-04\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 7.3885e-04\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 7.4806e-04\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 7.1348e-04\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 6.8583e-04\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 6.6653e-04\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 6.9655e-04\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 7.1017e-04\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.8038e-04\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.6211e-04\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.5689e-04\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.7130e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 6.0267e-04\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 5.9390e-04\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 5.8980e-04\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.3456e-04\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 5.7024e-04\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 5.7723e-04\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 5.5510e-04\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.5276e-04\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.2280e-04\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.0195e-04\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.3478e-04\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.2259e-04\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.1581e-04\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.3696e-04\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 5.0868e-04\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.1515e-04\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.1294e-04\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.9056e-04 - val_loss: 5.2421e-04\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.7682e-04 - val_loss: 4.9154e-04\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.6355e-04 - val_loss: 5.4601e-04\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.6530e-04 - val_loss: 4.7546e-04\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.9402e-04 - val_loss: 4.7110e-04\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.4654e-04 - val_loss: 4.9735e-04\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.2597e-04 - val_loss: 5.4115e-04\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.1355e-04 - val_loss: 4.6199e-04\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.0347e-04 - val_loss: 5.0625e-04\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9.0265e-04 - val_loss: 4.8405e-04\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.9444e-04 - val_loss: 4.4748e-04\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.8291e-04 - val_loss: 4.4490e-04\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.8161e-04 - val_loss: 4.4565e-04\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.7538e-04 - val_loss: 4.7131e-04\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.6733e-04 - val_loss: 4.6859e-04\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.5608e-04 - val_loss: 4.9397e-04\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.5732e-04 - val_loss: 4.3427e-04\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.7610e-04 - val_loss: 4.6341e-04\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.3429e-04 - val_loss: 4.7144e-04\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.3019e-04 - val_loss: 4.3054e-04\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.3675e-04 - val_loss: 4.2058e-04\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.1807e-04 - val_loss: 4.1755e-04\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.1719e-04 - val_loss: 4.1771e-04\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.0776e-04 - val_loss: 4.1962e-04\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.0121e-04 - val_loss: 4.2764e-04\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 8.0112e-04 - val_loss: 4.3165e-04\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.9482e-04 - val_loss: 4.0756e-04\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.8733e-04 - val_loss: 4.0897e-04\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.8416e-04 - val_loss: 4.0971e-04\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.7799e-04 - val_loss: 4.0482e-04\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.8230e-04 - val_loss: 4.1883e-04\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.8451e-04 - val_loss: 4.1923e-04\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.8918e-04 - val_loss: 4.2233e-04\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.6619e-04 - val_loss: 4.5273e-04\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.5789e-04 - val_loss: 4.4469e-04\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.5108e-04 - val_loss: 4.3425e-04\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.5077e-04 - val_loss: 3.8914e-04\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.4156e-04 - val_loss: 4.0416e-04\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.4048e-04 - val_loss: 4.2652e-04\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.4343e-04 - val_loss: 4.0244e-04\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.3488e-04 - val_loss: 4.7767e-04\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.3877e-04 - val_loss: 3.9148e-04\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 7.2457e-04 - val_loss: 3.8466e-04\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.2603e-04 - val_loss: 4.1734e-04\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.1513e-04 - val_loss: 3.7653e-04\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.1897e-04 - val_loss: 4.0165e-04\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 7.0680e-04 - val_loss: 4.0487e-04\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 7.0751e-04 - val_loss: 3.7130e-04\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.9621e-04 - val_loss: 4.0770e-04\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.9811e-04 - val_loss: 3.7800e-04\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.9749e-04 - val_loss: 3.6742e-04\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.9452e-04 - val_loss: 4.2538e-04\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.8941e-04 - val_loss: 3.6373e-04\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.8676e-04 - val_loss: 5.0635e-04\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.8122e-04 - val_loss: 3.6425e-04\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.8990e-04 - val_loss: 4.1942e-04\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.7288e-04 - val_loss: 3.7266e-04\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.6574e-04 - val_loss: 4.0170e-04\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.6452e-04 - val_loss: 4.0751e-04\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 6ms/step - loss: 6.7516e-04 - val_loss: 3.6622e-04\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.8564e-04 - val_loss: 3.5712e-04\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.5863e-04 - val_loss: 4.8090e-04\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 6.7867e-04 - val_loss: 3.7763e-04\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.4787e-04 - val_loss: 3.5093e-04\n",
      "Thời gian huấn luyện:  20.92561912536621\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_13 (GRU)                (None, 10, 96)            28512     \n",
      "                                                                 \n",
      " flatten_55 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,473\n",
      "Trainable params: 29,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "35/35 [==============================] - 0s 941us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 1s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0442 - val_loss: 0.0029\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 9.9587e-04\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 9.8964e-04\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 9.8921e-04\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 9.7177e-04\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 9.6849e-04\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 9.5574e-04\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 9.5720e-04\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 9.4218e-04\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 3ms/step - loss: 9.9642e-04 - val_loss: 9.3718e-04\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 9.3195e-04\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.9025e-04 - val_loss: 9.2200e-04\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.7805e-04 - val_loss: 9.1194e-04\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.6751e-04 - val_loss: 9.0403e-04\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.6595e-04 - val_loss: 8.9795e-04\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.5768e-04 - val_loss: 8.9044e-04\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.5811e-04 - val_loss: 8.9802e-04\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.4168e-04 - val_loss: 8.7854e-04\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.3414e-04 - val_loss: 8.6805e-04\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.2615e-04 - val_loss: 8.6034e-04\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.1976e-04 - val_loss: 8.5463e-04\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.1560e-04 - val_loss: 8.4670e-04\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.0831e-04 - val_loss: 8.3943e-04\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.0044e-04 - val_loss: 8.3258e-04\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.9783e-04 - val_loss: 8.2619e-04\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.9912e-04 - val_loss: 8.4133e-04\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 8.8317e-04 - val_loss: 8.1158e-04\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.7476e-04 - val_loss: 8.0850e-04\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.6839e-04 - val_loss: 7.9890e-04\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.6248e-04 - val_loss: 7.9973e-04\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.5658e-04 - val_loss: 7.8574e-04\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.5398e-04 - val_loss: 7.8538e-04\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.4658e-04 - val_loss: 7.7330e-04\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.3773e-04 - val_loss: 7.6468e-04\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.2987e-04 - val_loss: 7.6068e-04\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.2383e-04 - val_loss: 7.5225e-04\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.2588e-04 - val_loss: 7.4886e-04\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.1499e-04 - val_loss: 7.3942e-04\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.0543e-04 - val_loss: 7.3522e-04\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.0314e-04 - val_loss: 7.2766e-04\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.9346e-04 - val_loss: 7.2158e-04\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.8772e-04 - val_loss: 7.1483e-04\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.8208e-04 - val_loss: 7.1958e-04\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.8150e-04 - val_loss: 7.0364e-04\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.7008e-04 - val_loss: 6.9751e-04\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.6332e-04 - val_loss: 6.9700e-04\n",
      "Thời gian huấn luyện:  7.110063552856445\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_70 (Dense)            (None, 10, 96)            192       \n",
      "                                                                 \n",
      " flatten_56 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,153\n",
      "Trainable params: 1,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 1s 9ms/step - loss: 0.0063 - val_loss: 0.0021\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 9.6307e-04\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 9.3373e-04\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 8.2123e-04\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 9.4457e-04 - val_loss: 7.6896e-04\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.6702e-04 - val_loss: 7.3567e-04\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.3189e-04 - val_loss: 7.1114e-04\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.1229e-04 - val_loss: 6.9456e-04\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.0000e-04 - val_loss: 6.8691e-04\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.5956e-04 - val_loss: 6.5969e-04\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.2838e-04 - val_loss: 7.8135e-04\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.0108e-04 - val_loss: 6.2759e-04\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.1821e-04 - val_loss: 6.4840e-04\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.2337e-04 - val_loss: 6.6685e-04\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.2308e-04 - val_loss: 6.6877e-04\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.9111e-04 - val_loss: 5.8401e-04\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.1429e-04 - val_loss: 6.1341e-04\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.7305e-04 - val_loss: 5.6396e-04\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.7545e-04 - val_loss: 5.6783e-04\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.9012e-04 - val_loss: 5.8287e-04\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.9123e-04 - val_loss: 5.4878e-04\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.5618e-04 - val_loss: 5.3987e-04\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.9099e-04 - val_loss: 5.4902e-04\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.4388e-04 - val_loss: 6.0606e-04\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.3095e-04 - val_loss: 5.2876e-04\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.4752e-04 - val_loss: 5.9347e-04\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.2418e-04 - val_loss: 5.3637e-04\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.0867e-04 - val_loss: 5.1410e-04\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 4ms/step - loss: 6.0116e-04 - val_loss: 5.1270e-04\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.9634e-04 - val_loss: 5.1187e-04\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.1092e-04 - val_loss: 5.3798e-04\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.3330e-04 - val_loss: 5.0403e-04\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.9498e-04 - val_loss: 4.9665e-04\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.1673e-04 - val_loss: 5.6227e-04\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.9279e-04 - val_loss: 4.9126e-04\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.7705e-04 - val_loss: 4.8616e-04\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.0747e-04 - val_loss: 4.9866e-04\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.7621e-04 - val_loss: 4.9777e-04\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.7216e-04 - val_loss: 4.9129e-04\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.6293e-04 - val_loss: 5.3204e-04\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.8588e-04 - val_loss: 4.7768e-04\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.7771e-04 - val_loss: 4.7298e-04\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.5481e-04 - val_loss: 4.6727e-04\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.6723e-04 - val_loss: 4.6903e-04\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.5340e-04 - val_loss: 4.7715e-04\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.4493e-04 - val_loss: 4.6915e-04\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.6168e-04 - val_loss: 4.6545e-04\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.4965e-04 - val_loss: 4.5645e-04\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.5778e-04 - val_loss: 4.7483e-04\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.4835e-04 - val_loss: 4.7140e-04\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.4665e-04 - val_loss: 4.6539e-04\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.7229e-04 - val_loss: 4.5124e-04\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.8779e-04 - val_loss: 4.5282e-04\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.4941e-04 - val_loss: 4.4645e-04\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.2641e-04 - val_loss: 4.5290e-04\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.3030e-04 - val_loss: 4.4571e-04\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.6167e-04 - val_loss: 4.5458e-04\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.5226e-04 - val_loss: 5.4686e-04\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.2519e-04 - val_loss: 4.4031e-04\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.2185e-04 - val_loss: 4.3759e-04\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.3904e-04 - val_loss: 5.3552e-04\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.3940e-04 - val_loss: 4.9723e-04\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.2384e-04 - val_loss: 4.3045e-04\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.1272e-04 - val_loss: 4.4517e-04\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.1856e-04 - val_loss: 4.2808e-04\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.1488e-04 - val_loss: 4.2793e-04\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.5722e-04 - val_loss: 4.3072e-04\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.2099e-04 - val_loss: 4.5849e-04\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.3066e-04 - val_loss: 4.2611e-04\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.1167e-04 - val_loss: 4.2367e-04\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.2775e-04 - val_loss: 4.2434e-04\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.1320e-04 - val_loss: 4.3063e-04\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.9861e-04 - val_loss: 4.3608e-04\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.2384e-04 - val_loss: 4.2155e-04\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.1886e-04 - val_loss: 4.1656e-04\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.0993e-04 - val_loss: 4.4440e-04\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.4211e-04 - val_loss: 4.2040e-04\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.0133e-04 - val_loss: 4.1123e-04\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.5799e-04 - val_loss: 4.2780e-04\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.9405e-04 - val_loss: 4.0870e-04\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.0251e-04 - val_loss: 4.1890e-04\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.9136e-04 - val_loss: 4.0524e-04\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.9149e-04 - val_loss: 4.0794e-04\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.0010e-04 - val_loss: 4.0476e-04\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.8424e-04 - val_loss: 4.1252e-04\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.2400e-04 - val_loss: 5.1962e-04\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.1174e-04 - val_loss: 4.0577e-04\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4.9365e-04 - val_loss: 4.0807e-04\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.0373e-04 - val_loss: 4.2611e-04\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.1018e-04 - val_loss: 4.0425e-04\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.9740e-04 - val_loss: 3.9703e-04\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.1439e-04 - val_loss: 4.7460e-04\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.1334e-04 - val_loss: 3.9730e-04\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4.8209e-04 - val_loss: 3.9337e-04\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4.7748e-04 - val_loss: 3.9332e-04\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4.9764e-04 - val_loss: 4.3691e-04\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.0230e-04 - val_loss: 3.9205e-04\n",
      "Thời gian huấn luyện:  10.797170877456665\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_14 (SimpleRNN)   (None, 10, 96)            9408      \n",
      "                                                                 \n",
      " flatten_57 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,369\n",
      "Trainable params: 10,369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 2s 19ms/step - loss: 0.0223 - val_loss: 0.0018\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 9.7832e-04\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 9.7377e-04\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 9.6439e-04\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 9.5244e-04\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 9.5786e-04\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 9.4906e-04\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 9.8964e-04\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.9880e-04 - val_loss: 9.3634e-04\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.9212e-04 - val_loss: 9.5150e-04\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.7618e-04 - val_loss: 9.1127e-04\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.8333e-04 - val_loss: 9.1073e-04\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.7753e-04 - val_loss: 9.6007e-04\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.6060e-04 - val_loss: 9.0476e-04\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.7837e-04 - val_loss: 8.9169e-04\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.5231e-04 - val_loss: 8.9496e-04\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.5143e-04 - val_loss: 8.9799e-04\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 7ms/step - loss: 9.7972e-04 - val_loss: 9.4088e-04\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.4610e-04 - val_loss: 8.9199e-04\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.3512e-04 - val_loss: 8.8639e-04\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.3407e-04 - val_loss: 8.7752e-04\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.5100e-04 - val_loss: 8.7084e-04\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.3950e-04 - val_loss: 8.8078e-04\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.3859e-04 - val_loss: 9.0629e-04\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.1351e-04 - val_loss: 8.6037e-04\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.1884e-04 - val_loss: 8.6951e-04\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.1530e-04 - val_loss: 8.5348e-04\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.1565e-04 - val_loss: 8.7259e-04\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.1154e-04 - val_loss: 8.6034e-04\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.0239e-04 - val_loss: 8.7348e-04\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.9913e-04 - val_loss: 8.8358e-04\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.9436e-04 - val_loss: 9.4035e-04\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.8356e-04 - val_loss: 9.2602e-04\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.9941e-04 - val_loss: 8.7044e-04\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.8255e-04 - val_loss: 8.5237e-04\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.9803e-04 - val_loss: 8.4003e-04\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7760e-04 - val_loss: 8.3297e-04\n",
      "Thời gian huấn luyện:  21.741520404815674\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_14 (LSTM)              (None, 10, 96)            37632     \n",
      "                                                                 \n",
      " flatten_58 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,593\n",
      "Trainable params: 38,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 2s 18ms/step - loss: 0.0125 - val_loss: 0.0025\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 9.8572e-04\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 9.4919e-04\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 9.4395e-04\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.9788e-04 - val_loss: 9.1163e-04\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.7202e-04 - val_loss: 8.9745e-04\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.4995e-04 - val_loss: 9.1225e-04\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.4578e-04 - val_loss: 8.6540e-04\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.2519e-04 - val_loss: 8.4842e-04\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.1587e-04 - val_loss: 8.3901e-04\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.0103e-04 - val_loss: 8.3850e-04\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 9.0003e-04 - val_loss: 8.1388e-04\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.8169e-04 - val_loss: 8.3615e-04\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.7232e-04 - val_loss: 7.9978e-04\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.6028e-04 - val_loss: 7.8019e-04\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.5479e-04 - val_loss: 7.7392e-04\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.3646e-04 - val_loss: 7.6318e-04\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.3328e-04 - val_loss: 7.7684e-04\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.2740e-04 - val_loss: 7.4992e-04\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.1597e-04 - val_loss: 7.4963e-04\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.2167e-04 - val_loss: 7.3645e-04\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.0343e-04 - val_loss: 7.3085e-04\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.9300e-04 - val_loss: 7.4366e-04\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.9494e-04 - val_loss: 7.1722e-04\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.8329e-04 - val_loss: 7.4911e-04\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 8.1244e-04 - val_loss: 7.3003e-04\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 7ms/step - loss: 7.9449e-04 - val_loss: 7.1759e-04\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.9249e-04 - val_loss: 6.9487e-04\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.7417e-04 - val_loss: 7.0849e-04\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.5979e-04 - val_loss: 7.2677e-04\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.5388e-04 - val_loss: 7.1793e-04\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.5353e-04 - val_loss: 6.7609e-04\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.4030e-04 - val_loss: 6.7350e-04\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.3604e-04 - val_loss: 6.8028e-04\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.3207e-04 - val_loss: 6.6489e-04\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.4204e-04 - val_loss: 6.8095e-04\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.2894e-04 - val_loss: 6.6813e-04\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.1978e-04 - val_loss: 6.6011e-04\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.1888e-04 - val_loss: 6.6032e-04\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.1414e-04 - val_loss: 6.5557e-04\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.1152e-04 - val_loss: 6.4818e-04\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.1124e-04 - val_loss: 6.4108e-04\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.0014e-04 - val_loss: 6.3905e-04\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 6.9988e-04 - val_loss: 6.8270e-04\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.1064e-04 - val_loss: 6.2993e-04\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 7.0359e-04 - val_loss: 6.2906e-04\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.9563e-04 - val_loss: 6.2095e-04\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.8205e-04 - val_loss: 6.2813e-04\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.8192e-04 - val_loss: 6.4057e-04\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.7557e-04 - val_loss: 6.1639e-04\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.7496e-04 - val_loss: 6.1125e-04\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.6963e-04 - val_loss: 6.2285e-04\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.8435e-04 - val_loss: 6.0379e-04\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 6.6096e-04 - val_loss: 5.9914e-04\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.7754e-04 - val_loss: 6.2900e-04\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.6104e-04 - val_loss: 6.0345e-04\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.5703e-04 - val_loss: 6.5694e-04\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.5505e-04 - val_loss: 6.0231e-04\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.5527e-04 - val_loss: 5.9479e-04\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.4300e-04 - val_loss: 5.8477e-04\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.4440e-04 - val_loss: 5.7879e-04\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.4265e-04 - val_loss: 5.7921e-04\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.3788e-04 - val_loss: 5.8579e-04\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.3168e-04 - val_loss: 6.1778e-04\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.3316e-04 - val_loss: 5.8396e-04\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 6.3683e-04 - val_loss: 5.7034e-04\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.5043e-04 - val_loss: 5.7822e-04\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.4139e-04 - val_loss: 5.7978e-04\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.2416e-04 - val_loss: 5.6542e-04\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 6.2847e-04 - val_loss: 5.5687e-04\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.1626e-04 - val_loss: 6.0123e-04\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.1817e-04 - val_loss: 5.6102e-04\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.0960e-04 - val_loss: 5.5174e-04\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.1101e-04 - val_loss: 5.5701e-04\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.1018e-04 - val_loss: 5.4973e-04\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 6.0234e-04 - val_loss: 5.9196e-04\n",
      "Thời gian huấn luyện:  20.769975900650024\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_14 (GRU)                (None, 10, 96)            28512     \n",
      "                                                                 \n",
      " flatten_59 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,473\n",
      "Trainable params: 29,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1000us/step\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0448 - val_loss: 0.0020\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 9.4698e-04\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 9.4817e-04\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 9.3916e-04\n",
      "Epoch 16/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 8.4576e-04\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 8.4593e-04\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.8025e-04\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.3757e-04\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.9402e-04\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.5841e-04\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.1215e-04\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.2778e-04\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.8319e-04\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.0780e-04\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.8928e-04\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.0262e-04\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.7367e-04\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.6509e-04\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.7383e-04\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.8704e-04\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.3826e-04\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.6813e-04\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.2698e-04\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.4935e-04\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.2841e-04\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.1464e-04\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.2569e-04\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.2702e-04\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.0406e-04\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.9590e-04\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.1767e-04\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.9479e-04\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.0261e-04\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.9728e-04\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.7340e-04\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.8307e-04\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.7216e-04\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.5367e-04\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.6232e-04\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.4193e-04\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.4559e-04\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.8593e-04 - val_loss: 5.3598e-04\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.8092e-04 - val_loss: 5.6851e-04\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.6607e-04 - val_loss: 5.2022e-04\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.6216e-04 - val_loss: 5.1193e-04\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.6702e-04 - val_loss: 5.1426e-04\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.3978e-04 - val_loss: 5.4533e-04\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.3934e-04 - val_loss: 5.2481e-04\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.3038e-04 - val_loss: 4.9435e-04\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.2370e-04 - val_loss: 5.3730e-04\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.0610e-04 - val_loss: 5.0487e-04\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.0523e-04 - val_loss: 5.0398e-04\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.9267e-04 - val_loss: 4.7243e-04\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.7743e-04 - val_loss: 4.7784e-04\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.7083e-04 - val_loss: 4.7206e-04\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.6702e-04 - val_loss: 4.6895e-04\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.5471e-04 - val_loss: 4.5304e-04\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.4840e-04 - val_loss: 4.5515e-04\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.3882e-04 - val_loss: 4.6216e-04\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.2934e-04 - val_loss: 4.4588e-04\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.2119e-04 - val_loss: 4.4661e-04\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.1201e-04 - val_loss: 4.4870e-04\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.0707e-04 - val_loss: 4.3262e-04\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.9797e-04 - val_loss: 4.3611e-04\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.9006e-04 - val_loss: 4.3804e-04\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.8504e-04 - val_loss: 4.2215e-04\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.7530e-04 - val_loss: 4.2074e-04\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.6973e-04 - val_loss: 4.1124e-04\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.6587e-04 - val_loss: 4.2705e-04\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.5782e-04 - val_loss: 4.0649e-04\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.6055e-04 - val_loss: 4.4684e-04\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.4357e-04 - val_loss: 3.9101e-04\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.4347e-04 - val_loss: 3.9040e-04\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.2692e-04 - val_loss: 3.9850e-04\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.2095e-04 - val_loss: 3.8005e-04\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.1810e-04 - val_loss: 3.8518e-04\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.0914e-04 - val_loss: 3.8912e-04\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.0398e-04 - val_loss: 3.7241e-04\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.9949e-04 - val_loss: 3.7102e-04\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.9344e-04 - val_loss: 3.7421e-04\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.8486e-04 - val_loss: 3.6127e-04\n",
      "Epoch 93/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 6.8216e-04 - val_loss: 3.7533e-04\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.7643e-04 - val_loss: 3.6359e-04\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.7314e-04 - val_loss: 3.5532e-04\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.6546e-04 - val_loss: 3.5368e-04\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.6001e-04 - val_loss: 3.4713e-04\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.5728e-04 - val_loss: 3.5344e-04\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.5042e-04 - val_loss: 3.6218e-04\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.5038e-04 - val_loss: 3.6534e-04\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.4410e-04 - val_loss: 3.4840e-04\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.3788e-04 - val_loss: 3.5163e-04\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.3306e-04 - val_loss: 3.3237e-04\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.2941e-04 - val_loss: 3.3794e-04\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.2892e-04 - val_loss: 3.3417e-04\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.2814e-04 - val_loss: 3.4396e-04\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.1779e-04 - val_loss: 3.3055e-04\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.1451e-04 - val_loss: 3.2991e-04\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.1489e-04 - val_loss: 3.3671e-04\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.2260e-04 - val_loss: 3.2598e-04\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0023e-04 - val_loss: 3.7204e-04\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0720e-04 - val_loss: 3.2792e-04\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0273e-04 - val_loss: 3.1794e-04\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9396e-04 - val_loss: 3.1106e-04\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9205e-04 - val_loss: 3.0909e-04\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9926e-04 - val_loss: 3.1145e-04\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8793e-04 - val_loss: 3.1446e-04\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8824e-04 - val_loss: 3.3734e-04\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8379e-04 - val_loss: 3.1149e-04\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7942e-04 - val_loss: 3.0602e-04\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8523e-04 - val_loss: 3.0052e-04\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7385e-04 - val_loss: 3.0362e-04\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6964e-04 - val_loss: 3.3678e-04\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7702e-04 - val_loss: 3.2009e-04\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7063e-04 - val_loss: 2.9571e-04\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6802e-04 - val_loss: 2.9783e-04\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6118e-04 - val_loss: 2.9417e-04\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6146e-04 - val_loss: 2.9454e-04\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6013e-04 - val_loss: 2.9933e-04\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5944e-04 - val_loss: 2.9201e-04\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5572e-04 - val_loss: 2.8922e-04\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5474e-04 - val_loss: 2.9342e-04\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5332e-04 - val_loss: 2.8761e-04\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4721e-04 - val_loss: 3.0653e-04\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5593e-04 - val_loss: 3.0218e-04\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4949e-04 - val_loss: 2.9529e-04\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4855e-04 - val_loss: 2.9445e-04\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4338e-04 - val_loss: 2.8350e-04\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4173e-04 - val_loss: 2.8318e-04\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4011e-04 - val_loss: 2.8880e-04\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4060e-04 - val_loss: 2.8029e-04\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3374e-04 - val_loss: 2.8939e-04\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3863e-04 - val_loss: 2.7865e-04\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3559e-04 - val_loss: 2.8078e-04\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.5037e-04 - val_loss: 3.0926e-04\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3087e-04 - val_loss: 2.8314e-04\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2965e-04 - val_loss: 2.7547e-04\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3179e-04 - val_loss: 2.9065e-04\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2703e-04 - val_loss: 2.8252e-04\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2506e-04 - val_loss: 2.8304e-04\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2351e-04 - val_loss: 2.8301e-04\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2059e-04 - val_loss: 2.8499e-04\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2419e-04 - val_loss: 2.7260e-04\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2171e-04 - val_loss: 2.7005e-04\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1845e-04 - val_loss: 2.7048e-04\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1552e-04 - val_loss: 2.7685e-04\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1428e-04 - val_loss: 2.6792e-04\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1717e-04 - val_loss: 2.7094e-04\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1741e-04 - val_loss: 2.8387e-04\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1135e-04 - val_loss: 2.7462e-04\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1119e-04 - val_loss: 2.6545e-04\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1082e-04 - val_loss: 2.6680e-04\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1168e-04 - val_loss: 2.8935e-04\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0817e-04 - val_loss: 2.6452e-04\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0617e-04 - val_loss: 2.6831e-04\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0457e-04 - val_loss: 2.7042e-04\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0246e-04 - val_loss: 2.7452e-04\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0820e-04 - val_loss: 2.7731e-04\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9912e-04 - val_loss: 2.6125e-04\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0310e-04 - val_loss: 2.6066e-04\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0213e-04 - val_loss: 2.6812e-04\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1348e-04 - val_loss: 2.5936e-04\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0598e-04 - val_loss: 2.8339e-04\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0343e-04 - val_loss: 2.6349e-04\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9556e-04 - val_loss: 2.7145e-04\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9413e-04 - val_loss: 2.5742e-04\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9392e-04 - val_loss: 2.6283e-04\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9114e-04 - val_loss: 2.6283e-04\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9346e-04 - val_loss: 2.8098e-04\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9437e-04 - val_loss: 2.5727e-04\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9038e-04 - val_loss: 2.5551e-04\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8903e-04 - val_loss: 2.5897e-04\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9298e-04 - val_loss: 2.5460e-04\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8886e-04 - val_loss: 2.5440e-04\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8896e-04 - val_loss: 2.5895e-04\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8968e-04 - val_loss: 2.7240e-04\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8680e-04 - val_loss: 2.5678e-04\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8460e-04 - val_loss: 2.5393e-04\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8670e-04 - val_loss: 2.5673e-04\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8196e-04 - val_loss: 2.5174e-04\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8408e-04 - val_loss: 2.5329e-04\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8013e-04 - val_loss: 2.5848e-04\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8155e-04 - val_loss: 2.5630e-04\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.7899e-04 - val_loss: 2.5064e-04\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8277e-04 - val_loss: 2.5238e-04\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.7921e-04 - val_loss: 2.5629e-04\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.7826e-04 - val_loss: 2.5474e-04\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.7737e-04 - val_loss: 2.5537e-04\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8118e-04 - val_loss: 2.4964e-04\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.7629e-04 - val_loss: 2.6165e-04\n",
      "Thời gian huấn luyện:  13.646236181259155\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_75 (Dense)            (None, 10, 96)            192       \n",
      "                                                                 \n",
      " flatten_60 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,153\n",
      "Trainable params: 1,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 1s 8ms/step - loss: 0.0096 - val_loss: 0.0014\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 9.4833e-04\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 7.9748e-04\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 7.5995e-04\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 8.2217e-04\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.6892e-04\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.4171e-04\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.6831e-04\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.7827e-04\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.9070e-04\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 6.2617e-04\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.9111e-04 - val_loss: 5.3320e-04\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.6223e-04 - val_loss: 5.2255e-04\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 5.1850e-04\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.8257e-04 - val_loss: 5.8079e-04\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.2556e-04 - val_loss: 5.2224e-04\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.1939e-04 - val_loss: 5.6759e-04\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.1607e-04 - val_loss: 4.9693e-04\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.7889e-04 - val_loss: 5.1135e-04\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.7216e-04 - val_loss: 5.0443e-04\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.5329e-04 - val_loss: 4.9599e-04\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.5529e-04 - val_loss: 4.9094e-04\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.4969e-04 - val_loss: 4.6876e-04\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.6249e-04 - val_loss: 4.8616e-04\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.2705e-04 - val_loss: 5.1914e-04\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.3788e-04 - val_loss: 4.7058e-04\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.4741e-04 - val_loss: 4.7016e-04\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.1075e-04 - val_loss: 5.0783e-04\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.8830e-04 - val_loss: 4.9056e-04\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.9864e-04 - val_loss: 4.5158e-04\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.8139e-04 - val_loss: 4.4633e-04\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.8162e-04 - val_loss: 4.3592e-04\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.8763e-04 - val_loss: 5.5718e-04\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.6966e-04 - val_loss: 4.6374e-04\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.5740e-04 - val_loss: 4.3414e-04\n",
      "Epoch 36/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 7.4649e-04 - val_loss: 4.7841e-04\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.5285e-04 - val_loss: 4.1763e-04\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.5092e-04 - val_loss: 4.8526e-04\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.3744e-04 - val_loss: 4.6450e-04\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2409e-04 - val_loss: 4.1650e-04\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2304e-04 - val_loss: 4.1536e-04\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1993e-04 - val_loss: 4.0167e-04\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2593e-04 - val_loss: 3.9754e-04\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.1695e-04 - val_loss: 3.9876e-04\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2350e-04 - val_loss: 3.9864e-04\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.0186e-04 - val_loss: 4.7331e-04\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.9517e-04 - val_loss: 3.8870e-04\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8769e-04 - val_loss: 3.8750e-04\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.1815e-04 - val_loss: 4.1629e-04\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0019e-04 - val_loss: 3.8245e-04\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8224e-04 - val_loss: 4.1911e-04\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8414e-04 - val_loss: 3.8949e-04\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6747e-04 - val_loss: 3.7586e-04\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6700e-04 - val_loss: 3.6886e-04\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.7391e-04 - val_loss: 3.7320e-04\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.9685e-04 - val_loss: 4.8212e-04\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.4122e-04 - val_loss: 4.2121e-04\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5588e-04 - val_loss: 3.9741e-04\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4685e-04 - val_loss: 4.2570e-04\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4986e-04 - val_loss: 4.0418e-04\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4095e-04 - val_loss: 3.5328e-04\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3627e-04 - val_loss: 3.5415e-04\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5341e-04 - val_loss: 3.7533e-04\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8099e-04 - val_loss: 3.5435e-04\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3409e-04 - val_loss: 3.7316e-04\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2534e-04 - val_loss: 3.5643e-04\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2802e-04 - val_loss: 3.4237e-04\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4148e-04 - val_loss: 4.0852e-04\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3634e-04 - val_loss: 5.0361e-04\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4223e-04 - val_loss: 3.5999e-04\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1054e-04 - val_loss: 3.3455e-04\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1271e-04 - val_loss: 3.3358e-04\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1182e-04 - val_loss: 3.6169e-04\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9210e-04 - val_loss: 3.3371e-04\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0967e-04 - val_loss: 3.3751e-04\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0419e-04 - val_loss: 3.4617e-04\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3023e-04 - val_loss: 3.3061e-04\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0441e-04 - val_loss: 3.7363e-04\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9047e-04 - val_loss: 3.4953e-04\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8632e-04 - val_loss: 3.2071e-04\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3398e-04 - val_loss: 3.2080e-04\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8391e-04 - val_loss: 3.4392e-04\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2774e-04 - val_loss: 3.2665e-04\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7878e-04 - val_loss: 3.1588e-04\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6560e-04 - val_loss: 3.3619e-04\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6493e-04 - val_loss: 3.4443e-04\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8518e-04 - val_loss: 3.0810e-04\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6740e-04 - val_loss: 3.0712e-04\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6563e-04 - val_loss: 3.1858e-04\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6401e-04 - val_loss: 5.9180e-04\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0034e-04 - val_loss: 3.0353e-04\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6670e-04 - val_loss: 3.3817e-04\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6689e-04 - val_loss: 3.0528e-04\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6087e-04 - val_loss: 3.2573e-04\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4711e-04 - val_loss: 2.9905e-04\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4767e-04 - val_loss: 3.0698e-04\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5519e-04 - val_loss: 2.9525e-04\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7591e-04 - val_loss: 3.4235e-04\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3487e-04 - val_loss: 3.0073e-04\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4620e-04 - val_loss: 3.0111e-04\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4655e-04 - val_loss: 4.3777e-04\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7906e-04 - val_loss: 2.8843e-04\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2762e-04 - val_loss: 3.0593e-04\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2449e-04 - val_loss: 2.8585e-04\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3008e-04 - val_loss: 3.0684e-04\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3457e-04 - val_loss: 2.8526e-04\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4507e-04 - val_loss: 2.8216e-04\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3338e-04 - val_loss: 2.8029e-04\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2411e-04 - val_loss: 2.9318e-04\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1238e-04 - val_loss: 2.7954e-04\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1394e-04 - val_loss: 2.9270e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2264e-04 - val_loss: 2.7711e-04\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2110e-04 - val_loss: 2.8204e-04\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2723e-04 - val_loss: 3.3373e-04\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0379e-04 - val_loss: 3.3089e-04\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1174e-04 - val_loss: 2.7316e-04\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0610e-04 - val_loss: 2.7149e-04\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2171e-04 - val_loss: 2.8009e-04\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9771e-04 - val_loss: 2.9873e-04\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0255e-04 - val_loss: 2.9942e-04\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1648e-04 - val_loss: 2.6977e-04\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9337e-04 - val_loss: 2.6711e-04\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0251e-04 - val_loss: 2.7931e-04\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9523e-04 - val_loss: 2.7620e-04\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9717e-04 - val_loss: 2.7715e-04\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1562e-04 - val_loss: 2.6193e-04\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9400e-04 - val_loss: 2.6298e-04\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1174e-04 - val_loss: 2.7111e-04\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9877e-04 - val_loss: 2.6480e-04\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8680e-04 - val_loss: 2.6019e-04\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1089e-04 - val_loss: 2.5891e-04\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8539e-04 - val_loss: 3.6658e-04\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2957e-04 - val_loss: 2.6699e-04\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8381e-04 - val_loss: 2.6013e-04\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8122e-04 - val_loss: 2.6687e-04\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7552e-04 - val_loss: 2.5841e-04\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7296e-04 - val_loss: 3.2224e-04\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0143e-04 - val_loss: 2.5149e-04\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8572e-04 - val_loss: 2.8373e-04\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7645e-04 - val_loss: 2.7674e-04\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8357e-04 - val_loss: 2.4973e-04\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7262e-04 - val_loss: 2.5255e-04\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6395e-04 - val_loss: 2.5779e-04\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7461e-04 - val_loss: 2.4743e-04\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7213e-04 - val_loss: 2.4622e-04\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6453e-04 - val_loss: 2.7785e-04\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7822e-04 - val_loss: 2.6397e-04\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7963e-04 - val_loss: 2.5585e-04\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6591e-04 - val_loss: 2.7499e-04\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6634e-04 - val_loss: 2.4391e-04\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7319e-04 - val_loss: 2.7352e-04\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8906e-04 - val_loss: 2.5622e-04\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7990e-04 - val_loss: 2.4278e-04\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7220e-04 - val_loss: 2.6319e-04\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7201e-04 - val_loss: 2.4107e-04\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5275e-04 - val_loss: 2.5763e-04\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6138e-04 - val_loss: 2.5854e-04\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7818e-04 - val_loss: 2.4182e-04\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7377e-04 - val_loss: 2.7437e-04\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6082e-04 - val_loss: 2.4352e-04\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6150e-04 - val_loss: 3.3986e-04\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6420e-04 - val_loss: 2.6480e-04\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6371e-04 - val_loss: 2.3661e-04\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9218e-04 - val_loss: 2.4062e-04\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.5871e-04 - val_loss: 2.3425e-04\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5857e-04 - val_loss: 2.3534e-04\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6162e-04 - val_loss: 2.4347e-04\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4605e-04 - val_loss: 2.4663e-04\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5215e-04 - val_loss: 2.3358e-04\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5575e-04 - val_loss: 2.3466e-04\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5786e-04 - val_loss: 2.3554e-04\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5936e-04 - val_loss: 2.5012e-04\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4502e-04 - val_loss: 2.6878e-04\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4785e-04 - val_loss: 2.4561e-04\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7315e-04 - val_loss: 2.5049e-04\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5412e-04 - val_loss: 2.2976e-04\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5699e-04 - val_loss: 2.3472e-04\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3911e-04 - val_loss: 2.3794e-04\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5842e-04 - val_loss: 2.4014e-04\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4925e-04 - val_loss: 2.3158e-04\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6219e-04 - val_loss: 3.1015e-04\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4154e-04 - val_loss: 2.2645e-04\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3783e-04 - val_loss: 2.2985e-04\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4787e-04 - val_loss: 2.2630e-04\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4436e-04 - val_loss: 2.4026e-04\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4721e-04 - val_loss: 2.4355e-04\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4200e-04 - val_loss: 2.2827e-04\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4348e-04 - val_loss: 2.3863e-04\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4513e-04 - val_loss: 2.2509e-04\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3348e-04 - val_loss: 2.3012e-04\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4094e-04 - val_loss: 2.3278e-04\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4430e-04 - val_loss: 2.4683e-04\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4965e-04 - val_loss: 2.3367e-04\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3612e-04 - val_loss: 2.2276e-04\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5238e-04 - val_loss: 2.5696e-04\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7005e-04 - val_loss: 2.6738e-04\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3945e-04 - val_loss: 2.6066e-04\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4048e-04 - val_loss: 2.3407e-04\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3536e-04 - val_loss: 2.2170e-04\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.2961e-04 - val_loss: 2.2377e-04\n",
      "Thời gian huấn luyện:  21.374991416931152\n",
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_15 (SimpleRNN)   (None, 10, 96)            9408      \n",
      "                                                                 \n",
      " flatten_61 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,369\n",
      "Trainable params: 10,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 2s 29ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 140/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0707\n",
      "Thời gian huấn luyện:  44.458821296691895\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_15 (LSTM)              (None, 10, 96)            37632     \n",
      "                                                                 \n",
      " flatten_62 (Flatten)        (None, 960)               0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 1)                 961       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,593\n",
      "Trainable params: 38,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 2s 16ms/step - loss: 0.0108 - val_loss: 0.0012\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 9.6571e-04\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 9.8306e-04\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 9.0140e-04\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 8.8504e-04\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 8.8431e-04\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 8.6763e-04\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.8772e-04\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.4647e-04\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 7.7141e-04\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 8.1612e-04\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 7.4449e-04\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 7.2018e-04\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 8.9244e-04\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 7.3024e-04\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 7.5157e-04\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.7674e-04\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.7380e-04\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.2445e-04\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 7.3603e-04\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 6.1390e-04\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.9471e-04\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.8453e-04\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.9374e-04\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.4293e-04\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 5.8895e-04\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.8127e-04 - val_loss: 5.2081e-04\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.8222e-04 - val_loss: 5.6738e-04\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.4656e-04 - val_loss: 5.1081e-04\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.2044e-04 - val_loss: 4.9804e-04\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.2183e-04 - val_loss: 5.2252e-04\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.9824e-04 - val_loss: 5.0779e-04\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.9125e-04 - val_loss: 5.3582e-04\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.8216e-04 - val_loss: 4.9283e-04\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.7077e-04 - val_loss: 5.2446e-04\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.6220e-04 - val_loss: 4.9185e-04\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.5513e-04 - val_loss: 4.7887e-04\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.4858e-04 - val_loss: 4.6301e-04\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.4280e-04 - val_loss: 4.8322e-04\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.3032e-04 - val_loss: 4.6570e-04\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.2015e-04 - val_loss: 4.4670e-04\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.4176e-04 - val_loss: 5.0092e-04\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.1814e-04 - val_loss: 4.5378e-04\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.9923e-04 - val_loss: 4.3622e-04\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.0841e-04 - val_loss: 4.7790e-04\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.9261e-04 - val_loss: 4.4041e-04\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.8327e-04 - val_loss: 5.1675e-04\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.9949e-04 - val_loss: 4.2426e-04\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.9741e-04 - val_loss: 4.6183e-04\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.7049e-04 - val_loss: 4.2836e-04\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.0746e-04 - val_loss: 5.0591e-04\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.8968e-04 - val_loss: 4.2023e-04\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.5002e-04 - val_loss: 4.1227e-04\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.4793e-04 - val_loss: 4.1264e-04\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.4395e-04 - val_loss: 4.1367e-04\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.3505e-04 - val_loss: 4.0366e-04\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.4078e-04 - val_loss: 4.9951e-04\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.3516e-04 - val_loss: 4.0431e-04\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.2111e-04 - val_loss: 3.9799e-04\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.1534e-04 - val_loss: 3.9582e-04\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.3120e-04 - val_loss: 3.9196e-04\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.2151e-04 - val_loss: 4.1223e-04\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.9967e-04 - val_loss: 4.3976e-04\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.0356e-04 - val_loss: 3.8558e-04\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.0850e-04 - val_loss: 3.9650e-04\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.0618e-04 - val_loss: 3.8100e-04\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.0654e-04 - val_loss: 4.2097e-04\n",
      "Epoch 68/200\n",
      "21/32 [==================>...........] - ETA: 0s - loss: 7.1060e-04"
     ]
    }
   ],
   "source": [
    "#dataset_ratio, epoch, batch_size, validation\n",
    "information_FFNN_df = []\n",
    "information_RNN_df = []\n",
    "information_LSTM_df = []\n",
    "information_GRU_df = []\n",
    "params = [[0.6, 0.7, 0.8], [50, 100, 200], [32], [0.1, 0.15, 0.2]]\n",
    "# params = [[0.8], [1, 2], [32], [0.15]]\n",
    "params = get_combinations(params)\n",
    "for p in params:\n",
    "    ratio = p[0]\n",
    "    train_size = int(len(ds) * ratio)\n",
    "    test_size = len(ds) - train_size\n",
    "    train, test = ds[0:train_size,:], ds[train_size:len(ds)+1,:]\n",
    "    trainX, trainY, testX, testY = create_train_test_data(train, test, look_back)\n",
    "    \n",
    "    epochs = p[1]\n",
    "    batch_size= p[2]\n",
    "    validation_split= p[3]\n",
    "    \n",
    "    \n",
    "    delta_ffnn, model_ffnn = create_ffnn_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split)\n",
    "    delta_rnn, model_rnn = create_rnn_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split)\n",
    "    delta_lstm, model_lstm = create_lstm_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split)\n",
    "    delta_gru, model_gru =create_gru_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split)\n",
    "    \n",
    "    models_bag = {\n",
    "        \"FFNN\": model_ffnn,\n",
    "        \"RNN\": model_rnn,\n",
    "        \"LSTM\": model_lstm,\n",
    "        \"GRU\": model_gru\n",
    "    }\n",
    "    \n",
    "    accuracy_bag = {}\n",
    "    \n",
    "    for model_name, trained_model in models_bag.items():\n",
    "        if model_name == 'FFNN':\n",
    "            mse, mae, mape, rmse, trainPredict, testPredict = create_accuracy(trained_model, scaler, trainX, trainY, testX, testY)\n",
    "            info = [model_name] + list(p) + [mse, mae] + [delta_ffnn]\n",
    "            information_FFNN_df.append(info)\n",
    "        elif model_name == 'RNN':\n",
    "            mse, mae, mape, rmse, trainPredict, testPredict = create_accuracy(trained_model, scaler, trainX, trainY, testX, testY)\n",
    "            info = [model_name] + list(p) + [mse, mae] + [delta_rnn]\n",
    "            information_RNN_df.append(info)\n",
    "        elif model_name == 'LSTM':\n",
    "            mse, mae, mape, rmse, trainPredict, testPredict = create_accuracy(trained_model, scaler, trainX, trainY, testX, testY)\n",
    "            info = [model_name] + list(p) + [mse, mae] + [delta_lstm]\n",
    "            information_LSTM_df.append(info)\n",
    "        elif model_name == 'GRU':\n",
    "            mse, mae, mape, rmse, trainPredict, testPredict = create_accuracy(trained_model, scaler, trainX, trainY, testX, testY)\n",
    "            info = [model_name] + list(p) + [mse, mae] + [delta_gru]\n",
    "            information_GRU_df.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f886a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "information_FFNN_df = pd.DataFrame(information_FFNN_df)\n",
    "information_FFNN_df.columns = ['Model', 'Training ratio', 'Epochs', 'Batch_size', 'Validation', 'MSE', 'MAE', 'Training Time']\n",
    "\n",
    "information_RNN_df = pd.DataFrame(information_RNN_df)\n",
    "information_RNN_df.columns = ['Model', 'Training ratio', 'Epochs', 'Batch_size', 'Validation', 'MSE', 'MAE', 'Training Time']\n",
    "\n",
    "information_LSTM_df = pd.DataFrame(information_LSTM_df)\n",
    "information_LSTM_df.columns = ['Model', 'Training ratio', 'Epochs', 'Batch_size', 'Validation', 'MSE', 'MAE', 'Training Time']\n",
    "\n",
    "information_GRU_df = pd.DataFrame(information_GRU_df)\n",
    "information_GRU_df.columns = ['Model', 'Training ratio', 'Epochs', 'Batch_size', 'Validation', 'MSE', 'MAE', 'Training Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c830b6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "information_FFNN_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7adadef",
   "metadata": {},
   "outputs": [],
   "source": [
    "information_RNN_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52633989",
   "metadata": {},
   "outputs": [],
   "source": [
    "information_LSTM_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768ef36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "information_GRU_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42f959e",
   "metadata": {},
   "source": [
    "## Best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c148fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_best_params(info_df, ds, look_back, opt):\n",
    "    index = info_df.MSE.argmin()\n",
    "    ratio = info_df.iloc[index, 1]\n",
    "    epochs = info_df.iloc[index, 2]\n",
    "    batch_size = info_df.iloc[index, 3]\n",
    "    validation = info_df.iloc[index, 4]\n",
    "    \n",
    "    train_size = int(len(ds) * ratio)\n",
    "    test_size = len(ds) - train_size\n",
    "    train, test = ds[0:train_size,:], ds[train_size:len(ds)+1,:]\n",
    "    trainX, trainY, testX, testY = create_train_test_data(train, test, look_back)\n",
    "    \n",
    "    return [trainX, trainY, testX, testY], [trainX, trainY, look_back, opt, epochs, batch_size, validation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52707d6e",
   "metadata": {},
   "source": [
    "### Chose the best look_back in (1,3,5,10,20,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cfdfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_bag = [] # Ex: rmse_bag[1] == [0.9, 0.8, 0.9, 0.9] --> FFNN, RNN, LSTM, GRU\n",
    "\n",
    "for look_back in [1, 3, 5, 10, 20, 30]:\n",
    "    FFNN_data, FFNN_params = prepare_best_params(information_FFNN_df,ds, look_back, opt)\n",
    "    FFNN_delta, FFNN_model = create_ffnn_model(*FFNN_params)\n",
    "    FFNN_mse, FFNN_mae, FFNN_mape, FFNN_rmse, FFNN_trainPredict, FFNN_testPredict = create_accuracy(FFNN_model, scaler, *FFNN_data)\n",
    "    \n",
    "    RNN_data, RNN_params = prepare_best_params(information_RNN_df,ds, look_back, opt)\n",
    "    RNN_delta, RNN_model = create_rnn_model(*RNN_params)\n",
    "    RNN_mse, RNN_mae, RNN_mape, RNN_rmse, RNN_trainPredict, RNN_testPredict = create_accuracy(RNN_model, scaler, *RNN_data)\n",
    "    \n",
    "    LSTM_data, LSTM_params = prepare_best_params(information_LSTM_df,ds, look_back, opt)\n",
    "    LSTM_delta, LSTM_model = create_lstm_model(*LSTM_params)\n",
    "    LSTM_mse, LSTM_mae, LSTM_mape, LSTM_rmse, LSTM_trainPredict, LSTM_testPredict = create_accuracy(LSTM_model, scaler, *LSTM_data)\n",
    "    \n",
    "    GRU_data, GRU_params = prepare_best_params(information_GRU_df,ds, look_back, opt)\n",
    "    GRU_delta, GRU_model = create_gru_model(*GRU_params)\n",
    "    GRU_mse, GRU_mae, GRU_mape, GRU_rmse, GRU_trainPredict, GRU_testPredict = create_accuracy(GRU_model, scaler, *GRU_data)\n",
    "    \n",
    "    # Lưu các RMSE\n",
    "    rmse_bag.append([FFNN_rmse, RNN_rmse, LSTM_rmse, GRU_rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7209307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_bag = pd.DataFrame(rmse_bag, index=[1, 3, 5, 10, 20, 30], columns=['FFNN', 'RNN', 'LSTM', 'GRU'])\n",
    "rmse_bag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bc3d79",
   "metadata": {},
   "source": [
    "### So the chosen look_back is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67a4d4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back=30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d18bca3",
   "metadata": {},
   "source": [
    "## Chose the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ceb9782",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_table = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13103ef7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepare_best_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19312\\652349603.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mFFNN_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFFNN_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_best_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minformation_FFNN_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlook_back\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mFFNN_delta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFFNN_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_ffnn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mFFNN_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mFFNN_mse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFFNN_mae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFFNN_mape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFFNN_rmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFFNN_trainPredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFFNN_testPredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFFNN_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mFFNN_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcompare_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mFFNN_mse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFFNN_mae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFFNN_mape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFFNN_rmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFFNN_delta\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prepare_best_params' is not defined"
     ]
    }
   ],
   "source": [
    "FFNN_data, FFNN_params = prepare_best_params(information_FFNN_df,ds, look_back, opt)\n",
    "FFNN_delta, FFNN_model = create_ffnn_model(*FFNN_params)\n",
    "FFNN_mse, FFNN_mae, FFNN_mape, FFNN_rmse, FFNN_trainPredict, FFNN_testPredict = create_accuracy(FFNN_model, scaler, *FFNN_data)\n",
    "compare_table.append([FFNN_mse, FFNN_mae, FFNN_mape, FFNN_rmse, FFNN_delta])\n",
    "    \n",
    "RNN_data, RNN_params = prepare_best_params(information_RNN_df,ds, look_back, opt)\n",
    "RNN_delta, RNN_model = create_rnn_model(*RNN_params)\n",
    "RNN_mse, RNN_mae, RNN_mape, RNN_rmse, RNN_trainPredict, RNN_testPredict = create_accuracy(RNN_model, scaler, *RNN_data)\n",
    "compare_table.append([RNN_mse, RNN_mae, RNN_mape, RNN_rmse, RNN_delta])\n",
    "    \n",
    "LSTM_data, LSTM_params = prepare_best_params(information_LSTM_df,ds, look_back, opt)\n",
    "LSTM_delta, LSTM_model = create_lstm_model(*LSTM_params)\n",
    "LSTM_mse, LSTM_mae, LSTM_mape, LSTM_rmse, LSTM_trainPredict, LSTM_testPredict = create_accuracy(LSTM_model, scaler, *LSTM_data)\n",
    "compare_table.append([LSTM_mse, LSTM_mae, LSTM_mape, LSTM_rmse, LSTM_delta])\n",
    "    \n",
    "GRU_data, GRU_params = prepare_best_params(information_GRU_df,ds, look_back, opt)\n",
    "GRU_delta, GRU_model = create_gru_model(*GRU_params)\n",
    "GRU_mse, GRU_mae, GRU_mape, GRU_rmse, GRU_trainPredict, GRU_testPredict = create_accuracy(GRU_model, scaler, *GRU_data)\n",
    "compare_table.append([GRU_mse, GRU_mae, GRU_mape, GRU_rmse, GRU_delta])\n",
    "\n",
    "#Save models\n",
    "FFNN_model.save('ffnn_model.h5')\n",
    "RNN_model.save('rnn_model.h5')\n",
    "LSTM_model.save('lstm_model.h5')\n",
    "GRU_model.save('gru_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "911fde1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FFNN</th>\n",
       "      <td>20.554</td>\n",
       "      <td>2.599</td>\n",
       "      <td>1.891</td>\n",
       "      <td>4.534</td>\n",
       "      <td>21.849180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RNN</th>\n",
       "      <td>12.106</td>\n",
       "      <td>2.114</td>\n",
       "      <td>1.637</td>\n",
       "      <td>3.479</td>\n",
       "      <td>69.440982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>20.577</td>\n",
       "      <td>2.701</td>\n",
       "      <td>2.033</td>\n",
       "      <td>4.536</td>\n",
       "      <td>172.268095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU</th>\n",
       "      <td>13.741</td>\n",
       "      <td>2.275</td>\n",
       "      <td>1.784</td>\n",
       "      <td>3.707</td>\n",
       "      <td>189.129154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MSE    MAE   MAPE   RMSE  Training Time\n",
       "FFNN  20.554  2.599  1.891  4.534      21.849180\n",
       "RNN   12.106  2.114  1.637  3.479      69.440982\n",
       "LSTM  20.577  2.701  2.033  4.536     172.268095\n",
       "GRU   13.741  2.275  1.784  3.707     189.129154"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_table = pd.DataFrame(compare_table, index=[\"FFNN\", \"RNN\", \"LSTM\", \"GRU\"], columns=[\"MSE\", \"MAE\", \"MAPE\", \"RMSE\", \"Training Time\"])\n",
    "compare_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f283c24",
   "metadata": {},
   "source": [
    "### So best params are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18ff8be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "look_back, opt, epochs, batch_size, validation\n",
      "FFNN [30, <keras.optimizers.optimizer_v2.adam.Adam object at 0x00000198C4687A30>, 200, 32, 0.2]\n",
      "RNN [30, <keras.optimizers.optimizer_v2.adam.Adam object at 0x00000198C4687A30>, 200, 32, 0.15]\n",
      "LSTM [30, <keras.optimizers.optimizer_v2.adam.Adam object at 0x00000198C4687A30>, 200, 32, 0.2]\n",
      "GRU [30, <keras.optimizers.optimizer_v2.adam.Adam object at 0x00000198C4687A30>, 200, 32, 0.1]\n"
     ]
    }
   ],
   "source": [
    "print(\"look_back, opt, epochs, batch_size, validation\")\n",
    "print(\"FFNN\", FFNN_params[2:])\n",
    "print(\"RNN\", RNN_params[2:])\n",
    "print(\"LSTM\", LSTM_params[2:])\n",
    "print(\"GRU\", GRU_params[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439069e2",
   "metadata": {},
   "source": [
    "## So the best model in this case is RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da7f1900",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RNN_model\n",
    "trainPredict = RNN_trainPredict\n",
    "testPredict = RNN_testPredict\n",
    "model_name = \"RNN\"\n",
    "mse, mae, mape, rmse = LSTM_mse, LSTM_mae, LSTM_mape, LSTM_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e64dbe3",
   "metadata": {},
   "source": [
    "## Trực quan hóa kết quả dự đoán của best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51247994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1430x770 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RNN</th>\n",
       "      <td>20.577</td>\n",
       "      <td>2.701</td>\n",
       "      <td>2.033</td>\n",
       "      <td>4.536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MSE    MAE   MAPE   RMSE\n",
       "RNN  20.577  2.701  2.033  4.536"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_plot(ds, trainPredict, testPredict, scaler, look_back, model_name, stock_name)\n",
    "pd.DataFrame([[mse, mae, mape, rmse]], index=[model_name], columns=[\"MSE\", \"MAE\", \"MAPE\", \"RMSE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0264578",
   "metadata": {},
   "source": [
    "## Remake model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1945ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_best_params(info_df, ds, look_back, opt):\n",
    "    index = info_df.MSE.argmin()\n",
    "    ratio = info_df.iloc[index, 1]\n",
    "    epochs = info_df.iloc[index, 2]\n",
    "    batch_size = info_df.iloc[index, 3]\n",
    "    validation = info_df.iloc[index, 4]\n",
    "    \n",
    "    train_size = int(len(ds) * ratio)\n",
    "    test_size = len(ds) - train_size\n",
    "    train, test = ds[0:train_size,:], ds[train_size:len(ds)+1,:]\n",
    "    trainX, trainY, testX, testY = create_train_test_data(train, test, look_back)\n",
    "    \n",
    "    return [trainX, trainY, testX, testY], [trainX, trainY, look_back, opt, epochs, batch_size, validation]\n",
    "\n",
    "look_back = 30\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "epochs = 200\n",
    "batch_size = 32 \n",
    "validation_split = 0.2\n",
    "\n",
    "train_size = int(len(ds) * ratio)\n",
    "    test_size = len(ds) - train_size\n",
    "    train, test = ds[0:train_size,:], ds[train_size:len(ds)+1,:]\n",
    "    trainX, trainY, testX, testY = create_train_test_data(train, test, look_back)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
