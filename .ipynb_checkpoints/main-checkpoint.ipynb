{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d05ab8a",
   "metadata": {},
   "source": [
    "# Load thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd15c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from tabulate import tabulate\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import SimpleRNN\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import pandas_datareader.data as web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62625b21",
   "metadata": {},
   "source": [
    "# Chuẩn bị dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b91ce7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_name = \"REMX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc88cf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = web.DataReader(stock_name,data_source=\"yahoo\",start=\"01/01/2005\",end=\"01/01/2019\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c874f93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2057.000000</td>\n",
       "      <td>2057.000000</td>\n",
       "      <td>2057.000000</td>\n",
       "      <td>2057.000000</td>\n",
       "      <td>2057.000000</td>\n",
       "      <td>2057.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>118.529913</td>\n",
       "      <td>116.226913</td>\n",
       "      <td>117.510481</td>\n",
       "      <td>117.314628</td>\n",
       "      <td>16896.980068</td>\n",
       "      <td>85.298984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>75.889912</td>\n",
       "      <td>73.916038</td>\n",
       "      <td>75.124950</td>\n",
       "      <td>74.875467</td>\n",
       "      <td>24716.632762</td>\n",
       "      <td>49.075820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>34.169998</td>\n",
       "      <td>33.209999</td>\n",
       "      <td>33.480000</td>\n",
       "      <td>34.080002</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>26.701105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>57.570000</td>\n",
       "      <td>56.520000</td>\n",
       "      <td>57.029999</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>3933.000000</td>\n",
       "      <td>45.561840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>89.970001</td>\n",
       "      <td>88.500000</td>\n",
       "      <td>89.099998</td>\n",
       "      <td>89.370003</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>72.631874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>154.800003</td>\n",
       "      <td>152.399994</td>\n",
       "      <td>153.600006</td>\n",
       "      <td>153.479996</td>\n",
       "      <td>18667.000000</td>\n",
       "      <td>110.656998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>346.920013</td>\n",
       "      <td>336.839996</td>\n",
       "      <td>342.359985</td>\n",
       "      <td>342.119995</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>231.411667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              High          Low         Open        Close         Volume  \\\n",
       "count  2057.000000  2057.000000  2057.000000  2057.000000    2057.000000   \n",
       "mean    118.529913   116.226913   117.510481   117.314628   16896.980068   \n",
       "std      75.889912    73.916038    75.124950    74.875467   24716.632762   \n",
       "min      34.169998    33.209999    33.480000    34.080002     333.000000   \n",
       "25%      57.570000    56.520000    57.029999    57.000000    3933.000000   \n",
       "50%      89.970001    88.500000    89.099998    89.370003    8000.000000   \n",
       "75%     154.800003   152.399994   153.600006   153.479996   18667.000000   \n",
       "max     346.920013   336.839996   342.359985   342.119995  250000.000000   \n",
       "\n",
       "         Adj Close  \n",
       "count  2057.000000  \n",
       "mean     85.298984  \n",
       "std      49.075820  \n",
       "min      26.701105  \n",
       "25%      45.561840  \n",
       "50%      72.631874  \n",
       "75%     110.656998  \n",
       "max     231.411667  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27453666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2057, 1)                  Close\n",
      "Date                  \n",
      "2010-10-28  234.119995\n",
      "2010-10-29  247.320007\n",
      "2010-11-01  246.000000\n",
      "2010-11-02  245.399994\n",
      "2010-11-03  243.600006\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = raw_data.dropna()\n",
    "df = df[['Close']]\n",
    "first_price = df.Close.iloc[0]\n",
    "print(df.shape, df.head())\n",
    "\n",
    "df.Close.plot()\n",
    "def create_ds(ds, look_back):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(ds)-look_back-1): \n",
    "        data = ds[i:(i+look_back), 0]      \n",
    "        dataX.append(data)\n",
    "        dataY.append(ds[i + look_back, 0]) \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "ds = df.values\n",
    "ds = ds.astype('float32')\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "ds = scaler.fit_transform(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90a229de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Chia tập train và tập test theo ty lệ 0.85, 0.15\n",
    "# train_size = int(len(ds) * 0.85)\n",
    "# test_size = len(ds) - train_size\n",
    "# train, test = ds[0:train_size,:], ds[train_size:len(ds)+1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560617e4",
   "metadata": {},
   "source": [
    "# outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6323037",
   "metadata": {},
   "source": [
    "#### 1:\n",
    "#### Đầu vào: train, test, look_back, opt, epochs, batch_size, validation_split\n",
    "#### Đầu ra: Trained model\n",
    "#### 2:\n",
    "#### Đầu vào: 4 trained models\n",
    "#### Đầu ra: 4 plots + bảng so sánh độ chính xác"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865ea794",
   "metadata": {},
   "source": [
    "# Xây dựng models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1f28081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_data(train, test, look_back):\n",
    "    trainX, trainY = create_ds(train, look_back)\n",
    "    testX, testY = create_ds(test, look_back)\n",
    "\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "    testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21a7835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainX, trainY, testX, testY = create_train_test_data(train, test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c4a1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_nodes = math.sqrt(len(trainX) * 3) + 2 * math.sqrt(len(trainX) / 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b7e608",
   "metadata": {},
   "source": [
    "## FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2713269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ffnn_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split):\n",
    "    # create model\n",
    "    hidden_nodes = int(math.sqrt(len(trainX) * 3) + 2 * math.sqrt(len(trainX) / 3))\n",
    "    model_ffnn = Sequential()\n",
    "    model_ffnn.add(Dense(hidden_nodes, input_shape = (trainX.shape[1],trainX.shape[2]), activation = 'relu', kernel_initializer='uniform'))\n",
    "#     model_ffnn.add(Dropout(0.4))\n",
    "#     model_ffnn.add(Dense(400, activation = 'relu', kernel_initializer='uniform' ))\n",
    "#     model_ffnn.add(Dropout(0.3))\n",
    "#     model_ffnn.add(Dense(150, activation = 'relu' ))\n",
    "#     model_ffnn.add(Dropout(0.3))\n",
    "#     model_ffnn.add(Dense(100, activation = 'hard_sigmoid' ))\n",
    "#     model_ffnn.add(Dropout(0.2))\n",
    "#     model_ffnn.add(Dense(50, activation = 'relu' ))\n",
    "#     model_ffnn.add(Dropout(0.1))\n",
    "#     model_ffnn.add(Dense(10, activation = 'relu' ))\n",
    "    model_ffnn.add(Flatten())\n",
    "    model_ffnn.add(Dense(1, activation = 'relu'))\n",
    "    # train created model\n",
    "    model_ffnn.compile(optimizer= opt, loss = \"mean_squared_error\")\n",
    "    start = time.time()\n",
    "    history = model_ffnn.fit(trainX, trainY, epochs = epochs , batch_size= batch_size, shuffle=True ,validation_split = validation_split)\n",
    "    print('Thời gian huấn luyện: ', time.time() - start)\n",
    "    model_ffnn.summary()\n",
    "    delta = time.time() - start\n",
    "    return delta, model_ffnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb585959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6feb7f00",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3b056c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split):\n",
    "    # create model\n",
    "    hidden_nodes = int(math.sqrt(len(trainX) * 3) + 2 * math.sqrt(len(trainX) / 3))\n",
    "    model_rnn = Sequential()\n",
    "    model_rnn.add(SimpleRNN(units = hidden_nodes, activation = \"tanh\", return_sequences = True, input_shape = (look_back,1)))\n",
    "#     model_rnn.add(Dropout(0.3))\n",
    "#     model_rnn.add(SimpleRNN(units = 50, activation = \"tanh\", return_sequences = True))\n",
    "#     model_rnn.add(Dropout(0.2))\n",
    "#     model_rnn.add(SimpleRNN(units = 50, activation = \"tanh\", return_sequences = True))\n",
    "#     model_rnn.add(Dropout(0.1))\n",
    "#     model_rnn.add(SimpleRNN(units = 50))\n",
    "    model_rnn.add(Flatten())\n",
    "    model_rnn.add(Dense(units = 1))\n",
    "    # train created model\n",
    "    model_rnn.compile(optimizer= opt, loss = \"mean_squared_error\")\n",
    "    start = time.time()\n",
    "    history = model_rnn.fit(trainX, trainY, epochs = epochs , batch_size= batch_size, shuffle=True ,validation_split = validation_split)\n",
    "    print('Thời gian huấn luyện: ', time.time() - start)\n",
    "    model_rnn.summary()\n",
    "    delta = time.time() - start\n",
    "    return delta, model_rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdadcde",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c306e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split):\n",
    "    # create model\n",
    "    hidden_nodes = int(math.sqrt(len(trainX) * 3) + 2 * math.sqrt(len(trainX) / 3))\n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(LSTM(hidden_nodes, activation = 'tanh', input_shape=(look_back,1),return_sequences=True))\n",
    "    model_lstm.add(Flatten())\n",
    "    model_lstm.add(Dense(1, activation = 'relu'))\n",
    "    # train created model\n",
    "    model_lstm.compile(optimizer= opt, loss = \"mean_squared_error\")\n",
    "    start = time.time()\n",
    "    history = model_lstm.fit(trainX, trainY, epochs = epochs , batch_size= batch_size, shuffle=True ,validation_split = validation_split)\n",
    "    print('Thời gian huấn luyện: ', time.time() - start)\n",
    "    model_lstm.summary()\n",
    "    delta = time.time() - start\n",
    "    return delta, model_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b222798",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fbf25ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gru_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split):\n",
    "    # create model\n",
    "    hidden_nodes = int(math.sqrt(len(trainX) * 3) + 2 * math.sqrt(len(trainX) / 3))\n",
    "    model_gru = Sequential()\n",
    "    model_gru.add(GRU(hidden_nodes, activation='tanh', recurrent_activation='sigmoid', input_shape=(look_back,1), return_sequences=True)) \n",
    "    model_gru.add(Flatten())\n",
    "    model_gru.add(Dense(1, activation = 'relu'))\n",
    "    # train created model\n",
    "    model_gru.compile(optimizer= opt, loss = \"mean_squared_error\")\n",
    "    start = time.time()\n",
    "    history = model_gru.fit(trainX, trainY, epochs = epochs , batch_size= batch_size, shuffle=True ,validation_split = validation_split)\n",
    "    print('Thời gian huấn luyện: ', time.time() - start)\n",
    "    model_gru.summary()\n",
    "    delta = time.time() - start\n",
    "    return delta, model_gru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0acfa5",
   "metadata": {},
   "source": [
    "# Trực quan hóa, so sánh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb06f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def calculate_performance(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    return round(mse, 3), round(mae, 3), round(mape, 3), round(rmse, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a2452ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_accuracy(trained_model, scaler, trainX, trainY, testX, testY):\n",
    "    trainPredict = trained_model.predict(trainX)\n",
    "    testPredict = trained_model.predict(testX)\n",
    "\n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform([trainY])\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY = scaler.inverse_transform([testY])\n",
    "\n",
    "    mse, mae, mape, rmse = calculate_performance(trainY[0],trainPredict[:, 0])\n",
    "    return mse, mae, mape, rmse, trainPredict, testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9eefe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(ds, trainPredict, testPredict, scaler, look_back, model_name, stock_name):\n",
    "    trainPredictPlot = np.empty_like(ds)\n",
    "    trainPredictPlot[:, :] = np.nan\n",
    "    trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "    testPredictPlot = np.empty_like(ds)\n",
    "    testPredictPlot[:, :] = np.nan\n",
    "    testPredictPlot[len(trainPredict)+(look_back*2)+1:len(ds)-1, :] = testPredict\n",
    "\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure(figsize=(13,7), dpi=110)\n",
    "    plt.grid(color='grey', linestyle='dashed')\n",
    "    plt.xlabel(\"{0} result\".format(model_name))\n",
    "    plt.ylabel('{0}'.format(stock_name),rotation=90)\n",
    "    plt.plot(scaler.inverse_transform(ds), label = 'Actual Closing Prices', linewidth = 1.2, color = 'c')\n",
    "    plt.plot(trainPredictPlot, label = 'A.I. Train Data Price Predictions_After fit', linewidth = 0.9, color = 'k')\n",
    "    plt.plot(testPredictPlot, label = 'A.I. Test Data Price Predictions', linewidth = 0.9, color = 'r')\n",
    "    legend = plt.legend(fontsize = 12,frameon = True)\n",
    "    legend.get_frame().set_edgecolor('b')\n",
    "    legend.get_frame().set_linewidth(0.4)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116dbf09",
   "metadata": {},
   "source": [
    "# Thực nghiệm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6f7494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 10\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "import itertools\n",
    "def get_combinations(parameters):\n",
    "    return list(itertools.product(*parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d74ce315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 36/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 37/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 38/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 39/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 40/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 41/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 42/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 43/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 44/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 45/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 46/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 47/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 48/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 49/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 50/50\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Thời gian huấn luyện:  4.122392177581787\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10, 100)           200       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,201\n",
      "Trainable params: 1,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "35/35 [==============================] - 1s 8ms/step - loss: 0.0123 - val_loss: 3.4702e-04\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 2.5772e-04\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 8.4635e-04 - val_loss: 2.7429e-04\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 8.1854e-04 - val_loss: 2.0876e-04\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 7.6355e-04 - val_loss: 1.6907e-04\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 7.7206e-04 - val_loss: 1.1523e-04\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 7.0740e-04 - val_loss: 1.1466e-04\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6.7378e-04 - val_loss: 1.2096e-04\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6.5477e-04 - val_loss: 8.5096e-05\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6.1649e-04 - val_loss: 1.0113e-04\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6.2531e-04 - val_loss: 9.8975e-05\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6.2065e-04 - val_loss: 6.8097e-05\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.9162e-04 - val_loss: 6.6481e-05\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.8707e-04 - val_loss: 5.6622e-05\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.7080e-04 - val_loss: 5.7032e-05\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.4995e-04 - val_loss: 6.4993e-05\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.3485e-04 - val_loss: 5.5873e-05\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.2217e-04 - val_loss: 5.8122e-05\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.4469e-04 - val_loss: 5.6024e-05\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.0977e-04 - val_loss: 5.9074e-05\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.1431e-04 - val_loss: 5.3366e-05\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.0174e-04 - val_loss: 7.5936e-05\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 5.4061e-04 - val_loss: 5.4420e-05\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.9315e-04 - val_loss: 7.0361e-05\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.0141e-04 - val_loss: 4.9365e-05\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.2847e-04 - val_loss: 5.9379e-05\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.6906e-04 - val_loss: 5.2392e-05\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.6054e-04 - val_loss: 7.8151e-05\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.6846e-04 - val_loss: 4.7479e-05\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.8332e-04 - val_loss: 6.8689e-05\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.8598e-04 - val_loss: 8.5308e-05\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.5461e-04 - val_loss: 4.6477e-05\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.5575e-04 - val_loss: 5.1163e-05\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.3948e-04 - val_loss: 4.5050e-05\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.5629e-04 - val_loss: 4.8764e-05\n",
      "Epoch 36/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.3979e-04 - val_loss: 4.4056e-05\n",
      "Epoch 37/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.6195e-04 - val_loss: 4.7285e-05\n",
      "Epoch 38/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.3961e-04 - val_loss: 4.9541e-05\n",
      "Epoch 39/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.2734e-04 - val_loss: 4.8366e-05\n",
      "Epoch 40/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.4042e-04 - val_loss: 4.5656e-05\n",
      "Epoch 41/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.2031e-04 - val_loss: 4.2899e-05\n",
      "Epoch 42/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.2632e-04 - val_loss: 5.1480e-05\n",
      "Epoch 43/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.1765e-04 - val_loss: 4.1618e-05\n",
      "Epoch 44/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.0118e-04 - val_loss: 4.6559e-05\n",
      "Epoch 45/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.1036e-04 - val_loss: 4.7866e-05\n",
      "Epoch 46/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.9604e-04 - val_loss: 5.0484e-05\n",
      "Epoch 47/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.0589e-04 - val_loss: 4.5992e-05\n",
      "Epoch 48/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.0513e-04 - val_loss: 4.0788e-05\n",
      "Epoch 49/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.4284e-04 - val_loss: 6.0051e-05\n",
      "Epoch 50/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.7886e-04 - val_loss: 3.8675e-05\n",
      "Thời gian huấn luyện:  6.326710939407349\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 10, 100)           10200     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,201\n",
      "Trainable params: 11,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "35/35 [==============================] - 2s 17ms/step - loss: 0.0438 - val_loss: 0.0018\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 6.2199e-04\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.7527e-04 - val_loss: 4.6143e-04\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.6815e-04 - val_loss: 2.6032e-04\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.5683e-04 - val_loss: 2.3829e-04\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.6042e-04 - val_loss: 2.4370e-04\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.5485e-04 - val_loss: 2.1117e-04\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.5729e-04 - val_loss: 2.2673e-04\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.5453e-04 - val_loss: 2.6664e-04\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.5548e-04 - val_loss: 3.1967e-04\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.5258e-04 - val_loss: 3.1808e-04\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.4400e-04 - val_loss: 2.3417e-04\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.3366e-04 - val_loss: 2.4979e-04\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.5896e-04 - val_loss: 1.9660e-04\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.3648e-04 - val_loss: 1.7981e-04\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.3442e-04 - val_loss: 1.7873e-04\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.3900e-04 - val_loss: 2.0356e-04\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.2788e-04 - val_loss: 1.6966e-04\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.5363e-04 - val_loss: 2.1765e-04\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.2018e-04 - val_loss: 1.8247e-04\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.2416e-04 - val_loss: 1.8463e-04\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.2697e-04 - val_loss: 1.8434e-04\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.1646e-04 - val_loss: 2.0201e-04\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.1548e-04 - val_loss: 2.0066e-04\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.1408e-04 - val_loss: 1.4680e-04\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.2619e-04 - val_loss: 1.9749e-04\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.0751e-04 - val_loss: 1.5853e-04\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.0908e-04 - val_loss: 1.6062e-04\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.0565e-04 - val_loss: 1.5391e-04\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.0325e-04 - val_loss: 1.7702e-04\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.1600e-04 - val_loss: 2.2475e-04\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.2435e-04 - val_loss: 1.4295e-04\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 7.9971e-04 - val_loss: 1.5830e-04\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 7.9543e-04 - val_loss: 1.3099e-04\n",
      "Epoch 36/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 7.9359e-04 - val_loss: 1.5721e-04\n",
      "Epoch 37/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.0361e-04 - val_loss: 1.6216e-04\n",
      "Epoch 38/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.0295e-04 - val_loss: 1.6658e-04\n",
      "Epoch 39/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 7.9305e-04 - val_loss: 1.3294e-04\n",
      "Epoch 40/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 7.8952e-04 - val_loss: 1.4288e-04\n",
      "Epoch 41/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 7.8306e-04 - val_loss: 1.1646e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 7.9909e-04 - val_loss: 1.3487e-04\n",
      "Epoch 43/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 7.8341e-04 - val_loss: 1.6181e-04\n",
      "Epoch 44/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 7.8795e-04 - val_loss: 1.9490e-04\n",
      "Epoch 45/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 7.7901e-04 - val_loss: 1.3879e-04\n",
      "Epoch 46/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.7132e-04 - val_loss: 1.5090e-04\n",
      "Epoch 47/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 7.6541e-04 - val_loss: 1.4330e-04\n",
      "Epoch 48/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.6994e-04 - val_loss: 1.5483e-04\n",
      "Epoch 49/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.6324e-04 - val_loss: 1.4714e-04\n",
      "Epoch 50/50\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.6122e-04 - val_loss: 1.6892e-04\n",
      "Thời gian huấn luyện:  12.854628324508667\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 10, 100)           40800     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,801\n",
      "Trainable params: 41,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "35/35 [==============================] - 2s 15ms/step - loss: 0.0363 - val_loss: 0.0010\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 5.7465e-04\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 8.1973e-04 - val_loss: 1.7106e-04\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 7.0767e-04 - val_loss: 9.4806e-05\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.9443e-04 - val_loss: 7.9889e-05\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.9709e-04 - val_loss: 8.1621e-05\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.8142e-04 - val_loss: 7.7910e-05\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.8570e-04 - val_loss: 8.1352e-05\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.7737e-04 - val_loss: 9.0053e-05\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.8510e-04 - val_loss: 7.8448e-05\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.7933e-04 - val_loss: 8.1999e-05\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.6649e-04 - val_loss: 9.2258e-05\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.6633e-04 - val_loss: 1.0291e-04\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.6324e-04 - val_loss: 8.4536e-05\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.5575e-04 - val_loss: 8.6653e-05\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.5392e-04 - val_loss: 7.5472e-05\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.4964e-04 - val_loss: 9.3787e-05\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.4926e-04 - val_loss: 7.5497e-05\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.4595e-04 - val_loss: 7.1446e-05\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.6359e-04 - val_loss: 1.0119e-04\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.4960e-04 - val_loss: 7.4683e-05\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.3407e-04 - val_loss: 8.5550e-05\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.2822e-04 - val_loss: 8.1409e-05\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.2942e-04 - val_loss: 7.5851e-05\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.2033e-04 - val_loss: 6.9514e-05\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.3186e-04 - val_loss: 7.0447e-05\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.2596e-04 - val_loss: 7.3108e-05\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.1999e-04 - val_loss: 7.8804e-05\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.0791e-04 - val_loss: 6.7623e-05\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.1630e-04 - val_loss: 9.0565e-05\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.0156e-04 - val_loss: 8.1221e-05\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.0435e-04 - val_loss: 7.4580e-05\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.0949e-04 - val_loss: 6.8999e-05\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 5.9643e-04 - val_loss: 7.6190e-05\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 5.8898e-04 - val_loss: 7.8507e-05\n",
      "Epoch 36/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 5.8516e-04 - val_loss: 6.4704e-05\n",
      "Epoch 37/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 6.0905e-04 - val_loss: 8.3926e-05\n",
      "Epoch 38/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 5.9485e-04 - val_loss: 7.5627e-05\n",
      "Epoch 39/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 5.7601e-04 - val_loss: 7.3729e-05\n",
      "Epoch 40/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 5.7159e-04 - val_loss: 6.9479e-05\n",
      "Epoch 41/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 5.6622e-04 - val_loss: 7.6631e-05\n",
      "Epoch 42/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 5.7269e-04 - val_loss: 6.2844e-05\n",
      "Epoch 43/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 5.6899e-04 - val_loss: 7.8428e-05\n",
      "Epoch 44/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 5.5601e-04 - val_loss: 6.3245e-05\n",
      "Epoch 45/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 5.5606e-04 - val_loss: 8.2610e-05\n",
      "Epoch 46/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 5.5225e-04 - val_loss: 6.8851e-05\n",
      "Epoch 47/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.4999e-04 - val_loss: 6.0808e-05\n",
      "Epoch 48/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.6129e-04 - val_loss: 1.0777e-04\n",
      "Epoch 49/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 5.5898e-04 - val_loss: 6.0758e-05\n",
      "Epoch 50/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 5.3407e-04 - val_loss: 6.5333e-05\n",
      "Thời gian huấn luyện:  11.882563829421997\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 10, 100)           30900     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,901\n",
      "Trainable params: 31,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "39/39 [==============================] - 0s 895us/step\n",
      "26/26 [==============================] - 0s 880us/step\n",
      "39/39 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 1ms/step\n",
      "39/39 [==============================] - 1s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Thời gian huấn luyện:  3.5652687549591064\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 10, 100)           200       \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,201\n",
      "Trainable params: 1,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 1s 8ms/step - loss: 0.0068 - val_loss: 3.1498e-04\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 5.0493e-04\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 3.9504e-04\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 9.3228e-04 - val_loss: 2.8427e-04\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.9601e-04 - val_loss: 1.7793e-04\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.9433e-04 - val_loss: 9.7357e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.0397e-04 - val_loss: 1.2944e-04\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 7.4608e-04 - val_loss: 8.3993e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 7.0935e-04 - val_loss: 1.2130e-04\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.8587e-04 - val_loss: 8.9972e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.9652e-04 - val_loss: 5.5520e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 7.1652e-04 - val_loss: 6.3555e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.5988e-04 - val_loss: 8.0510e-05\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.5040e-04 - val_loss: 5.5819e-05\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 5.8733e-04 - val_loss: 4.7270e-05\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.9746e-04 - val_loss: 5.1885e-05\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 7.2274e-04 - val_loss: 5.4290e-05\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.6778e-04 - val_loss: 5.0645e-05\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 5.7876e-04 - val_loss: 4.6497e-05\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.4586e-04 - val_loss: 4.5847e-05\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 3ms/step - loss: 5.5313e-04 - val_loss: 4.7280e-05\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.3709e-04 - val_loss: 4.4093e-05\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.2584e-04 - val_loss: 4.3156e-05\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.2068e-04 - val_loss: 4.1522e-05\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.2667e-04 - val_loss: 5.4233e-05\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.2203e-04 - val_loss: 4.7519e-05\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.5823e-04 - val_loss: 4.2065e-05\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.0308e-04 - val_loss: 4.3155e-05\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.8222e-04 - val_loss: 3.9706e-05\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.0667e-04 - val_loss: 4.0792e-05\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.5834e-04 - val_loss: 3.8906e-05\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.0631e-04 - val_loss: 3.9056e-05\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.4974e-04 - val_loss: 3.8592e-05\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.5470e-04 - val_loss: 3.7962e-05\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.4875e-04 - val_loss: 3.9410e-05\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.4909e-04 - val_loss: 4.2506e-05\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.2829e-04 - val_loss: 4.5861e-05\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.7813e-04 - val_loss: 6.1484e-05\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.6767e-04 - val_loss: 3.9208e-05\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.5557e-04 - val_loss: 4.0063e-05\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.9741e-04 - val_loss: 3.5106e-05\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.6172e-04 - val_loss: 4.2655e-05\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.4546e-04 - val_loss: 4.2850e-05\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.0957e-04 - val_loss: 3.5784e-05\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.0834e-04 - val_loss: 3.4795e-05\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.1981e-04 - val_loss: 3.5969e-05\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.2202e-04 - val_loss: 3.7664e-05\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.1390e-04 - val_loss: 3.9979e-05\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.0410e-04 - val_loss: 4.3898e-05\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.1809e-04 - val_loss: 3.2494e-05\n",
      "Thời gian huấn luyện:  5.9258575439453125\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_1 (SimpleRNN)    (None, 10, 100)           10200     \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,201\n",
      "Trainable params: 11,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 2s 16ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Thời gian huấn luyện:  12.018875360488892\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 10, 100)           40800     \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,801\n",
      "Trainable params: 41,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 2s 15ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Thời gian huấn luyện:  11.644776821136475\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_1 (GRU)                 (None, 10, 100)           30900     \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,901\n",
      "Trainable params: 31,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "39/39 [==============================] - 0s 869us/step\n",
      "26/26 [==============================] - 0s 880us/step\n",
      "39/39 [==============================] - 0s 1ms/step\n",
      "26/26 [==============================] - 0s 1ms/step\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 37/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 40/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 41/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 44/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 48/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Thời gian huấn luyện:  3.5465149879455566\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 10, 100)           200       \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,201\n",
      "Trainable params: 1,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "31/31 [==============================] - 1s 8ms/step - loss: 0.0125 - val_loss: 2.4962e-04\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 4.5039e-04\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 3.2305e-04\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 2.2918e-04\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 4.4173e-04\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 2.2519e-04\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 9.7323e-04 - val_loss: 2.4386e-04\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 9.4303e-04 - val_loss: 1.4613e-04\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 9.7450e-04 - val_loss: 8.7228e-05\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 9.1996e-04 - val_loss: 1.1382e-04\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 8.2700e-04 - val_loss: 6.6807e-05\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 8.5429e-04 - val_loss: 6.2015e-05\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 8.0989e-04 - val_loss: 5.7674e-05\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.9066e-04 - val_loss: 5.4224e-05\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.6874e-04 - val_loss: 6.3611e-05\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.3954e-04 - val_loss: 5.4812e-05\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.2766e-04 - val_loss: 6.0025e-05\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.7282e-04 - val_loss: 6.1636e-05\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 8.0386e-04 - val_loss: 5.4393e-05\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.7647e-04 - val_loss: 4.9147e-05\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.8801e-04 - val_loss: 4.8290e-05\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.2622e-04 - val_loss: 4.5319e-05\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.5665e-04 - val_loss: 4.5160e-05\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.5103e-04 - val_loss: 6.6762e-05\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.1311e-04 - val_loss: 4.2910e-05\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 3ms/step - loss: 6.2722e-04 - val_loss: 6.3696e-05\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.3260e-04 - val_loss: 5.5331e-05\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.0356e-04 - val_loss: 4.8600e-05\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.0863e-04 - val_loss: 6.2937e-05\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.6278e-04 - val_loss: 5.7333e-05\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.1596e-04 - val_loss: 1.0994e-04\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.7851e-04 - val_loss: 5.1431e-05\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.7192e-04 - val_loss: 4.9975e-05\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.7465e-04 - val_loss: 4.0260e-05\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.5689e-04 - val_loss: 4.7237e-05\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.7042e-04 - val_loss: 5.1110e-05\n",
      "Epoch 37/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.3833e-04 - val_loss: 5.1483e-05\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.2262e-04 - val_loss: 9.2668e-05\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.7131e-04 - val_loss: 7.0230e-05\n",
      "Epoch 40/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.6757e-04 - val_loss: 7.6005e-05\n",
      "Epoch 41/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.2856e-04 - val_loss: 5.3632e-05\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.4950e-04 - val_loss: 4.1717e-05\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.1452e-04 - val_loss: 5.2262e-05\n",
      "Epoch 44/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.9992e-04 - val_loss: 4.4789e-05\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.0423e-04 - val_loss: 5.2286e-05\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.9292e-04 - val_loss: 5.8280e-05\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.8359e-04 - val_loss: 5.1888e-05\n",
      "Epoch 48/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.0280e-04 - val_loss: 4.7920e-05\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.4164e-04 - val_loss: 5.3435e-05\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.8033e-04 - val_loss: 5.0622e-05\n",
      "Thời gian huấn luyện:  6.2588722705841064\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_2 (SimpleRNN)    (None, 10, 100)           10200     \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,201\n",
      "Trainable params: 11,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "31/31 [==============================] - 2s 19ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 37/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 40/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 41/50\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 44/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Thời gian huấn luyện:  13.431443214416504\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 10, 100)           40800     \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,801\n",
      "Trainable params: 41,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "31/31 [==============================] - 2s 16ms/step - loss: 0.0337 - val_loss: 7.9783e-04\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 9.9302e-04\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 4.4265e-04\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 9.4674e-04 - val_loss: 2.2911e-04\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 9.1135e-04 - val_loss: 8.7152e-05\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.9932e-04 - val_loss: 8.4403e-05\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.9114e-04 - val_loss: 7.3260e-05\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 8.9401e-04 - val_loss: 7.4287e-05\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.8738e-04 - val_loss: 8.2138e-05\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.9453e-04 - val_loss: 6.7277e-05\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.8270e-04 - val_loss: 6.7071e-05\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.8981e-04 - val_loss: 7.1912e-05\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.7246e-04 - val_loss: 8.6039e-05\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 8.7165e-04 - val_loss: 7.8616e-05\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 8.6431e-04 - val_loss: 7.3152e-05\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 8.5763e-04 - val_loss: 8.4704e-05\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 8.5903e-04 - val_loss: 6.6157e-05\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.6210e-04 - val_loss: 6.5974e-05\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.5603e-04 - val_loss: 7.2510e-05\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.4901e-04 - val_loss: 7.1938e-05\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.4628e-04 - val_loss: 7.1602e-05\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.3686e-04 - val_loss: 6.9922e-05\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.3399e-04 - val_loss: 6.9007e-05\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 8.3074e-04 - val_loss: 8.2784e-05\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.3082e-04 - val_loss: 6.5011e-05\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.4179e-04 - val_loss: 7.1231e-05\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.1899e-04 - val_loss: 7.5022e-05\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.1362e-04 - val_loss: 6.3251e-05\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.0817e-04 - val_loss: 6.7729e-05\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.0731e-04 - val_loss: 6.4805e-05\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.0383e-04 - val_loss: 6.6470e-05\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.1503e-04 - val_loss: 7.2541e-05\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.9834e-04 - val_loss: 6.2009e-05\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 7.9950e-04 - val_loss: 7.4842e-05\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 7.9462e-04 - val_loss: 6.2364e-05\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 7.8880e-04 - val_loss: 6.1357e-05\n",
      "Epoch 37/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.8939e-04 - val_loss: 7.1030e-05\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 7.7267e-04 - val_loss: 7.9659e-05\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 7.7447e-04 - val_loss: 6.5305e-05\n",
      "Epoch 40/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 7.6998e-04 - val_loss: 6.0911e-05\n",
      "Epoch 41/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 7.6863e-04 - val_loss: 5.8600e-05\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.6215e-04 - val_loss: 6.2873e-05\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.5753e-04 - val_loss: 7.4650e-05\n",
      "Epoch 44/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 7.6274e-04 - val_loss: 7.0168e-05\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 7.6257e-04 - val_loss: 6.0196e-05\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.4868e-04 - val_loss: 6.1994e-05\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.4341e-04 - val_loss: 6.1854e-05\n",
      "Epoch 48/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 7.4419e-04 - val_loss: 5.8347e-05\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.3467e-04 - val_loss: 5.6884e-05\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.2767e-04 - val_loss: 7.7870e-05\n",
      "Thời gian huấn luyện:  11.823021173477173\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_2 (GRU)                 (None, 10, 100)           30900     \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,901\n",
      "Trainable params: 31,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "39/39 [==============================] - 0s 921us/step\n",
      "26/26 [==============================] - 0s 959us/step\n",
      "39/39 [==============================] - 0s 1ms/step\n",
      "26/26 [==============================] - 0s 1ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.0135\n",
      "Thời gian huấn luyện:  6.77278733253479\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 10, 100)           200       \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,201\n",
      "Trainable params: 1,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 2.2429e-04\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 1.6353e-04\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 2.1628e-04\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 9.4517e-04 - val_loss: 2.8673e-04\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 9.3518e-04 - val_loss: 2.1360e-04\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 8.7332e-04 - val_loss: 2.1496e-04\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 8.3868e-04 - val_loss: 2.2092e-04\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 8.1443e-04 - val_loss: 1.7367e-04\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 7.8336e-04 - val_loss: 1.3976e-04\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 8.1899e-04 - val_loss: 2.0850e-04\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 7.3851e-04 - val_loss: 1.1222e-04\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 7.1223e-04 - val_loss: 1.4013e-04\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6.8161e-04 - val_loss: 1.2765e-04\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6.5053e-04 - val_loss: 1.3613e-04\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6.4092e-04 - val_loss: 9.8854e-05\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6.2418e-04 - val_loss: 9.7728e-05\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.9631e-04 - val_loss: 1.0673e-04\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.9329e-04 - val_loss: 8.8203e-05\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.9068e-04 - val_loss: 9.4013e-05\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.5744e-04 - val_loss: 9.6632e-05\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.4454e-04 - val_loss: 7.9212e-05\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.2663e-04 - val_loss: 7.8327e-05\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.4075e-04 - val_loss: 6.4898e-05\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.2203e-04 - val_loss: 7.5448e-05\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.0340e-04 - val_loss: 6.3314e-05\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.8451e-04 - val_loss: 5.6437e-05\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.7873e-04 - val_loss: 5.1271e-05\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.7191e-04 - val_loss: 4.6436e-05\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.6493e-04 - val_loss: 4.5656e-05\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.6695e-04 - val_loss: 4.6182e-05\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.5111e-04 - val_loss: 4.4734e-05\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.6664e-04 - val_loss: 4.3371e-05\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.5412e-04 - val_loss: 5.3053e-05\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.4461e-04 - val_loss: 4.2052e-05\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.3542e-04 - val_loss: 4.1731e-05\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.4103e-04 - val_loss: 4.5513e-05\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.3926e-04 - val_loss: 4.0766e-05\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.1127e-04 - val_loss: 4.1012e-05\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.6992e-04 - val_loss: 4.8194e-05\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.5439e-04 - val_loss: 4.4747e-05\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.2480e-04 - val_loss: 4.2530e-05\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.0839e-04 - val_loss: 3.9910e-05\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.0111e-04 - val_loss: 4.5154e-05\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.5372e-04 - val_loss: 3.9341e-05\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.9155e-04 - val_loss: 4.1115e-05\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3.9126e-04 - val_loss: 4.1316e-05\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3.7655e-04 - val_loss: 3.9019e-05\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.9727e-04 - val_loss: 4.1768e-05\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.3198e-04 - val_loss: 7.4489e-05\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.5213e-04 - val_loss: 3.6696e-05\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.7187e-04 - val_loss: 4.0566e-05\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.6667e-04 - val_loss: 3.9296e-05\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.6435e-04 - val_loss: 3.6290e-05\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.7053e-04 - val_loss: 3.6316e-05\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3.9497e-04 - val_loss: 4.5523e-05\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 4ms/step - loss: 3.6012e-04 - val_loss: 3.6680e-05\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.7751e-04 - val_loss: 3.9563e-05\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.4434e-04 - val_loss: 3.7564e-05\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.5273e-04 - val_loss: 3.7075e-05\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.6644e-04 - val_loss: 3.4330e-05\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.6584e-04 - val_loss: 4.9918e-05\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.6989e-04 - val_loss: 4.5810e-05\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.6061e-04 - val_loss: 3.6133e-05\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.3506e-04 - val_loss: 3.5462e-05\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.6177e-04 - val_loss: 3.3060e-05\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.4189e-04 - val_loss: 3.5910e-05\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.3091e-04 - val_loss: 3.7481e-05\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.5440e-04 - val_loss: 4.1401e-05\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.3143e-04 - val_loss: 3.3349e-05\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.2069e-04 - val_loss: 4.2923e-05\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.2197e-04 - val_loss: 3.6104e-05\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.6004e-04 - val_loss: 4.5964e-05\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.8311e-04 - val_loss: 4.3575e-05\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.6471e-04 - val_loss: 3.1108e-05\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.1229e-04 - val_loss: 3.9923e-05\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.1921e-04 - val_loss: 3.4224e-05\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.0490e-04 - val_loss: 3.6645e-05\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.2043e-04 - val_loss: 3.3908e-05\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.9953e-04 - val_loss: 3.5639e-05\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.0317e-04 - val_loss: 3.2454e-05\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.4211e-04 - val_loss: 3.4460e-05\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.9338e-04 - val_loss: 3.5484e-05\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.9571e-04 - val_loss: 2.9315e-05\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.0784e-04 - val_loss: 3.6509e-05\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.0011e-04 - val_loss: 2.9361e-05\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.0714e-04 - val_loss: 2.9976e-05\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.8858e-04 - val_loss: 3.0427e-05\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.8475e-04 - val_loss: 2.8967e-05\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.0071e-04 - val_loss: 3.1358e-05\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.0331e-04 - val_loss: 2.8490e-05\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.1419e-04 - val_loss: 5.9420e-05\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.2378e-04 - val_loss: 3.0588e-05\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.7296e-04 - val_loss: 2.8104e-05\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.9715e-04 - val_loss: 3.7091e-05\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.8592e-04 - val_loss: 3.5644e-05\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.8096e-04 - val_loss: 2.7099e-05\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.9339e-04 - val_loss: 2.7275e-05\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.8693e-04 - val_loss: 3.5269e-05\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.8818e-04 - val_loss: 2.7715e-05\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.8399e-04 - val_loss: 2.8291e-05\n",
      "Thời gian huấn luyện:  11.539186477661133\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_3 (SimpleRNN)    (None, 10, 100)           10200     \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,201\n",
      "Trainable params: 11,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 16ms/step - loss: 0.0487 - val_loss: 0.0022\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.3496e-04\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 9.8033e-04 - val_loss: 3.5949e-04\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 1s 15ms/step - loss: 9.2515e-04 - val_loss: 2.9311e-04\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 9.1811e-04 - val_loss: 1.7837e-04\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 9.1708e-04 - val_loss: 1.9828e-04\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 9.1214e-04 - val_loss: 2.5058e-04\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 9.1642e-04 - val_loss: 2.2193e-04\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 9.0688e-04 - val_loss: 2.1904e-04\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 9.1387e-04 - val_loss: 2.0096e-04\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.9800e-04 - val_loss: 2.3280e-04\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 9.0847e-04 - val_loss: 1.5554e-04\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 9.0584e-04 - val_loss: 1.6144e-04\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 9.0465e-04 - val_loss: 1.9036e-04\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 9.1106e-04 - val_loss: 1.8198e-04\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.8775e-04 - val_loss: 1.5605e-04\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 9.0365e-04 - val_loss: 2.0279e-04\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.9357e-04 - val_loss: 1.9526e-04\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.8868e-04 - val_loss: 1.6427e-04\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.8701e-04 - val_loss: 1.5304e-04\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.9113e-04 - val_loss: 1.8335e-04\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.8194e-04 - val_loss: 1.8457e-04\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 8ms/step - loss: 8.9125e-04 - val_loss: 1.7215e-04\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.7907e-04 - val_loss: 1.6866e-04\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.7112e-04 - val_loss: 1.4249e-04\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.9786e-04 - val_loss: 1.5758e-04\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.7863e-04 - val_loss: 1.2084e-04\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.9336e-04 - val_loss: 1.7242e-04\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.8512e-04 - val_loss: 1.6301e-04\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.5698e-04 - val_loss: 1.6790e-04\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.5911e-04 - val_loss: 1.7162e-04\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.5814e-04 - val_loss: 1.7084e-04\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.5593e-04 - val_loss: 1.4361e-04\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.5658e-04 - val_loss: 1.6075e-04\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.5243e-04 - val_loss: 1.1769e-04\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.7463e-04 - val_loss: 1.6975e-04\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.6623e-04 - val_loss: 1.4642e-04\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.3999e-04 - val_loss: 1.3341e-04\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.3431e-04 - val_loss: 2.0722e-04\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.5215e-04 - val_loss: 1.2066e-04\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.3256e-04 - val_loss: 1.2516e-04\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.4534e-04 - val_loss: 1.7530e-04\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.3251e-04 - val_loss: 1.1440e-04\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.4858e-04 - val_loss: 1.7839e-04\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.2387e-04 - val_loss: 1.4423e-04\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.3718e-04 - val_loss: 1.3155e-04\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.1832e-04 - val_loss: 1.2249e-04\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.1506e-04 - val_loss: 1.2727e-04\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.1481e-04 - val_loss: 1.3707e-04\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.2866e-04 - val_loss: 1.3588e-04\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.0493e-04 - val_loss: 1.8253e-04\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.1844e-04 - val_loss: 1.5934e-04\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.9997e-04 - val_loss: 1.4685e-04\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.0730e-04 - val_loss: 1.1843e-04\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.1529e-04 - val_loss: 1.1168e-04\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.8113e-04 - val_loss: 1.1073e-04\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.0613e-04 - val_loss: 1.1541e-04\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.9060e-04 - val_loss: 1.4300e-04\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.9602e-04 - val_loss: 1.0721e-04\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.0380e-04 - val_loss: 1.0456e-04\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.9911e-04 - val_loss: 1.2815e-04\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.7015e-04 - val_loss: 9.9475e-05\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.0078e-04 - val_loss: 1.4633e-04\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.7454e-04 - val_loss: 1.1250e-04\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.6002e-04 - val_loss: 9.4786e-05\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.8077e-04 - val_loss: 1.2503e-04\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.6225e-04 - val_loss: 1.4305e-04\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.6289e-04 - val_loss: 1.1139e-04\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.4846e-04 - val_loss: 1.4268e-04\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.5693e-04 - val_loss: 1.1215e-04\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.4672e-04 - val_loss: 1.4004e-04\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.4467e-04 - val_loss: 1.0404e-04\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.3524e-04 - val_loss: 1.1623e-04\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.3202e-04 - val_loss: 1.1666e-04\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 7.3160e-04 - val_loss: 1.0272e-04\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.2653e-04 - val_loss: 1.0421e-04\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.2412e-04 - val_loss: 1.1778e-04\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.2720e-04 - val_loss: 1.0850e-04\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.3766e-04 - val_loss: 9.7302e-05\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.2246e-04 - val_loss: 1.3421e-04\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.1834e-04 - val_loss: 9.0987e-05\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.0349e-04 - val_loss: 1.1203e-04\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 6.9904e-04 - val_loss: 1.2071e-04\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.0306e-04 - val_loss: 1.0494e-04\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.1962e-04 - val_loss: 1.1074e-04\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 6.9128e-04 - val_loss: 1.0941e-04\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 6.9065e-04 - val_loss: 1.1017e-04\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 6.9271e-04 - val_loss: 9.3021e-05\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 6.8580e-04 - val_loss: 8.8264e-05\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 6.7631e-04 - val_loss: 9.8868e-05\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 6.7842e-04 - val_loss: 1.1423e-04\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 6.5907e-04 - val_loss: 7.9710e-05\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 6.7704e-04 - val_loss: 1.0779e-04\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 6.5733e-04 - val_loss: 9.0793e-05\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 6.6121e-04 - val_loss: 8.0906e-05\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 6.6647e-04 - val_loss: 7.7434e-05\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.2565e-04 - val_loss: 9.1419e-05\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 6.9518e-04 - val_loss: 1.0230e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 6.4023e-04 - val_loss: 9.2708e-05\n",
      "Thời gian huấn luyện:  28.87978768348694\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 10, 100)           40800     \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,801\n",
      "Trainable params: 41,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 16ms/step - loss: 0.0306 - val_loss: 7.8274e-04\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 4.3721e-04\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.7178e-04 - val_loss: 1.7027e-04\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.0556e-04 - val_loss: 8.2796e-05\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.9347e-04 - val_loss: 8.5005e-05\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.9641e-04 - val_loss: 7.7355e-05\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.9315e-04 - val_loss: 7.6482e-05\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.9335e-04 - val_loss: 7.4125e-05\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.8776e-04 - val_loss: 8.5321e-05\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.7996e-04 - val_loss: 7.8678e-05\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.7389e-04 - val_loss: 8.2748e-05\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.6587e-04 - val_loss: 7.2625e-05\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.7163e-04 - val_loss: 8.3107e-05\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.7940e-04 - val_loss: 7.7683e-05\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.6481e-04 - val_loss: 7.4901e-05\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.6003e-04 - val_loss: 7.2865e-05\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.5415e-04 - val_loss: 7.3322e-05\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.5807e-04 - val_loss: 7.8778e-05\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.4725e-04 - val_loss: 7.0124e-05\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.5693e-04 - val_loss: 8.4494e-05\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.4368e-04 - val_loss: 8.1239e-05\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.4963e-04 - val_loss: 6.9341e-05\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.4934e-04 - val_loss: 7.1323e-05\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.2931e-04 - val_loss: 7.0825e-05\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.2180e-04 - val_loss: 6.7904e-05\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.3508e-04 - val_loss: 7.0282e-05\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.2841e-04 - val_loss: 6.7444e-05\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.1733e-04 - val_loss: 6.8696e-05\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.1421e-04 - val_loss: 6.6759e-05\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.0899e-04 - val_loss: 6.6446e-05\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.0628e-04 - val_loss: 8.0385e-05\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.0247e-04 - val_loss: 6.8320e-05\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.0304e-04 - val_loss: 7.2050e-05\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.0161e-04 - val_loss: 6.9189e-05\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.9779e-04 - val_loss: 8.3057e-05\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.8818e-04 - val_loss: 7.4978e-05\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.8690e-04 - val_loss: 6.7659e-05\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.8999e-04 - val_loss: 6.3587e-05\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.7507e-04 - val_loss: 6.7851e-05\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.7288e-04 - val_loss: 6.2715e-05\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.6873e-04 - val_loss: 6.5958e-05\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.6590e-04 - val_loss: 6.5506e-05\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.6341e-04 - val_loss: 6.4488e-05\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.6294e-04 - val_loss: 6.1092e-05\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.7325e-04 - val_loss: 6.9344e-05\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.4718e-04 - val_loss: 6.0177e-05\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.4624e-04 - val_loss: 5.9278e-05\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.3999e-04 - val_loss: 5.8915e-05\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.4765e-04 - val_loss: 6.0787e-05\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.5064e-04 - val_loss: 5.7985e-05\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.3088e-04 - val_loss: 5.9864e-05\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.2981e-04 - val_loss: 5.8450e-05\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.2504e-04 - val_loss: 5.7179e-05\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 5.1790e-04 - val_loss: 5.8866e-05\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.1411e-04 - val_loss: 5.6499e-05\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.1589e-04 - val_loss: 7.7375e-05\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.1039e-04 - val_loss: 5.5477e-05\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.0533e-04 - val_loss: 5.8879e-05\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.0848e-04 - val_loss: 6.4348e-05\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.0037e-04 - val_loss: 5.9159e-05\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.0990e-04 - val_loss: 5.3829e-05\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.8883e-04 - val_loss: 5.5221e-05\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.8862e-04 - val_loss: 5.4986e-05\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.9305e-04 - val_loss: 5.8480e-05\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.8577e-04 - val_loss: 5.2187e-05\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.8104e-04 - val_loss: 5.1946e-05\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.8852e-04 - val_loss: 5.2083e-05\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 7ms/step - loss: 4.7533e-04 - val_loss: 5.5699e-05\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.6840e-04 - val_loss: 5.0714e-05\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.7373e-04 - val_loss: 5.0461e-05\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.6332e-04 - val_loss: 5.7106e-05\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.6055e-04 - val_loss: 5.0083e-05\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.5793e-04 - val_loss: 5.3105e-05\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.5153e-04 - val_loss: 4.9556e-05\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 4.5415e-04 - val_loss: 5.0886e-05\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 4.5555e-04 - val_loss: 4.8564e-05\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 4.3997e-04 - val_loss: 4.9050e-05\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.3917e-04 - val_loss: 4.8906e-05\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.3944e-04 - val_loss: 4.7490e-05\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.3896e-04 - val_loss: 6.1197e-05\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.5099e-04 - val_loss: 4.9246e-05\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.3418e-04 - val_loss: 4.6733e-05\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 4.2665e-04 - val_loss: 4.6289e-05\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.2588e-04 - val_loss: 5.3502e-05\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.3613e-04 - val_loss: 4.5721e-05\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.2039e-04 - val_loss: 5.8131e-05\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.2860e-04 - val_loss: 4.5514e-05\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.1167e-04 - val_loss: 6.3779e-05\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.3644e-04 - val_loss: 4.4568e-05\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.2042e-04 - val_loss: 5.6923e-05\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.1999e-04 - val_loss: 4.4545e-05\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.0483e-04 - val_loss: 4.8444e-05\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.9893e-04 - val_loss: 5.3928e-05\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.0348e-04 - val_loss: 4.3182e-05\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.9764e-04 - val_loss: 5.8776e-05\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.9948e-04 - val_loss: 4.2771e-05\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.9458e-04 - val_loss: 4.2442e-05\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.8885e-04 - val_loss: 4.2248e-05\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.9428e-04 - val_loss: 4.2205e-05\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.8114e-04 - val_loss: 4.1716e-05\n",
      "Thời gian huấn luyện:  26.475974559783936\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_3 (GRU)                 (None, 10, 100)           30900     \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,901\n",
      "Trainable params: 31,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "39/39 [==============================] - 0s 974us/step\n",
      "26/26 [==============================] - 0s 920us/step\n",
      "39/39 [==============================] - 0s 1ms/step\n",
      "26/26 [==============================] - 0s 1ms/step\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Thời gian huấn luyện:  7.744066953659058\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 10, 100)           200       \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,201\n",
      "Trainable params: 1,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 8ms/step - loss: 0.0335 - val_loss: 7.3245e-04\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 1.0010e-04\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 1.5390e-04\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 1.9626e-04\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 2.2038e-04\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 2.1546e-04\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 3ms/step - loss: 9.9311e-04 - val_loss: 1.7953e-04\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 2.7874e-04\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 9.4183e-04 - val_loss: 1.9457e-04\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 9.6158e-04 - val_loss: 1.9524e-04\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.9375e-04 - val_loss: 2.2580e-04\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 8.8827e-04 - val_loss: 1.7222e-04\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.7656e-04 - val_loss: 1.6239e-04\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.3718e-04 - val_loss: 1.5684e-04\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.2714e-04 - val_loss: 1.6274e-04\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.1678e-04 - val_loss: 1.3484e-04\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 8.0169e-04 - val_loss: 1.7014e-04\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 7.7636e-04 - val_loss: 1.3301e-04\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 7.6707e-04 - val_loss: 1.5161e-04\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 7.4786e-04 - val_loss: 1.1269e-04\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 7.3468e-04 - val_loss: 1.1565e-04\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 7.1908e-04 - val_loss: 1.4391e-04\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 7.0705e-04 - val_loss: 1.0514e-04\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 7.1491e-04 - val_loss: 9.3421e-05\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 6.8531e-04 - val_loss: 8.9289e-05\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.7653e-04 - val_loss: 9.7297e-05\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.5973e-04 - val_loss: 9.7022e-05\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.5725e-04 - val_loss: 7.1765e-05\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.3133e-04 - val_loss: 9.3354e-05\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.1904e-04 - val_loss: 6.7974e-05\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.0824e-04 - val_loss: 6.4310e-05\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.9593e-04 - val_loss: 7.7924e-05\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.8565e-04 - val_loss: 6.0955e-05\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.8391e-04 - val_loss: 6.1873e-05\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 6.1692e-04 - val_loss: 5.1489e-05\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 5.8595e-04 - val_loss: 6.3016e-05\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.5838e-04 - val_loss: 5.7836e-05\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.7357e-04 - val_loss: 5.6314e-05\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.4570e-04 - val_loss: 4.5845e-05\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.3155e-04 - val_loss: 5.4788e-05\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.4689e-04 - val_loss: 4.6883e-05\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.3261e-04 - val_loss: 4.4264e-05\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 5.2419e-04 - val_loss: 4.3412e-05\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 5.1030e-04 - val_loss: 4.6712e-05\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 5.2557e-04 - val_loss: 4.3474e-05\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.0503e-04 - val_loss: 4.2215e-05\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.9080e-04 - val_loss: 4.2063e-05\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.8778e-04 - val_loss: 4.1889e-05\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.9619e-04 - val_loss: 4.0764e-05\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.0320e-04 - val_loss: 4.0414e-05\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 5.0389e-04 - val_loss: 4.3093e-05\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 4.8680e-04 - val_loss: 4.6859e-05\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.6942e-04 - val_loss: 4.2561e-05\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.6960e-04 - val_loss: 3.9128e-05\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.6181e-04 - val_loss: 4.3947e-05\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.9108e-04 - val_loss: 3.8416e-05\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.6843e-04 - val_loss: 4.0701e-05\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.6156e-04 - val_loss: 3.8176e-05\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.4156e-04 - val_loss: 3.7490e-05\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.5166e-04 - val_loss: 4.3470e-05\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.7411e-04 - val_loss: 5.3287e-05\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.3318e-04 - val_loss: 3.6847e-05\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.3471e-04 - val_loss: 3.9652e-05\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 4.4958e-04 - val_loss: 3.6738e-05\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 4.2919e-04 - val_loss: 3.6932e-05\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.4774e-04 - val_loss: 3.6880e-05\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.3301e-04 - val_loss: 3.5639e-05\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 4.1935e-04 - val_loss: 3.5336e-05\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 4.2545e-04 - val_loss: 4.9655e-05\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.5121e-04 - val_loss: 3.5223e-05\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.1209e-04 - val_loss: 3.4643e-05\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.2276e-04 - val_loss: 3.4325e-05\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.0825e-04 - val_loss: 3.4122e-05\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.9964e-04 - val_loss: 3.4991e-05\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.9501e-04 - val_loss: 3.4336e-05\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.2585e-04 - val_loss: 3.5623e-05\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.1077e-04 - val_loss: 3.3116e-05\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.0360e-04 - val_loss: 3.3844e-05\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.8398e-04 - val_loss: 3.3772e-05\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.9753e-04 - val_loss: 3.8750e-05\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.9444e-04 - val_loss: 3.4369e-05\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.0285e-04 - val_loss: 4.4747e-05\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 3ms/step - loss: 4.2208e-04 - val_loss: 3.2699e-05\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 3.9368e-04 - val_loss: 3.2076e-05\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 3.8968e-04 - val_loss: 3.1870e-05\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.9338e-04 - val_loss: 3.4683e-05\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.8555e-04 - val_loss: 3.5557e-05\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.8206e-04 - val_loss: 3.1470e-05\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.7275e-04 - val_loss: 3.1093e-05\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.7321e-04 - val_loss: 3.0768e-05\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.6393e-04 - val_loss: 3.2279e-05\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 3.8530e-04 - val_loss: 3.0555e-05\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 3.7517e-04 - val_loss: 3.2498e-05\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.7560e-04 - val_loss: 3.0155e-05\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.5634e-04 - val_loss: 3.2673e-05\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.9508e-04 - val_loss: 3.5171e-05\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.0578e-04 - val_loss: 3.2604e-05\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.7477e-04 - val_loss: 3.0421e-05\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.5125e-04 - val_loss: 3.0273e-05\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.6275e-04 - val_loss: 2.9911e-05\n",
      "Thời gian huấn luyện:  12.349432468414307\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_4 (SimpleRNN)    (None, 10, 100)           10200     \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,201\n",
      "Trainable params: 11,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 2s 17ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.0150\n",
      "Thời gian huấn luyện:  24.608225345611572\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 10, 100)           40800     \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,801\n",
      "Trainable params: 41,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 2s 16ms/step - loss: 0.0515 - val_loss: 0.0022\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.1846e-04\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.7012e-04 - val_loss: 1.7514e-04\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 9.0077e-04 - val_loss: 1.3220e-04\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.9911e-04 - val_loss: 1.0373e-04\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.7824e-04 - val_loss: 9.0029e-05\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.8075e-04 - val_loss: 8.1746e-05\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 8.7076e-04 - val_loss: 8.0263e-05\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.6880e-04 - val_loss: 8.1189e-05\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.6342e-04 - val_loss: 8.6843e-05\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.5817e-04 - val_loss: 7.9902e-05\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.6678e-04 - val_loss: 7.9508e-05\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.5505e-04 - val_loss: 7.9544e-05\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.5547e-04 - val_loss: 7.8575e-05\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.4742e-04 - val_loss: 8.3894e-05\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.4029e-04 - val_loss: 7.9520e-05\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.3416e-04 - val_loss: 8.9017e-05\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.3709e-04 - val_loss: 7.6491e-05\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.3966e-04 - val_loss: 7.6769e-05\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.4352e-04 - val_loss: 7.5900e-05\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.1303e-04 - val_loss: 9.7678e-05\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.1181e-04 - val_loss: 7.6298e-05\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.1897e-04 - val_loss: 7.8240e-05\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.0934e-04 - val_loss: 7.4446e-05\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 6ms/step - loss: 8.0234e-04 - val_loss: 7.8097e-05\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.9696e-04 - val_loss: 7.3659e-05\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.9759e-04 - val_loss: 7.3037e-05\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.0077e-04 - val_loss: 7.4477e-05\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.8959e-04 - val_loss: 7.3358e-05\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 7.8042e-04 - val_loss: 8.7257e-05\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.7438e-04 - val_loss: 7.2202e-05\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.7281e-04 - val_loss: 7.3785e-05\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.7618e-04 - val_loss: 7.5988e-05\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.6793e-04 - val_loss: 7.3830e-05\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.8712e-04 - val_loss: 8.1197e-05\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.6657e-04 - val_loss: 6.9524e-05\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.5392e-04 - val_loss: 7.4779e-05\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.5939e-04 - val_loss: 7.0241e-05\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.5322e-04 - val_loss: 7.4797e-05\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.3900e-04 - val_loss: 6.9980e-05\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.4022e-04 - val_loss: 7.0303e-05\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.4230e-04 - val_loss: 7.3146e-05\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.3552e-04 - val_loss: 7.9809e-05\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 7.4216e-04 - val_loss: 6.7738e-05\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 7.2059e-04 - val_loss: 6.8534e-05\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.2278e-04 - val_loss: 6.8321e-05\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.0896e-04 - val_loss: 6.9130e-05\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.0327e-04 - val_loss: 6.4647e-05\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.9708e-04 - val_loss: 8.0617e-05\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.0265e-04 - val_loss: 6.4110e-05\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.9437e-04 - val_loss: 6.3811e-05\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 6.9110e-04 - val_loss: 7.5016e-05\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 7.0862e-04 - val_loss: 6.7147e-05\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 6.8891e-04 - val_loss: 6.4029e-05\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 6.7223e-04 - val_loss: 6.2101e-05\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 6.8186e-04 - val_loss: 6.4166e-05\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 6.6677e-04 - val_loss: 6.1892e-05\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.7054e-04 - val_loss: 6.4799e-05\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.5717e-04 - val_loss: 6.1004e-05\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.5261e-04 - val_loss: 6.1085e-05\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.5564e-04 - val_loss: 5.9133e-05\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.4801e-04 - val_loss: 6.5085e-05\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.3432e-04 - val_loss: 5.8633e-05\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.3852e-04 - val_loss: 6.3607e-05\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.4726e-04 - val_loss: 6.3296e-05\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.3005e-04 - val_loss: 5.9945e-05\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.1439e-04 - val_loss: 5.6546e-05\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.3339e-04 - val_loss: 6.7168e-05\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.3355e-04 - val_loss: 6.1925e-05\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.0997e-04 - val_loss: 5.5310e-05\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.1022e-04 - val_loss: 5.5672e-05\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.9873e-04 - val_loss: 5.7500e-05\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.9122e-04 - val_loss: 5.4046e-05\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.0685e-04 - val_loss: 5.4012e-05\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.0247e-04 - val_loss: 5.3720e-05\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.8571e-04 - val_loss: 6.0254e-05\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.7748e-04 - val_loss: 5.2892e-05\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.7293e-04 - val_loss: 5.5358e-05\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.6060e-04 - val_loss: 5.4085e-05\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.5054e-04 - val_loss: 6.0377e-05\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.7589e-04 - val_loss: 5.7245e-05\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.7685e-04 - val_loss: 5.5844e-05\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.4837e-04 - val_loss: 5.0618e-05\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.4910e-04 - val_loss: 5.6469e-05\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.4053e-04 - val_loss: 5.1284e-05\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.3336e-04 - val_loss: 5.8520e-05\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.4216e-04 - val_loss: 5.0937e-05\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.3820e-04 - val_loss: 5.3401e-05\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.2748e-04 - val_loss: 4.9646e-05\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.4009e-04 - val_loss: 5.0625e-05\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.3019e-04 - val_loss: 6.5175e-05\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.1603e-04 - val_loss: 4.7691e-05\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.1977e-04 - val_loss: 5.4082e-05\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.1899e-04 - val_loss: 4.7515e-05\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.0192e-04 - val_loss: 4.9967e-05\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.9485e-04 - val_loss: 6.2467e-05\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.9666e-04 - val_loss: 4.6136e-05\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.0669e-04 - val_loss: 4.9475e-05\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.1577e-04 - val_loss: 5.2461e-05\n",
      "Thời gian huấn luyện:  24.00437641143799\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_4 (GRU)                 (None, 10, 100)           30900     \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,901\n",
      "Trainable params: 31,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "39/39 [==============================] - 0s 947us/step\n",
      "26/26 [==============================] - 0s 1ms/step\n",
      "39/39 [==============================] - 0s 1ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "39/39 [==============================] - 1s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.1478 - val_loss: 0.0089\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0457\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0286\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0245\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0206\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0166\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0134\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0105\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0083\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0065\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0026\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.1584e-04 - val_loss: 0.0021\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.4125e-04 - val_loss: 0.0019\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.9834e-04 - val_loss: 0.0016\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7430e-04 - val_loss: 0.0014\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5565e-04 - val_loss: 0.0013\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.4576e-04 - val_loss: 0.0013\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3912e-04 - val_loss: 0.0012\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3874e-04 - val_loss: 0.0012\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3407e-04 - val_loss: 0.0011\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3355e-04 - val_loss: 0.0010\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3195e-04 - val_loss: 0.0011\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2862e-04 - val_loss: 0.0011\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3001e-04 - val_loss: 0.0010\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3066e-04 - val_loss: 9.8650e-04\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2688e-04 - val_loss: 0.0011\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3354e-04 - val_loss: 0.0010\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2664e-04 - val_loss: 0.0010\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2355e-04 - val_loss: 9.6162e-04\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2316e-04 - val_loss: 9.5929e-04\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2232e-04 - val_loss: 9.6183e-04\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2268e-04 - val_loss: 0.0010\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.1521e-04 - val_loss: 9.3661e-04\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2731e-04 - val_loss: 9.5371e-04\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2483e-04 - val_loss: 9.5483e-04\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2051e-04 - val_loss: 9.7839e-04\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.1373e-04 - val_loss: 9.6783e-04\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.1251e-04 - val_loss: 9.3461e-04\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.1812e-04 - val_loss: 8.8267e-04\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.1207e-04 - val_loss: 9.3394e-04\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0901e-04 - val_loss: 9.2663e-04\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0718e-04 - val_loss: 9.0424e-04\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0815e-04 - val_loss: 9.4963e-04\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0515e-04 - val_loss: 0.0010\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.1471e-04 - val_loss: 9.6975e-04\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0780e-04 - val_loss: 8.8927e-04\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0221e-04 - val_loss: 0.0010\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0152e-04 - val_loss: 8.7252e-04\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.9721e-04 - val_loss: 9.4240e-04\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.9616e-04 - val_loss: 8.0285e-04\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.9648e-04 - val_loss: 9.3891e-04\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.9859e-04 - val_loss: 8.9001e-04\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.9192e-04 - val_loss: 9.7245e-04\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.9390e-04 - val_loss: 8.4380e-04\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.9213e-04 - val_loss: 8.4788e-04\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.9024e-04 - val_loss: 8.8286e-04\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.8800e-04 - val_loss: 7.8451e-04\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.8537e-04 - val_loss: 9.4517e-04\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.8772e-04 - val_loss: 8.4530e-04\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.8456e-04 - val_loss: 8.0046e-04\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.9028e-04 - val_loss: 7.6115e-04\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.8178e-04 - val_loss: 8.5988e-04\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.9116e-04 - val_loss: 8.7755e-04\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.8396e-04 - val_loss: 8.6611e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.8325e-04 - val_loss: 8.5106e-04\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.7444e-04 - val_loss: 8.4955e-04\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.7531e-04 - val_loss: 8.6567e-04\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.7555e-04 - val_loss: 7.9665e-04\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.7142e-04 - val_loss: 8.1570e-04\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.6739e-04 - val_loss: 7.6541e-04\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.7200e-04 - val_loss: 8.0227e-04\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.6693e-04 - val_loss: 8.0812e-04\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.6699e-04 - val_loss: 7.5758e-04\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.6799e-04 - val_loss: 7.5396e-04\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.6861e-04 - val_loss: 7.9590e-04\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.5837e-04 - val_loss: 7.6194e-04\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.5819e-04 - val_loss: 8.2135e-04\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.5660e-04 - val_loss: 7.5619e-04\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.5336e-04 - val_loss: 7.4638e-04\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.5453e-04 - val_loss: 7.3140e-04\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.5203e-04 - val_loss: 8.4287e-04\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.5162e-04 - val_loss: 7.9538e-04\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.4555e-04 - val_loss: 6.9566e-04\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.4779e-04 - val_loss: 7.2995e-04\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.4538e-04 - val_loss: 7.6414e-04\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.4438e-04 - val_loss: 7.7039e-04\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.3926e-04 - val_loss: 6.8068e-04\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.3918e-04 - val_loss: 7.8585e-04\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.4129e-04 - val_loss: 7.3879e-04\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.3731e-04 - val_loss: 7.4327e-04\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.3456e-04 - val_loss: 7.4504e-04\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.3629e-04 - val_loss: 7.1694e-04\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.3395e-04 - val_loss: 6.4639e-04\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.2865e-04 - val_loss: 7.7344e-04\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.1805e-04 - val_loss: 5.9297e-04\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.3262e-04 - val_loss: 8.0725e-04\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.2761e-04 - val_loss: 8.4295e-04\n",
      "Thời gian huấn luyện:  7.281192064285278\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_25 (Dense)            (None, 10, 100)           200       \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,201\n",
      "Trainable params: 1,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 1s 8ms/step - loss: 0.0309 - val_loss: 2.2015e-04\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 3.5271e-04\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 5.0477e-04\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 4.3784e-04\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 6.1342e-04\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 5.0436e-04\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 5.2776e-04\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 4.9459e-04\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.8787e-04\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.8590e-04\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 4.2572e-04\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.3964e-04\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 3.7249e-04\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 9.8828e-04 - val_loss: 2.9387e-04\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 9.6444e-04 - val_loss: 2.8538e-04\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 9.3212e-04 - val_loss: 2.4515e-04\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 9.2815e-04 - val_loss: 2.8475e-04\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 8.7716e-04 - val_loss: 2.0996e-04\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 8.7318e-04 - val_loss: 1.9703e-04\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 8.6214e-04 - val_loss: 1.6309e-04\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 8.0775e-04 - val_loss: 2.5417e-04\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 8.1147e-04 - val_loss: 1.5110e-04\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 7.7410e-04 - val_loss: 1.8178e-04\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 7.6752e-04 - val_loss: 1.3032e-04\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 7.4586e-04 - val_loss: 1.4106e-04\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 7.3977e-04 - val_loss: 8.8632e-05\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.2254e-04 - val_loss: 9.7522e-05\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.2012e-04 - val_loss: 7.8453e-05\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.8077e-04 - val_loss: 7.1397e-05\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 7.2398e-04 - val_loss: 5.9606e-05\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 7.0710e-04 - val_loss: 7.8951e-05\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.6648e-04 - val_loss: 5.6281e-05\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.5089e-04 - val_loss: 7.9646e-05\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.2876e-04 - val_loss: 7.2110e-05\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.3406e-04 - val_loss: 5.5214e-05\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 3ms/step - loss: 6.2184e-04 - val_loss: 4.9080e-05\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 6.1768e-04 - val_loss: 4.6970e-05\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.7083e-04 - val_loss: 6.1334e-05\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.1981e-04 - val_loss: 4.6659e-05\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.9517e-04 - val_loss: 4.9118e-05\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.2942e-04 - val_loss: 4.7342e-05\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.8752e-04 - val_loss: 4.4209e-05\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.8618e-04 - val_loss: 4.8453e-05\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.9673e-04 - val_loss: 4.2737e-05\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.6253e-04 - val_loss: 3.9596e-05\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.5987e-04 - val_loss: 4.3067e-05\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.5335e-04 - val_loss: 4.4784e-05\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 6.2101e-04 - val_loss: 5.0879e-05\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.4229e-04 - val_loss: 5.0098e-05\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.4438e-04 - val_loss: 3.7559e-05\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.4637e-04 - val_loss: 4.3089e-05\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.3045e-04 - val_loss: 4.3652e-05\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.2386e-04 - val_loss: 4.1266e-05\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.3068e-04 - val_loss: 5.3259e-05\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.7757e-04 - val_loss: 4.0187e-05\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.3843e-04 - val_loss: 4.8967e-05\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.3606e-04 - val_loss: 3.6830e-05\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.9067e-04 - val_loss: 3.5429e-05\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.9395e-04 - val_loss: 3.7508e-05\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.1307e-04 - val_loss: 4.8267e-05\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.2954e-04 - val_loss: 3.4722e-05\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.8700e-04 - val_loss: 4.1818e-05\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.8117e-04 - val_loss: 5.1536e-05\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.7768e-04 - val_loss: 3.5485e-05\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.7258e-04 - val_loss: 3.4208e-05\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.0575e-04 - val_loss: 3.5478e-05\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.0675e-04 - val_loss: 4.9197e-05\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.6302e-04 - val_loss: 3.5327e-05\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.7844e-04 - val_loss: 3.2845e-05\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.7871e-04 - val_loss: 3.2828e-05\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.7217e-04 - val_loss: 3.5696e-05\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.4519e-04 - val_loss: 3.3077e-05\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.7788e-04 - val_loss: 4.9365e-05\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.9141e-04 - val_loss: 4.4798e-05\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.5433e-04 - val_loss: 4.0293e-05\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.6245e-04 - val_loss: 4.4599e-05\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.3151e-04 - val_loss: 3.2285e-05\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.3948e-04 - val_loss: 3.2732e-05\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.3610e-04 - val_loss: 3.4778e-05\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.8498e-04 - val_loss: 3.5613e-05\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.1886e-04 - val_loss: 4.1289e-05\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.1055e-04 - val_loss: 5.1767e-05\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.3311e-04 - val_loss: 3.4150e-05\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.1309e-04 - val_loss: 4.4785e-05\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.1321e-04 - val_loss: 2.9917e-05\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.2545e-04 - val_loss: 4.4935e-05\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.3209e-04 - val_loss: 3.9613e-05\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.4740e-04 - val_loss: 3.7284e-05\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.2377e-04 - val_loss: 3.0040e-05\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.1422e-04 - val_loss: 3.9707e-05\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.0723e-04 - val_loss: 2.9541e-05\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.1370e-04 - val_loss: 2.8743e-05\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.0272e-04 - val_loss: 2.9478e-05\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.1549e-04 - val_loss: 3.9450e-05\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.0036e-04 - val_loss: 3.9434e-05\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.8762e-04 - val_loss: 2.8789e-05\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.8674e-04 - val_loss: 3.2958e-05\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3.9141e-04 - val_loss: 2.8582e-05\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.0156e-04 - val_loss: 3.5684e-05\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.3209e-04 - val_loss: 2.8165e-05\n",
      "Thời gian huấn luyện:  11.964419603347778\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_5 (SimpleRNN)    (None, 10, 100)           10200     \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,201\n",
      "Trainable params: 11,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 2s 19ms/step - loss: 0.0481 - val_loss: 0.0018\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 9.9253e-04\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 5.0914e-04\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.9828e-04 - val_loss: 3.3074e-04\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.7785e-04 - val_loss: 2.8936e-04\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.6789e-04 - val_loss: 2.1188e-04\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.7354e-04 - val_loss: 2.2993e-04\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.6909e-04 - val_loss: 2.2151e-04\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.7888e-04 - val_loss: 2.0447e-04\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.6239e-04 - val_loss: 1.6073e-04\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.6375e-04 - val_loss: 1.8160e-04\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.5676e-04 - val_loss: 1.6601e-04\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.6953e-04 - val_loss: 1.7230e-04\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.5748e-04 - val_loss: 1.6988e-04\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.4700e-04 - val_loss: 1.6072e-04\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.5504e-04 - val_loss: 1.7711e-04\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.4700e-04 - val_loss: 1.3620e-04\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.6424e-04 - val_loss: 1.3004e-04\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.3182e-04 - val_loss: 2.2438e-04\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.4835e-04 - val_loss: 1.3402e-04\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.4356e-04 - val_loss: 1.4000e-04\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.3440e-04 - val_loss: 1.8915e-04\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.3922e-04 - val_loss: 1.6537e-04\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.3427e-04 - val_loss: 1.7518e-04\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.3844e-04 - val_loss: 1.7447e-04\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.3030e-04 - val_loss: 1.7271e-04\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.3222e-04 - val_loss: 1.8385e-04\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.2580e-04 - val_loss: 1.7037e-04\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.3140e-04 - val_loss: 1.7804e-04\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.1014e-04 - val_loss: 2.0194e-04\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.2241e-04 - val_loss: 1.6344e-04\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.2346e-04 - val_loss: 1.8437e-04\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.1055e-04 - val_loss: 1.4654e-04\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.0437e-04 - val_loss: 1.3673e-04\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.0025e-04 - val_loss: 1.8072e-04\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 9.1614e-04 - val_loss: 2.2760e-04\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 9.0795e-04 - val_loss: 1.6757e-04\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.0721e-04 - val_loss: 1.3714e-04\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 8.9687e-04 - val_loss: 1.6134e-04\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 8.8995e-04 - val_loss: 1.2643e-04\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 9.0341e-04 - val_loss: 1.5876e-04\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 8.8479e-04 - val_loss: 2.1763e-04\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.0064e-04 - val_loss: 1.1313e-04\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.8424e-04 - val_loss: 1.4948e-04\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.9315e-04 - val_loss: 1.2965e-04\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 8.8099e-04 - val_loss: 1.4468e-04\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 8.8369e-04 - val_loss: 1.4518e-04\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 8.6872e-04 - val_loss: 1.2332e-04\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.6286e-04 - val_loss: 1.2454e-04\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.6744e-04 - val_loss: 1.2697e-04\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.5840e-04 - val_loss: 1.3980e-04\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.5931e-04 - val_loss: 1.3680e-04\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.5280e-04 - val_loss: 1.2917e-04\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.5146e-04 - val_loss: 1.2759e-04\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.4621e-04 - val_loss: 1.0934e-04\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.4875e-04 - val_loss: 1.8617e-04\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.5948e-04 - val_loss: 1.2581e-04\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.4344e-04 - val_loss: 1.3002e-04\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.3408e-04 - val_loss: 1.2777e-04\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.3389e-04 - val_loss: 1.1650e-04\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.3721e-04 - val_loss: 8.1316e-05\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.4306e-04 - val_loss: 9.6466e-05\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.3842e-04 - val_loss: 1.5945e-04\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.3821e-04 - val_loss: 1.2726e-04\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.3622e-04 - val_loss: 1.3372e-04\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.1622e-04 - val_loss: 1.3016e-04\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.3792e-04 - val_loss: 2.0227e-04\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.2854e-04 - val_loss: 1.6838e-04\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.1186e-04 - val_loss: 1.0842e-04\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.0380e-04 - val_loss: 1.0873e-04\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 8.0459e-04 - val_loss: 1.7592e-04\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.9180e-04 - val_loss: 1.7844e-04\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.2039e-04 - val_loss: 1.1274e-04\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.8788e-04 - val_loss: 1.0768e-04\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.3635e-04 - val_loss: 1.5701e-04\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.8558e-04 - val_loss: 1.4027e-04\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.7950e-04 - val_loss: 1.1079e-04\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.9105e-04 - val_loss: 1.1816e-04\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 8ms/step - loss: 7.9813e-04 - val_loss: 1.2694e-04\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.0213e-04 - val_loss: 1.3811e-04\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.6283e-04 - val_loss: 1.0561e-04\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.6629e-04 - val_loss: 1.3000e-04\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.7403e-04 - val_loss: 1.4865e-04\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.8544e-04 - val_loss: 1.0068e-04\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.5254e-04 - val_loss: 1.4931e-04\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 7.5432e-04 - val_loss: 1.1683e-04\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.6110e-04 - val_loss: 1.0267e-04\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.4437e-04 - val_loss: 8.9854e-05\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.3380e-04 - val_loss: 1.1747e-04\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.3228e-04 - val_loss: 1.0941e-04\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.3660e-04 - val_loss: 1.3837e-04\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.4438e-04 - val_loss: 9.0781e-05\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.3141e-04 - val_loss: 1.6624e-04\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.6605e-04 - val_loss: 8.6127e-05\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.1010e-04 - val_loss: 9.4597e-05\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.2028e-04 - val_loss: 1.0370e-04\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.4040e-04 - val_loss: 1.0877e-04\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 6.9964e-04 - val_loss: 8.9616e-05\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.2686e-04 - val_loss: 8.5734e-05\n",
      "Thời gian huấn luyện:  26.35852360725403\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_5 (LSTM)               (None, 10, 100)           40800     \n",
      "                                                                 \n",
      " flatten_22 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,801\n",
      "Trainable params: 41,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 2s 17ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.0169\n",
      "Thời gian huấn luyện:  23.368433237075806\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_5 (GRU)                 (None, 10, 100)           30900     \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,901\n",
      "Trainable params: 31,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "39/39 [==============================] - 0s 869us/step\n",
      "26/26 [==============================] - 0s 880us/step\n",
      "39/39 [==============================] - 0s 1ms/step\n",
      "26/26 [==============================] - 0s 1ms/step\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1402 - val_loss: 0.0057\n",
      "Epoch 2/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.0405\n",
      "Epoch 3/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0284\n",
      "Epoch 4/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0224\n",
      "Epoch 5/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0176\n",
      "Epoch 6/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0138\n",
      "Epoch 7/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0106\n",
      "Epoch 8/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0080\n",
      "Epoch 9/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0060\n",
      "Epoch 10/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 11/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 12/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 13/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0023\n",
      "Epoch 14/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 9.1781e-04 - val_loss: 0.0019\n",
      "Epoch 15/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 8.3986e-04 - val_loss: 0.0016\n",
      "Epoch 16/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 7.9600e-04 - val_loss: 0.0014\n",
      "Epoch 17/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 7.6800e-04 - val_loss: 0.0012\n",
      "Epoch 18/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 7.4960e-04 - val_loss: 0.0010\n",
      "Epoch 19/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 7.4168e-04 - val_loss: 9.7308e-04\n",
      "Epoch 20/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 7.3306e-04 - val_loss: 8.8737e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 7.3184e-04 - val_loss: 7.9048e-04\n",
      "Epoch 22/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 7.2229e-04 - val_loss: 7.5045e-04\n",
      "Epoch 23/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 7.2130e-04 - val_loss: 6.9512e-04\n",
      "Epoch 24/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 7.1806e-04 - val_loss: 6.8455e-04\n",
      "Epoch 25/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 7.1421e-04 - val_loss: 6.4583e-04\n",
      "Epoch 26/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 7.1484e-04 - val_loss: 6.1709e-04\n",
      "Epoch 27/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 7.1294e-04 - val_loss: 6.2701e-04\n",
      "Epoch 28/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 7.1185e-04 - val_loss: 6.1761e-04\n",
      "Epoch 29/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 7.1069e-04 - val_loss: 5.6598e-04\n",
      "Epoch 30/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 7.0820e-04 - val_loss: 5.3740e-04\n",
      "Epoch 31/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 7.0500e-04 - val_loss: 5.5208e-04\n",
      "Epoch 32/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 7.0332e-04 - val_loss: 5.2551e-04\n",
      "Epoch 33/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 7.0041e-04 - val_loss: 5.4046e-04\n",
      "Epoch 34/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 7.0380e-04 - val_loss: 5.5957e-04\n",
      "Epoch 35/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 7.0370e-04 - val_loss: 4.9781e-04\n",
      "Epoch 36/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.9810e-04 - val_loss: 4.7935e-04\n",
      "Epoch 37/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.9972e-04 - val_loss: 4.8815e-04\n",
      "Epoch 38/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.9829e-04 - val_loss: 4.9608e-04\n",
      "Epoch 39/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.9336e-04 - val_loss: 4.7355e-04\n",
      "Epoch 40/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.9218e-04 - val_loss: 4.6694e-04\n",
      "Epoch 41/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.9182e-04 - val_loss: 4.4479e-04\n",
      "Epoch 42/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.8835e-04 - val_loss: 4.6121e-04\n",
      "Epoch 43/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.9409e-04 - val_loss: 4.2544e-04\n",
      "Epoch 44/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.8801e-04 - val_loss: 4.6071e-04\n",
      "Epoch 45/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.8644e-04 - val_loss: 4.2695e-04\n",
      "Epoch 46/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.8584e-04 - val_loss: 4.8672e-04\n",
      "Epoch 47/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.8785e-04 - val_loss: 4.2994e-04\n",
      "Epoch 48/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.8283e-04 - val_loss: 4.3471e-04\n",
      "Epoch 49/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.8378e-04 - val_loss: 4.4577e-04\n",
      "Epoch 50/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.7987e-04 - val_loss: 4.0232e-04\n",
      "Epoch 51/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.8069e-04 - val_loss: 4.0911e-04\n",
      "Epoch 52/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.7562e-04 - val_loss: 4.3830e-04\n",
      "Epoch 53/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.7623e-04 - val_loss: 4.3109e-04\n",
      "Epoch 54/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.7733e-04 - val_loss: 4.0981e-04\n",
      "Epoch 55/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.7312e-04 - val_loss: 4.2779e-04\n",
      "Epoch 56/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.7401e-04 - val_loss: 4.2036e-04\n",
      "Epoch 57/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.7264e-04 - val_loss: 3.9494e-04\n",
      "Epoch 58/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.7585e-04 - val_loss: 4.3434e-04\n",
      "Epoch 59/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.7126e-04 - val_loss: 3.9565e-04\n",
      "Epoch 60/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.6468e-04 - val_loss: 4.0399e-04\n",
      "Epoch 61/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.7072e-04 - val_loss: 3.8535e-04\n",
      "Epoch 62/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.6280e-04 - val_loss: 3.9084e-04\n",
      "Epoch 63/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.6303e-04 - val_loss: 3.6111e-04\n",
      "Epoch 64/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.6651e-04 - val_loss: 3.9157e-04\n",
      "Epoch 65/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.7108e-04 - val_loss: 4.3530e-04\n",
      "Epoch 66/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.5695e-04 - val_loss: 3.6410e-04\n",
      "Epoch 67/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.6028e-04 - val_loss: 3.7104e-04\n",
      "Epoch 68/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.5962e-04 - val_loss: 3.6262e-04\n",
      "Epoch 69/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.5708e-04 - val_loss: 3.8952e-04\n",
      "Epoch 70/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.5596e-04 - val_loss: 4.3861e-04\n",
      "Epoch 71/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.5863e-04 - val_loss: 4.0681e-04\n",
      "Epoch 72/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.5456e-04 - val_loss: 4.1958e-04\n",
      "Epoch 73/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.5193e-04 - val_loss: 3.7293e-04\n",
      "Epoch 74/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.4728e-04 - val_loss: 3.8018e-04\n",
      "Epoch 75/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.4763e-04 - val_loss: 3.5753e-04\n",
      "Epoch 76/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.4430e-04 - val_loss: 3.9488e-04\n",
      "Epoch 77/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.4645e-04 - val_loss: 3.7023e-04\n",
      "Epoch 78/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.3945e-04 - val_loss: 3.7896e-04\n",
      "Epoch 79/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.3761e-04 - val_loss: 3.7943e-04\n",
      "Epoch 80/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.3825e-04 - val_loss: 3.8493e-04\n",
      "Epoch 81/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.3608e-04 - val_loss: 3.8314e-04\n",
      "Epoch 82/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.3431e-04 - val_loss: 4.1193e-04\n",
      "Epoch 83/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.3604e-04 - val_loss: 3.9451e-04\n",
      "Epoch 84/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.3090e-04 - val_loss: 3.6463e-04\n",
      "Epoch 85/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.2882e-04 - val_loss: 3.4180e-04\n",
      "Epoch 86/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.3179e-04 - val_loss: 3.6409e-04\n",
      "Epoch 87/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.2706e-04 - val_loss: 3.6840e-04\n",
      "Epoch 88/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.2302e-04 - val_loss: 3.5400e-04\n",
      "Epoch 89/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.2340e-04 - val_loss: 3.6912e-04\n",
      "Epoch 90/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.1910e-04 - val_loss: 3.5902e-04\n",
      "Epoch 91/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.2092e-04 - val_loss: 3.6910e-04\n",
      "Epoch 92/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.2252e-04 - val_loss: 3.7627e-04\n",
      "Epoch 93/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.1414e-04 - val_loss: 3.5268e-04\n",
      "Epoch 94/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.1292e-04 - val_loss: 4.0563e-04\n",
      "Epoch 95/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.1061e-04 - val_loss: 3.8629e-04\n",
      "Epoch 96/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.1164e-04 - val_loss: 3.5408e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.0713e-04 - val_loss: 3.3238e-04\n",
      "Epoch 98/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.1535e-04 - val_loss: 3.7384e-04\n",
      "Epoch 99/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.0549e-04 - val_loss: 3.5258e-04\n",
      "Epoch 100/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.0289e-04 - val_loss: 3.5877e-04\n",
      "Epoch 101/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.0254e-04 - val_loss: 3.7990e-04\n",
      "Epoch 102/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.0238e-04 - val_loss: 3.8863e-04\n",
      "Epoch 103/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.0039e-04 - val_loss: 3.7335e-04\n",
      "Epoch 104/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.0153e-04 - val_loss: 3.7076e-04\n",
      "Epoch 105/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.1539e-04 - val_loss: 3.6821e-04\n",
      "Epoch 106/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.9314e-04 - val_loss: 3.3639e-04\n",
      "Epoch 107/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.9946e-04 - val_loss: 3.9746e-04\n",
      "Epoch 108/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.8823e-04 - val_loss: 3.4125e-04\n",
      "Epoch 109/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.9201e-04 - val_loss: 3.4136e-04\n",
      "Epoch 110/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.7885e-04 - val_loss: 3.9949e-04\n",
      "Epoch 111/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.8205e-04 - val_loss: 3.4280e-04\n",
      "Epoch 112/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.8331e-04 - val_loss: 3.3457e-04\n",
      "Epoch 113/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.7668e-04 - val_loss: 3.5619e-04\n",
      "Epoch 114/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.8137e-04 - val_loss: 3.7439e-04\n",
      "Epoch 115/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.7559e-04 - val_loss: 3.2841e-04\n",
      "Epoch 116/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.7372e-04 - val_loss: 3.4447e-04\n",
      "Epoch 117/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.7314e-04 - val_loss: 3.6460e-04\n",
      "Epoch 118/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.7460e-04 - val_loss: 3.4230e-04\n",
      "Epoch 119/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.6966e-04 - val_loss: 3.6958e-04\n",
      "Epoch 120/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.6747e-04 - val_loss: 3.2937e-04\n",
      "Epoch 121/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.6706e-04 - val_loss: 3.2130e-04\n",
      "Epoch 122/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.6429e-04 - val_loss: 3.6661e-04\n",
      "Epoch 123/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.5742e-04 - val_loss: 3.4211e-04\n",
      "Epoch 124/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.6241e-04 - val_loss: 3.3804e-04\n",
      "Epoch 125/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.5464e-04 - val_loss: 3.1659e-04\n",
      "Epoch 126/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.5938e-04 - val_loss: 3.0485e-04\n",
      "Epoch 127/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.4706e-04 - val_loss: 3.1103e-04\n",
      "Epoch 128/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.5196e-04 - val_loss: 3.2774e-04\n",
      "Epoch 129/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.4602e-04 - val_loss: 3.5477e-04\n",
      "Epoch 130/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.4245e-04 - val_loss: 3.4592e-04\n",
      "Epoch 131/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.4086e-04 - val_loss: 3.3904e-04\n",
      "Epoch 132/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.4307e-04 - val_loss: 3.7598e-04\n",
      "Epoch 133/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.4088e-04 - val_loss: 3.0374e-04\n",
      "Epoch 134/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.3602e-04 - val_loss: 3.3334e-04\n",
      "Epoch 135/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.3730e-04 - val_loss: 3.0128e-04\n",
      "Epoch 136/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.3404e-04 - val_loss: 3.2322e-04\n",
      "Epoch 137/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.2885e-04 - val_loss: 3.3072e-04\n",
      "Epoch 138/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.4134e-04 - val_loss: 3.7884e-04\n",
      "Epoch 139/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.2998e-04 - val_loss: 3.4171e-04\n",
      "Epoch 140/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.2337e-04 - val_loss: 3.1916e-04\n",
      "Epoch 141/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.2359e-04 - val_loss: 3.0561e-04\n",
      "Epoch 142/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.2613e-04 - val_loss: 2.9811e-04\n",
      "Epoch 143/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.2339e-04 - val_loss: 3.1109e-04\n",
      "Epoch 144/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.2746e-04 - val_loss: 3.2640e-04\n",
      "Epoch 145/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.1581e-04 - val_loss: 3.3635e-04\n",
      "Epoch 146/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.1137e-04 - val_loss: 2.9439e-04\n",
      "Epoch 147/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.1157e-04 - val_loss: 3.3651e-04\n",
      "Epoch 148/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.0910e-04 - val_loss: 3.0402e-04\n",
      "Epoch 149/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.0631e-04 - val_loss: 2.8361e-04\n",
      "Epoch 150/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.1020e-04 - val_loss: 2.9563e-04\n",
      "Epoch 151/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.0723e-04 - val_loss: 3.2488e-04\n",
      "Epoch 152/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.0239e-04 - val_loss: 3.2237e-04\n",
      "Epoch 153/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.0200e-04 - val_loss: 3.3591e-04\n",
      "Epoch 154/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.9843e-04 - val_loss: 3.0839e-04\n",
      "Epoch 155/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.9357e-04 - val_loss: 3.0027e-04\n",
      "Epoch 156/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.9397e-04 - val_loss: 2.9342e-04\n",
      "Epoch 157/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.9993e-04 - val_loss: 3.0047e-04\n",
      "Epoch 158/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.8862e-04 - val_loss: 2.9427e-04\n",
      "Epoch 159/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.8640e-04 - val_loss: 2.9683e-04\n",
      "Epoch 160/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.8617e-04 - val_loss: 2.8682e-04\n",
      "Epoch 161/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.8635e-04 - val_loss: 2.9864e-04\n",
      "Epoch 162/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.9744e-04 - val_loss: 2.5524e-04\n",
      "Epoch 163/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.0114e-04 - val_loss: 2.7692e-04\n",
      "Epoch 164/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.8166e-04 - val_loss: 3.2244e-04\n",
      "Epoch 165/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.7707e-04 - val_loss: 3.4321e-04\n",
      "Epoch 166/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.8431e-04 - val_loss: 2.6552e-04\n",
      "Epoch 167/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.7673e-04 - val_loss: 3.0553e-04\n",
      "Epoch 168/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.7375e-04 - val_loss: 2.8932e-04\n",
      "Epoch 169/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.7089e-04 - val_loss: 2.8703e-04\n",
      "Epoch 170/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.7028e-04 - val_loss: 3.0920e-04\n",
      "Epoch 171/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.6455e-04 - val_loss: 2.6673e-04\n",
      "Epoch 172/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 4.6154e-04 - val_loss: 3.3381e-04\n",
      "Epoch 173/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.7582e-04 - val_loss: 3.0413e-04\n",
      "Epoch 174/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.6184e-04 - val_loss: 2.7763e-04\n",
      "Epoch 175/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.5954e-04 - val_loss: 3.0041e-04\n",
      "Epoch 176/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.6202e-04 - val_loss: 2.5737e-04\n",
      "Epoch 177/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.5344e-04 - val_loss: 2.8687e-04\n",
      "Epoch 178/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.5358e-04 - val_loss: 2.5768e-04\n",
      "Epoch 179/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.5496e-04 - val_loss: 2.8254e-04\n",
      "Epoch 180/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.4915e-04 - val_loss: 2.7558e-04\n",
      "Epoch 181/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.5013e-04 - val_loss: 2.3742e-04\n",
      "Epoch 182/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.5066e-04 - val_loss: 2.5992e-04\n",
      "Epoch 183/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.5188e-04 - val_loss: 3.0366e-04\n",
      "Epoch 184/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.4520e-04 - val_loss: 2.6202e-04\n",
      "Epoch 185/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.4101e-04 - val_loss: 2.7288e-04\n",
      "Epoch 186/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.4096e-04 - val_loss: 2.8405e-04\n",
      "Epoch 187/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.4433e-04 - val_loss: 2.8706e-04\n",
      "Epoch 188/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.3513e-04 - val_loss: 2.5612e-04\n",
      "Epoch 189/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.4531e-04 - val_loss: 2.5273e-04\n",
      "Epoch 190/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.3985e-04 - val_loss: 2.4329e-04\n",
      "Epoch 191/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.2995e-04 - val_loss: 2.3126e-04\n",
      "Epoch 192/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.2913e-04 - val_loss: 2.9116e-04\n",
      "Epoch 193/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.2996e-04 - val_loss: 2.7381e-04\n",
      "Epoch 194/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.2487e-04 - val_loss: 2.5419e-04\n",
      "Epoch 195/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.2368e-04 - val_loss: 2.5662e-04\n",
      "Epoch 196/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.3546e-04 - val_loss: 2.3907e-04\n",
      "Epoch 197/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.3024e-04 - val_loss: 2.8682e-04\n",
      "Epoch 198/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 4.2549e-04 - val_loss: 2.7208e-04\n",
      "Epoch 199/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.2128e-04 - val_loss: 2.8394e-04\n",
      "Epoch 200/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.2105e-04 - val_loss: 2.4844e-04\n",
      "Thời gian huấn luyện:  13.787961721420288\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 10, 100)           200       \n",
      "                                                                 \n",
      " flatten_24 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,201\n",
      "Trainable params: 1,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "35/35 [==============================] - 1s 8ms/step - loss: 0.0305 - val_loss: 1.7193e-04\n",
      "Epoch 2/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 2.6510e-04\n",
      "Epoch 3/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 4.3442e-04\n",
      "Epoch 4/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 4.3135e-04\n",
      "Epoch 5/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 4.1082e-04\n",
      "Epoch 6/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 3.5108e-04\n",
      "Epoch 7/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 2.7347e-04\n",
      "Epoch 8/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 3.1383e-04\n",
      "Epoch 9/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 2.5892e-04\n",
      "Epoch 10/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 2.8719e-04\n",
      "Epoch 11/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 2.9133e-04\n",
      "Epoch 12/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 2.4647e-04\n",
      "Epoch 13/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 2.5092e-04\n",
      "Epoch 14/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 1.8245e-04\n",
      "Epoch 15/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 9.9898e-04 - val_loss: 2.1145e-04\n",
      "Epoch 16/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 9.6378e-04 - val_loss: 1.9507e-04\n",
      "Epoch 17/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 9.2248e-04 - val_loss: 1.5353e-04\n",
      "Epoch 18/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 9.1955e-04 - val_loss: 1.3851e-04\n",
      "Epoch 19/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 8.8797e-04 - val_loss: 1.6786e-04\n",
      "Epoch 20/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 8.4451e-04 - val_loss: 1.2195e-04\n",
      "Epoch 21/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 8.4907e-04 - val_loss: 1.5124e-04\n",
      "Epoch 22/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 8.1435e-04 - val_loss: 1.0008e-04\n",
      "Epoch 23/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 8.0638e-04 - val_loss: 8.7180e-05\n",
      "Epoch 24/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 7.7894e-04 - val_loss: 1.0331e-04\n",
      "Epoch 25/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 7.6065e-04 - val_loss: 8.7002e-05\n",
      "Epoch 26/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 7.4226e-04 - val_loss: 1.0174e-04\n",
      "Epoch 27/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 7.2995e-04 - val_loss: 9.9505e-05\n",
      "Epoch 28/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 7.3938e-04 - val_loss: 9.2384e-05\n",
      "Epoch 29/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 7.1759e-04 - val_loss: 7.6672e-05\n",
      "Epoch 30/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6.9753e-04 - val_loss: 7.1871e-05\n",
      "Epoch 31/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 7.1324e-04 - val_loss: 6.8399e-05\n",
      "Epoch 32/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6.8753e-04 - val_loss: 7.8365e-05\n",
      "Epoch 33/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6.5375e-04 - val_loss: 7.0246e-05\n",
      "Epoch 34/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6.8383e-04 - val_loss: 7.0830e-05\n",
      "Epoch 35/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6.4489e-04 - val_loss: 8.2048e-05\n",
      "Epoch 36/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6.7207e-04 - val_loss: 6.3961e-05\n",
      "Epoch 37/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6.3856e-04 - val_loss: 6.1387e-05\n",
      "Epoch 38/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.9424e-04 - val_loss: 5.9415e-05\n",
      "Epoch 39/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6.0056e-04 - val_loss: 6.1310e-05\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 6.4292e-04 - val_loss: 5.7823e-05\n",
      "Epoch 41/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6.0364e-04 - val_loss: 6.2197e-05\n",
      "Epoch 42/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6.1268e-04 - val_loss: 5.6606e-05\n",
      "Epoch 43/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 6.1871e-04 - val_loss: 5.7724e-05\n",
      "Epoch 44/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.5990e-04 - val_loss: 5.7456e-05\n",
      "Epoch 45/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.5107e-04 - val_loss: 5.7186e-05\n",
      "Epoch 46/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.5260e-04 - val_loss: 6.5158e-05\n",
      "Epoch 47/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.6082e-04 - val_loss: 5.3341e-05\n",
      "Epoch 48/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 5.6574e-04 - val_loss: 6.8765e-05\n",
      "Epoch 49/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 5.5514e-04 - val_loss: 5.2821e-05\n",
      "Epoch 50/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.3540e-04 - val_loss: 5.3264e-05\n",
      "Epoch 51/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.3806e-04 - val_loss: 5.1967e-05\n",
      "Epoch 52/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 5.6333e-04 - val_loss: 6.0560e-05\n",
      "Epoch 53/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 5.5118e-04 - val_loss: 5.8692e-05\n",
      "Epoch 54/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.0727e-04 - val_loss: 5.0187e-05\n",
      "Epoch 55/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.9452e-04 - val_loss: 5.2297e-05\n",
      "Epoch 56/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 4.9174e-04 - val_loss: 5.5332e-05\n",
      "Epoch 57/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.9875e-04 - val_loss: 7.2105e-05\n",
      "Epoch 58/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.1188e-04 - val_loss: 4.9584e-05\n",
      "Epoch 59/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 5.2939e-04 - val_loss: 4.7275e-05\n",
      "Epoch 60/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 4.7571e-04 - val_loss: 5.0009e-05\n",
      "Epoch 61/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 4.9014e-04 - val_loss: 4.7054e-05\n",
      "Epoch 62/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 4.6059e-04 - val_loss: 4.6583e-05\n",
      "Epoch 63/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 4.6067e-04 - val_loss: 5.4199e-05\n",
      "Epoch 64/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 4.6163e-04 - val_loss: 4.6440e-05\n",
      "Epoch 65/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.8367e-04 - val_loss: 4.5844e-05\n",
      "Epoch 66/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.8109e-04 - val_loss: 4.7226e-05\n",
      "Epoch 67/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.7403e-04 - val_loss: 4.6043e-05\n",
      "Epoch 68/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.7167e-04 - val_loss: 7.6212e-05\n",
      "Epoch 69/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.0197e-04 - val_loss: 4.7529e-05\n",
      "Epoch 70/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.4744e-04 - val_loss: 6.1802e-05\n",
      "Epoch 71/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 4.4366e-04 - val_loss: 4.2753e-05\n",
      "Epoch 72/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.2662e-04 - val_loss: 4.3398e-05\n",
      "Epoch 73/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.2868e-04 - val_loss: 5.5401e-05\n",
      "Epoch 74/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.2270e-04 - val_loss: 4.5176e-05\n",
      "Epoch 75/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.3809e-04 - val_loss: 4.9781e-05\n",
      "Epoch 76/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.6484e-04 - val_loss: 4.8739e-05\n",
      "Epoch 77/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.1451e-04 - val_loss: 7.4469e-05\n",
      "Epoch 78/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.7375e-04 - val_loss: 4.1933e-05\n",
      "Epoch 79/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.4294e-04 - val_loss: 4.0836e-05\n",
      "Epoch 80/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.4310e-04 - val_loss: 4.1026e-05\n",
      "Epoch 81/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.0478e-04 - val_loss: 5.0250e-05\n",
      "Epoch 82/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.9489e-04 - val_loss: 4.3360e-05\n",
      "Epoch 83/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.1605e-04 - val_loss: 4.9466e-05\n",
      "Epoch 84/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.9138e-04 - val_loss: 4.1255e-05\n",
      "Epoch 85/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.0723e-04 - val_loss: 4.3131e-05\n",
      "Epoch 86/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.0094e-04 - val_loss: 3.9430e-05\n",
      "Epoch 87/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.0921e-04 - val_loss: 3.7792e-05\n",
      "Epoch 88/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.8590e-04 - val_loss: 4.4592e-05\n",
      "Epoch 89/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.8875e-04 - val_loss: 3.7629e-05\n",
      "Epoch 90/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3.6342e-04 - val_loss: 3.8223e-05\n",
      "Epoch 91/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.9572e-04 - val_loss: 4.2520e-05\n",
      "Epoch 92/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.6986e-04 - val_loss: 4.1800e-05\n",
      "Epoch 93/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.0876e-04 - val_loss: 3.7264e-05\n",
      "Epoch 94/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.7757e-04 - val_loss: 3.9333e-05\n",
      "Epoch 95/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.0240e-04 - val_loss: 3.5636e-05\n",
      "Epoch 96/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.6116e-04 - val_loss: 3.5249e-05\n",
      "Epoch 97/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.4889e-04 - val_loss: 3.5945e-05\n",
      "Epoch 98/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.4966e-04 - val_loss: 3.9161e-05\n",
      "Epoch 99/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.5598e-04 - val_loss: 3.7472e-05\n",
      "Epoch 100/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.6942e-04 - val_loss: 3.3950e-05\n",
      "Epoch 101/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.6230e-04 - val_loss: 3.5699e-05\n",
      "Epoch 102/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.8048e-04 - val_loss: 4.1146e-05\n",
      "Epoch 103/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.4274e-04 - val_loss: 3.3765e-05\n",
      "Epoch 104/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.4925e-04 - val_loss: 3.4487e-05\n",
      "Epoch 105/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.4340e-04 - val_loss: 3.5898e-05\n",
      "Epoch 106/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.9513e-04 - val_loss: 3.6414e-05\n",
      "Epoch 107/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.6991e-04 - val_loss: 4.2640e-05\n",
      "Epoch 108/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.1083e-04 - val_loss: 4.0225e-05\n",
      "Epoch 109/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.8961e-04 - val_loss: 3.4179e-05\n",
      "Epoch 110/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.4046e-04 - val_loss: 3.4157e-05\n",
      "Epoch 111/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.2430e-04 - val_loss: 4.0353e-05\n",
      "Epoch 112/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.4523e-04 - val_loss: 3.1506e-05\n",
      "Epoch 113/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.2893e-04 - val_loss: 3.6129e-05\n",
      "Epoch 114/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.5675e-04 - val_loss: 3.1277e-05\n",
      "Epoch 115/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.2710e-04 - val_loss: 3.1376e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.2692e-04 - val_loss: 3.0869e-05\n",
      "Epoch 117/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.1572e-04 - val_loss: 3.1539e-05\n",
      "Epoch 118/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.2060e-04 - val_loss: 3.0397e-05\n",
      "Epoch 119/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.1574e-04 - val_loss: 3.4320e-05\n",
      "Epoch 120/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.2635e-04 - val_loss: 3.4507e-05\n",
      "Epoch 121/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.4991e-04 - val_loss: 2.9999e-05\n",
      "Epoch 122/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.0877e-04 - val_loss: 3.0093e-05\n",
      "Epoch 123/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.0828e-04 - val_loss: 3.5908e-05\n",
      "Epoch 124/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.9908e-04 - val_loss: 4.4154e-05\n",
      "Epoch 125/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.2198e-04 - val_loss: 3.7425e-05\n",
      "Epoch 126/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.1487e-04 - val_loss: 3.2629e-05\n",
      "Epoch 127/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.1844e-04 - val_loss: 2.9793e-05\n",
      "Epoch 128/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.0296e-04 - val_loss: 2.9173e-05\n",
      "Epoch 129/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.9770e-04 - val_loss: 2.8936e-05\n",
      "Epoch 130/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.3118e-04 - val_loss: 3.2797e-05\n",
      "Epoch 131/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.0301e-04 - val_loss: 3.7540e-05\n",
      "Epoch 132/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.7861e-04 - val_loss: 2.9711e-05\n",
      "Epoch 133/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.2626e-04 - val_loss: 2.9320e-05\n",
      "Epoch 134/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.8364e-04 - val_loss: 2.8796e-05\n",
      "Epoch 135/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.9977e-04 - val_loss: 2.7920e-05\n",
      "Epoch 136/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.9883e-04 - val_loss: 2.7877e-05\n",
      "Epoch 137/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.0186e-04 - val_loss: 3.2325e-05\n",
      "Epoch 138/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.1260e-04 - val_loss: 2.7400e-05\n",
      "Epoch 139/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.0191e-04 - val_loss: 3.2420e-05\n",
      "Epoch 140/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.7352e-04 - val_loss: 2.7458e-05\n",
      "Epoch 141/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.8793e-04 - val_loss: 2.7431e-05\n",
      "Epoch 142/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.8111e-04 - val_loss: 2.6852e-05\n",
      "Epoch 143/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.7341e-04 - val_loss: 2.7772e-05\n",
      "Epoch 144/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.7045e-04 - val_loss: 2.9611e-05\n",
      "Epoch 145/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.7030e-04 - val_loss: 2.6578e-05\n",
      "Epoch 146/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.1592e-04 - val_loss: 3.7324e-05\n",
      "Epoch 147/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3.2541e-04 - val_loss: 2.6809e-05\n",
      "Epoch 148/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3.0084e-04 - val_loss: 2.6419e-05\n",
      "Epoch 149/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2.8698e-04 - val_loss: 2.7081e-05\n",
      "Epoch 150/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2.7389e-04 - val_loss: 2.6391e-05\n",
      "Epoch 151/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.7290e-04 - val_loss: 2.8442e-05\n",
      "Epoch 152/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.7578e-04 - val_loss: 2.7251e-05\n",
      "Epoch 153/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3.0715e-04 - val_loss: 2.6540e-05\n",
      "Epoch 154/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3.0975e-04 - val_loss: 3.0464e-05\n",
      "Epoch 155/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2.7966e-04 - val_loss: 2.5914e-05\n",
      "Epoch 156/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2.7882e-04 - val_loss: 2.5794e-05\n",
      "Epoch 157/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2.7034e-04 - val_loss: 2.7613e-05\n",
      "Epoch 158/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.5019e-04 - val_loss: 4.4894e-05\n",
      "Epoch 159/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.7558e-04 - val_loss: 3.4145e-05\n",
      "Epoch 160/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.9200e-04 - val_loss: 2.5640e-05\n",
      "Epoch 161/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.4960e-04 - val_loss: 2.5228e-05\n",
      "Epoch 162/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.4903e-04 - val_loss: 2.6715e-05\n",
      "Epoch 163/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.8325e-04 - val_loss: 2.4968e-05\n",
      "Epoch 164/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.4991e-04 - val_loss: 2.5364e-05\n",
      "Epoch 165/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.5045e-04 - val_loss: 2.4292e-05\n",
      "Epoch 166/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.5999e-04 - val_loss: 2.6513e-05\n",
      "Epoch 167/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2.6092e-04 - val_loss: 2.4452e-05\n",
      "Epoch 168/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.5677e-04 - val_loss: 3.7557e-05\n",
      "Epoch 169/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.9792e-04 - val_loss: 2.5250e-05\n",
      "Epoch 170/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.6069e-04 - val_loss: 2.9706e-05\n",
      "Epoch 171/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.3235e-04 - val_loss: 3.4668e-05\n",
      "Epoch 172/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.6060e-04 - val_loss: 2.5419e-05\n",
      "Epoch 173/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.8783e-04 - val_loss: 3.2296e-05\n",
      "Epoch 174/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.7599e-04 - val_loss: 2.9073e-05\n",
      "Epoch 175/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.6159e-04 - val_loss: 2.4511e-05\n",
      "Epoch 176/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.4709e-04 - val_loss: 2.4901e-05\n",
      "Epoch 177/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.4042e-04 - val_loss: 2.7609e-05\n",
      "Epoch 178/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.7583e-04 - val_loss: 2.3035e-05\n",
      "Epoch 179/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.4297e-04 - val_loss: 2.4731e-05\n",
      "Epoch 180/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.4483e-04 - val_loss: 2.5013e-05\n",
      "Epoch 181/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.4804e-04 - val_loss: 2.6529e-05\n",
      "Epoch 182/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.5419e-04 - val_loss: 2.7362e-05\n",
      "Epoch 183/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.3211e-04 - val_loss: 2.4624e-05\n",
      "Epoch 184/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.3102e-04 - val_loss: 2.2711e-05\n",
      "Epoch 185/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.4119e-04 - val_loss: 2.2964e-05\n",
      "Epoch 186/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.5133e-04 - val_loss: 2.2525e-05\n",
      "Epoch 187/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.4229e-04 - val_loss: 2.8086e-05\n",
      "Epoch 188/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.5796e-04 - val_loss: 2.6030e-05\n",
      "Epoch 189/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.3495e-04 - val_loss: 2.2117e-05\n",
      "Epoch 190/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.5061e-04 - val_loss: 2.2400e-05\n",
      "Epoch 191/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 2.7401e-04 - val_loss: 2.2460e-05\n",
      "Epoch 192/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.5425e-04 - val_loss: 2.2461e-05\n",
      "Epoch 193/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.2531e-04 - val_loss: 2.4365e-05\n",
      "Epoch 194/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.3501e-04 - val_loss: 2.3360e-05\n",
      "Epoch 195/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.1527e-04 - val_loss: 2.3913e-05\n",
      "Epoch 196/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.4470e-04 - val_loss: 2.7798e-05\n",
      "Epoch 197/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.4422e-04 - val_loss: 2.1971e-05\n",
      "Epoch 198/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.2366e-04 - val_loss: 2.3178e-05\n",
      "Epoch 199/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.2942e-04 - val_loss: 2.1342e-05\n",
      "Epoch 200/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.2673e-04 - val_loss: 2.2580e-05\n",
      "Thời gian huấn luyện:  24.056790590286255\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_6 (SimpleRNN)    (None, 10, 100)           10200     \n",
      "                                                                 \n",
      " flatten_25 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,201\n",
      "Trainable params: 11,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "35/35 [==============================] - 2s 17ms/step - loss: 0.0345 - val_loss: 0.0011\n",
      "Epoch 2/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 3/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 5.3417e-04\n",
      "Epoch 4/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.9455e-04 - val_loss: 2.8329e-04\n",
      "Epoch 5/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.8170e-04 - val_loss: 2.2275e-04\n",
      "Epoch 6/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.7033e-04 - val_loss: 1.9770e-04\n",
      "Epoch 7/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.7299e-04 - val_loss: 1.9857e-04\n",
      "Epoch 8/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.7346e-04 - val_loss: 1.8640e-04\n",
      "Epoch 9/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.8827e-04 - val_loss: 2.3422e-04\n",
      "Epoch 10/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.8129e-04 - val_loss: 1.5848e-04\n",
      "Epoch 11/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.6697e-04 - val_loss: 2.0516e-04\n",
      "Epoch 12/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.6261e-04 - val_loss: 1.6723e-04\n",
      "Epoch 13/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.6179e-04 - val_loss: 1.7393e-04\n",
      "Epoch 14/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.5179e-04 - val_loss: 1.6981e-04\n",
      "Epoch 15/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.5290e-04 - val_loss: 1.9124e-04\n",
      "Epoch 16/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.5179e-04 - val_loss: 1.9439e-04\n",
      "Epoch 17/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.4324e-04 - val_loss: 1.7153e-04\n",
      "Epoch 18/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.5517e-04 - val_loss: 1.6729e-04\n",
      "Epoch 19/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.4732e-04 - val_loss: 2.1095e-04\n",
      "Epoch 20/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.4600e-04 - val_loss: 1.8071e-04\n",
      "Epoch 21/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.3650e-04 - val_loss: 1.5010e-04\n",
      "Epoch 22/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.3796e-04 - val_loss: 1.5982e-04\n",
      "Epoch 23/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.3529e-04 - val_loss: 1.4920e-04\n",
      "Epoch 24/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.4177e-04 - val_loss: 1.6727e-04\n",
      "Epoch 25/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.4759e-04 - val_loss: 1.6633e-04\n",
      "Epoch 26/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.2276e-04 - val_loss: 1.9707e-04\n",
      "Epoch 27/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.2993e-04 - val_loss: 1.7770e-04\n",
      "Epoch 28/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.3084e-04 - val_loss: 1.9384e-04\n",
      "Epoch 29/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.3128e-04 - val_loss: 1.5002e-04\n",
      "Epoch 30/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.2414e-04 - val_loss: 1.6477e-04\n",
      "Epoch 31/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.2075e-04 - val_loss: 1.3121e-04\n",
      "Epoch 32/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.1828e-04 - val_loss: 1.5126e-04\n",
      "Epoch 33/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.1395e-04 - val_loss: 1.5816e-04\n",
      "Epoch 34/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.1052e-04 - val_loss: 1.4822e-04\n",
      "Epoch 35/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.0595e-04 - val_loss: 1.4319e-04\n",
      "Epoch 36/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.0098e-04 - val_loss: 1.2767e-04\n",
      "Epoch 37/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.1412e-04 - val_loss: 1.4254e-04\n",
      "Epoch 38/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.0541e-04 - val_loss: 1.2247e-04\n",
      "Epoch 39/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.0187e-04 - val_loss: 1.3864e-04\n",
      "Epoch 40/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.9747e-04 - val_loss: 1.3920e-04\n",
      "Epoch 41/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.9269e-04 - val_loss: 1.3971e-04\n",
      "Epoch 42/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.9317e-04 - val_loss: 1.2434e-04\n",
      "Epoch 43/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.9020e-04 - val_loss: 1.6170e-04\n",
      "Epoch 44/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.9282e-04 - val_loss: 1.2486e-04\n",
      "Epoch 45/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.8895e-04 - val_loss: 1.6281e-04\n",
      "Epoch 46/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.1359e-04 - val_loss: 1.3167e-04\n",
      "Epoch 47/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.9427e-04 - val_loss: 1.5482e-04\n",
      "Epoch 48/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.1125e-04 - val_loss: 1.1723e-04\n",
      "Epoch 49/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.6423e-04 - val_loss: 1.1766e-04\n",
      "Epoch 50/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.8986e-04 - val_loss: 1.2794e-04\n",
      "Epoch 51/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 7.6823e-04 - val_loss: 1.1641e-04\n",
      "Epoch 52/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.6631e-04 - val_loss: 1.8351e-04\n",
      "Epoch 53/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.6513e-04 - val_loss: 1.1391e-04\n",
      "Epoch 54/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 7.8895e-04 - val_loss: 1.5883e-04\n",
      "Epoch 55/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 7.6722e-04 - val_loss: 1.3354e-04\n",
      "Epoch 56/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 7.5595e-04 - val_loss: 1.0531e-04\n",
      "Epoch 57/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 7.7939e-04 - val_loss: 1.0515e-04\n",
      "Epoch 58/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.6071e-04 - val_loss: 1.2236e-04\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 7.6058e-04 - val_loss: 1.3834e-04\n",
      "Epoch 60/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 7.5443e-04 - val_loss: 1.1902e-04\n",
      "Epoch 61/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.4238e-04 - val_loss: 1.4372e-04\n",
      "Epoch 62/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.3561e-04 - val_loss: 1.3373e-04\n",
      "Epoch 63/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 7.5131e-04 - val_loss: 1.4678e-04\n",
      "Epoch 64/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.4369e-04 - val_loss: 8.7015e-05\n",
      "Epoch 65/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.6990e-04 - val_loss: 1.5978e-04\n",
      "Epoch 66/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.2747e-04 - val_loss: 1.1400e-04\n",
      "Epoch 67/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.2170e-04 - val_loss: 1.1234e-04\n",
      "Epoch 68/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.1676e-04 - val_loss: 1.3915e-04\n",
      "Epoch 69/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.5348e-04 - val_loss: 1.5514e-04\n",
      "Epoch 70/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 7.7104e-04 - val_loss: 9.9110e-05\n",
      "Epoch 71/200\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 7.1025e-04 - val_loss: 1.1529e-04\n",
      "Epoch 72/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.1142e-04 - val_loss: 1.0728e-04\n",
      "Epoch 73/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.0199e-04 - val_loss: 1.2277e-04\n",
      "Epoch 74/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.0909e-04 - val_loss: 1.2420e-04\n",
      "Epoch 75/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.0452e-04 - val_loss: 8.7638e-05\n",
      "Epoch 76/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.1302e-04 - val_loss: 1.0784e-04\n",
      "Epoch 77/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 6.9845e-04 - val_loss: 1.0586e-04\n",
      "Epoch 78/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 7.1330e-04 - val_loss: 9.8309e-05\n",
      "Epoch 79/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.0533e-04 - val_loss: 1.0197e-04\n",
      "Epoch 80/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 7.0803e-04 - val_loss: 1.0294e-04\n",
      "Epoch 81/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 6.8874e-04 - val_loss: 1.0247e-04\n",
      "Epoch 82/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.2573e-04 - val_loss: 1.1515e-04\n",
      "Epoch 83/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 6.7698e-04 - val_loss: 9.8345e-05\n",
      "Epoch 84/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.6946e-04 - val_loss: 1.4184e-04\n",
      "Epoch 85/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.8244e-04 - val_loss: 8.5334e-05\n",
      "Epoch 86/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.6163e-04 - val_loss: 9.5596e-05\n",
      "Epoch 87/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.6715e-04 - val_loss: 9.6673e-05\n",
      "Epoch 88/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.6680e-04 - val_loss: 9.9958e-05\n",
      "Epoch 89/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.6453e-04 - val_loss: 1.0968e-04\n",
      "Epoch 90/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.7811e-04 - val_loss: 7.6682e-05\n",
      "Epoch 91/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 6.7203e-04 - val_loss: 1.0577e-04\n",
      "Epoch 92/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.4972e-04 - val_loss: 9.9069e-05\n",
      "Epoch 93/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.3997e-04 - val_loss: 7.9399e-05\n",
      "Epoch 94/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.6578e-04 - val_loss: 8.6127e-05\n",
      "Epoch 95/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.5515e-04 - val_loss: 1.0155e-04\n",
      "Epoch 96/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.3307e-04 - val_loss: 9.6872e-05\n",
      "Epoch 97/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.3115e-04 - val_loss: 7.4511e-05\n",
      "Epoch 98/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.8948e-04 - val_loss: 1.0801e-04\n",
      "Epoch 99/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.6089e-04 - val_loss: 8.1828e-05\n",
      "Epoch 100/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 6.2027e-04 - val_loss: 7.8421e-05\n",
      "Epoch 101/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.2766e-04 - val_loss: 8.5021e-05\n",
      "Epoch 102/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.2235e-04 - val_loss: 9.3885e-05\n",
      "Epoch 103/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.3521e-04 - val_loss: 9.4290e-05\n",
      "Epoch 104/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.2182e-04 - val_loss: 7.6005e-05\n",
      "Epoch 105/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.2800e-04 - val_loss: 1.1486e-04\n",
      "Epoch 106/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.6119e-04 - val_loss: 1.2659e-04\n",
      "Epoch 107/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.2526e-04 - val_loss: 1.0903e-04\n",
      "Epoch 108/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.1808e-04 - val_loss: 8.6763e-05\n",
      "Epoch 109/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.9928e-04 - val_loss: 8.6358e-05\n",
      "Epoch 110/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.0391e-04 - val_loss: 8.3832e-05\n",
      "Epoch 111/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.9828e-04 - val_loss: 9.3630e-05\n",
      "Epoch 112/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.1290e-04 - val_loss: 7.4365e-05\n",
      "Epoch 113/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.9416e-04 - val_loss: 7.1527e-05\n",
      "Epoch 114/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.0504e-04 - val_loss: 7.7662e-05\n",
      "Epoch 115/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 5.9881e-04 - val_loss: 1.0217e-04\n",
      "Epoch 116/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.9077e-04 - val_loss: 7.7100e-05\n",
      "Epoch 117/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.8165e-04 - val_loss: 7.9749e-05\n",
      "Epoch 118/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.7557e-04 - val_loss: 6.7773e-05\n",
      "Epoch 119/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.7158e-04 - val_loss: 6.6081e-05\n",
      "Epoch 120/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.8550e-04 - val_loss: 7.7537e-05\n",
      "Epoch 121/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.7643e-04 - val_loss: 7.4438e-05\n",
      "Epoch 122/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.7700e-04 - val_loss: 7.6030e-05\n",
      "Epoch 123/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.8073e-04 - val_loss: 6.8774e-05\n",
      "Epoch 124/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.7390e-04 - val_loss: 7.9950e-05\n",
      "Epoch 125/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.6072e-04 - val_loss: 7.2381e-05\n",
      "Epoch 126/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.5933e-04 - val_loss: 6.2438e-05\n",
      "Epoch 127/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.4806e-04 - val_loss: 8.4184e-05\n",
      "Epoch 128/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.5577e-04 - val_loss: 6.5143e-05\n",
      "Epoch 129/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.9729e-04 - val_loss: 6.1257e-05\n",
      "Epoch 130/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.7726e-04 - val_loss: 6.1781e-05\n",
      "Epoch 131/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.5505e-04 - val_loss: 7.3963e-05\n",
      "Epoch 132/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.5703e-04 - val_loss: 8.5318e-05\n",
      "Epoch 133/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.4211e-04 - val_loss: 7.5030e-05\n",
      "Epoch 134/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 7ms/step - loss: 5.4446e-04 - val_loss: 6.0060e-05\n",
      "Epoch 135/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.4879e-04 - val_loss: 6.8653e-05\n",
      "Epoch 136/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.3366e-04 - val_loss: 6.7840e-05\n",
      "Epoch 137/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.2938e-04 - val_loss: 6.8839e-05\n",
      "Epoch 138/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.3665e-04 - val_loss: 6.5588e-05\n",
      "Epoch 139/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.2993e-04 - val_loss: 6.0890e-05\n",
      "Epoch 140/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.3039e-04 - val_loss: 8.0452e-05\n",
      "Epoch 141/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.2054e-04 - val_loss: 7.0637e-05\n",
      "Epoch 142/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.2151e-04 - val_loss: 6.8452e-05\n",
      "Epoch 143/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.2270e-04 - val_loss: 5.8759e-05\n",
      "Epoch 144/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.1788e-04 - val_loss: 5.7372e-05\n",
      "Epoch 145/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.2149e-04 - val_loss: 7.8142e-05\n",
      "Epoch 146/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.1770e-04 - val_loss: 7.7658e-05\n",
      "Epoch 147/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.9763e-04 - val_loss: 6.3130e-05\n",
      "Epoch 148/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.0740e-04 - val_loss: 5.9898e-05\n",
      "Epoch 149/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.1486e-04 - val_loss: 5.6445e-05\n",
      "Epoch 150/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.5980e-04 - val_loss: 5.6311e-05\n",
      "Epoch 151/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.2435e-04 - val_loss: 5.8375e-05\n",
      "Epoch 152/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.1178e-04 - val_loss: 5.6122e-05\n",
      "Epoch 153/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.0150e-04 - val_loss: 5.5377e-05\n",
      "Epoch 154/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.2285e-04 - val_loss: 6.4845e-05\n",
      "Epoch 155/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.0981e-04 - val_loss: 8.9809e-05\n",
      "Epoch 156/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.1399e-04 - val_loss: 6.5247e-05\n",
      "Epoch 157/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.0170e-04 - val_loss: 6.6397e-05\n",
      "Epoch 158/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.1809e-04 - val_loss: 7.1363e-05\n",
      "Epoch 159/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.3104e-04 - val_loss: 7.7248e-05\n",
      "Epoch 160/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.0748e-04 - val_loss: 5.8959e-05\n",
      "Epoch 161/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.0303e-04 - val_loss: 6.0214e-05\n",
      "Epoch 162/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.0921e-04 - val_loss: 5.5870e-05\n",
      "Epoch 163/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.7886e-04 - val_loss: 5.4528e-05\n",
      "Epoch 164/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.9192e-04 - val_loss: 6.0233e-05\n",
      "Epoch 165/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.5589e-04 - val_loss: 5.5658e-05\n",
      "Epoch 166/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.7402e-04 - val_loss: 5.6673e-05\n",
      "Epoch 167/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.8206e-04 - val_loss: 5.3915e-05\n",
      "Epoch 168/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.0289e-04 - val_loss: 5.3998e-05\n",
      "Epoch 169/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.9886e-04 - val_loss: 5.8431e-05\n",
      "Epoch 170/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.9466e-04 - val_loss: 5.4153e-05\n",
      "Epoch 171/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.8944e-04 - val_loss: 7.7035e-05\n",
      "Epoch 172/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.0389e-04 - val_loss: 6.0048e-05\n",
      "Epoch 173/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.8680e-04 - val_loss: 7.7549e-05\n",
      "Epoch 174/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.7608e-04 - val_loss: 6.1794e-05\n",
      "Epoch 175/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.6453e-04 - val_loss: 5.7890e-05\n",
      "Epoch 176/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.6099e-04 - val_loss: 8.0900e-05\n",
      "Epoch 177/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.0001e-04 - val_loss: 6.5295e-05\n",
      "Epoch 178/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.6887e-04 - val_loss: 5.8263e-05\n",
      "Epoch 179/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.6563e-04 - val_loss: 5.7455e-05\n",
      "Epoch 180/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.5960e-04 - val_loss: 6.0404e-05\n",
      "Epoch 181/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.7704e-04 - val_loss: 5.6752e-05\n",
      "Epoch 182/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.7286e-04 - val_loss: 5.2251e-05\n",
      "Epoch 183/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.8959e-04 - val_loss: 5.1843e-05\n",
      "Epoch 184/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.4889e-04 - val_loss: 8.2043e-05\n",
      "Epoch 185/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.9376e-04 - val_loss: 7.0838e-05\n",
      "Epoch 186/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.5767e-04 - val_loss: 6.2422e-05\n",
      "Epoch 187/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.5614e-04 - val_loss: 5.3998e-05\n",
      "Epoch 188/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.6470e-04 - val_loss: 5.6173e-05\n",
      "Epoch 189/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.6286e-04 - val_loss: 5.1281e-05\n",
      "Epoch 190/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.5483e-04 - val_loss: 5.7936e-05\n",
      "Epoch 191/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.4066e-04 - val_loss: 5.5335e-05\n",
      "Epoch 192/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.5055e-04 - val_loss: 5.1042e-05\n",
      "Epoch 193/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.4056e-04 - val_loss: 5.2636e-05\n",
      "Epoch 194/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.4690e-04 - val_loss: 5.8355e-05\n",
      "Epoch 195/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.4841e-04 - val_loss: 5.3780e-05\n",
      "Epoch 196/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.5489e-04 - val_loss: 6.1914e-05\n",
      "Epoch 197/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.4510e-04 - val_loss: 5.1611e-05\n",
      "Epoch 198/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.3787e-04 - val_loss: 6.8932e-05\n",
      "Epoch 199/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.4862e-04 - val_loss: 5.8480e-05\n",
      "Epoch 200/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.3024e-04 - val_loss: 6.6623e-05\n",
      "Thời gian huấn luyện:  52.23644018173218\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 10, 100)           40800     \n",
      "                                                                 \n",
      " flatten_26 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,801\n",
      "Trainable params: 41,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 2s 16ms/step - loss: 0.0258 - val_loss: 0.0011\n",
      "Epoch 2/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 5.2354e-04\n",
      "Epoch 3/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.8764e-04 - val_loss: 1.7296e-04\n",
      "Epoch 4/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.0128e-04 - val_loss: 1.1372e-04\n",
      "Epoch 5/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.9263e-04 - val_loss: 8.8155e-05\n",
      "Epoch 6/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.9730e-04 - val_loss: 9.8071e-05\n",
      "Epoch 7/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.8590e-04 - val_loss: 1.2009e-04\n",
      "Epoch 8/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.7594e-04 - val_loss: 8.7654e-05\n",
      "Epoch 9/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.6927e-04 - val_loss: 1.0165e-04\n",
      "Epoch 10/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.7504e-04 - val_loss: 8.6271e-05\n",
      "Epoch 11/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.6678e-04 - val_loss: 8.4540e-05\n",
      "Epoch 12/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.6404e-04 - val_loss: 8.6750e-05\n",
      "Epoch 13/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.6211e-04 - val_loss: 8.2781e-05\n",
      "Epoch 14/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.6259e-04 - val_loss: 1.0062e-04\n",
      "Epoch 15/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.9636e-04 - val_loss: 9.4382e-05\n",
      "Epoch 16/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.4183e-04 - val_loss: 9.9413e-05\n",
      "Epoch 17/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.4180e-04 - val_loss: 8.1244e-05\n",
      "Epoch 18/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.5424e-04 - val_loss: 9.4948e-05\n",
      "Epoch 19/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.3796e-04 - val_loss: 8.6378e-05\n",
      "Epoch 20/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.3624e-04 - val_loss: 8.2420e-05\n",
      "Epoch 21/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.3872e-04 - val_loss: 8.1148e-05\n",
      "Epoch 22/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.5418e-04 - val_loss: 8.9189e-05\n",
      "Epoch 23/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.2442e-04 - val_loss: 1.0302e-04\n",
      "Epoch 24/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.1123e-04 - val_loss: 8.5317e-05\n",
      "Epoch 25/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.1003e-04 - val_loss: 9.4844e-05\n",
      "Epoch 26/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.1711e-04 - val_loss: 8.2731e-05\n",
      "Epoch 27/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.1146e-04 - val_loss: 7.7813e-05\n",
      "Epoch 28/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.0518e-04 - val_loss: 8.8023e-05\n",
      "Epoch 29/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.9261e-04 - val_loss: 8.1455e-05\n",
      "Epoch 30/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.8813e-04 - val_loss: 8.1385e-05\n",
      "Epoch 31/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.7884e-04 - val_loss: 7.8306e-05\n",
      "Epoch 32/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.7798e-04 - val_loss: 7.7391e-05\n",
      "Epoch 33/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.8486e-04 - val_loss: 7.6803e-05\n",
      "Epoch 34/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.6743e-04 - val_loss: 7.3654e-05\n",
      "Epoch 35/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.6106e-04 - val_loss: 7.7357e-05\n",
      "Epoch 36/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.5767e-04 - val_loss: 7.2261e-05\n",
      "Epoch 37/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.5263e-04 - val_loss: 7.6274e-05\n",
      "Epoch 38/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.5269e-04 - val_loss: 8.9177e-05\n",
      "Epoch 39/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 6.4400e-04 - val_loss: 7.2943e-05\n",
      "Epoch 40/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 6.4692e-04 - val_loss: 7.8689e-05\n",
      "Epoch 41/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.3429e-04 - val_loss: 7.0548e-05\n",
      "Epoch 42/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.3391e-04 - val_loss: 7.2306e-05\n",
      "Epoch 43/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.2649e-04 - val_loss: 7.3098e-05\n",
      "Epoch 44/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.2304e-04 - val_loss: 7.3439e-05\n",
      "Epoch 45/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.1720e-04 - val_loss: 6.8724e-05\n",
      "Epoch 46/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.2474e-04 - val_loss: 7.3222e-05\n",
      "Epoch 47/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.0516e-04 - val_loss: 6.6656e-05\n",
      "Epoch 48/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.0259e-04 - val_loss: 6.8333e-05\n",
      "Epoch 49/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.1231e-04 - val_loss: 8.7361e-05\n",
      "Epoch 50/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.1173e-04 - val_loss: 8.0977e-05\n",
      "Epoch 51/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 6.0066e-04 - val_loss: 6.4722e-05\n",
      "Epoch 52/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 5.9044e-04 - val_loss: 6.8519e-05\n",
      "Epoch 53/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 5.9198e-04 - val_loss: 7.1062e-05\n",
      "Epoch 54/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.8183e-04 - val_loss: 6.6026e-05\n",
      "Epoch 55/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.8263e-04 - val_loss: 6.3713e-05\n",
      "Epoch 56/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 5.8784e-04 - val_loss: 7.0609e-05\n",
      "Epoch 57/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.6219e-04 - val_loss: 6.6250e-05\n",
      "Epoch 58/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 5.5749e-04 - val_loss: 6.0840e-05\n",
      "Epoch 59/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.7075e-04 - val_loss: 6.8934e-05\n",
      "Epoch 60/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.5060e-04 - val_loss: 6.7972e-05\n",
      "Epoch 61/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.4207e-04 - val_loss: 8.3180e-05\n",
      "Epoch 62/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.4806e-04 - val_loss: 5.9495e-05\n",
      "Epoch 63/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.4435e-04 - val_loss: 6.4908e-05\n",
      "Epoch 64/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.4437e-04 - val_loss: 6.3312e-05\n",
      "Epoch 65/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.3922e-04 - val_loss: 5.7391e-05\n",
      "Epoch 66/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.3062e-04 - val_loss: 6.3961e-05\n",
      "Epoch 67/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.4015e-04 - val_loss: 6.2283e-05\n",
      "Epoch 68/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.2912e-04 - val_loss: 6.2204e-05\n",
      "Epoch 69/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.3181e-04 - val_loss: 6.2272e-05\n",
      "Epoch 70/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.1615e-04 - val_loss: 6.0040e-05\n",
      "Epoch 71/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.4585e-04 - val_loss: 6.5059e-05\n",
      "Epoch 72/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.1726e-04 - val_loss: 6.2576e-05\n",
      "Epoch 73/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.9847e-04 - val_loss: 5.6146e-05\n",
      "Epoch 74/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.1074e-04 - val_loss: 7.8114e-05\n",
      "Epoch 75/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 5.0222e-04 - val_loss: 5.4406e-05\n",
      "Epoch 76/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.9420e-04 - val_loss: 8.1210e-05\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 7ms/step - loss: 4.9500e-04 - val_loss: 5.2641e-05\n",
      "Epoch 78/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.7957e-04 - val_loss: 5.1293e-05\n",
      "Epoch 79/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.8128e-04 - val_loss: 5.4384e-05\n",
      "Epoch 80/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.7668e-04 - val_loss: 5.4841e-05\n",
      "Epoch 81/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.7472e-04 - val_loss: 5.3748e-05\n",
      "Epoch 82/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.7566e-04 - val_loss: 5.0255e-05\n",
      "Epoch 83/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.7059e-04 - val_loss: 5.0376e-05\n",
      "Epoch 84/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.6010e-04 - val_loss: 4.8756e-05\n",
      "Epoch 85/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.6228e-04 - val_loss: 5.6107e-05\n",
      "Epoch 86/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.6227e-04 - val_loss: 4.8633e-05\n",
      "Epoch 87/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.5228e-04 - val_loss: 4.9811e-05\n",
      "Epoch 88/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.4911e-04 - val_loss: 4.8965e-05\n",
      "Epoch 89/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.3396e-04 - val_loss: 4.9029e-05\n",
      "Epoch 90/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.4760e-04 - val_loss: 4.7329e-05\n",
      "Epoch 91/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.6583e-04 - val_loss: 4.6631e-05\n",
      "Epoch 92/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.4902e-04 - val_loss: 5.4342e-05\n",
      "Epoch 93/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.4856e-04 - val_loss: 4.5804e-05\n",
      "Epoch 94/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.2613e-04 - val_loss: 4.5322e-05\n",
      "Epoch 95/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.3603e-04 - val_loss: 4.4876e-05\n",
      "Epoch 96/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.2624e-04 - val_loss: 4.6522e-05\n",
      "Epoch 97/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.1786e-04 - val_loss: 4.6249e-05\n",
      "Epoch 98/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.1922e-04 - val_loss: 4.4112e-05\n",
      "Epoch 99/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.0632e-04 - val_loss: 4.3763e-05\n",
      "Epoch 100/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.0499e-04 - val_loss: 4.3600e-05\n",
      "Epoch 101/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.0854e-04 - val_loss: 4.3558e-05\n",
      "Epoch 102/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.9946e-04 - val_loss: 4.6058e-05\n",
      "Epoch 103/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.0410e-04 - val_loss: 4.2776e-05\n",
      "Epoch 104/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.0072e-04 - val_loss: 4.4493e-05\n",
      "Epoch 105/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.1169e-04 - val_loss: 4.3658e-05\n",
      "Epoch 106/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 4.1962e-04 - val_loss: 4.7074e-05\n",
      "Epoch 107/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.8495e-04 - val_loss: 4.1805e-05\n",
      "Epoch 108/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.9655e-04 - val_loss: 4.1601e-05\n",
      "Epoch 109/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.8699e-04 - val_loss: 4.3793e-05\n",
      "Epoch 110/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.8827e-04 - val_loss: 4.0996e-05\n",
      "Epoch 111/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.8937e-04 - val_loss: 4.1166e-05\n",
      "Epoch 112/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.8270e-04 - val_loss: 4.1499e-05\n",
      "Epoch 113/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.7245e-04 - val_loss: 4.6485e-05\n",
      "Epoch 114/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.9249e-04 - val_loss: 4.2147e-05\n",
      "Epoch 115/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.7018e-04 - val_loss: 4.9423e-05\n",
      "Epoch 116/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.7749e-04 - val_loss: 5.3351e-05\n",
      "Epoch 117/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.6418e-04 - val_loss: 4.8909e-05\n",
      "Epoch 118/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.8856e-04 - val_loss: 4.0104e-05\n",
      "Epoch 119/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.7193e-04 - val_loss: 4.1530e-05\n",
      "Epoch 120/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.7593e-04 - val_loss: 3.9106e-05\n",
      "Epoch 121/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.6370e-04 - val_loss: 3.9216e-05\n",
      "Epoch 122/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.7458e-04 - val_loss: 4.3632e-05\n",
      "Epoch 123/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.5831e-04 - val_loss: 3.9417e-05\n",
      "Epoch 124/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.5317e-04 - val_loss: 3.8261e-05\n",
      "Epoch 125/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.5420e-04 - val_loss: 3.9360e-05\n",
      "Epoch 126/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.5749e-04 - val_loss: 4.6422e-05\n",
      "Epoch 127/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.7715e-04 - val_loss: 3.8685e-05\n",
      "Epoch 128/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.6821e-04 - val_loss: 3.7515e-05\n",
      "Epoch 129/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.4140e-04 - val_loss: 4.0631e-05\n",
      "Epoch 130/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.7358e-04 - val_loss: 4.3047e-05\n",
      "Epoch 131/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.6434e-04 - val_loss: 3.7162e-05\n",
      "Epoch 132/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.5460e-04 - val_loss: 3.7438e-05\n",
      "Epoch 133/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.4348e-04 - val_loss: 4.2566e-05\n",
      "Epoch 134/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.4055e-04 - val_loss: 3.7492e-05\n",
      "Epoch 135/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.4791e-04 - val_loss: 3.7893e-05\n",
      "Epoch 136/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.3812e-04 - val_loss: 3.6453e-05\n",
      "Epoch 137/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.5013e-04 - val_loss: 3.6986e-05\n",
      "Epoch 138/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.4806e-04 - val_loss: 3.9055e-05\n",
      "Epoch 139/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.3344e-04 - val_loss: 4.7169e-05\n",
      "Epoch 140/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.3413e-04 - val_loss: 3.6032e-05\n",
      "Epoch 141/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.3072e-04 - val_loss: 3.8225e-05\n",
      "Epoch 142/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.3995e-04 - val_loss: 3.7611e-05\n",
      "Epoch 143/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.4703e-04 - val_loss: 4.1511e-05\n",
      "Epoch 144/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.2306e-04 - val_loss: 5.3185e-05\n",
      "Epoch 145/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.2750e-04 - val_loss: 3.5844e-05\n",
      "Epoch 146/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.1918e-04 - val_loss: 3.7773e-05\n",
      "Epoch 147/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.3529e-04 - val_loss: 3.5114e-05\n",
      "Epoch 148/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.2599e-04 - val_loss: 4.9749e-05\n",
      "Epoch 149/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.1333e-04 - val_loss: 3.7028e-05\n",
      "Epoch 150/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.2998e-04 - val_loss: 3.5308e-05\n",
      "Epoch 151/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.1669e-04 - val_loss: 3.5116e-05\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 8ms/step - loss: 3.4215e-04 - val_loss: 3.4452e-05\n",
      "Epoch 153/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.1185e-04 - val_loss: 3.4110e-05\n",
      "Epoch 154/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.1737e-04 - val_loss: 3.3949e-05\n",
      "Epoch 155/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.0451e-04 - val_loss: 3.5264e-05\n",
      "Epoch 156/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.0877e-04 - val_loss: 5.4758e-05\n",
      "Epoch 157/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.1477e-04 - val_loss: 3.5588e-05\n",
      "Epoch 158/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.0319e-04 - val_loss: 3.3606e-05\n",
      "Epoch 159/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.0267e-04 - val_loss: 3.3410e-05\n",
      "Epoch 160/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.1144e-04 - val_loss: 3.3451e-05\n",
      "Epoch 161/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.0314e-04 - val_loss: 4.0387e-05\n",
      "Epoch 162/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.1113e-04 - val_loss: 3.5499e-05\n",
      "Epoch 163/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.0097e-04 - val_loss: 3.3691e-05\n",
      "Epoch 164/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.0137e-04 - val_loss: 3.6898e-05\n",
      "Epoch 165/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.0600e-04 - val_loss: 3.7266e-05\n",
      "Epoch 166/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.9525e-04 - val_loss: 3.2787e-05\n",
      "Epoch 167/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.0507e-04 - val_loss: 3.4595e-05\n",
      "Epoch 168/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.9220e-04 - val_loss: 3.5488e-05\n",
      "Epoch 169/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.1711e-04 - val_loss: 3.2659e-05\n",
      "Epoch 170/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.0726e-04 - val_loss: 3.2240e-05\n",
      "Epoch 171/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.8831e-04 - val_loss: 3.2624e-05\n",
      "Epoch 172/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.9014e-04 - val_loss: 3.1974e-05\n",
      "Epoch 173/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.8664e-04 - val_loss: 3.9257e-05\n",
      "Epoch 174/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.0652e-04 - val_loss: 3.6159e-05\n",
      "Epoch 175/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.8119e-04 - val_loss: 3.7152e-05\n",
      "Epoch 176/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.0853e-04 - val_loss: 3.4848e-05\n",
      "Epoch 177/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.8552e-04 - val_loss: 3.2072e-05\n",
      "Epoch 178/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.8128e-04 - val_loss: 3.9746e-05\n",
      "Epoch 179/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.9221e-04 - val_loss: 3.5083e-05\n",
      "Epoch 180/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.8808e-04 - val_loss: 3.8528e-05\n",
      "Epoch 181/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.8384e-04 - val_loss: 3.1727e-05\n",
      "Epoch 182/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.9879e-04 - val_loss: 4.2184e-05\n",
      "Epoch 183/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.9749e-04 - val_loss: 3.4101e-05\n",
      "Epoch 184/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.8828e-04 - val_loss: 3.1335e-05\n",
      "Epoch 185/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.8457e-04 - val_loss: 3.6789e-05\n",
      "Epoch 186/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.7287e-04 - val_loss: 3.7020e-05\n",
      "Epoch 187/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.7235e-04 - val_loss: 3.0859e-05\n",
      "Epoch 188/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.7424e-04 - val_loss: 3.8601e-05\n",
      "Epoch 189/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.7177e-04 - val_loss: 3.0365e-05\n",
      "Epoch 190/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.7493e-04 - val_loss: 4.2934e-05\n",
      "Epoch 191/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.6963e-04 - val_loss: 3.0041e-05\n",
      "Epoch 192/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.7032e-04 - val_loss: 3.0533e-05\n",
      "Epoch 193/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.6166e-04 - val_loss: 3.0929e-05\n",
      "Epoch 194/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.7104e-04 - val_loss: 3.6289e-05\n",
      "Epoch 195/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.0524e-04 - val_loss: 3.4310e-05\n",
      "Epoch 196/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.8051e-04 - val_loss: 3.0073e-05\n",
      "Epoch 197/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.6091e-04 - val_loss: 3.0901e-05\n",
      "Epoch 198/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.8456e-04 - val_loss: 2.9527e-05\n",
      "Epoch 199/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.7205e-04 - val_loss: 2.9397e-05\n",
      "Epoch 200/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 2.6282e-04 - val_loss: 3.5902e-05\n",
      "Thời gian huấn luyện:  50.53013586997986\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_6 (GRU)                 (None, 10, 100)           30900     \n",
      "                                                                 \n",
      " flatten_27 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,901\n",
      "Trainable params: 31,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "39/39 [==============================] - 0s 921us/step\n",
      "26/26 [==============================] - 0s 1ms/step\n",
      "39/39 [==============================] - 0s 1ms/step\n",
      "26/26 [==============================] - 0s 1ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.1340 - val_loss: 0.0092\n",
      "Epoch 2/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0389\n",
      "Epoch 3/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0262\n",
      "Epoch 4/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0214\n",
      "Epoch 5/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0172\n",
      "Epoch 6/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0137\n",
      "Epoch 7/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0109\n",
      "Epoch 8/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0082\n",
      "Epoch 9/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0065\n",
      "Epoch 10/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 11/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 12/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 13/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 14/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 15/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.9173e-04 - val_loss: 0.0011\n",
      "Epoch 16/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.1994e-04 - val_loss: 8.2373e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.7398e-04 - val_loss: 6.5448e-04\n",
      "Epoch 18/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.4691e-04 - val_loss: 5.5940e-04\n",
      "Epoch 19/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.3245e-04 - val_loss: 4.8745e-04\n",
      "Epoch 20/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.2063e-04 - val_loss: 4.0153e-04\n",
      "Epoch 21/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.1584e-04 - val_loss: 3.5848e-04\n",
      "Epoch 22/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.0884e-04 - val_loss: 3.5558e-04\n",
      "Epoch 23/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.0528e-04 - val_loss: 2.9203e-04\n",
      "Epoch 24/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.0453e-04 - val_loss: 2.9884e-04\n",
      "Epoch 25/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.0313e-04 - val_loss: 2.6791e-04\n",
      "Epoch 26/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.9927e-04 - val_loss: 2.5808e-04\n",
      "Epoch 27/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.0021e-04 - val_loss: 2.5462e-04\n",
      "Epoch 28/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.9858e-04 - val_loss: 2.2302e-04\n",
      "Epoch 29/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.9642e-04 - val_loss: 2.3563e-04\n",
      "Epoch 30/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.9378e-04 - val_loss: 2.1891e-04\n",
      "Epoch 31/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.9380e-04 - val_loss: 2.2081e-04\n",
      "Epoch 32/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.9407e-04 - val_loss: 2.2401e-04\n",
      "Epoch 33/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.9113e-04 - val_loss: 1.9423e-04\n",
      "Epoch 34/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.9246e-04 - val_loss: 2.0290e-04\n",
      "Epoch 35/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.8812e-04 - val_loss: 1.9570e-04\n",
      "Epoch 36/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.8910e-04 - val_loss: 1.7723e-04\n",
      "Epoch 37/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.8775e-04 - val_loss: 1.7594e-04\n",
      "Epoch 38/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.8777e-04 - val_loss: 1.8913e-04\n",
      "Epoch 39/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.8434e-04 - val_loss: 1.8409e-04\n",
      "Epoch 40/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.8300e-04 - val_loss: 1.6835e-04\n",
      "Epoch 41/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.8179e-04 - val_loss: 1.7123e-04\n",
      "Epoch 42/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.8490e-04 - val_loss: 1.6662e-04\n",
      "Epoch 43/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.8805e-04 - val_loss: 1.6839e-04\n",
      "Epoch 44/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.8083e-04 - val_loss: 1.5231e-04\n",
      "Epoch 45/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.7810e-04 - val_loss: 1.6304e-04\n",
      "Epoch 46/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.8060e-04 - val_loss: 1.6730e-04\n",
      "Epoch 47/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.7441e-04 - val_loss: 1.5107e-04\n",
      "Epoch 48/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.7348e-04 - val_loss: 1.4457e-04\n",
      "Epoch 49/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.7668e-04 - val_loss: 1.5211e-04\n",
      "Epoch 50/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.7657e-04 - val_loss: 1.5551e-04\n",
      "Epoch 51/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.7060e-04 - val_loss: 1.4566e-04\n",
      "Epoch 52/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.6851e-04 - val_loss: 1.5035e-04\n",
      "Epoch 53/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.6752e-04 - val_loss: 1.5851e-04\n",
      "Epoch 54/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.6767e-04 - val_loss: 1.5545e-04\n",
      "Epoch 55/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.6557e-04 - val_loss: 1.3456e-04\n",
      "Epoch 56/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.7098e-04 - val_loss: 1.5302e-04\n",
      "Epoch 57/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.6304e-04 - val_loss: 1.3761e-04\n",
      "Epoch 58/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.6809e-04 - val_loss: 1.3747e-04\n",
      "Epoch 59/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.6078e-04 - val_loss: 1.3731e-04\n",
      "Epoch 60/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.6003e-04 - val_loss: 1.3775e-04\n",
      "Epoch 61/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.5975e-04 - val_loss: 1.4053e-04\n",
      "Epoch 62/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.5767e-04 - val_loss: 1.1805e-04\n",
      "Epoch 63/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.5622e-04 - val_loss: 1.5330e-04\n",
      "Epoch 64/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.5702e-04 - val_loss: 1.2557e-04\n",
      "Epoch 65/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.5407e-04 - val_loss: 1.3768e-04\n",
      "Epoch 66/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.5656e-04 - val_loss: 1.4661e-04\n",
      "Epoch 67/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.5386e-04 - val_loss: 1.3081e-04\n",
      "Epoch 68/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.5064e-04 - val_loss: 1.3375e-04\n",
      "Epoch 69/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.4703e-04 - val_loss: 1.2682e-04\n",
      "Epoch 70/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.4888e-04 - val_loss: 1.3221e-04\n",
      "Epoch 71/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.5576e-04 - val_loss: 1.2236e-04\n",
      "Epoch 72/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.4214e-04 - val_loss: 1.3674e-04\n",
      "Epoch 73/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.4425e-04 - val_loss: 1.2257e-04\n",
      "Epoch 74/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.4625e-04 - val_loss: 1.3819e-04\n",
      "Epoch 75/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.3947e-04 - val_loss: 1.1119e-04\n",
      "Epoch 76/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.4369e-04 - val_loss: 1.1603e-04\n",
      "Epoch 77/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.3558e-04 - val_loss: 1.4027e-04\n",
      "Epoch 78/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.3796e-04 - val_loss: 1.1564e-04\n",
      "Epoch 79/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.3327e-04 - val_loss: 1.1983e-04\n",
      "Epoch 80/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.3170e-04 - val_loss: 1.3074e-04\n",
      "Epoch 81/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.3272e-04 - val_loss: 1.3988e-04\n",
      "Epoch 82/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.3118e-04 - val_loss: 1.1619e-04\n",
      "Epoch 83/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.2894e-04 - val_loss: 1.2128e-04\n",
      "Epoch 84/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.2412e-04 - val_loss: 1.2042e-04\n",
      "Epoch 85/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.2940e-04 - val_loss: 1.2335e-04\n",
      "Epoch 86/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.2682e-04 - val_loss: 1.0919e-04\n",
      "Epoch 87/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.2344e-04 - val_loss: 1.1226e-04\n",
      "Epoch 88/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.2032e-04 - val_loss: 1.1008e-04\n",
      "Epoch 89/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.2276e-04 - val_loss: 1.2044e-04\n",
      "Epoch 90/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.1637e-04 - val_loss: 1.0485e-04\n",
      "Epoch 91/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.1527e-04 - val_loss: 1.1019e-04\n",
      "Epoch 92/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.1744e-04 - val_loss: 1.1708e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.1029e-04 - val_loss: 1.0732e-04\n",
      "Epoch 94/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.1162e-04 - val_loss: 1.0715e-04\n",
      "Epoch 95/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.0940e-04 - val_loss: 1.1279e-04\n",
      "Epoch 96/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.0521e-04 - val_loss: 1.1799e-04\n",
      "Epoch 97/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.0496e-04 - val_loss: 1.1536e-04\n",
      "Epoch 98/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.0099e-04 - val_loss: 1.2759e-04\n",
      "Epoch 99/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.0555e-04 - val_loss: 1.3262e-04\n",
      "Epoch 100/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.0374e-04 - val_loss: 1.0545e-04\n",
      "Epoch 101/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.0778e-04 - val_loss: 1.1817e-04\n",
      "Epoch 102/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.9735e-04 - val_loss: 1.2023e-04\n",
      "Epoch 103/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.9248e-04 - val_loss: 1.0896e-04\n",
      "Epoch 104/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.9256e-04 - val_loss: 1.0262e-04\n",
      "Epoch 105/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.0044e-04 - val_loss: 1.1863e-04\n",
      "Epoch 106/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.8738e-04 - val_loss: 1.0554e-04\n",
      "Epoch 107/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.8603e-04 - val_loss: 1.0036e-04\n",
      "Epoch 108/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.8341e-04 - val_loss: 1.2948e-04\n",
      "Epoch 109/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.8471e-04 - val_loss: 1.0057e-04\n",
      "Epoch 110/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.8209e-04 - val_loss: 1.0057e-04\n",
      "Epoch 111/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.8333e-04 - val_loss: 1.0006e-04\n",
      "Epoch 112/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.8070e-04 - val_loss: 1.0529e-04\n",
      "Epoch 113/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.7450e-04 - val_loss: 1.1672e-04\n",
      "Epoch 114/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.8652e-04 - val_loss: 9.5504e-05\n",
      "Epoch 115/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.7362e-04 - val_loss: 1.1292e-04\n",
      "Epoch 116/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.7150e-04 - val_loss: 1.0389e-04\n",
      "Epoch 117/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.6935e-04 - val_loss: 1.0665e-04\n",
      "Epoch 118/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.7087e-04 - val_loss: 1.0997e-04\n",
      "Epoch 119/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.6463e-04 - val_loss: 1.0645e-04\n",
      "Epoch 120/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.7680e-04 - val_loss: 9.6799e-05\n",
      "Epoch 121/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.8397e-04 - val_loss: 1.0179e-04\n",
      "Epoch 122/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.5734e-04 - val_loss: 9.3594e-05\n",
      "Epoch 123/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.5948e-04 - val_loss: 1.3684e-04\n",
      "Epoch 124/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.7262e-04 - val_loss: 1.1440e-04\n",
      "Epoch 125/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.5756e-04 - val_loss: 1.0889e-04\n",
      "Epoch 126/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.5128e-04 - val_loss: 9.3728e-05\n",
      "Epoch 127/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.5123e-04 - val_loss: 1.0462e-04\n",
      "Epoch 128/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.5014e-04 - val_loss: 9.6607e-05\n",
      "Epoch 129/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.4479e-04 - val_loss: 9.2352e-05\n",
      "Epoch 130/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.5105e-04 - val_loss: 1.0249e-04\n",
      "Epoch 131/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.4188e-04 - val_loss: 9.3808e-05\n",
      "Epoch 132/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.4239e-04 - val_loss: 1.0893e-04\n",
      "Epoch 133/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.3763e-04 - val_loss: 9.5397e-05\n",
      "Epoch 134/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.4081e-04 - val_loss: 9.1631e-05\n",
      "Epoch 135/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.4198e-04 - val_loss: 9.5129e-05\n",
      "Epoch 136/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.3207e-04 - val_loss: 9.4403e-05\n",
      "Epoch 137/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.3737e-04 - val_loss: 1.0439e-04\n",
      "Epoch 138/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.2654e-04 - val_loss: 1.0245e-04\n",
      "Epoch 139/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.2852e-04 - val_loss: 9.9711e-05\n",
      "Epoch 140/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.2789e-04 - val_loss: 1.0745e-04\n",
      "Epoch 141/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.2440e-04 - val_loss: 1.1292e-04\n",
      "Epoch 142/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.2576e-04 - val_loss: 9.0525e-05\n",
      "Epoch 143/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.2597e-04 - val_loss: 9.0851e-05\n",
      "Epoch 144/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.1741e-04 - val_loss: 9.3957e-05\n",
      "Epoch 145/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.1912e-04 - val_loss: 9.5998e-05\n",
      "Epoch 146/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.1461e-04 - val_loss: 1.0057e-04\n",
      "Epoch 147/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.1406e-04 - val_loss: 8.8798e-05\n",
      "Epoch 148/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.1412e-04 - val_loss: 1.0184e-04\n",
      "Epoch 149/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.0811e-04 - val_loss: 9.2788e-05\n",
      "Epoch 150/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.0635e-04 - val_loss: 9.0215e-05\n",
      "Epoch 151/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.0198e-04 - val_loss: 1.3476e-04\n",
      "Epoch 152/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.0361e-04 - val_loss: 9.0706e-05\n",
      "Epoch 153/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.0473e-04 - val_loss: 8.7049e-05\n",
      "Epoch 154/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.0635e-04 - val_loss: 8.4378e-05\n",
      "Epoch 155/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.0790e-04 - val_loss: 8.4853e-05\n",
      "Epoch 156/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.1401e-04 - val_loss: 8.7724e-05\n",
      "Epoch 157/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.9549e-04 - val_loss: 8.6955e-05\n",
      "Epoch 158/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.0278e-04 - val_loss: 8.3773e-05\n",
      "Epoch 159/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.9540e-04 - val_loss: 8.7790e-05\n",
      "Epoch 160/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.8963e-04 - val_loss: 9.2300e-05\n",
      "Epoch 161/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.8775e-04 - val_loss: 9.1099e-05\n",
      "Epoch 162/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.8742e-04 - val_loss: 8.5975e-05\n",
      "Epoch 163/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.8452e-04 - val_loss: 1.1616e-04\n",
      "Epoch 164/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.8141e-04 - val_loss: 9.2456e-05\n",
      "Epoch 165/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.7744e-04 - val_loss: 9.1346e-05\n",
      "Epoch 166/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.7580e-04 - val_loss: 8.9767e-05\n",
      "Epoch 167/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.7944e-04 - val_loss: 8.2709e-05\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 2ms/step - loss: 4.7643e-04 - val_loss: 9.6589e-05\n",
      "Epoch 169/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.7678e-04 - val_loss: 1.0432e-04\n",
      "Epoch 170/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.7052e-04 - val_loss: 8.0022e-05\n",
      "Epoch 171/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.8340e-04 - val_loss: 8.1707e-05\n",
      "Epoch 172/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.6453e-04 - val_loss: 9.2433e-05\n",
      "Epoch 173/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.6337e-04 - val_loss: 8.6402e-05\n",
      "Epoch 174/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.6563e-04 - val_loss: 1.1111e-04\n",
      "Epoch 175/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.6717e-04 - val_loss: 9.4540e-05\n",
      "Epoch 176/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.6472e-04 - val_loss: 7.8491e-05\n",
      "Epoch 177/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.6250e-04 - val_loss: 8.4524e-05\n",
      "Epoch 178/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.5721e-04 - val_loss: 9.3938e-05\n",
      "Epoch 179/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.5916e-04 - val_loss: 8.2106e-05\n",
      "Epoch 180/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.5136e-04 - val_loss: 1.0294e-04\n",
      "Epoch 181/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.5232e-04 - val_loss: 8.0964e-05\n",
      "Epoch 182/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.5083e-04 - val_loss: 8.6023e-05\n",
      "Epoch 183/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.5027e-04 - val_loss: 9.1659e-05\n",
      "Epoch 184/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.4526e-04 - val_loss: 8.1310e-05\n",
      "Epoch 185/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.4996e-04 - val_loss: 9.3019e-05\n",
      "Epoch 186/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.4535e-04 - val_loss: 8.0821e-05\n",
      "Epoch 187/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.3973e-04 - val_loss: 8.9049e-05\n",
      "Epoch 188/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.3748e-04 - val_loss: 8.2701e-05\n",
      "Epoch 189/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.3659e-04 - val_loss: 7.7697e-05\n",
      "Epoch 190/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.4755e-04 - val_loss: 8.1599e-05\n",
      "Epoch 191/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.3210e-04 - val_loss: 7.7718e-05\n",
      "Epoch 192/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.3131e-04 - val_loss: 7.4794e-05\n",
      "Epoch 193/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.3211e-04 - val_loss: 8.0104e-05\n",
      "Epoch 194/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.3056e-04 - val_loss: 9.5191e-05\n",
      "Epoch 195/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.3211e-04 - val_loss: 8.1623e-05\n",
      "Epoch 196/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.2620e-04 - val_loss: 7.5288e-05\n",
      "Epoch 197/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.2462e-04 - val_loss: 8.9822e-05\n",
      "Epoch 198/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.2134e-04 - val_loss: 8.5377e-05\n",
      "Epoch 199/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.2965e-04 - val_loss: 7.1342e-05\n",
      "Epoch 200/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.1902e-04 - val_loss: 7.8530e-05\n",
      "Thời gian huấn luyện:  14.253999948501587\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_35 (Dense)            (None, 10, 100)           200       \n",
      "                                                                 \n",
      " flatten_28 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,201\n",
      "Trainable params: 1,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "33/33 [==============================] - 1s 9ms/step - loss: 0.0187 - val_loss: 1.6171e-04\n",
      "Epoch 2/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 2.7047e-04\n",
      "Epoch 3/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 3.5033e-04\n",
      "Epoch 4/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 2.7217e-04\n",
      "Epoch 5/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 2.3197e-04\n",
      "Epoch 6/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 3.0307e-04\n",
      "Epoch 7/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 2.9489e-04\n",
      "Epoch 8/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 2.9442e-04\n",
      "Epoch 9/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 2.1274e-04\n",
      "Epoch 10/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 2.8713e-04\n",
      "Epoch 11/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 2.2700e-04\n",
      "Epoch 12/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 9.9682e-04 - val_loss: 2.1221e-04\n",
      "Epoch 13/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 9.3933e-04 - val_loss: 1.9553e-04\n",
      "Epoch 14/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 9.2822e-04 - val_loss: 1.5723e-04\n",
      "Epoch 15/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.8772e-04 - val_loss: 1.4378e-04\n",
      "Epoch 16/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.5143e-04 - val_loss: 1.4540e-04\n",
      "Epoch 17/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.4715e-04 - val_loss: 1.3009e-04\n",
      "Epoch 18/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.0880e-04 - val_loss: 1.2587e-04\n",
      "Epoch 19/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 7.6457e-04 - val_loss: 1.6440e-04\n",
      "Epoch 20/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 7.4160e-04 - val_loss: 1.1235e-04\n",
      "Epoch 21/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.9636e-04 - val_loss: 1.1142e-04\n",
      "Epoch 22/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.9066e-04 - val_loss: 9.9203e-05\n",
      "Epoch 23/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.6486e-04 - val_loss: 6.9334e-05\n",
      "Epoch 24/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.6968e-04 - val_loss: 9.9309e-05\n",
      "Epoch 25/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 6.3409e-04 - val_loss: 7.4324e-05\n",
      "Epoch 26/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 6.0807e-04 - val_loss: 7.3624e-05\n",
      "Epoch 27/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.0825e-04 - val_loss: 5.1419e-05\n",
      "Epoch 28/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.4426e-04 - val_loss: 5.6923e-05\n",
      "Epoch 29/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.8171e-04 - val_loss: 5.4681e-05\n",
      "Epoch 30/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 5.7690e-04 - val_loss: 5.0571e-05\n",
      "Epoch 31/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.4509e-04 - val_loss: 4.6011e-05\n",
      "Epoch 32/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.6236e-04 - val_loss: 5.0967e-05\n",
      "Epoch 33/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.4996e-04 - val_loss: 4.4775e-05\n",
      "Epoch 34/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.2135e-04 - val_loss: 4.5872e-05\n",
      "Epoch 35/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.3449e-04 - val_loss: 4.3459e-05\n",
      "Epoch 36/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 3ms/step - loss: 5.1001e-04 - val_loss: 5.0321e-05\n",
      "Epoch 37/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.4849e-04 - val_loss: 4.4168e-05\n",
      "Epoch 38/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.0764e-04 - val_loss: 4.9706e-05\n",
      "Epoch 39/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.9482e-04 - val_loss: 4.2139e-05\n",
      "Epoch 40/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.7777e-04 - val_loss: 4.3580e-05\n",
      "Epoch 41/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.0278e-04 - val_loss: 6.1405e-05\n",
      "Epoch 42/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.6670e-04 - val_loss: 4.0726e-05\n",
      "Epoch 43/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.1609e-04 - val_loss: 4.0795e-05\n",
      "Epoch 44/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.0198e-04 - val_loss: 5.3011e-05\n",
      "Epoch 45/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.8857e-04 - val_loss: 4.2835e-05\n",
      "Epoch 46/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 4.5846e-04 - val_loss: 4.7113e-05\n",
      "Epoch 47/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.7433e-04 - val_loss: 4.2283e-05\n",
      "Epoch 48/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.5913e-04 - val_loss: 4.2338e-05\n",
      "Epoch 49/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.4474e-04 - val_loss: 3.9772e-05\n",
      "Epoch 50/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.6665e-04 - val_loss: 4.3376e-05\n",
      "Epoch 51/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.5111e-04 - val_loss: 5.0980e-05\n",
      "Epoch 52/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.3079e-04 - val_loss: 3.8533e-05\n",
      "Epoch 53/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.5480e-04 - val_loss: 4.4054e-05\n",
      "Epoch 54/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.2005e-04 - val_loss: 3.6286e-05\n",
      "Epoch 55/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 4.2452e-04 - val_loss: 4.3979e-05\n",
      "Epoch 56/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.1862e-04 - val_loss: 4.5397e-05\n",
      "Epoch 57/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.2429e-04 - val_loss: 5.4471e-05\n",
      "Epoch 58/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.4775e-04 - val_loss: 3.4415e-05\n",
      "Epoch 59/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.0939e-04 - val_loss: 3.5031e-05\n",
      "Epoch 60/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.0141e-04 - val_loss: 4.4949e-05\n",
      "Epoch 61/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.9914e-04 - val_loss: 3.5449e-05\n",
      "Epoch 62/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.0859e-04 - val_loss: 3.4730e-05\n",
      "Epoch 63/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.1027e-04 - val_loss: 3.3999e-05\n",
      "Epoch 64/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.2418e-04 - val_loss: 3.4379e-05\n",
      "Epoch 65/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.0774e-04 - val_loss: 3.4133e-05\n",
      "Epoch 66/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.3034e-04 - val_loss: 3.4489e-05\n",
      "Epoch 67/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.9318e-04 - val_loss: 3.3129e-05\n",
      "Epoch 68/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.0251e-04 - val_loss: 3.2475e-05\n",
      "Epoch 69/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.0442e-04 - val_loss: 3.4733e-05\n",
      "Epoch 70/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.9462e-04 - val_loss: 3.2493e-05\n",
      "Epoch 71/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.9406e-04 - val_loss: 3.2036e-05\n",
      "Epoch 72/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 3.8446e-04 - val_loss: 4.2357e-05\n",
      "Epoch 73/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.6891e-04 - val_loss: 3.9268e-05\n",
      "Epoch 74/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.8815e-04 - val_loss: 3.1318e-05\n",
      "Epoch 75/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.6455e-04 - val_loss: 3.1861e-05\n",
      "Epoch 76/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.8579e-04 - val_loss: 3.5726e-05\n",
      "Epoch 77/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.7848e-04 - val_loss: 3.0754e-05\n",
      "Epoch 78/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.6273e-04 - val_loss: 3.0502e-05\n",
      "Epoch 79/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 3.5997e-04 - val_loss: 3.2247e-05\n",
      "Epoch 80/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 3.4651e-04 - val_loss: 3.5936e-05\n",
      "Epoch 81/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.6852e-04 - val_loss: 3.5069e-05\n",
      "Epoch 82/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.5732e-04 - val_loss: 3.1910e-05\n",
      "Epoch 83/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.5303e-04 - val_loss: 2.9874e-05\n",
      "Epoch 84/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.9675e-04 - val_loss: 2.9535e-05\n",
      "Epoch 85/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.5553e-04 - val_loss: 2.8792e-05\n",
      "Epoch 86/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 3.7448e-04 - val_loss: 2.9451e-05\n",
      "Epoch 87/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 3.9345e-04 - val_loss: 3.5586e-05\n",
      "Epoch 88/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.6339e-04 - val_loss: 2.9692e-05\n",
      "Epoch 89/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.3799e-04 - val_loss: 2.8529e-05\n",
      "Epoch 90/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.7385e-04 - val_loss: 3.0478e-05\n",
      "Epoch 91/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.4129e-04 - val_loss: 3.5309e-05\n",
      "Epoch 92/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.5460e-04 - val_loss: 3.0062e-05\n",
      "Epoch 93/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.9821e-04 - val_loss: 3.1406e-05\n",
      "Epoch 94/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.9048e-04 - val_loss: 2.9978e-05\n",
      "Epoch 95/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.4532e-04 - val_loss: 3.0147e-05\n",
      "Epoch 96/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.9070e-04 - val_loss: 3.3600e-05\n",
      "Epoch 97/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.2748e-04 - val_loss: 3.0681e-05\n",
      "Epoch 98/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.3662e-04 - val_loss: 3.2094e-05\n",
      "Epoch 99/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.6066e-04 - val_loss: 2.7440e-05\n",
      "Epoch 100/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.2899e-04 - val_loss: 3.0342e-05\n",
      "Epoch 101/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.3197e-04 - val_loss: 2.6830e-05\n",
      "Epoch 102/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.3668e-04 - val_loss: 2.7018e-05\n",
      "Epoch 103/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.4642e-04 - val_loss: 2.6582e-05\n",
      "Epoch 104/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.2558e-04 - val_loss: 2.7960e-05\n",
      "Epoch 105/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.3246e-04 - val_loss: 2.7674e-05\n",
      "Epoch 106/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.2437e-04 - val_loss: 2.8181e-05\n",
      "Epoch 107/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.4237e-04 - val_loss: 3.5267e-05\n",
      "Epoch 108/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.3566e-04 - val_loss: 2.7544e-05\n",
      "Epoch 109/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.3283e-04 - val_loss: 2.5568e-05\n",
      "Epoch 110/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.1018e-04 - val_loss: 3.5766e-05\n",
      "Epoch 111/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.3114e-04 - val_loss: 2.6985e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.1351e-04 - val_loss: 2.5281e-05\n",
      "Epoch 113/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 3.0679e-04 - val_loss: 2.6264e-05\n",
      "Epoch 114/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 3.3255e-04 - val_loss: 2.5255e-05\n",
      "Epoch 115/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.1742e-04 - val_loss: 2.9214e-05\n",
      "Epoch 116/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 3.1575e-04 - val_loss: 2.5886e-05\n",
      "Epoch 117/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.0979e-04 - val_loss: 3.0722e-05\n",
      "Epoch 118/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.1498e-04 - val_loss: 2.5192e-05\n",
      "Epoch 119/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.9616e-04 - val_loss: 2.4946e-05\n",
      "Epoch 120/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.0902e-04 - val_loss: 2.7033e-05\n",
      "Epoch 121/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.1724e-04 - val_loss: 3.3534e-05\n",
      "Epoch 122/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.1097e-04 - val_loss: 2.4185e-05\n",
      "Epoch 123/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.0132e-04 - val_loss: 2.5496e-05\n",
      "Epoch 124/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.1059e-04 - val_loss: 2.4112e-05\n",
      "Epoch 125/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 2.8960e-04 - val_loss: 2.4120e-05\n",
      "Epoch 126/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 2.9666e-04 - val_loss: 2.5936e-05\n",
      "Epoch 127/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.9420e-04 - val_loss: 2.6439e-05\n",
      "Epoch 128/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.8734e-04 - val_loss: 2.6207e-05\n",
      "Epoch 129/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.1679e-04 - val_loss: 2.4687e-05\n",
      "Epoch 130/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.5195e-04 - val_loss: 2.4664e-05\n",
      "Epoch 131/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.7981e-04 - val_loss: 2.3692e-05\n",
      "Epoch 132/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.2367e-04 - val_loss: 2.4880e-05\n",
      "Epoch 133/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.8347e-04 - val_loss: 2.3042e-05\n",
      "Epoch 134/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.9951e-04 - val_loss: 2.3076e-05\n",
      "Epoch 135/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.9026e-04 - val_loss: 2.3894e-05\n",
      "Epoch 136/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.8331e-04 - val_loss: 2.3232e-05\n",
      "Epoch 137/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.8336e-04 - val_loss: 2.5420e-05\n",
      "Epoch 138/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.0507e-04 - val_loss: 2.6136e-05\n",
      "Epoch 139/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.7419e-04 - val_loss: 2.2539e-05\n",
      "Epoch 140/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.7554e-04 - val_loss: 2.2660e-05\n",
      "Epoch 141/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.8835e-04 - val_loss: 2.2804e-05\n",
      "Epoch 142/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.7249e-04 - val_loss: 3.0589e-05\n",
      "Epoch 143/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.0767e-04 - val_loss: 2.5979e-05\n",
      "Epoch 144/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.7340e-04 - val_loss: 2.2393e-05\n",
      "Epoch 145/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.8188e-04 - val_loss: 2.4313e-05\n",
      "Epoch 146/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.2610e-04 - val_loss: 2.3596e-05\n",
      "Epoch 147/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.7473e-04 - val_loss: 2.2431e-05\n",
      "Epoch 148/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.6458e-04 - val_loss: 4.0418e-05\n",
      "Epoch 149/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.1065e-04 - val_loss: 2.4897e-05\n",
      "Epoch 150/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.7624e-04 - val_loss: 2.2138e-05\n",
      "Epoch 151/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.6747e-04 - val_loss: 2.2535e-05\n",
      "Epoch 152/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.6805e-04 - val_loss: 2.1664e-05\n",
      "Epoch 153/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.6157e-04 - val_loss: 2.3213e-05\n",
      "Epoch 154/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.6822e-04 - val_loss: 2.2899e-05\n",
      "Epoch 155/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.5512e-04 - val_loss: 2.2786e-05\n",
      "Epoch 156/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.7247e-04 - val_loss: 2.1190e-05\n",
      "Epoch 157/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.9283e-04 - val_loss: 3.3897e-05\n",
      "Epoch 158/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 3.1261e-04 - val_loss: 2.4612e-05\n",
      "Epoch 159/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 2.6030e-04 - val_loss: 2.0900e-05\n",
      "Epoch 160/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.5066e-04 - val_loss: 2.0892e-05\n",
      "Epoch 161/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.5855e-04 - val_loss: 2.1432e-05\n",
      "Epoch 162/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.9648e-04 - val_loss: 2.3596e-05\n",
      "Epoch 163/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.7065e-04 - val_loss: 2.4723e-05\n",
      "Epoch 164/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 2.8440e-04 - val_loss: 2.0937e-05\n",
      "Epoch 165/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 2.4662e-04 - val_loss: 2.2290e-05\n",
      "Epoch 166/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.6126e-04 - val_loss: 2.1469e-05\n",
      "Epoch 167/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.6592e-04 - val_loss: 2.0334e-05\n",
      "Epoch 168/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.5272e-04 - val_loss: 2.0973e-05\n",
      "Epoch 169/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.4563e-04 - val_loss: 2.5793e-05\n",
      "Epoch 170/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.6780e-04 - val_loss: 2.4661e-05\n",
      "Epoch 171/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.7467e-04 - val_loss: 2.0133e-05\n",
      "Epoch 172/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.5938e-04 - val_loss: 2.0056e-05\n",
      "Epoch 173/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.7355e-04 - val_loss: 2.3631e-05\n",
      "Epoch 174/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.6138e-04 - val_loss: 1.9956e-05\n",
      "Epoch 175/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.0734e-04 - val_loss: 2.0226e-05\n",
      "Epoch 176/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 2.6989e-04 - val_loss: 3.0786e-05\n",
      "Epoch 177/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 2.8768e-04 - val_loss: 2.8204e-05\n",
      "Epoch 178/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.7027e-04 - val_loss: 2.0692e-05\n",
      "Epoch 179/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.8504e-04 - val_loss: 4.3547e-05\n",
      "Epoch 180/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.4566e-04 - val_loss: 2.3396e-05\n",
      "Epoch 181/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.6749e-04 - val_loss: 2.1828e-05\n",
      "Epoch 182/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.6092e-04 - val_loss: 1.9642e-05\n",
      "Epoch 183/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.4473e-04 - val_loss: 1.9834e-05\n",
      "Epoch 184/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.4188e-04 - val_loss: 2.1970e-05\n",
      "Epoch 185/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.4122e-04 - val_loss: 1.9319e-05\n",
      "Epoch 186/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.3070e-04 - val_loss: 1.9149e-05\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 3ms/step - loss: 2.5620e-04 - val_loss: 2.2758e-05\n",
      "Epoch 188/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.4988e-04 - val_loss: 2.4469e-05\n",
      "Epoch 189/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.3348e-04 - val_loss: 1.9153e-05\n",
      "Epoch 190/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.4279e-04 - val_loss: 2.3670e-05\n",
      "Epoch 191/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.3408e-04 - val_loss: 2.0219e-05\n",
      "Epoch 192/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.3722e-04 - val_loss: 1.9699e-05\n",
      "Epoch 193/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.3227e-04 - val_loss: 2.4408e-05\n",
      "Epoch 194/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.3862e-04 - val_loss: 2.3160e-05\n",
      "Epoch 195/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.3408e-04 - val_loss: 1.8807e-05\n",
      "Epoch 196/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.2915e-04 - val_loss: 2.0657e-05\n",
      "Epoch 197/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.3148e-04 - val_loss: 2.4053e-05\n",
      "Epoch 198/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.4577e-04 - val_loss: 1.8822e-05\n",
      "Epoch 199/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.4045e-04 - val_loss: 1.8497e-05\n",
      "Epoch 200/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.2873e-04 - val_loss: 1.8368e-05\n",
      "Thời gian huấn luyện:  23.173789739608765\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_7 (SimpleRNN)    (None, 10, 100)           10200     \n",
      "                                                                 \n",
      " flatten_29 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,201\n",
      "Trainable params: 11,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "33/33 [==============================] - 2s 17ms/step - loss: 0.0491 - val_loss: 0.0017\n",
      "Epoch 2/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 3/200\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 6.9128e-04\n",
      "Epoch 4/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 3.8129e-04\n",
      "Epoch 5/200\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 3.2045e-04\n",
      "Epoch 6/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 2.4706e-04\n",
      "Epoch 7/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.9958e-04 - val_loss: 1.8496e-04\n",
      "Epoch 8/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 2.0986e-04\n",
      "Epoch 9/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.9234e-04 - val_loss: 1.4035e-04\n",
      "Epoch 10/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.9366e-04 - val_loss: 1.7838e-04\n",
      "Epoch 11/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.9270e-04 - val_loss: 1.6215e-04\n",
      "Epoch 12/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.9433e-04 - val_loss: 1.8301e-04\n",
      "Epoch 13/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.8595e-04 - val_loss: 1.4303e-04\n",
      "Epoch 14/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.9031e-04 - val_loss: 2.0210e-04\n",
      "Epoch 15/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.8098e-04 - val_loss: 1.6089e-04\n",
      "Epoch 16/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.7945e-04 - val_loss: 1.6834e-04\n",
      "Epoch 17/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.7017e-04 - val_loss: 1.3210e-04\n",
      "Epoch 18/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.7963e-04 - val_loss: 1.5282e-04\n",
      "Epoch 19/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.8301e-04 - val_loss: 1.4063e-04\n",
      "Epoch 20/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.7517e-04 - val_loss: 1.3428e-04\n",
      "Epoch 21/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.7295e-04 - val_loss: 1.2967e-04\n",
      "Epoch 22/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.9010e-04 - val_loss: 1.2818e-04\n",
      "Epoch 23/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 1.4637e-04\n",
      "Epoch 24/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.9101e-04 - val_loss: 1.8502e-04\n",
      "Epoch 25/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.9384e-04 - val_loss: 1.2018e-04\n",
      "Epoch 26/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.8424e-04 - val_loss: 1.4052e-04\n",
      "Epoch 27/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.6399e-04 - val_loss: 1.9163e-04\n",
      "Epoch 28/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.8021e-04 - val_loss: 1.7184e-04\n",
      "Epoch 29/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.9164e-04 - val_loss: 1.4334e-04\n",
      "Epoch 30/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.6867e-04 - val_loss: 1.6552e-04\n",
      "Epoch 31/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.5831e-04 - val_loss: 1.2062e-04\n",
      "Epoch 32/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.5518e-04 - val_loss: 1.2149e-04\n",
      "Epoch 33/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.3959e-04 - val_loss: 1.4541e-04\n",
      "Epoch 34/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.3659e-04 - val_loss: 1.3671e-04\n",
      "Epoch 35/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.4054e-04 - val_loss: 1.5015e-04\n",
      "Epoch 36/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.4256e-04 - val_loss: 1.3630e-04\n",
      "Epoch 37/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.3459e-04 - val_loss: 1.4727e-04\n",
      "Epoch 38/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.2573e-04 - val_loss: 1.1184e-04\n",
      "Epoch 39/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.4256e-04 - val_loss: 1.2793e-04\n",
      "Epoch 40/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.5165e-04 - val_loss: 1.9410e-04\n",
      "Epoch 41/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.3098e-04 - val_loss: 1.5567e-04\n",
      "Epoch 42/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.4028e-04 - val_loss: 1.4903e-04\n",
      "Epoch 43/200\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 9.1722e-04 - val_loss: 1.4102e-04\n",
      "Epoch 44/200\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 9.2852e-04 - val_loss: 1.3696e-04\n",
      "Epoch 45/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.2012e-04 - val_loss: 1.2851e-04\n",
      "Epoch 46/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.1023e-04 - val_loss: 1.1028e-04\n",
      "Epoch 47/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.2296e-04 - val_loss: 1.1922e-04\n",
      "Epoch 48/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.1191e-04 - val_loss: 1.3784e-04\n",
      "Epoch 49/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.0602e-04 - val_loss: 1.2649e-04\n",
      "Epoch 50/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.9809e-04 - val_loss: 1.4169e-04\n",
      "Epoch 51/200\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 9.0266e-04 - val_loss: 1.0881e-04\n",
      "Epoch 52/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.8336e-04 - val_loss: 1.5605e-04\n",
      "Epoch 53/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.2286e-04 - val_loss: 1.3356e-04\n",
      "Epoch 54/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.5714e-04 - val_loss: 8.9051e-05\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 7ms/step - loss: 9.0072e-04 - val_loss: 1.0666e-04\n",
      "Epoch 56/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.7412e-04 - val_loss: 9.6612e-05\n",
      "Epoch 57/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.7759e-04 - val_loss: 1.0693e-04\n",
      "Epoch 58/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.7707e-04 - val_loss: 1.0847e-04\n",
      "Epoch 59/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.6894e-04 - val_loss: 9.0801e-05\n",
      "Epoch 60/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.2239e-04 - val_loss: 1.4306e-04\n",
      "Epoch 61/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.1755e-04 - val_loss: 1.1945e-04\n",
      "Epoch 62/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.6520e-04 - val_loss: 1.0471e-04\n",
      "Epoch 63/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.7100e-04 - val_loss: 9.4964e-05\n",
      "Epoch 64/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.6766e-04 - val_loss: 8.8517e-05\n",
      "Epoch 65/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.5901e-04 - val_loss: 1.6523e-04\n",
      "Epoch 66/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.9051e-04 - val_loss: 1.0973e-04\n",
      "Epoch 67/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.5613e-04 - val_loss: 1.0203e-04\n",
      "Epoch 68/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.4323e-04 - val_loss: 9.1070e-05\n",
      "Epoch 69/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.5761e-04 - val_loss: 1.0639e-04\n",
      "Epoch 70/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.3808e-04 - val_loss: 1.1011e-04\n",
      "Epoch 71/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.4057e-04 - val_loss: 1.1471e-04\n",
      "Epoch 72/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.3527e-04 - val_loss: 1.0276e-04\n",
      "Epoch 73/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.3543e-04 - val_loss: 1.1657e-04\n",
      "Epoch 74/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.3374e-04 - val_loss: 9.4850e-05\n",
      "Epoch 75/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.2654e-04 - val_loss: 1.1666e-04\n",
      "Epoch 76/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.3955e-04 - val_loss: 9.4813e-05\n",
      "Epoch 77/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.1876e-04 - val_loss: 8.4150e-05\n",
      "Epoch 78/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.1735e-04 - val_loss: 8.9281e-05\n",
      "Epoch 79/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.4059e-04 - val_loss: 1.4435e-04\n",
      "Epoch 80/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.0861e-04 - val_loss: 1.0736e-04\n",
      "Epoch 81/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.2994e-04 - val_loss: 8.8376e-05\n",
      "Epoch 82/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.0559e-04 - val_loss: 1.0313e-04\n",
      "Epoch 83/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.2647e-04 - val_loss: 9.2364e-05\n",
      "Epoch 84/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.9432e-04 - val_loss: 9.3675e-05\n",
      "Epoch 85/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.1440e-04 - val_loss: 1.0111e-04\n",
      "Epoch 86/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.0802e-04 - val_loss: 1.1597e-04\n",
      "Epoch 87/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.0189e-04 - val_loss: 8.4714e-05\n",
      "Epoch 88/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.8009e-04 - val_loss: 7.7119e-05\n",
      "Epoch 89/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.9161e-04 - val_loss: 1.2211e-04\n",
      "Epoch 90/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.8526e-04 - val_loss: 7.5894e-05\n",
      "Epoch 91/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.8761e-04 - val_loss: 9.3831e-05\n",
      "Epoch 92/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.7473e-04 - val_loss: 8.8187e-05\n",
      "Epoch 93/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.6271e-04 - val_loss: 8.0187e-05\n",
      "Epoch 94/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.5757e-04 - val_loss: 7.7515e-05\n",
      "Epoch 95/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.5706e-04 - val_loss: 8.0036e-05\n",
      "Epoch 96/200\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 7.7238e-04 - val_loss: 8.3967e-05\n",
      "Epoch 97/200\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 7.5621e-04 - val_loss: 9.1869e-05\n",
      "Epoch 98/200\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 7.6184e-04 - val_loss: 7.3015e-05\n",
      "Epoch 99/200\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 7.6170e-04 - val_loss: 7.3476e-05\n",
      "Epoch 100/200\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 7.7080e-04 - val_loss: 1.1515e-04\n",
      "Epoch 101/200\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 7.5678e-04 - val_loss: 8.1924e-05\n",
      "Epoch 102/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.2901e-04 - val_loss: 8.6891e-05\n",
      "Epoch 103/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.6367e-04 - val_loss: 1.0345e-04\n",
      "Epoch 104/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.4408e-04 - val_loss: 8.6228e-05\n",
      "Epoch 105/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.2808e-04 - val_loss: 7.1084e-05\n",
      "Epoch 106/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.3803e-04 - val_loss: 9.9748e-05\n",
      "Epoch 107/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.1632e-04 - val_loss: 7.1126e-05\n",
      "Epoch 108/200\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 7.1785e-04 - val_loss: 7.5036e-05\n",
      "Epoch 109/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.3002e-04 - val_loss: 6.9544e-05\n",
      "Epoch 110/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.0262e-04 - val_loss: 8.4078e-05\n",
      "Epoch 111/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.9667e-04 - val_loss: 7.2626e-05\n",
      "Epoch 112/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.9902e-04 - val_loss: 7.9976e-05\n",
      "Epoch 113/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.9026e-04 - val_loss: 8.4316e-05\n",
      "Epoch 114/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.8709e-04 - val_loss: 7.0026e-05\n",
      "Epoch 115/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.7799e-04 - val_loss: 7.7207e-05\n",
      "Epoch 116/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.7596e-04 - val_loss: 8.4352e-05\n",
      "Epoch 117/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.9678e-04 - val_loss: 7.7488e-05\n",
      "Epoch 118/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.6692e-04 - val_loss: 6.6537e-05\n",
      "Epoch 119/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.7274e-04 - val_loss: 8.7355e-05\n",
      "Epoch 120/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.7008e-04 - val_loss: 6.4533e-05\n",
      "Epoch 121/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.1681e-04 - val_loss: 6.7822e-05\n",
      "Epoch 122/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.5198e-04 - val_loss: 6.6360e-05\n",
      "Epoch 123/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.6425e-04 - val_loss: 1.0300e-04\n",
      "Epoch 124/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.0257e-04 - val_loss: 6.2371e-05\n",
      "Epoch 125/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.5356e-04 - val_loss: 6.3415e-05\n",
      "Epoch 126/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.3550e-04 - val_loss: 6.8633e-05\n",
      "Epoch 127/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.5407e-04 - val_loss: 7.2542e-05\n",
      "Epoch 128/200\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 6.3911e-04 - val_loss: 6.1169e-05\n",
      "Epoch 129/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.4277e-04 - val_loss: 6.9448e-05\n",
      "Epoch 130/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 7ms/step - loss: 6.2920e-04 - val_loss: 6.7032e-05\n",
      "Epoch 131/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.2338e-04 - val_loss: 5.9897e-05\n",
      "Epoch 132/200\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 6.2892e-04 - val_loss: 5.9964e-05\n",
      "Epoch 133/200\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 6.0651e-04 - val_loss: 6.4969e-05\n",
      "Epoch 134/200\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 6.0113e-04 - val_loss: 5.9602e-05\n",
      "Epoch 135/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.1251e-04 - val_loss: 5.7982e-05\n",
      "Epoch 136/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.9286e-04 - val_loss: 6.0627e-05\n",
      "Epoch 137/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.9590e-04 - val_loss: 5.7625e-05\n",
      "Epoch 138/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.9047e-04 - val_loss: 5.6612e-05\n",
      "Epoch 139/200\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 5.8165e-04 - val_loss: 5.9597e-05\n",
      "Epoch 140/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.0157e-04 - val_loss: 5.5613e-05\n",
      "Epoch 141/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.7700e-04 - val_loss: 5.7175e-05\n",
      "Epoch 142/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.0042e-04 - val_loss: 5.6229e-05\n",
      "Epoch 143/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.7089e-04 - val_loss: 5.6913e-05\n",
      "Epoch 144/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.6865e-04 - val_loss: 6.3952e-05\n",
      "Epoch 145/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.5962e-04 - val_loss: 5.4434e-05\n",
      "Epoch 146/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.6813e-04 - val_loss: 5.5258e-05\n",
      "Epoch 147/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.7392e-04 - val_loss: 5.6609e-05\n",
      "Epoch 148/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 6.1536e-04 - val_loss: 5.7131e-05\n",
      "Epoch 149/200\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 5.6035e-04 - val_loss: 5.5097e-05\n",
      "Epoch 150/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.7105e-04 - val_loss: 5.4698e-05\n",
      "Epoch 151/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.4053e-04 - val_loss: 5.5632e-05\n",
      "Epoch 152/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.6038e-04 - val_loss: 5.2929e-05\n",
      "Epoch 153/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.3788e-04 - val_loss: 5.1910e-05\n",
      "Epoch 154/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.6229e-04 - val_loss: 5.2036e-05\n",
      "Epoch 155/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.8501e-04 - val_loss: 5.4129e-05\n",
      "Epoch 156/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.4008e-04 - val_loss: 5.3489e-05\n",
      "Epoch 157/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.3318e-04 - val_loss: 5.1175e-05\n",
      "Epoch 158/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.2943e-04 - val_loss: 5.0920e-05\n",
      "Epoch 159/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.4978e-04 - val_loss: 5.2650e-05\n",
      "Epoch 160/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.3094e-04 - val_loss: 5.1470e-05\n",
      "Epoch 161/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.2602e-04 - val_loss: 5.0290e-05\n",
      "Epoch 162/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.4087e-04 - val_loss: 5.1364e-05\n",
      "Epoch 163/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.2060e-04 - val_loss: 5.0428e-05\n",
      "Epoch 164/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.1766e-04 - val_loss: 5.9277e-05\n",
      "Epoch 165/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.2137e-04 - val_loss: 4.9486e-05\n",
      "Epoch 166/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.2007e-04 - val_loss: 5.0790e-05\n",
      "Epoch 167/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.1981e-04 - val_loss: 5.0528e-05\n",
      "Epoch 168/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.2859e-04 - val_loss: 4.9150e-05\n",
      "Epoch 169/200\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 5.0135e-04 - val_loss: 4.9694e-05\n",
      "Epoch 170/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.0256e-04 - val_loss: 5.5665e-05\n",
      "Epoch 171/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.2114e-04 - val_loss: 4.9012e-05\n",
      "Epoch 172/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.0994e-04 - val_loss: 4.8681e-05\n",
      "Epoch 173/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.0266e-04 - val_loss: 5.1304e-05\n",
      "Epoch 174/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.2770e-04 - val_loss: 4.8698e-05\n",
      "Epoch 175/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.4151e-04 - val_loss: 4.8942e-05\n",
      "Epoch 176/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.0170e-04 - val_loss: 5.6195e-05\n",
      "Epoch 177/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.1650e-04 - val_loss: 4.8996e-05\n",
      "Epoch 178/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.9777e-04 - val_loss: 5.0289e-05\n",
      "Epoch 179/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.0223e-04 - val_loss: 5.3231e-05\n",
      "Epoch 180/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.8514e-04 - val_loss: 5.1086e-05\n",
      "Epoch 181/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.9444e-04 - val_loss: 5.1312e-05\n",
      "Epoch 182/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.8047e-04 - val_loss: 4.8106e-05\n",
      "Epoch 183/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.8121e-04 - val_loss: 4.8297e-05\n",
      "Epoch 184/200\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 4.8426e-04 - val_loss: 4.7902e-05\n",
      "Epoch 185/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.1315e-04 - val_loss: 4.8445e-05\n",
      "Epoch 186/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.9308e-04 - val_loss: 5.0733e-05\n",
      "Epoch 187/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.8406e-04 - val_loss: 4.8037e-05\n",
      "Epoch 188/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.1756e-04 - val_loss: 5.1984e-05\n",
      "Epoch 189/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.8012e-04 - val_loss: 5.0429e-05\n",
      "Epoch 190/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.9082e-04 - val_loss: 5.2769e-05\n",
      "Epoch 191/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.7103e-04 - val_loss: 4.7684e-05\n",
      "Epoch 192/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.7934e-04 - val_loss: 4.9662e-05\n",
      "Epoch 193/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.7893e-04 - val_loss: 5.0450e-05\n",
      "Epoch 194/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.7663e-04 - val_loss: 4.8172e-05\n",
      "Epoch 195/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.6963e-04 - val_loss: 6.8609e-05\n",
      "Epoch 196/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.9671e-04 - val_loss: 5.3267e-05\n",
      "Epoch 197/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.1126e-04 - val_loss: 4.6999e-05\n",
      "Epoch 198/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.6319e-04 - val_loss: 4.7819e-05\n",
      "Epoch 199/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.6324e-04 - val_loss: 4.8327e-05\n",
      "Epoch 200/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.5929e-04 - val_loss: 4.6658e-05\n",
      "Thời gian huấn luyện:  48.01848316192627\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_7 (LSTM)               (None, 10, 100)           40800     \n",
      "                                                                 \n",
      " flatten_30 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_38 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,801\n",
      "Trainable params: 41,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "33/33 [==============================] - 2s 16ms/step - loss: 0.1126 - val_loss: 0.0113\n",
      "Epoch 2/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 3/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.0294e-04\n",
      "Epoch 4/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.2894e-04 - val_loss: 2.1982e-04\n",
      "Epoch 5/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.5569e-04 - val_loss: 9.1144e-05\n",
      "Epoch 6/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.4655e-04 - val_loss: 9.3782e-05\n",
      "Epoch 7/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.3377e-04 - val_loss: 8.4549e-05\n",
      "Epoch 8/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.3011e-04 - val_loss: 7.7738e-05\n",
      "Epoch 9/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.3270e-04 - val_loss: 7.6218e-05\n",
      "Epoch 10/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.3545e-04 - val_loss: 7.9305e-05\n",
      "Epoch 11/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.1984e-04 - val_loss: 8.7435e-05\n",
      "Epoch 12/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.1892e-04 - val_loss: 7.6792e-05\n",
      "Epoch 13/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.1461e-04 - val_loss: 7.7945e-05\n",
      "Epoch 14/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.1694e-04 - val_loss: 8.4968e-05\n",
      "Epoch 15/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.0808e-04 - val_loss: 7.6207e-05\n",
      "Epoch 16/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.0187e-04 - val_loss: 8.0601e-05\n",
      "Epoch 17/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.1171e-04 - val_loss: 8.3557e-05\n",
      "Epoch 18/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.0390e-04 - val_loss: 7.8561e-05\n",
      "Epoch 19/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.9283e-04 - val_loss: 7.3951e-05\n",
      "Epoch 20/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.9830e-04 - val_loss: 7.5263e-05\n",
      "Epoch 21/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.9248e-04 - val_loss: 7.5765e-05\n",
      "Epoch 22/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.8012e-04 - val_loss: 7.5954e-05\n",
      "Epoch 23/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.9031e-04 - val_loss: 7.2259e-05\n",
      "Epoch 24/200\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 7.7797e-04 - val_loss: 7.3719e-05\n",
      "Epoch 25/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.6741e-04 - val_loss: 7.0548e-05\n",
      "Epoch 26/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.7314e-04 - val_loss: 7.4768e-05\n",
      "Epoch 27/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.7506e-04 - val_loss: 7.6568e-05\n",
      "Epoch 28/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.6735e-04 - val_loss: 7.0014e-05\n",
      "Epoch 29/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.5516e-04 - val_loss: 6.9980e-05\n",
      "Epoch 30/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.5036e-04 - val_loss: 6.8600e-05\n",
      "Epoch 31/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.4782e-04 - val_loss: 7.1804e-05\n",
      "Epoch 32/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.4326e-04 - val_loss: 6.9940e-05\n",
      "Epoch 33/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.3973e-04 - val_loss: 6.7562e-05\n",
      "Epoch 34/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.4086e-04 - val_loss: 7.2571e-05\n",
      "Epoch 35/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.3347e-04 - val_loss: 6.9853e-05\n",
      "Epoch 36/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.2709e-04 - val_loss: 6.8942e-05\n",
      "Epoch 37/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.2296e-04 - val_loss: 7.8147e-05\n",
      "Epoch 38/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.2059e-04 - val_loss: 6.7440e-05\n",
      "Epoch 39/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.1330e-04 - val_loss: 6.7949e-05\n",
      "Epoch 40/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.0716e-04 - val_loss: 6.4943e-05\n",
      "Epoch 41/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.0618e-04 - val_loss: 6.5362e-05\n",
      "Epoch 42/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 7.0654e-04 - val_loss: 7.3263e-05\n",
      "Epoch 43/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.1435e-04 - val_loss: 6.3864e-05\n",
      "Epoch 44/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.9589e-04 - val_loss: 6.3414e-05\n",
      "Epoch 45/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.8696e-04 - val_loss: 6.7256e-05\n",
      "Epoch 46/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.0826e-04 - val_loss: 8.0906e-05\n",
      "Epoch 47/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.8419e-04 - val_loss: 8.5971e-05\n",
      "Epoch 48/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.1293e-04 - val_loss: 6.2307e-05\n",
      "Epoch 49/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.6787e-04 - val_loss: 6.2828e-05\n",
      "Epoch 50/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.7127e-04 - val_loss: 6.9953e-05\n",
      "Epoch 51/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.6445e-04 - val_loss: 6.0845e-05\n",
      "Epoch 52/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.5784e-04 - val_loss: 6.1462e-05\n",
      "Epoch 53/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.5348e-04 - val_loss: 6.4827e-05\n",
      "Epoch 54/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.4992e-04 - val_loss: 5.9386e-05\n",
      "Epoch 55/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.4632e-04 - val_loss: 5.9119e-05\n",
      "Epoch 56/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.4676e-04 - val_loss: 6.4647e-05\n",
      "Epoch 57/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.3722e-04 - val_loss: 6.9969e-05\n",
      "Epoch 58/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.3840e-04 - val_loss: 7.1917e-05\n",
      "Epoch 59/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.3201e-04 - val_loss: 6.1741e-05\n",
      "Epoch 60/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.3323e-04 - val_loss: 5.7311e-05\n",
      "Epoch 61/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.2228e-04 - val_loss: 5.8305e-05\n",
      "Epoch 62/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.1805e-04 - val_loss: 5.5951e-05\n",
      "Epoch 63/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.3408e-04 - val_loss: 7.8876e-05\n",
      "Epoch 64/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.0729e-04 - val_loss: 5.6286e-05\n",
      "Epoch 65/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.0400e-04 - val_loss: 5.9313e-05\n",
      "Epoch 66/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.8988e-04 - val_loss: 5.4242e-05\n",
      "Epoch 67/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.9065e-04 - val_loss: 5.3960e-05\n",
      "Epoch 68/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.8541e-04 - val_loss: 5.5414e-05\n",
      "Epoch 69/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.0820e-04 - val_loss: 5.3576e-05\n",
      "Epoch 70/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.7041e-04 - val_loss: 5.5357e-05\n",
      "Epoch 71/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.6610e-04 - val_loss: 7.0751e-05\n",
      "Epoch 72/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.8204e-04 - val_loss: 6.6126e-05\n",
      "Epoch 73/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.9793e-04 - val_loss: 5.2301e-05\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 6ms/step - loss: 5.6928e-04 - val_loss: 5.0828e-05\n",
      "Epoch 75/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.5491e-04 - val_loss: 5.1582e-05\n",
      "Epoch 76/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.4258e-04 - val_loss: 5.0574e-05\n",
      "Epoch 77/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.4379e-04 - val_loss: 4.9789e-05\n",
      "Epoch 78/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.3826e-04 - val_loss: 5.0158e-05\n",
      "Epoch 79/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.3630e-04 - val_loss: 4.8758e-05\n",
      "Epoch 80/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.2610e-04 - val_loss: 4.8441e-05\n",
      "Epoch 81/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.2315e-04 - val_loss: 5.4336e-05\n",
      "Epoch 82/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.3400e-04 - val_loss: 5.1211e-05\n",
      "Epoch 83/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.2312e-04 - val_loss: 5.3291e-05\n",
      "Epoch 84/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.1582e-04 - val_loss: 4.8758e-05\n",
      "Epoch 85/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.2633e-04 - val_loss: 6.7626e-05\n",
      "Epoch 86/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.2536e-04 - val_loss: 4.6865e-05\n",
      "Epoch 87/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 5.0307e-04 - val_loss: 4.5597e-05\n",
      "Epoch 88/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.0323e-04 - val_loss: 4.5553e-05\n",
      "Epoch 89/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.9385e-04 - val_loss: 4.8355e-05\n",
      "Epoch 90/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.9374e-04 - val_loss: 6.0467e-05\n",
      "Epoch 91/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.9000e-04 - val_loss: 4.4765e-05\n",
      "Epoch 92/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.8359e-04 - val_loss: 4.7570e-05\n",
      "Epoch 93/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.8094e-04 - val_loss: 4.4758e-05\n",
      "Epoch 94/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.6835e-04 - val_loss: 4.3157e-05\n",
      "Epoch 95/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.6508e-04 - val_loss: 5.0389e-05\n",
      "Epoch 96/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.8145e-04 - val_loss: 4.3930e-05\n",
      "Epoch 97/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.8245e-04 - val_loss: 4.8023e-05\n",
      "Epoch 98/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.5847e-04 - val_loss: 4.1712e-05\n",
      "Epoch 99/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.6222e-04 - val_loss: 4.1768e-05\n",
      "Epoch 100/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.5040e-04 - val_loss: 5.1170e-05\n",
      "Epoch 101/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.4746e-04 - val_loss: 4.0966e-05\n",
      "Epoch 102/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.4239e-04 - val_loss: 4.6389e-05\n",
      "Epoch 103/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.3776e-04 - val_loss: 4.1272e-05\n",
      "Epoch 104/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.3489e-04 - val_loss: 4.0111e-05\n",
      "Epoch 105/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.3283e-04 - val_loss: 4.0347e-05\n",
      "Epoch 106/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.3635e-04 - val_loss: 5.1467e-05\n",
      "Epoch 107/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.2647e-04 - val_loss: 3.9312e-05\n",
      "Epoch 108/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.3783e-04 - val_loss: 3.9108e-05\n",
      "Epoch 109/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.2350e-04 - val_loss: 4.3878e-05\n",
      "Epoch 110/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.3633e-04 - val_loss: 5.3335e-05\n",
      "Epoch 111/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.2676e-04 - val_loss: 4.2469e-05\n",
      "Epoch 112/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.1409e-04 - val_loss: 5.1788e-05\n",
      "Epoch 113/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.1202e-04 - val_loss: 3.7761e-05\n",
      "Epoch 114/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.0712e-04 - val_loss: 5.0750e-05\n",
      "Epoch 115/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.1555e-04 - val_loss: 3.8403e-05\n",
      "Epoch 116/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 4.0754e-04 - val_loss: 3.9109e-05\n",
      "Epoch 117/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.1091e-04 - val_loss: 3.7405e-05\n",
      "Epoch 118/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.2248e-04 - val_loss: 3.6704e-05\n",
      "Epoch 119/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.9566e-04 - val_loss: 4.9685e-05\n",
      "Epoch 120/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.0022e-04 - val_loss: 5.7026e-05\n",
      "Epoch 121/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.9542e-04 - val_loss: 4.2311e-05\n",
      "Epoch 122/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.2351e-04 - val_loss: 5.1241e-05\n",
      "Epoch 123/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 3.9969e-04 - val_loss: 3.7658e-05\n",
      "Epoch 124/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.9739e-04 - val_loss: 4.1198e-05\n",
      "Epoch 125/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.8155e-04 - val_loss: 4.5601e-05\n",
      "Epoch 126/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.8455e-04 - val_loss: 3.6977e-05\n",
      "Epoch 127/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 3.8003e-04 - val_loss: 3.7634e-05\n",
      "Epoch 128/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.8257e-04 - val_loss: 4.1131e-05\n",
      "Epoch 129/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.7472e-04 - val_loss: 4.2492e-05\n",
      "Epoch 130/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.8081e-04 - val_loss: 4.2420e-05\n",
      "Epoch 131/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.6826e-04 - val_loss: 3.4945e-05\n",
      "Epoch 132/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.1951e-04 - val_loss: 3.4531e-05\n",
      "Epoch 133/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.0719e-04 - val_loss: 3.6281e-05\n",
      "Epoch 134/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.8079e-04 - val_loss: 4.6139e-05\n",
      "Epoch 135/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.6487e-04 - val_loss: 3.7138e-05\n",
      "Epoch 136/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.6120e-04 - val_loss: 3.4933e-05\n",
      "Epoch 137/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.7921e-04 - val_loss: 3.8785e-05\n",
      "Epoch 138/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.5517e-04 - val_loss: 5.4939e-05\n",
      "Epoch 139/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.5465e-04 - val_loss: 4.0398e-05\n",
      "Epoch 140/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.6131e-04 - val_loss: 4.4621e-05\n",
      "Epoch 141/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.6284e-04 - val_loss: 4.6012e-05\n",
      "Epoch 142/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.5894e-04 - val_loss: 3.9010e-05\n",
      "Epoch 143/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.4890e-04 - val_loss: 3.5669e-05\n",
      "Epoch 144/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.4170e-04 - val_loss: 4.8210e-05\n",
      "Epoch 145/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 3.5866e-04 - val_loss: 3.9765e-05\n",
      "Epoch 146/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 3.5026e-04 - val_loss: 4.1070e-05\n",
      "Epoch 147/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.6580e-04 - val_loss: 4.1953e-05\n",
      "Epoch 148/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.4075e-04 - val_loss: 3.6826e-05\n",
      "Epoch 149/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 6ms/step - loss: 3.3870e-04 - val_loss: 3.4925e-05\n",
      "Epoch 150/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.5530e-04 - val_loss: 3.1892e-05\n",
      "Epoch 151/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.4143e-04 - val_loss: 3.5571e-05\n",
      "Epoch 152/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.2967e-04 - val_loss: 5.3209e-05\n",
      "Epoch 153/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 3.2920e-04 - val_loss: 3.6106e-05\n",
      "Epoch 154/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.3476e-04 - val_loss: 3.1594e-05\n",
      "Epoch 155/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.3564e-04 - val_loss: 4.7458e-05\n",
      "Epoch 156/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.2431e-04 - val_loss: 3.3884e-05\n",
      "Epoch 157/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.2952e-04 - val_loss: 3.1151e-05\n",
      "Epoch 158/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.2571e-04 - val_loss: 4.4702e-05\n",
      "Epoch 159/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.1816e-04 - val_loss: 3.7628e-05\n",
      "Epoch 160/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.3018e-04 - val_loss: 7.4212e-05\n",
      "Epoch 161/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.6289e-04 - val_loss: 3.9102e-05\n",
      "Epoch 162/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.1434e-04 - val_loss: 4.4202e-05\n",
      "Epoch 163/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.3603e-04 - val_loss: 3.7761e-05\n",
      "Epoch 164/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.2671e-04 - val_loss: 3.0232e-05\n",
      "Epoch 165/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.1547e-04 - val_loss: 3.1867e-05\n",
      "Epoch 166/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.5020e-04 - val_loss: 3.1858e-05\n",
      "Epoch 167/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.2724e-04 - val_loss: 4.3955e-05\n",
      "Epoch 168/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.1612e-04 - val_loss: 5.3671e-05\n",
      "Epoch 169/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.1066e-04 - val_loss: 3.4489e-05\n",
      "Epoch 170/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.3188e-04 - val_loss: 3.1206e-05\n",
      "Epoch 171/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.0981e-04 - val_loss: 3.1999e-05\n",
      "Epoch 172/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.1735e-04 - val_loss: 3.0250e-05\n",
      "Epoch 173/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.2971e-04 - val_loss: 3.2408e-05\n",
      "Epoch 174/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.1996e-04 - val_loss: 3.3472e-05\n",
      "Epoch 175/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.1219e-04 - val_loss: 2.9420e-05\n",
      "Epoch 176/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.0021e-04 - val_loss: 3.6473e-05\n",
      "Epoch 177/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.9600e-04 - val_loss: 3.3432e-05\n",
      "Epoch 178/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.9586e-04 - val_loss: 4.1266e-05\n",
      "Epoch 179/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 3.0493e-04 - val_loss: 6.2348e-05\n",
      "Epoch 180/200\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 3.3704e-04 - val_loss: 3.2536e-05\n",
      "Epoch 181/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 2.9031e-04 - val_loss: 3.4188e-05\n",
      "Epoch 182/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 3.0894e-04 - val_loss: 2.8682e-05\n",
      "Epoch 183/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.2125e-04 - val_loss: 2.9893e-05\n",
      "Epoch 184/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.9944e-04 - val_loss: 3.0657e-05\n",
      "Epoch 185/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.9936e-04 - val_loss: 3.0339e-05\n",
      "Epoch 186/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 2.9812e-04 - val_loss: 2.7990e-05\n",
      "Epoch 187/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 2.9848e-04 - val_loss: 3.9623e-05\n",
      "Epoch 188/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.8888e-04 - val_loss: 3.2905e-05\n",
      "Epoch 189/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.9684e-04 - val_loss: 4.5594e-05\n",
      "Epoch 190/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.9180e-04 - val_loss: 2.9394e-05\n",
      "Epoch 191/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.8006e-04 - val_loss: 3.5194e-05\n",
      "Epoch 192/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 2.7543e-04 - val_loss: 2.9815e-05\n",
      "Epoch 193/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.7381e-04 - val_loss: 2.9217e-05\n",
      "Epoch 194/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.8630e-04 - val_loss: 2.8264e-05\n",
      "Epoch 195/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.8579e-04 - val_loss: 3.3955e-05\n",
      "Epoch 196/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 2.7764e-04 - val_loss: 2.9578e-05\n",
      "Epoch 197/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.9770e-04 - val_loss: 3.2922e-05\n",
      "Epoch 198/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.7539e-04 - val_loss: 4.4784e-05\n",
      "Epoch 199/200\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.2685e-04 - val_loss: 3.2451e-05\n",
      "Epoch 200/200\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 2.9812e-04 - val_loss: 2.7561e-05\n",
      "Thời gian huấn luyện:  43.38700222969055\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_7 (GRU)                 (None, 10, 100)           30900     \n",
      "                                                                 \n",
      " flatten_31 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,901\n",
      "Trainable params: 31,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "39/39 [==============================] - 0s 869us/step\n",
      "26/26 [==============================] - 0s 921us/step\n",
      "39/39 [==============================] - 0s 1ms/step\n",
      "26/26 [==============================] - 0s 1ms/step\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "39/39 [==============================] - 1s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.1521 - val_loss: 0.0062\n",
      "Epoch 2/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0425\n",
      "Epoch 3/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0267\n",
      "Epoch 4/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0237\n",
      "Epoch 5/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0198\n",
      "Epoch 6/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0163\n",
      "Epoch 7/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0128\n",
      "Epoch 8/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0102\n",
      "Epoch 9/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0083\n",
      "Epoch 10/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0063\n",
      "Epoch 11/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 12/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 14/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 15/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 16/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.5629e-04 - val_loss: 0.0017\n",
      "Epoch 17/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.9281e-04 - val_loss: 0.0014\n",
      "Epoch 18/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.4822e-04 - val_loss: 0.0013\n",
      "Epoch 19/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.2191e-04 - val_loss: 0.0012\n",
      "Epoch 20/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.9987e-04 - val_loss: 0.0010\n",
      "Epoch 21/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.9250e-04 - val_loss: 9.4416e-04\n",
      "Epoch 22/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.8724e-04 - val_loss: 9.1045e-04\n",
      "Epoch 23/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7962e-04 - val_loss: 8.4684e-04\n",
      "Epoch 24/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7632e-04 - val_loss: 8.0152e-04\n",
      "Epoch 25/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7310e-04 - val_loss: 8.0652e-04\n",
      "Epoch 26/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7090e-04 - val_loss: 7.8315e-04\n",
      "Epoch 27/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7397e-04 - val_loss: 7.3747e-04\n",
      "Epoch 28/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6835e-04 - val_loss: 7.3874e-04\n",
      "Epoch 29/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6808e-04 - val_loss: 7.4778e-04\n",
      "Epoch 30/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6706e-04 - val_loss: 7.3924e-04\n",
      "Epoch 31/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6811e-04 - val_loss: 7.6317e-04\n",
      "Epoch 32/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6305e-04 - val_loss: 7.2171e-04\n",
      "Epoch 33/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6187e-04 - val_loss: 7.2336e-04\n",
      "Epoch 34/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6717e-04 - val_loss: 7.6103e-04\n",
      "Epoch 35/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5961e-04 - val_loss: 6.8593e-04\n",
      "Epoch 36/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6165e-04 - val_loss: 6.9705e-04\n",
      "Epoch 37/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5747e-04 - val_loss: 7.1979e-04\n",
      "Epoch 38/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5615e-04 - val_loss: 6.9166e-04\n",
      "Epoch 39/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5890e-04 - val_loss: 6.4763e-04\n",
      "Epoch 40/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5433e-04 - val_loss: 7.6324e-04\n",
      "Epoch 41/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6397e-04 - val_loss: 7.2722e-04\n",
      "Epoch 42/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5300e-04 - val_loss: 7.0361e-04\n",
      "Epoch 43/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5024e-04 - val_loss: 6.5004e-04\n",
      "Epoch 44/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5119e-04 - val_loss: 6.9147e-04\n",
      "Epoch 45/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5173e-04 - val_loss: 6.6329e-04\n",
      "Epoch 46/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5153e-04 - val_loss: 6.7603e-04\n",
      "Epoch 47/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.4551e-04 - val_loss: 7.1915e-04\n",
      "Epoch 48/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.4582e-04 - val_loss: 6.5575e-04\n",
      "Epoch 49/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.4374e-04 - val_loss: 6.6555e-04\n",
      "Epoch 50/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5017e-04 - val_loss: 7.2987e-04\n",
      "Epoch 51/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.4644e-04 - val_loss: 6.9368e-04\n",
      "Epoch 52/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.4254e-04 - val_loss: 6.8221e-04\n",
      "Epoch 53/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.4312e-04 - val_loss: 6.1899e-04\n",
      "Epoch 54/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.4013e-04 - val_loss: 6.5981e-04\n",
      "Epoch 55/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3713e-04 - val_loss: 6.2386e-04\n",
      "Epoch 56/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3563e-04 - val_loss: 6.0624e-04\n",
      "Epoch 57/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3248e-04 - val_loss: 7.0690e-04\n",
      "Epoch 58/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3608e-04 - val_loss: 6.8972e-04\n",
      "Epoch 59/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2956e-04 - val_loss: 6.0987e-04\n",
      "Epoch 60/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3024e-04 - val_loss: 5.7728e-04\n",
      "Epoch 61/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3188e-04 - val_loss: 5.9333e-04\n",
      "Epoch 62/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2819e-04 - val_loss: 6.8532e-04\n",
      "Epoch 63/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3040e-04 - val_loss: 6.6753e-04\n",
      "Epoch 64/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2367e-04 - val_loss: 6.4806e-04\n",
      "Epoch 65/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2216e-04 - val_loss: 6.1951e-04\n",
      "Epoch 66/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2050e-04 - val_loss: 5.9391e-04\n",
      "Epoch 67/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2042e-04 - val_loss: 6.7763e-04\n",
      "Epoch 68/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.1472e-04 - val_loss: 5.8759e-04\n",
      "Epoch 69/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2586e-04 - val_loss: 5.3268e-04\n",
      "Epoch 70/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.1967e-04 - val_loss: 5.8231e-04\n",
      "Epoch 71/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.1457e-04 - val_loss: 5.8829e-04\n",
      "Epoch 72/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.1287e-04 - val_loss: 5.9292e-04\n",
      "Epoch 73/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0914e-04 - val_loss: 5.7192e-04\n",
      "Epoch 74/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0656e-04 - val_loss: 6.8286e-04\n",
      "Epoch 75/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0908e-04 - val_loss: 5.4346e-04\n",
      "Epoch 76/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.1397e-04 - val_loss: 5.1936e-04\n",
      "Epoch 77/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0431e-04 - val_loss: 5.9078e-04\n",
      "Epoch 78/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.9917e-04 - val_loss: 6.1388e-04\n",
      "Epoch 79/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.9819e-04 - val_loss: 5.7410e-04\n",
      "Epoch 80/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.0174e-04 - val_loss: 5.9762e-04\n",
      "Epoch 81/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.9771e-04 - val_loss: 5.7745e-04\n",
      "Epoch 82/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.9454e-04 - val_loss: 5.5268e-04\n",
      "Epoch 83/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.9768e-04 - val_loss: 5.4831e-04\n",
      "Epoch 84/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.9046e-04 - val_loss: 5.1670e-04\n",
      "Epoch 85/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.8858e-04 - val_loss: 6.5449e-04\n",
      "Epoch 86/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.9831e-04 - val_loss: 5.6165e-04\n",
      "Epoch 87/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.8336e-04 - val_loss: 5.8826e-04\n",
      "Epoch 88/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.8198e-04 - val_loss: 5.3672e-04\n",
      "Epoch 89/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step - loss: 6.8375e-04 - val_loss: 6.0083e-04\n",
      "Epoch 90/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.8029e-04 - val_loss: 5.2941e-04\n",
      "Epoch 91/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.8545e-04 - val_loss: 5.9460e-04\n",
      "Epoch 92/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.7974e-04 - val_loss: 5.7091e-04\n",
      "Epoch 93/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.8001e-04 - val_loss: 5.7017e-04\n",
      "Epoch 94/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.7689e-04 - val_loss: 5.2907e-04\n",
      "Epoch 95/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.6822e-04 - val_loss: 5.0389e-04\n",
      "Epoch 96/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.7540e-04 - val_loss: 5.6184e-04\n",
      "Epoch 97/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.6432e-04 - val_loss: 5.5564e-04\n",
      "Epoch 98/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.6316e-04 - val_loss: 6.0472e-04\n",
      "Epoch 99/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.6940e-04 - val_loss: 5.4861e-04\n",
      "Epoch 100/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.6079e-04 - val_loss: 5.2459e-04\n",
      "Epoch 101/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.6847e-04 - val_loss: 5.0867e-04\n",
      "Epoch 102/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.5782e-04 - val_loss: 5.1575e-04\n",
      "Epoch 103/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.5609e-04 - val_loss: 5.2909e-04\n",
      "Epoch 104/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.6414e-04 - val_loss: 4.0225e-04\n",
      "Epoch 105/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.6934e-04 - val_loss: 5.7040e-04\n",
      "Epoch 106/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.4955e-04 - val_loss: 5.3898e-04\n",
      "Epoch 107/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.4672e-04 - val_loss: 6.1259e-04\n",
      "Epoch 108/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.4624e-04 - val_loss: 5.2702e-04\n",
      "Epoch 109/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.4267e-04 - val_loss: 5.1271e-04\n",
      "Epoch 110/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.4124e-04 - val_loss: 4.3496e-04\n",
      "Epoch 111/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.4899e-04 - val_loss: 4.2579e-04\n",
      "Epoch 112/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.3916e-04 - val_loss: 5.5020e-04\n",
      "Epoch 113/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.4329e-04 - val_loss: 4.7699e-04\n",
      "Epoch 114/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.3630e-04 - val_loss: 5.2502e-04\n",
      "Epoch 115/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.3641e-04 - val_loss: 4.7928e-04\n",
      "Epoch 116/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.2792e-04 - val_loss: 4.8059e-04\n",
      "Epoch 117/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.2463e-04 - val_loss: 4.9779e-04\n",
      "Epoch 118/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.2182e-04 - val_loss: 4.2415e-04\n",
      "Epoch 119/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.3133e-04 - val_loss: 4.3521e-04\n",
      "Epoch 120/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.2516e-04 - val_loss: 5.2538e-04\n",
      "Epoch 121/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.2465e-04 - val_loss: 5.0161e-04\n",
      "Epoch 122/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.2137e-04 - val_loss: 5.2112e-04\n",
      "Epoch 123/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.1665e-04 - val_loss: 5.3062e-04\n",
      "Epoch 124/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.1104e-04 - val_loss: 4.9354e-04\n",
      "Epoch 125/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.2136e-04 - val_loss: 5.9027e-04\n",
      "Epoch 126/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.1837e-04 - val_loss: 5.3104e-04\n",
      "Epoch 127/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.1561e-04 - val_loss: 4.4332e-04\n",
      "Epoch 128/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.0274e-04 - val_loss: 4.7606e-04\n",
      "Epoch 129/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.0544e-04 - val_loss: 4.4631e-04\n",
      "Epoch 130/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.0796e-04 - val_loss: 4.5659e-04\n",
      "Epoch 131/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.9289e-04 - val_loss: 4.8637e-04\n",
      "Epoch 132/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.9587e-04 - val_loss: 4.6096e-04\n",
      "Epoch 133/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.8797e-04 - val_loss: 3.8549e-04\n",
      "Epoch 134/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.9095e-04 - val_loss: 4.0393e-04\n",
      "Epoch 135/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.9526e-04 - val_loss: 3.8765e-04\n",
      "Epoch 136/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.8528e-04 - val_loss: 5.0096e-04\n",
      "Epoch 137/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.8560e-04 - val_loss: 4.7143e-04\n",
      "Epoch 138/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.8837e-04 - val_loss: 4.0935e-04\n",
      "Epoch 139/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.8161e-04 - val_loss: 4.0720e-04\n",
      "Epoch 140/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.7596e-04 - val_loss: 4.5156e-04\n",
      "Epoch 141/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.7684e-04 - val_loss: 4.3199e-04\n",
      "Epoch 142/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.7024e-04 - val_loss: 4.8624e-04\n",
      "Epoch 143/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.7105e-04 - val_loss: 3.8534e-04\n",
      "Epoch 144/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.6808e-04 - val_loss: 3.8065e-04\n",
      "Epoch 145/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.6357e-04 - val_loss: 4.6267e-04\n",
      "Epoch 146/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.6876e-04 - val_loss: 3.6340e-04\n",
      "Epoch 147/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5951e-04 - val_loss: 4.1938e-04\n",
      "Epoch 148/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.6125e-04 - val_loss: 3.9568e-04\n",
      "Epoch 149/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5722e-04 - val_loss: 3.9724e-04\n",
      "Epoch 150/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5695e-04 - val_loss: 4.3795e-04\n",
      "Epoch 151/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5325e-04 - val_loss: 4.3478e-04\n",
      "Epoch 152/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.4761e-04 - val_loss: 3.3169e-04\n",
      "Epoch 153/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.4917e-04 - val_loss: 3.6054e-04\n",
      "Epoch 154/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.5041e-04 - val_loss: 4.3460e-04\n",
      "Epoch 155/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.4227e-04 - val_loss: 4.0239e-04\n",
      "Epoch 156/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.4099e-04 - val_loss: 4.1798e-04\n",
      "Epoch 157/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.4362e-04 - val_loss: 4.1911e-04\n",
      "Epoch 158/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3864e-04 - val_loss: 3.8851e-04\n",
      "Epoch 159/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3511e-04 - val_loss: 4.1895e-04\n",
      "Epoch 160/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.2941e-04 - val_loss: 3.5042e-04\n",
      "Epoch 161/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.2929e-04 - val_loss: 4.6073e-04\n",
      "Epoch 162/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3295e-04 - val_loss: 3.9136e-04\n",
      "Epoch 163/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.2932e-04 - val_loss: 3.2558e-04\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step - loss: 5.3615e-04 - val_loss: 3.7105e-04\n",
      "Epoch 165/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.2497e-04 - val_loss: 4.0089e-04\n",
      "Epoch 166/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.2108e-04 - val_loss: 3.8218e-04\n",
      "Epoch 167/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.1539e-04 - val_loss: 3.5318e-04\n",
      "Epoch 168/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.2181e-04 - val_loss: 2.9333e-04\n",
      "Epoch 169/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.1981e-04 - val_loss: 2.9124e-04\n",
      "Epoch 170/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.0865e-04 - val_loss: 3.8880e-04\n",
      "Epoch 171/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.0888e-04 - val_loss: 3.5172e-04\n",
      "Epoch 172/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.1419e-04 - val_loss: 3.0784e-04\n",
      "Epoch 173/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.1142e-04 - val_loss: 3.0298e-04\n",
      "Epoch 174/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.0902e-04 - val_loss: 3.4565e-04\n",
      "Epoch 175/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.0141e-04 - val_loss: 3.3131e-04\n",
      "Epoch 176/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.0082e-04 - val_loss: 3.5384e-04\n",
      "Epoch 177/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 5.0202e-04 - val_loss: 3.8549e-04\n",
      "Epoch 178/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 4.9221e-04 - val_loss: 3.7149e-04\n",
      "Epoch 179/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 4.9178e-04 - val_loss: 3.5002e-04\n",
      "Epoch 180/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 4.8845e-04 - val_loss: 3.7033e-04\n",
      "Epoch 181/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 4.8853e-04 - val_loss: 3.8550e-04\n",
      "Epoch 182/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 4.9588e-04 - val_loss: 3.4322e-04\n",
      "Epoch 183/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.8588e-04 - val_loss: 3.5161e-04\n",
      "Epoch 184/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.8704e-04 - val_loss: 3.4164e-04\n",
      "Epoch 185/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 4.7876e-04 - val_loss: 3.0277e-04\n",
      "Epoch 186/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 4.7815e-04 - val_loss: 3.0476e-04\n",
      "Epoch 187/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 4.7443e-04 - val_loss: 3.4037e-04\n",
      "Epoch 188/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 4.7464e-04 - val_loss: 3.2369e-04\n",
      "Epoch 189/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 4.6931e-04 - val_loss: 3.5638e-04\n",
      "Epoch 190/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 4.7498e-04 - val_loss: 3.3922e-04\n",
      "Epoch 191/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 4.6827e-04 - val_loss: 3.2197e-04\n",
      "Epoch 192/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 4.6878e-04 - val_loss: 3.3591e-04\n",
      "Epoch 193/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 4.6240e-04 - val_loss: 3.5815e-04\n",
      "Epoch 194/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 4.6112e-04 - val_loss: 3.1808e-04\n",
      "Epoch 195/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 4.7496e-04 - val_loss: 3.6236e-04\n",
      "Epoch 196/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 4.6093e-04 - val_loss: 3.2034e-04\n",
      "Epoch 197/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 4.5944e-04 - val_loss: 3.0439e-04\n",
      "Epoch 198/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 4.5494e-04 - val_loss: 2.9820e-04\n",
      "Epoch 199/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 4.5042e-04 - val_loss: 3.4313e-04\n",
      "Epoch 200/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 4.5585e-04 - val_loss: 3.3035e-04\n",
      "Thời gian huấn luyện:  13.907136678695679\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_40 (Dense)            (None, 10, 100)           200       \n",
      "                                                                 \n",
      " flatten_32 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,201\n",
      "Trainable params: 1,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "31/31 [==============================] - 1s 8ms/step - loss: 0.0257 - val_loss: 7.3678e-05\n",
      "Epoch 2/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 2.7907e-04\n",
      "Epoch 3/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 9.7611e-04 - val_loss: 3.7672e-04\n",
      "Epoch 4/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 9.2881e-04 - val_loss: 6.0653e-04\n",
      "Epoch 5/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 8.6323e-04 - val_loss: 5.1735e-04\n",
      "Epoch 6/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 8.6293e-04 - val_loss: 4.3548e-04\n",
      "Epoch 7/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 8.1200e-04 - val_loss: 4.3370e-04\n",
      "Epoch 8/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 7.9372e-04 - val_loss: 4.1021e-04\n",
      "Epoch 9/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 7.7644e-04 - val_loss: 3.4553e-04\n",
      "Epoch 10/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 7.6717e-04 - val_loss: 2.8245e-04\n",
      "Epoch 11/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 7.4234e-04 - val_loss: 2.4324e-04\n",
      "Epoch 12/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.2975e-04 - val_loss: 2.1960e-04\n",
      "Epoch 13/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 7.1214e-04 - val_loss: 2.0208e-04\n",
      "Epoch 14/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 6.9610e-04 - val_loss: 1.8980e-04\n",
      "Epoch 15/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 6.8306e-04 - val_loss: 1.8296e-04\n",
      "Epoch 16/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 6.7465e-04 - val_loss: 1.3491e-04\n",
      "Epoch 17/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 6.8279e-04 - val_loss: 1.7054e-04\n",
      "Epoch 18/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 6.6479e-04 - val_loss: 1.5948e-04\n",
      "Epoch 19/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 6.8902e-04 - val_loss: 1.1132e-04\n",
      "Epoch 20/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 6.3537e-04 - val_loss: 1.3068e-04\n",
      "Epoch 21/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 6.2852e-04 - val_loss: 1.2424e-04\n",
      "Epoch 22/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 6.1127e-04 - val_loss: 1.0658e-04\n",
      "Epoch 23/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 6.0939e-04 - val_loss: 8.6487e-05\n",
      "Epoch 24/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 6.1440e-04 - val_loss: 8.6144e-05\n",
      "Epoch 25/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.9489e-04 - val_loss: 6.3415e-05\n",
      "Epoch 26/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 6.0053e-04 - val_loss: 1.5938e-04\n",
      "Epoch 27/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.9315e-04 - val_loss: 9.6975e-05\n",
      "Epoch 28/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.7601e-04 - val_loss: 6.8559e-05\n",
      "Epoch 29/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.7968e-04 - val_loss: 6.0631e-05\n",
      "Epoch 30/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.6488e-04 - val_loss: 7.5146e-05\n",
      "Epoch 31/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.7740e-04 - val_loss: 4.9876e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.7691e-04 - val_loss: 5.0401e-05\n",
      "Epoch 33/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.5144e-04 - val_loss: 5.0813e-05\n",
      "Epoch 34/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.7911e-04 - val_loss: 6.0862e-05\n",
      "Epoch 35/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.3645e-04 - val_loss: 7.2902e-05\n",
      "Epoch 36/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.3898e-04 - val_loss: 4.9016e-05\n",
      "Epoch 37/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.3555e-04 - val_loss: 3.9241e-05\n",
      "Epoch 38/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.7060e-04 - val_loss: 3.9529e-05\n",
      "Epoch 39/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.2306e-04 - val_loss: 6.4922e-05\n",
      "Epoch 40/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.2170e-04 - val_loss: 4.1962e-05\n",
      "Epoch 41/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.1791e-04 - val_loss: 3.7553e-05\n",
      "Epoch 42/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.1557e-04 - val_loss: 3.8012e-05\n",
      "Epoch 43/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.5076e-04 - val_loss: 3.7389e-05\n",
      "Epoch 44/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.0742e-04 - val_loss: 3.7524e-05\n",
      "Epoch 45/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.0543e-04 - val_loss: 3.7350e-05\n",
      "Epoch 46/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.9460e-04 - val_loss: 4.5493e-05\n",
      "Epoch 47/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.0290e-04 - val_loss: 4.2668e-05\n",
      "Epoch 48/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.5479e-04 - val_loss: 6.1947e-05\n",
      "Epoch 49/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.3154e-04 - val_loss: 5.2158e-05\n",
      "Epoch 50/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.1754e-04 - val_loss: 4.8335e-05\n",
      "Epoch 51/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.8531e-04 - val_loss: 3.9168e-05\n",
      "Epoch 52/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.2856e-04 - val_loss: 3.8115e-05\n",
      "Epoch 53/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.9558e-04 - val_loss: 3.6956e-05\n",
      "Epoch 54/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.8297e-04 - val_loss: 3.6431e-05\n",
      "Epoch 55/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.9020e-04 - val_loss: 3.4518e-05\n",
      "Epoch 56/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.6425e-04 - val_loss: 3.3648e-05\n",
      "Epoch 57/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.6375e-04 - val_loss: 4.8186e-05\n",
      "Epoch 58/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.7280e-04 - val_loss: 3.5627e-05\n",
      "Epoch 59/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.7385e-04 - val_loss: 3.9341e-05\n",
      "Epoch 60/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.0070e-04 - val_loss: 3.3050e-05\n",
      "Epoch 61/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.6705e-04 - val_loss: 3.5519e-05\n",
      "Epoch 62/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.5681e-04 - val_loss: 3.9393e-05\n",
      "Epoch 63/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.5636e-04 - val_loss: 3.8148e-05\n",
      "Epoch 64/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.5620e-04 - val_loss: 3.3934e-05\n",
      "Epoch 65/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.6740e-04 - val_loss: 3.2372e-05\n",
      "Epoch 66/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.4624e-04 - val_loss: 3.3446e-05\n",
      "Epoch 67/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.5482e-04 - val_loss: 3.1801e-05\n",
      "Epoch 68/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.4440e-04 - val_loss: 3.7624e-05\n",
      "Epoch 69/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.5329e-04 - val_loss: 3.6121e-05\n",
      "Epoch 70/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.4651e-04 - val_loss: 3.4331e-05\n",
      "Epoch 71/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.4524e-04 - val_loss: 3.4240e-05\n",
      "Epoch 72/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.7645e-04 - val_loss: 3.7308e-05\n",
      "Epoch 73/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.1341e-04 - val_loss: 3.1018e-05\n",
      "Epoch 74/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.2832e-04 - val_loss: 3.4078e-05\n",
      "Epoch 75/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.1936e-04 - val_loss: 3.0690e-05\n",
      "Epoch 76/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.2648e-04 - val_loss: 3.7185e-05\n",
      "Epoch 77/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.2596e-04 - val_loss: 4.4174e-05\n",
      "Epoch 78/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.2415e-04 - val_loss: 3.0325e-05\n",
      "Epoch 79/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.1468e-04 - val_loss: 3.0154e-05\n",
      "Epoch 80/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.1843e-04 - val_loss: 3.1402e-05\n",
      "Epoch 81/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.1118e-04 - val_loss: 3.0723e-05\n",
      "Epoch 82/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.1284e-04 - val_loss: 3.5714e-05\n",
      "Epoch 83/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.1110e-04 - val_loss: 2.9849e-05\n",
      "Epoch 84/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.1024e-04 - val_loss: 3.1412e-05\n",
      "Epoch 85/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.0545e-04 - val_loss: 3.1012e-05\n",
      "Epoch 86/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.0803e-04 - val_loss: 3.1300e-05\n",
      "Epoch 87/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.9307e-04 - val_loss: 2.9400e-05\n",
      "Epoch 88/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.9656e-04 - val_loss: 2.8833e-05\n",
      "Epoch 89/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.9423e-04 - val_loss: 2.9132e-05\n",
      "Epoch 90/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.9929e-04 - val_loss: 2.9537e-05\n",
      "Epoch 91/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.9838e-04 - val_loss: 2.8557e-05\n",
      "Epoch 92/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.8742e-04 - val_loss: 2.9981e-05\n",
      "Epoch 93/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.7918e-04 - val_loss: 3.6344e-05\n",
      "Epoch 94/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.1032e-04 - val_loss: 2.9546e-05\n",
      "Epoch 95/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.0414e-04 - val_loss: 3.0206e-05\n",
      "Epoch 96/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.2199e-04 - val_loss: 3.2697e-05\n",
      "Epoch 97/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.0811e-04 - val_loss: 2.7992e-05\n",
      "Epoch 98/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.7159e-04 - val_loss: 3.3128e-05\n",
      "Epoch 99/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.7830e-04 - val_loss: 2.9263e-05\n",
      "Epoch 100/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.0633e-04 - val_loss: 2.7513e-05\n",
      "Epoch 101/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.8148e-04 - val_loss: 2.8462e-05\n",
      "Epoch 102/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.7178e-04 - val_loss: 3.0152e-05\n",
      "Epoch 103/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.9592e-04 - val_loss: 3.9171e-05\n",
      "Epoch 104/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.8470e-04 - val_loss: 3.5746e-05\n",
      "Epoch 105/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.3488e-04 - val_loss: 3.6633e-05\n",
      "Epoch 106/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.9128e-04 - val_loss: 2.6833e-05\n",
      "Epoch 107/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.2809e-04 - val_loss: 2.7842e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.8029e-04 - val_loss: 2.9524e-05\n",
      "Epoch 109/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.9816e-04 - val_loss: 2.7466e-05\n",
      "Epoch 110/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.7130e-04 - val_loss: 2.6759e-05\n",
      "Epoch 111/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.6201e-04 - val_loss: 3.1274e-05\n",
      "Epoch 112/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.5197e-04 - val_loss: 2.6261e-05\n",
      "Epoch 113/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.9361e-04 - val_loss: 2.7778e-05\n",
      "Epoch 114/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.6737e-04 - val_loss: 2.7687e-05\n",
      "Epoch 115/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.6833e-04 - val_loss: 2.6193e-05\n",
      "Epoch 116/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.7319e-04 - val_loss: 2.5934e-05\n",
      "Epoch 117/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.4633e-04 - val_loss: 2.5802e-05\n",
      "Epoch 118/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.5467e-04 - val_loss: 2.6239e-05\n",
      "Epoch 119/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.5494e-04 - val_loss: 2.5821e-05\n",
      "Epoch 120/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.4568e-04 - val_loss: 2.5703e-05\n",
      "Epoch 121/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.5834e-04 - val_loss: 2.6616e-05\n",
      "Epoch 122/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.7742e-04 - val_loss: 2.5681e-05\n",
      "Epoch 123/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.3192e-04 - val_loss: 2.5050e-05\n",
      "Epoch 124/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.4512e-04 - val_loss: 2.5249e-05\n",
      "Epoch 125/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.3337e-04 - val_loss: 2.5318e-05\n",
      "Epoch 126/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.6292e-04 - val_loss: 2.9503e-05\n",
      "Epoch 127/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.3436e-04 - val_loss: 2.4956e-05\n",
      "Epoch 128/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.7648e-04 - val_loss: 2.5580e-05\n",
      "Epoch 129/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.2951e-04 - val_loss: 2.5695e-05\n",
      "Epoch 130/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.4034e-04 - val_loss: 2.4956e-05\n",
      "Epoch 131/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.4426e-04 - val_loss: 2.4457e-05\n",
      "Epoch 132/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.5131e-04 - val_loss: 2.8725e-05\n",
      "Epoch 133/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.4216e-04 - val_loss: 4.7591e-05\n",
      "Epoch 134/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.3736e-04 - val_loss: 4.5715e-05\n",
      "Epoch 135/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.3178e-04 - val_loss: 2.4306e-05\n",
      "Epoch 136/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.5992e-04 - val_loss: 2.4006e-05\n",
      "Epoch 137/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.2239e-04 - val_loss: 2.3858e-05\n",
      "Epoch 138/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.4992e-04 - val_loss: 2.3894e-05\n",
      "Epoch 139/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.2782e-04 - val_loss: 2.3814e-05\n",
      "Epoch 140/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.2383e-04 - val_loss: 2.3956e-05\n",
      "Epoch 141/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.1204e-04 - val_loss: 2.3884e-05\n",
      "Epoch 142/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.2234e-04 - val_loss: 3.4784e-05\n",
      "Epoch 143/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.3631e-04 - val_loss: 2.3429e-05\n",
      "Epoch 144/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.2377e-04 - val_loss: 2.4544e-05\n",
      "Epoch 145/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.2310e-04 - val_loss: 2.7986e-05\n",
      "Epoch 146/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.4852e-04 - val_loss: 2.3972e-05\n",
      "Epoch 147/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.1920e-04 - val_loss: 2.5980e-05\n",
      "Epoch 148/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.2396e-04 - val_loss: 2.7328e-05\n",
      "Epoch 149/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.2219e-04 - val_loss: 2.8484e-05\n",
      "Epoch 150/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.1122e-04 - val_loss: 2.2815e-05\n",
      "Epoch 151/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.0940e-04 - val_loss: 2.6492e-05\n",
      "Epoch 152/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.0795e-04 - val_loss: 2.4573e-05\n",
      "Epoch 153/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.4977e-04 - val_loss: 2.4330e-05\n",
      "Epoch 154/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.0075e-04 - val_loss: 2.2545e-05\n",
      "Epoch 155/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.0496e-04 - val_loss: 2.2474e-05\n",
      "Epoch 156/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.2803e-04 - val_loss: 2.2995e-05\n",
      "Epoch 157/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.4143e-04 - val_loss: 2.9606e-05\n",
      "Epoch 158/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.3515e-04 - val_loss: 2.8460e-05\n",
      "Epoch 159/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.1004e-04 - val_loss: 2.7733e-05\n",
      "Epoch 160/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.9246e-04 - val_loss: 2.2376e-05\n",
      "Epoch 161/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.0174e-04 - val_loss: 2.1924e-05\n",
      "Epoch 162/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.3053e-04 - val_loss: 2.2221e-05\n",
      "Epoch 163/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.0321e-04 - val_loss: 2.2532e-05\n",
      "Epoch 164/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.9356e-04 - val_loss: 2.1652e-05\n",
      "Epoch 165/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.9767e-04 - val_loss: 2.4508e-05\n",
      "Epoch 166/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.0858e-04 - val_loss: 2.2246e-05\n",
      "Epoch 167/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.9601e-04 - val_loss: 2.9440e-05\n",
      "Epoch 168/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.4322e-04 - val_loss: 2.1397e-05\n",
      "Epoch 169/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.3152e-04 - val_loss: 2.2141e-05\n",
      "Epoch 170/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.0621e-04 - val_loss: 2.2135e-05\n",
      "Epoch 171/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.8192e-04 - val_loss: 2.2631e-05\n",
      "Epoch 172/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.8465e-04 - val_loss: 2.1368e-05\n",
      "Epoch 173/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.9549e-04 - val_loss: 2.2506e-05\n",
      "Epoch 174/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.1373e-04 - val_loss: 2.1073e-05\n",
      "Epoch 175/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.1760e-04 - val_loss: 2.0996e-05\n",
      "Epoch 176/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.7711e-04 - val_loss: 2.1475e-05\n",
      "Epoch 177/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.8271e-04 - val_loss: 2.1944e-05\n",
      "Epoch 178/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.7244e-04 - val_loss: 2.0788e-05\n",
      "Epoch 179/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.8158e-04 - val_loss: 2.5599e-05\n",
      "Epoch 180/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.8262e-04 - val_loss: 2.0587e-05\n",
      "Epoch 181/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.7543e-04 - val_loss: 2.1084e-05\n",
      "Epoch 182/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.9032e-04 - val_loss: 2.0765e-05\n",
      "Epoch 183/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 4ms/step - loss: 3.0377e-04 - val_loss: 2.2863e-05\n",
      "Epoch 184/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.6993e-04 - val_loss: 2.1154e-05\n",
      "Epoch 185/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.0018e-04 - val_loss: 4.3453e-05\n",
      "Epoch 186/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.6828e-04 - val_loss: 2.0410e-05\n",
      "Epoch 187/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.0458e-04 - val_loss: 2.0662e-05\n",
      "Epoch 188/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.7805e-04 - val_loss: 2.6187e-05\n",
      "Epoch 189/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.7747e-04 - val_loss: 3.0825e-05\n",
      "Epoch 190/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.8385e-04 - val_loss: 2.8854e-05\n",
      "Epoch 191/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.9558e-04 - val_loss: 2.1405e-05\n",
      "Epoch 192/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.6627e-04 - val_loss: 2.2143e-05\n",
      "Epoch 193/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.0672e-04 - val_loss: 2.1423e-05\n",
      "Epoch 194/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.6485e-04 - val_loss: 2.1167e-05\n",
      "Epoch 195/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.6296e-04 - val_loss: 2.0330e-05\n",
      "Epoch 196/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.6187e-04 - val_loss: 1.9669e-05\n",
      "Epoch 197/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.6025e-04 - val_loss: 1.9819e-05\n",
      "Epoch 198/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.9820e-04 - val_loss: 2.3885e-05\n",
      "Epoch 199/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.0577e-04 - val_loss: 2.1973e-05\n",
      "Epoch 200/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.7819e-04 - val_loss: 2.3685e-05\n",
      "Thời gian huấn luyện:  23.7024347782135\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_8 (SimpleRNN)    (None, 10, 100)           10200     \n",
      "                                                                 \n",
      " flatten_33 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,201\n",
      "Trainable params: 11,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "31/31 [==============================] - 2s 19ms/step - loss: 0.0561 - val_loss: 0.0023\n",
      "Epoch 2/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 3/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 4/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 7.2456e-04\n",
      "Epoch 5/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 5.1462e-04\n",
      "Epoch 6/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 4.1376e-04\n",
      "Epoch 7/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 3.8700e-04\n",
      "Epoch 8/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 2.8283e-04\n",
      "Epoch 9/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 2.9296e-04\n",
      "Epoch 10/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 2.9545e-04\n",
      "Epoch 11/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 2.0558e-04\n",
      "Epoch 12/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 2.4177e-04\n",
      "Epoch 13/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 2.5403e-04\n",
      "Epoch 14/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 2.4606e-04\n",
      "Epoch 15/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 2.2505e-04\n",
      "Epoch 16/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 2.1684e-04\n",
      "Epoch 17/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.9980e-04 - val_loss: 1.8146e-04\n",
      "Epoch 18/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 2.2120e-04\n",
      "Epoch 19/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 2.1527e-04\n",
      "Epoch 20/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.9979e-04 - val_loss: 2.3869e-04\n",
      "Epoch 21/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.9714e-04 - val_loss: 2.0901e-04\n",
      "Epoch 22/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 1.6862e-04\n",
      "Epoch 23/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 1.6125e-04\n",
      "Epoch 24/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 2.0379e-04\n",
      "Epoch 25/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.9248e-04 - val_loss: 2.1738e-04\n",
      "Epoch 26/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.8492e-04 - val_loss: 2.3992e-04\n",
      "Epoch 27/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 9.8624e-04 - val_loss: 2.1586e-04\n",
      "Epoch 28/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.8095e-04 - val_loss: 1.9924e-04\n",
      "Epoch 29/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 9.9015e-04 - val_loss: 1.8516e-04\n",
      "Epoch 30/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.8360e-04 - val_loss: 2.5457e-04\n",
      "Epoch 31/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.9663e-04 - val_loss: 2.1912e-04\n",
      "Epoch 32/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.7132e-04 - val_loss: 1.9637e-04\n",
      "Epoch 33/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.8108e-04 - val_loss: 2.0535e-04\n",
      "Epoch 34/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.7196e-04 - val_loss: 2.2059e-04\n",
      "Epoch 35/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.6496e-04 - val_loss: 2.3827e-04\n",
      "Epoch 36/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.8641e-04 - val_loss: 2.0105e-04\n",
      "Epoch 37/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.6303e-04 - val_loss: 2.0911e-04\n",
      "Epoch 38/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.9131e-04 - val_loss: 2.9189e-04\n",
      "Epoch 39/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.7727e-04 - val_loss: 2.4463e-04\n",
      "Epoch 40/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.6582e-04 - val_loss: 1.6799e-04\n",
      "Epoch 41/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.6397e-04 - val_loss: 2.0617e-04\n",
      "Epoch 42/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.4309e-04 - val_loss: 1.4466e-04\n",
      "Epoch 43/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.6154e-04 - val_loss: 1.5984e-04\n",
      "Epoch 44/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.6200e-04 - val_loss: 1.5366e-04\n",
      "Epoch 45/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.4986e-04 - val_loss: 1.6788e-04\n",
      "Epoch 46/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.3817e-04 - val_loss: 1.8641e-04\n",
      "Epoch 47/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.4578e-04 - val_loss: 1.4468e-04\n",
      "Epoch 48/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.7817e-04 - val_loss: 1.3578e-04\n",
      "Epoch 49/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.6185e-04 - val_loss: 1.8847e-04\n",
      "Epoch 50/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.3259e-04 - val_loss: 1.6769e-04\n",
      "Epoch 51/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.4983e-04 - val_loss: 1.3897e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.5614e-04 - val_loss: 2.0009e-04\n",
      "Epoch 53/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.4053e-04 - val_loss: 2.1806e-04\n",
      "Epoch 54/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.5574e-04 - val_loss: 1.8729e-04\n",
      "Epoch 55/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.1707e-04 - val_loss: 1.6130e-04\n",
      "Epoch 56/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.2592e-04 - val_loss: 1.9492e-04\n",
      "Epoch 57/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.3211e-04 - val_loss: 1.8580e-04\n",
      "Epoch 58/200\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 9.1219e-04 - val_loss: 1.5837e-04\n",
      "Epoch 59/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 9.1127e-04 - val_loss: 1.5954e-04\n",
      "Epoch 60/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 9.0901e-04 - val_loss: 1.5423e-04\n",
      "Epoch 61/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.0095e-04 - val_loss: 2.4309e-04\n",
      "Epoch 62/200\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 9.2241e-04 - val_loss: 1.4934e-04\n",
      "Epoch 63/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.0803e-04 - val_loss: 1.9826e-04\n",
      "Epoch 64/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 9.0872e-04 - val_loss: 1.7711e-04\n",
      "Epoch 65/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 9.0108e-04 - val_loss: 1.4389e-04\n",
      "Epoch 66/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.9667e-04 - val_loss: 1.2933e-04\n",
      "Epoch 67/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.9307e-04 - val_loss: 1.5371e-04\n",
      "Epoch 68/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 8.8733e-04 - val_loss: 1.4624e-04\n",
      "Epoch 69/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 9.3623e-04 - val_loss: 1.1510e-04\n",
      "Epoch 70/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 9.1389e-04 - val_loss: 1.8067e-04\n",
      "Epoch 71/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 9.1258e-04 - val_loss: 1.1119e-04\n",
      "Epoch 72/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.0197e-04 - val_loss: 1.1239e-04\n",
      "Epoch 73/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.0100e-04 - val_loss: 1.6323e-04\n",
      "Epoch 74/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.7406e-04 - val_loss: 1.3232e-04\n",
      "Epoch 75/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.6285e-04 - val_loss: 1.4715e-04\n",
      "Epoch 76/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.6285e-04 - val_loss: 1.6912e-04\n",
      "Epoch 77/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.6424e-04 - val_loss: 1.5052e-04\n",
      "Epoch 78/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.5304e-04 - val_loss: 1.1798e-04\n",
      "Epoch 79/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.6678e-04 - val_loss: 2.3921e-04\n",
      "Epoch 80/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.7028e-04 - val_loss: 1.1479e-04\n",
      "Epoch 81/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.4310e-04 - val_loss: 1.2652e-04\n",
      "Epoch 82/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.3875e-04 - val_loss: 1.3008e-04\n",
      "Epoch 83/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.3544e-04 - val_loss: 1.2149e-04\n",
      "Epoch 84/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.2713e-04 - val_loss: 1.5993e-04\n",
      "Epoch 85/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.5483e-04 - val_loss: 1.3778e-04\n",
      "Epoch 86/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.2728e-04 - val_loss: 1.4161e-04\n",
      "Epoch 87/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.2249e-04 - val_loss: 8.5632e-05\n",
      "Epoch 88/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.2593e-04 - val_loss: 1.4238e-04\n",
      "Epoch 89/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.2619e-04 - val_loss: 1.1942e-04\n",
      "Epoch 90/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.2740e-04 - val_loss: 1.2499e-04\n",
      "Epoch 91/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.1511e-04 - val_loss: 1.1362e-04\n",
      "Epoch 92/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.1689e-04 - val_loss: 1.2078e-04\n",
      "Epoch 93/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.0405e-04 - val_loss: 1.3576e-04\n",
      "Epoch 94/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.0356e-04 - val_loss: 1.3762e-04\n",
      "Epoch 95/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.0969e-04 - val_loss: 1.5996e-04\n",
      "Epoch 96/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.2208e-04 - val_loss: 1.4643e-04\n",
      "Epoch 97/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.1945e-04 - val_loss: 9.9977e-05\n",
      "Epoch 98/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.8983e-04 - val_loss: 1.0870e-04\n",
      "Epoch 99/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.1482e-04 - val_loss: 1.0450e-04\n",
      "Epoch 100/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.8768e-04 - val_loss: 1.3041e-04\n",
      "Epoch 101/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.7279e-04 - val_loss: 1.1077e-04\n",
      "Epoch 102/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.8095e-04 - val_loss: 1.2020e-04\n",
      "Epoch 103/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.8038e-04 - val_loss: 1.7258e-04\n",
      "Epoch 104/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.9444e-04 - val_loss: 1.0487e-04\n",
      "Epoch 105/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.8261e-04 - val_loss: 1.2059e-04\n",
      "Epoch 106/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.5576e-04 - val_loss: 9.7389e-05\n",
      "Epoch 107/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.5076e-04 - val_loss: 1.3004e-04\n",
      "Epoch 108/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.5752e-04 - val_loss: 1.1522e-04\n",
      "Epoch 109/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.5503e-04 - val_loss: 9.4387e-05\n",
      "Epoch 110/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.4926e-04 - val_loss: 1.0565e-04\n",
      "Epoch 111/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.7168e-04 - val_loss: 1.0887e-04\n",
      "Epoch 112/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.6463e-04 - val_loss: 8.2700e-05\n",
      "Epoch 113/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.5079e-04 - val_loss: 1.2933e-04\n",
      "Epoch 114/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.4095e-04 - val_loss: 1.0805e-04\n",
      "Epoch 115/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.2667e-04 - val_loss: 8.8348e-05\n",
      "Epoch 116/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 7.1653e-04 - val_loss: 7.6779e-05\n",
      "Epoch 117/200\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 7.2886e-04 - val_loss: 1.4325e-04\n",
      "Epoch 118/200\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 7.2485e-04 - val_loss: 7.2196e-05\n",
      "Epoch 119/200\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 7.3338e-04 - val_loss: 7.7542e-05\n",
      "Epoch 120/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 7.3768e-04 - val_loss: 1.6232e-04\n",
      "Epoch 121/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 7.1215e-04 - val_loss: 9.8538e-05\n",
      "Epoch 122/200\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 6.9376e-04 - val_loss: 9.3933e-05\n",
      "Epoch 123/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 7.0301e-04 - val_loss: 8.0474e-05\n",
      "Epoch 124/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 6.8289e-04 - val_loss: 9.1721e-05\n",
      "Epoch 125/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 6.9359e-04 - val_loss: 8.1645e-05\n",
      "Epoch 126/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 6.8520e-04 - val_loss: 7.7090e-05\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 8ms/step - loss: 6.7869e-04 - val_loss: 6.4479e-05\n",
      "Epoch 128/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 6.8668e-04 - val_loss: 7.3511e-05\n",
      "Epoch 129/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 6.6759e-04 - val_loss: 9.7345e-05\n",
      "Epoch 130/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 6.8992e-04 - val_loss: 6.6038e-05\n",
      "Epoch 131/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 6.7689e-04 - val_loss: 6.0463e-05\n",
      "Epoch 132/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 6.8081e-04 - val_loss: 7.1163e-05\n",
      "Epoch 133/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 6.6933e-04 - val_loss: 6.1209e-05\n",
      "Epoch 134/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 7.0423e-04 - val_loss: 7.7885e-05\n",
      "Epoch 135/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 6.4267e-04 - val_loss: 7.2970e-05\n",
      "Epoch 136/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 6.4167e-04 - val_loss: 5.6262e-05\n",
      "Epoch 137/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 6.4021e-04 - val_loss: 6.3682e-05\n",
      "Epoch 138/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 6.6278e-04 - val_loss: 9.4380e-05\n",
      "Epoch 139/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 6.5475e-04 - val_loss: 5.3539e-05\n",
      "Epoch 140/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 6.5576e-04 - val_loss: 5.9495e-05\n",
      "Epoch 141/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 6.3365e-04 - val_loss: 6.3066e-05\n",
      "Epoch 142/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 6.4528e-04 - val_loss: 6.8393e-05\n",
      "Epoch 143/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 6.2249e-04 - val_loss: 5.2970e-05\n",
      "Epoch 144/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 6.4468e-04 - val_loss: 6.4939e-05\n",
      "Epoch 145/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 6.2421e-04 - val_loss: 4.9600e-05\n",
      "Epoch 146/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 6.0423e-04 - val_loss: 5.2916e-05\n",
      "Epoch 147/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 6.1015e-04 - val_loss: 5.2763e-05\n",
      "Epoch 148/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 6.5937e-04 - val_loss: 8.5941e-05\n",
      "Epoch 149/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 6.3173e-04 - val_loss: 5.4356e-05\n",
      "Epoch 150/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 6.0020e-04 - val_loss: 5.0804e-05\n",
      "Epoch 151/200\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 6.1047e-04 - val_loss: 6.5736e-05\n",
      "Epoch 152/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 6.1907e-04 - val_loss: 5.8357e-05\n",
      "Epoch 153/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.7979e-04 - val_loss: 6.0803e-05\n",
      "Epoch 154/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 6.1588e-04 - val_loss: 5.1212e-05\n",
      "Epoch 155/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.7788e-04 - val_loss: 4.7844e-05\n",
      "Epoch 156/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.8046e-04 - val_loss: 4.7309e-05\n",
      "Epoch 157/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.9115e-04 - val_loss: 4.8030e-05\n",
      "Epoch 158/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.8226e-04 - val_loss: 4.9852e-05\n",
      "Epoch 159/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.9644e-04 - val_loss: 5.3199e-05\n",
      "Epoch 160/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.7971e-04 - val_loss: 4.6200e-05\n",
      "Epoch 161/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.7999e-04 - val_loss: 4.7764e-05\n",
      "Epoch 162/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.5892e-04 - val_loss: 4.5855e-05\n",
      "Epoch 163/200\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 6.0518e-04 - val_loss: 4.5570e-05\n",
      "Epoch 164/200\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 5.6033e-04 - val_loss: 4.6972e-05\n",
      "Epoch 165/200\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 5.6180e-04 - val_loss: 4.7203e-05\n",
      "Epoch 166/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.6209e-04 - val_loss: 4.7961e-05\n",
      "Epoch 167/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.5623e-04 - val_loss: 4.8752e-05\n",
      "Epoch 168/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.6627e-04 - val_loss: 4.7725e-05\n",
      "Epoch 169/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.4418e-04 - val_loss: 4.6763e-05\n",
      "Epoch 170/200\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 5.8674e-04 - val_loss: 4.4483e-05\n",
      "Epoch 171/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.5367e-04 - val_loss: 5.0300e-05\n",
      "Epoch 172/200\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 5.7205e-04 - val_loss: 4.4604e-05\n",
      "Epoch 173/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.5860e-04 - val_loss: 4.9912e-05\n",
      "Epoch 174/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.3510e-04 - val_loss: 5.0925e-05\n",
      "Epoch 175/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.3711e-04 - val_loss: 4.9130e-05\n",
      "Epoch 176/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.6267e-04 - val_loss: 5.4680e-05\n",
      "Epoch 177/200\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 5.4756e-04 - val_loss: 4.3786e-05\n",
      "Epoch 178/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.3128e-04 - val_loss: 4.6640e-05\n",
      "Epoch 179/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.2952e-04 - val_loss: 5.1284e-05\n",
      "Epoch 180/200\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 5.5976e-04 - val_loss: 4.6491e-05\n",
      "Epoch 181/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.2952e-04 - val_loss: 4.9585e-05\n",
      "Epoch 182/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.5071e-04 - val_loss: 7.4083e-05\n",
      "Epoch 183/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.5611e-04 - val_loss: 4.4251e-05\n",
      "Epoch 184/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.3813e-04 - val_loss: 4.3255e-05\n",
      "Epoch 185/200\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 5.1765e-04 - val_loss: 5.2684e-05\n",
      "Epoch 186/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.2125e-04 - val_loss: 4.8989e-05\n",
      "Epoch 187/200\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 5.4029e-04 - val_loss: 4.3618e-05\n",
      "Epoch 188/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.2833e-04 - val_loss: 4.2383e-05\n",
      "Epoch 189/200\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 5.2333e-04 - val_loss: 5.1454e-05\n",
      "Epoch 190/200\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 5.5601e-04 - val_loss: 4.4063e-05\n",
      "Epoch 191/200\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 5.2489e-04 - val_loss: 4.3212e-05\n",
      "Epoch 192/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.2165e-04 - val_loss: 4.4519e-05\n",
      "Epoch 193/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.1156e-04 - val_loss: 4.4428e-05\n",
      "Epoch 194/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.0595e-04 - val_loss: 4.3216e-05\n",
      "Epoch 195/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.1947e-04 - val_loss: 5.9381e-05\n",
      "Epoch 196/200\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 5.3342e-04 - val_loss: 4.3762e-05\n",
      "Epoch 197/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.2322e-04 - val_loss: 4.9495e-05\n",
      "Epoch 198/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.0513e-04 - val_loss: 4.2481e-05\n",
      "Epoch 199/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.2745e-04 - val_loss: 4.9489e-05\n",
      "Epoch 200/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.2982e-04 - val_loss: 4.3789e-05\n",
      "Thời gian huấn luyện:  55.442564487457275\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 10, 100)           40800     \n",
      "                                                                 \n",
      " flatten_34 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,801\n",
      "Trainable params: 41,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "31/31 [==============================] - 2s 19ms/step - loss: 0.0485 - val_loss: 0.0022\n",
      "Epoch 2/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 3/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 6.2108e-04\n",
      "Epoch 4/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 3.5288e-04\n",
      "Epoch 5/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.2436e-04 - val_loss: 1.5649e-04\n",
      "Epoch 6/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 9.0254e-04 - val_loss: 1.0117e-04\n",
      "Epoch 7/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.8359e-04 - val_loss: 8.6804e-05\n",
      "Epoch 8/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.8404e-04 - val_loss: 1.0421e-04\n",
      "Epoch 9/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.7996e-04 - val_loss: 8.9280e-05\n",
      "Epoch 10/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.7942e-04 - val_loss: 8.5098e-05\n",
      "Epoch 11/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.7714e-04 - val_loss: 7.8063e-05\n",
      "Epoch 12/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.6119e-04 - val_loss: 7.2581e-05\n",
      "Epoch 13/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.5907e-04 - val_loss: 7.5725e-05\n",
      "Epoch 14/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.5000e-04 - val_loss: 9.7861e-05\n",
      "Epoch 15/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 8.6918e-04 - val_loss: 8.0511e-05\n",
      "Epoch 16/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 8.4696e-04 - val_loss: 6.8806e-05\n",
      "Epoch 17/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 8.5746e-04 - val_loss: 6.6464e-05\n",
      "Epoch 18/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 8.3961e-04 - val_loss: 7.8602e-05\n",
      "Epoch 19/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 8.3696e-04 - val_loss: 7.1697e-05\n",
      "Epoch 20/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 8.3882e-04 - val_loss: 8.2053e-05\n",
      "Epoch 21/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 8.3224e-04 - val_loss: 7.0922e-05\n",
      "Epoch 22/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 8.2313e-04 - val_loss: 6.5611e-05\n",
      "Epoch 23/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 8.1696e-04 - val_loss: 8.9664e-05\n",
      "Epoch 24/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 8.1534e-04 - val_loss: 7.4878e-05\n",
      "Epoch 25/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 8.1289e-04 - val_loss: 7.1501e-05\n",
      "Epoch 26/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 8.0354e-04 - val_loss: 6.9084e-05\n",
      "Epoch 27/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.9904e-04 - val_loss: 6.5012e-05\n",
      "Epoch 28/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.9741e-04 - val_loss: 7.5372e-05\n",
      "Epoch 29/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 8.0639e-04 - val_loss: 7.4090e-05\n",
      "Epoch 30/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.9730e-04 - val_loss: 6.1179e-05\n",
      "Epoch 31/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 8.0504e-04 - val_loss: 6.7754e-05\n",
      "Epoch 32/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.8381e-04 - val_loss: 7.1341e-05\n",
      "Epoch 33/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.7498e-04 - val_loss: 6.9807e-05\n",
      "Epoch 34/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.6867e-04 - val_loss: 6.7753e-05\n",
      "Epoch 35/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.7013e-04 - val_loss: 6.4535e-05\n",
      "Epoch 36/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.6640e-04 - val_loss: 9.5494e-05\n",
      "Epoch 37/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.5959e-04 - val_loss: 7.6020e-05\n",
      "Epoch 38/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.5771e-04 - val_loss: 6.9164e-05\n",
      "Epoch 39/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.5000e-04 - val_loss: 6.5285e-05\n",
      "Epoch 40/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.4655e-04 - val_loss: 5.8141e-05\n",
      "Epoch 41/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.4915e-04 - val_loss: 5.7874e-05\n",
      "Epoch 42/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.4325e-04 - val_loss: 6.7290e-05\n",
      "Epoch 43/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.2846e-04 - val_loss: 6.0700e-05\n",
      "Epoch 44/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.2625e-04 - val_loss: 5.8871e-05\n",
      "Epoch 45/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.2014e-04 - val_loss: 5.6350e-05\n",
      "Epoch 46/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.2153e-04 - val_loss: 5.6728e-05\n",
      "Epoch 47/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.2431e-04 - val_loss: 5.6387e-05\n",
      "Epoch 48/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.1713e-04 - val_loss: 6.4351e-05\n",
      "Epoch 49/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 7.0161e-04 - val_loss: 6.0070e-05\n",
      "Epoch 50/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 6.9651e-04 - val_loss: 8.1118e-05\n",
      "Epoch 51/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 7.1143e-04 - val_loss: 5.9752e-05\n",
      "Epoch 52/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 6.9148e-04 - val_loss: 5.4206e-05\n",
      "Epoch 53/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 6.8834e-04 - val_loss: 5.9116e-05\n",
      "Epoch 54/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 6.7949e-04 - val_loss: 6.1355e-05\n",
      "Epoch 55/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 6.7021e-04 - val_loss: 5.2975e-05\n",
      "Epoch 56/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 6.6456e-04 - val_loss: 5.7875e-05\n",
      "Epoch 57/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 6.6653e-04 - val_loss: 5.8116e-05\n",
      "Epoch 58/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 6.6970e-04 - val_loss: 5.3524e-05\n",
      "Epoch 59/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 6.7310e-04 - val_loss: 6.7762e-05\n",
      "Epoch 60/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 6.5471e-04 - val_loss: 5.7223e-05\n",
      "Epoch 61/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 6.4394e-04 - val_loss: 5.1875e-05\n",
      "Epoch 62/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 6.5249e-04 - val_loss: 5.0140e-05\n",
      "Epoch 63/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 6.3588e-04 - val_loss: 5.0090e-05\n",
      "Epoch 64/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 6.4100e-04 - val_loss: 5.0543e-05\n",
      "Epoch 65/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 6.5745e-04 - val_loss: 5.8354e-05\n",
      "Epoch 66/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 6.3253e-04 - val_loss: 4.9250e-05\n",
      "Epoch 67/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 6.1392e-04 - val_loss: 5.3567e-05\n",
      "Epoch 68/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 6.1176e-04 - val_loss: 5.5532e-05\n",
      "Epoch 69/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 6.0771e-04 - val_loss: 4.7903e-05\n",
      "Epoch 70/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 7ms/step - loss: 6.1015e-04 - val_loss: 4.7400e-05\n",
      "Epoch 71/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 6.1436e-04 - val_loss: 4.7047e-05\n",
      "Epoch 72/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 5.9888e-04 - val_loss: 6.8291e-05\n",
      "Epoch 73/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 6.1264e-04 - val_loss: 4.8042e-05\n",
      "Epoch 74/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.9143e-04 - val_loss: 5.9762e-05\n",
      "Epoch 75/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 5.8772e-04 - val_loss: 4.9626e-05\n",
      "Epoch 76/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 5.8910e-04 - val_loss: 4.6255e-05\n",
      "Epoch 77/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.7362e-04 - val_loss: 4.7082e-05\n",
      "Epoch 78/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.7055e-04 - val_loss: 5.6460e-05\n",
      "Epoch 79/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.7800e-04 - val_loss: 4.4641e-05\n",
      "Epoch 80/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.6788e-04 - val_loss: 4.4410e-05\n",
      "Epoch 81/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.5817e-04 - val_loss: 4.4213e-05\n",
      "Epoch 82/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.6235e-04 - val_loss: 4.5407e-05\n",
      "Epoch 83/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.4280e-04 - val_loss: 4.7384e-05\n",
      "Epoch 84/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.5348e-04 - val_loss: 4.3614e-05\n",
      "Epoch 85/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.3897e-04 - val_loss: 4.3094e-05\n",
      "Epoch 86/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.3917e-04 - val_loss: 5.4364e-05\n",
      "Epoch 87/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.4422e-04 - val_loss: 4.4629e-05\n",
      "Epoch 88/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.2675e-04 - val_loss: 4.3333e-05\n",
      "Epoch 89/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.3050e-04 - val_loss: 4.7879e-05\n",
      "Epoch 90/200\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 5.1506e-04 - val_loss: 4.2937e-05\n",
      "Epoch 91/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.3748e-04 - val_loss: 4.1611e-05\n",
      "Epoch 92/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.1669e-04 - val_loss: 5.3216e-05\n",
      "Epoch 93/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.1132e-04 - val_loss: 4.7424e-05\n",
      "Epoch 94/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.1423e-04 - val_loss: 4.0754e-05\n",
      "Epoch 95/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.2762e-04 - val_loss: 5.0382e-05\n",
      "Epoch 96/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.2234e-04 - val_loss: 4.0612e-05\n",
      "Epoch 97/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.1000e-04 - val_loss: 4.6522e-05\n",
      "Epoch 98/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.9566e-04 - val_loss: 4.2878e-05\n",
      "Epoch 99/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.9132e-04 - val_loss: 4.8212e-05\n",
      "Epoch 100/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.8886e-04 - val_loss: 3.9588e-05\n",
      "Epoch 101/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.8647e-04 - val_loss: 5.0647e-05\n",
      "Epoch 102/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.8519e-04 - val_loss: 4.5628e-05\n",
      "Epoch 103/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.0319e-04 - val_loss: 6.4022e-05\n",
      "Epoch 104/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 5.2109e-04 - val_loss: 4.7943e-05\n",
      "Epoch 105/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.9204e-04 - val_loss: 4.0132e-05\n",
      "Epoch 106/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.8038e-04 - val_loss: 4.1572e-05\n",
      "Epoch 107/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.6616e-04 - val_loss: 6.0480e-05\n",
      "Epoch 108/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.7437e-04 - val_loss: 4.6585e-05\n",
      "Epoch 109/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.6798e-04 - val_loss: 4.9880e-05\n",
      "Epoch 110/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.5763e-04 - val_loss: 4.4780e-05\n",
      "Epoch 111/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.7415e-04 - val_loss: 4.1958e-05\n",
      "Epoch 112/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.6991e-04 - val_loss: 5.7162e-05\n",
      "Epoch 113/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 4.5619e-04 - val_loss: 4.1641e-05\n",
      "Epoch 114/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.5126e-04 - val_loss: 4.3098e-05\n",
      "Epoch 115/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.7243e-04 - val_loss: 4.2367e-05\n",
      "Epoch 116/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.5712e-04 - val_loss: 3.8476e-05\n",
      "Epoch 117/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.9391e-04 - val_loss: 3.7691e-05\n",
      "Epoch 118/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.4364e-04 - val_loss: 4.4166e-05\n",
      "Epoch 119/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.3618e-04 - val_loss: 4.8024e-05\n",
      "Epoch 120/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.4895e-04 - val_loss: 4.6361e-05\n",
      "Epoch 121/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.4161e-04 - val_loss: 3.7066e-05\n",
      "Epoch 122/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.2843e-04 - val_loss: 3.6464e-05\n",
      "Epoch 123/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.4222e-04 - val_loss: 3.7906e-05\n",
      "Epoch 124/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.4274e-04 - val_loss: 3.7219e-05\n",
      "Epoch 125/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.4563e-04 - val_loss: 3.6882e-05\n",
      "Epoch 126/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.2668e-04 - val_loss: 5.6789e-05\n",
      "Epoch 127/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.2776e-04 - val_loss: 4.6013e-05\n",
      "Epoch 128/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.2964e-04 - val_loss: 5.3503e-05\n",
      "Epoch 129/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.2114e-04 - val_loss: 4.6268e-05\n",
      "Epoch 130/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.1883e-04 - val_loss: 3.8880e-05\n",
      "Epoch 131/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.1833e-04 - val_loss: 3.7648e-05\n",
      "Epoch 132/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.2078e-04 - val_loss: 5.6110e-05\n",
      "Epoch 133/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.2347e-04 - val_loss: 4.8151e-05\n",
      "Epoch 134/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.1670e-04 - val_loss: 3.6816e-05\n",
      "Epoch 135/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.1585e-04 - val_loss: 6.7922e-05\n",
      "Epoch 136/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.1180e-04 - val_loss: 3.6496e-05\n",
      "Epoch 137/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.0640e-04 - val_loss: 4.3007e-05\n",
      "Epoch 138/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.2219e-04 - val_loss: 5.9236e-05\n",
      "Epoch 139/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.1215e-04 - val_loss: 4.5992e-05\n",
      "Epoch 140/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.9913e-04 - val_loss: 4.7368e-05\n",
      "Epoch 141/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.1277e-04 - val_loss: 3.4143e-05\n",
      "Epoch 142/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.9888e-04 - val_loss: 5.8430e-05\n",
      "Epoch 143/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.1861e-04 - val_loss: 4.6221e-05\n",
      "Epoch 144/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.9186e-04 - val_loss: 3.8406e-05\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 8ms/step - loss: 4.0644e-04 - val_loss: 6.5320e-05\n",
      "Epoch 146/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.4030e-04 - val_loss: 7.1235e-05\n",
      "Epoch 147/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.3003e-04 - val_loss: 4.9227e-05\n",
      "Epoch 148/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.9844e-04 - val_loss: 4.1943e-05\n",
      "Epoch 149/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.9199e-04 - val_loss: 3.6695e-05\n",
      "Epoch 150/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.8598e-04 - val_loss: 3.9376e-05\n",
      "Epoch 151/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.8076e-04 - val_loss: 4.4424e-05\n",
      "Epoch 152/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.7727e-04 - val_loss: 3.6305e-05\n",
      "Epoch 153/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.2345e-04 - val_loss: 3.3200e-05\n",
      "Epoch 154/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.9728e-04 - val_loss: 3.9215e-05\n",
      "Epoch 155/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.9850e-04 - val_loss: 3.5355e-05\n",
      "Epoch 156/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.8541e-04 - val_loss: 3.6149e-05\n",
      "Epoch 157/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.8002e-04 - val_loss: 3.4315e-05\n",
      "Epoch 158/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.7795e-04 - val_loss: 3.8896e-05\n",
      "Epoch 159/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.6871e-04 - val_loss: 3.2161e-05\n",
      "Epoch 160/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.7932e-04 - val_loss: 3.8084e-05\n",
      "Epoch 161/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.6680e-04 - val_loss: 3.3570e-05\n",
      "Epoch 162/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.7261e-04 - val_loss: 4.1246e-05\n",
      "Epoch 163/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.1153e-04 - val_loss: 4.7240e-05\n",
      "Epoch 164/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.6132e-04 - val_loss: 3.1785e-05\n",
      "Epoch 165/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.8169e-04 - val_loss: 3.2812e-05\n",
      "Epoch 166/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.6646e-04 - val_loss: 5.0499e-05\n",
      "Epoch 167/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.6171e-04 - val_loss: 3.7192e-05\n",
      "Epoch 168/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.7478e-04 - val_loss: 3.0805e-05\n",
      "Epoch 169/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.9310e-04 - val_loss: 4.5632e-05\n",
      "Epoch 170/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.8015e-04 - val_loss: 3.2278e-05\n",
      "Epoch 171/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.8497e-04 - val_loss: 4.3232e-05\n",
      "Epoch 172/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.8944e-04 - val_loss: 3.0891e-05\n",
      "Epoch 173/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.5235e-04 - val_loss: 3.2081e-05\n",
      "Epoch 174/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.4467e-04 - val_loss: 5.5483e-05\n",
      "Epoch 175/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.4781e-04 - val_loss: 2.9916e-05\n",
      "Epoch 176/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.7950e-04 - val_loss: 3.2551e-05\n",
      "Epoch 177/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.5695e-04 - val_loss: 3.0772e-05\n",
      "Epoch 178/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.6381e-04 - val_loss: 5.6402e-05\n",
      "Epoch 179/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.6944e-04 - val_loss: 3.1878e-05\n",
      "Epoch 180/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.4018e-04 - val_loss: 3.0041e-05\n",
      "Epoch 181/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.6440e-04 - val_loss: 3.4713e-05\n",
      "Epoch 182/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.6800e-04 - val_loss: 3.1080e-05\n",
      "Epoch 183/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.7518e-04 - val_loss: 3.6291e-05\n",
      "Epoch 184/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.7534e-04 - val_loss: 2.9407e-05\n",
      "Epoch 185/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.3891e-04 - val_loss: 2.9339e-05\n",
      "Epoch 186/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.5336e-04 - val_loss: 2.9346e-05\n",
      "Epoch 187/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.5761e-04 - val_loss: 3.9791e-05\n",
      "Epoch 188/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.5556e-04 - val_loss: 3.2588e-05\n",
      "Epoch 189/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.5380e-04 - val_loss: 3.5149e-05\n",
      "Epoch 190/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.7264e-04 - val_loss: 3.1110e-05\n",
      "Epoch 191/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.3454e-04 - val_loss: 3.1103e-05\n",
      "Epoch 192/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.2513e-04 - val_loss: 2.8487e-05\n",
      "Epoch 193/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.2613e-04 - val_loss: 2.9962e-05\n",
      "Epoch 194/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.4866e-04 - val_loss: 4.2970e-05\n",
      "Epoch 195/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.3291e-04 - val_loss: 2.8175e-05\n",
      "Epoch 196/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.3364e-04 - val_loss: 2.8175e-05\n",
      "Epoch 197/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.2393e-04 - val_loss: 3.0143e-05\n",
      "Epoch 198/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 3.3544e-04 - val_loss: 2.8502e-05\n",
      "Epoch 199/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.2133e-04 - val_loss: 3.3917e-05\n",
      "Epoch 200/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.3243e-04 - val_loss: 2.7953e-05\n",
      "Thời gian huấn luyện:  49.32053565979004\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_8 (GRU)                 (None, 10, 100)           30900     \n",
      "                                                                 \n",
      " flatten_35 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,901\n",
      "Trainable params: 31,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "39/39 [==============================] - 0s 1ms/step\n",
      "26/26 [==============================] - 0s 1ms/step\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0902 - val_loss: 0.0492\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0259\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0168\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0087\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 9.2540e-04 - val_loss: 0.0012\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 7.0211e-04 - val_loss: 6.8782e-04\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 6.1899e-04 - val_loss: 5.3454e-04\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.9264e-04 - val_loss: 4.6356e-04\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.8212e-04 - val_loss: 3.8786e-04\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7872e-04 - val_loss: 3.3725e-04\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7480e-04 - val_loss: 3.2413e-04\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7064e-04 - val_loss: 2.9271e-04\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6828e-04 - val_loss: 2.7953e-04\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6700e-04 - val_loss: 2.6268e-04\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6342e-04 - val_loss: 2.6477e-04\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6079e-04 - val_loss: 2.3456e-04\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5851e-04 - val_loss: 2.4518e-04\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5888e-04 - val_loss: 2.2803e-04\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5530e-04 - val_loss: 2.1951e-04\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5362e-04 - val_loss: 2.1901e-04\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5557e-04 - val_loss: 2.0409e-04\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5499e-04 - val_loss: 2.0563e-04\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5036e-04 - val_loss: 2.0523e-04\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5150e-04 - val_loss: 1.9223e-04\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4816e-04 - val_loss: 1.9339e-04\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.4621e-04 - val_loss: 1.9009e-04\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4262e-04 - val_loss: 1.7291e-04\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4408e-04 - val_loss: 1.8231e-04\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.4308e-04 - val_loss: 1.8006e-04\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.4399e-04 - val_loss: 1.7297e-04\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3973e-04 - val_loss: 1.6385e-04\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3776e-04 - val_loss: 1.7719e-04\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4378e-04 - val_loss: 1.7687e-04\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4060e-04 - val_loss: 1.7251e-04\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4131e-04 - val_loss: 1.7239e-04\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4688e-04 - val_loss: 1.5719e-04\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3170e-04 - val_loss: 1.5755e-04\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3197e-04 - val_loss: 1.5405e-04\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3394e-04 - val_loss: 1.6801e-04\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3699e-04 - val_loss: 1.5802e-04\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2719e-04 - val_loss: 1.5605e-04\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3462e-04 - val_loss: 1.4936e-04\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2768e-04 - val_loss: 1.5817e-04\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2352e-04 - val_loss: 1.4576e-04\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2272e-04 - val_loss: 1.4604e-04\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2068e-04 - val_loss: 1.4627e-04\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.1508e-04 - val_loss: 1.4317e-04\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.1965e-04 - val_loss: 1.4425e-04\n",
      "Thời gian huấn luyện:  5.079127073287964\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_45 (Dense)            (None, 10, 109)           218       \n",
      "                                                                 \n",
      " flatten_36 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,309\n",
      "Trainable params: 1,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 1s 7ms/step - loss: 0.0243 - val_loss: 3.4453e-04\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 3.2045e-04\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 9.6949e-04 - val_loss: 3.2363e-04\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 9.5110e-04 - val_loss: 3.2557e-04\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 9.1976e-04 - val_loss: 3.2194e-04\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 8.6898e-04 - val_loss: 3.0394e-04\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 8.6552e-04 - val_loss: 2.8123e-04\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 8.1726e-04 - val_loss: 2.4350e-04\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.9206e-04 - val_loss: 2.2940e-04\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 7.9478e-04 - val_loss: 2.3387e-04\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 7.4246e-04 - val_loss: 2.0137e-04\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 7.2441e-04 - val_loss: 1.8814e-04\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 7.6305e-04 - val_loss: 1.7461e-04\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 6.9286e-04 - val_loss: 1.7968e-04\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 6.7872e-04 - val_loss: 1.8587e-04\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 6.7361e-04 - val_loss: 1.2606e-04\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 6.3966e-04 - val_loss: 1.2190e-04\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 6.4136e-04 - val_loss: 1.2515e-04\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 6.0671e-04 - val_loss: 1.2334e-04\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.9063e-04 - val_loss: 9.6949e-05\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 6.0939e-04 - val_loss: 9.2414e-05\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.6538e-04 - val_loss: 1.2217e-04\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 6.9461e-04 - val_loss: 9.8897e-05\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.5739e-04 - val_loss: 6.9224e-05\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.4873e-04 - val_loss: 7.4070e-05\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.2187e-04 - val_loss: 7.2503e-05\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.8024e-04 - val_loss: 4.9844e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.0265e-04 - val_loss: 5.0985e-05\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.0074e-04 - val_loss: 4.5197e-05\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.7857e-04 - val_loss: 4.2132e-05\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.7385e-04 - val_loss: 3.9087e-05\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.8112e-04 - val_loss: 4.4547e-05\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.6258e-04 - val_loss: 4.5019e-05\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.7206e-04 - val_loss: 3.5714e-05\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.5277e-04 - val_loss: 3.5631e-05\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.3914e-04 - val_loss: 3.1513e-05\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3728e-04 - val_loss: 3.3110e-05\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.4784e-04 - val_loss: 2.7704e-05\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.6440e-04 - val_loss: 2.9590e-05\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.2576e-04 - val_loss: 2.7554e-05\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3977e-04 - val_loss: 2.7765e-05\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.2558e-04 - val_loss: 2.6596e-05\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.1268e-04 - val_loss: 2.6584e-05\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.0849e-04 - val_loss: 2.8070e-05\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.0582e-04 - val_loss: 2.6217e-05\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.0169e-04 - val_loss: 2.7368e-05\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.0467e-04 - val_loss: 2.4351e-05\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.0236e-04 - val_loss: 2.4623e-05\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.1219e-04 - val_loss: 2.4854e-05\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.2790e-04 - val_loss: 2.6138e-05\n",
      "Thời gian huấn luyện:  7.989590406417847\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_9 (SimpleRNN)    (None, 10, 109)           12099     \n",
      "                                                                 \n",
      " flatten_37 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,190\n",
      "Trainable params: 13,190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 2s 17ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Thời gian huấn luyện:  19.8860125541687\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_9 (LSTM)               (None, 10, 109)           48396     \n",
      "                                                                 \n",
      " flatten_38 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,487\n",
      "Trainable params: 49,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 2s 17ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Thời gian huấn luyện:  17.790008544921875\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_9 (GRU)                 (None, 10, 109)           36624     \n",
      "                                                                 \n",
      " flatten_39 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,715\n",
      "Trainable params: 37,715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "45/45 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "45/45 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "45/45 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "45/45 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 2/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 3/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 4/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 5/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 6/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 7/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 8/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 9/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 10/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 12/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 13/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 14/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 15/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 16/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 17/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 18/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 19/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 20/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 21/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 22/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 23/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 24/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 25/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 26/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 27/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 28/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 29/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 30/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 31/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 32/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 33/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 34/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 35/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 36/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 37/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 38/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 39/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 40/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 41/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 42/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 43/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 44/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 45/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 46/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 47/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 48/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 49/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 50/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Thời gian huấn luyện:  4.6376025676727295\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_50 (Dense)            (None, 10, 109)           218       \n",
      "                                                                 \n",
      " flatten_40 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,309\n",
      "Trainable params: 1,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "38/38 [==============================] - 1s 8ms/step - loss: 0.0072 - val_loss: 4.4796e-04\n",
      "Epoch 2/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.8406e-04 - val_loss: 5.4467e-04\n",
      "Epoch 3/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.0156e-04 - val_loss: 3.4348e-04\n",
      "Epoch 4/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.3018e-04 - val_loss: 3.2530e-04\n",
      "Epoch 5/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 7.6776e-04 - val_loss: 2.5214e-04\n",
      "Epoch 6/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 7.3525e-04 - val_loss: 1.8618e-04\n",
      "Epoch 7/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 7.1620e-04 - val_loss: 1.5884e-04\n",
      "Epoch 8/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 6.5777e-04 - val_loss: 1.0458e-04\n",
      "Epoch 9/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 6.4711e-04 - val_loss: 9.5913e-05\n",
      "Epoch 10/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 6.2127e-04 - val_loss: 7.4567e-05\n",
      "Epoch 11/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 6.3553e-04 - val_loss: 6.4096e-05\n",
      "Epoch 12/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 6.3778e-04 - val_loss: 5.0960e-05\n",
      "Epoch 13/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 6.0857e-04 - val_loss: 4.7735e-05\n",
      "Epoch 14/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 6.1772e-04 - val_loss: 4.2365e-05\n",
      "Epoch 15/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 5.5109e-04 - val_loss: 3.7097e-05\n",
      "Epoch 16/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 5.8433e-04 - val_loss: 3.5158e-05\n",
      "Epoch 17/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.7261e-04 - val_loss: 4.4833e-05\n",
      "Epoch 18/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 5.4201e-04 - val_loss: 3.6147e-05\n",
      "Epoch 19/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 5.1262e-04 - val_loss: 3.2209e-05\n",
      "Epoch 20/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.0040e-04 - val_loss: 3.1609e-05\n",
      "Epoch 21/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.0393e-04 - val_loss: 3.1128e-05\n",
      "Epoch 22/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.9996e-04 - val_loss: 2.9935e-05\n",
      "Epoch 23/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.7961e-04 - val_loss: 2.8847e-05\n",
      "Epoch 24/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.7267e-04 - val_loss: 3.0190e-05\n",
      "Epoch 25/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.7411e-04 - val_loss: 2.9575e-05\n",
      "Epoch 26/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.4960e-04 - val_loss: 2.7824e-05\n",
      "Epoch 27/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 5.1412e-04 - val_loss: 3.0368e-05\n",
      "Epoch 28/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.8191e-04 - val_loss: 2.6930e-05\n",
      "Epoch 29/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.3652e-04 - val_loss: 2.6381e-05\n",
      "Epoch 30/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.6380e-04 - val_loss: 2.6126e-05\n",
      "Epoch 31/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.8496e-04 - val_loss: 2.6180e-05\n",
      "Epoch 32/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.3456e-04 - val_loss: 2.6575e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.3802e-04 - val_loss: 2.5356e-05\n",
      "Epoch 34/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.0914e-04 - val_loss: 2.4719e-05\n",
      "Epoch 35/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.3982e-04 - val_loss: 2.5189e-05\n",
      "Epoch 36/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.2927e-04 - val_loss: 2.4775e-05\n",
      "Epoch 37/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.0323e-04 - val_loss: 2.3551e-05\n",
      "Epoch 38/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.1907e-04 - val_loss: 2.3222e-05\n",
      "Epoch 39/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.8384e-04 - val_loss: 2.3227e-05\n",
      "Epoch 40/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.2771e-04 - val_loss: 2.3848e-05\n",
      "Epoch 41/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.0296e-04 - val_loss: 2.2808e-05\n",
      "Epoch 42/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.9427e-04 - val_loss: 2.2170e-05\n",
      "Epoch 43/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.7382e-04 - val_loss: 2.2222e-05\n",
      "Epoch 44/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.8339e-04 - val_loss: 2.2075e-05\n",
      "Epoch 45/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.8926e-04 - val_loss: 2.2119e-05\n",
      "Epoch 46/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.0945e-04 - val_loss: 2.2205e-05\n",
      "Epoch 47/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.0302e-04 - val_loss: 2.6341e-05\n",
      "Epoch 48/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.2651e-04 - val_loss: 2.2646e-05\n",
      "Epoch 49/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.0477e-04 - val_loss: 2.1726e-05\n",
      "Epoch 50/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.8946e-04 - val_loss: 2.0696e-05\n",
      "Thời gian huấn luyện:  7.463026523590088\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_10 (SimpleRNN)   (None, 10, 109)           12099     \n",
      "                                                                 \n",
      " flatten_41 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,190\n",
      "Trainable params: 13,190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "38/38 [==============================] - 2s 16ms/step - loss: 0.0362 - val_loss: 0.0015\n",
      "Epoch 2/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 7.5080e-04\n",
      "Epoch 3/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 9.0775e-04 - val_loss: 3.2071e-04\n",
      "Epoch 4/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 8.2841e-04 - val_loss: 1.7824e-04\n",
      "Epoch 5/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 8.2484e-04 - val_loss: 1.5473e-04\n",
      "Epoch 6/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 8.2058e-04 - val_loss: 1.2849e-04\n",
      "Epoch 7/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 8.2246e-04 - val_loss: 1.5040e-04\n",
      "Epoch 8/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 8.1718e-04 - val_loss: 1.3228e-04\n",
      "Epoch 9/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 8.1275e-04 - val_loss: 1.1607e-04\n",
      "Epoch 10/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 8.1101e-04 - val_loss: 1.3160e-04\n",
      "Epoch 11/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 8.0630e-04 - val_loss: 1.2673e-04\n",
      "Epoch 12/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 8.0778e-04 - val_loss: 1.3746e-04\n",
      "Epoch 13/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 8.0403e-04 - val_loss: 1.0245e-04\n",
      "Epoch 14/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 8.0789e-04 - val_loss: 9.3013e-05\n",
      "Epoch 15/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 7.9279e-04 - val_loss: 1.3418e-04\n",
      "Epoch 16/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 7.9585e-04 - val_loss: 8.9536e-05\n",
      "Epoch 17/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 7.9633e-04 - val_loss: 1.0502e-04\n",
      "Epoch 18/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 7.9981e-04 - val_loss: 1.0906e-04\n",
      "Epoch 19/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 7.8409e-04 - val_loss: 8.7787e-05\n",
      "Epoch 20/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 7.8987e-04 - val_loss: 1.0052e-04\n",
      "Epoch 21/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 7.7970e-04 - val_loss: 9.0117e-05\n",
      "Epoch 22/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 7.7085e-04 - val_loss: 1.0584e-04\n",
      "Epoch 23/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.7272e-04 - val_loss: 9.7283e-05\n",
      "Epoch 24/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.7483e-04 - val_loss: 9.7433e-05\n",
      "Epoch 25/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 7.7440e-04 - val_loss: 8.6018e-05\n",
      "Epoch 26/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 7.6637e-04 - val_loss: 7.9694e-05\n",
      "Epoch 27/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.6230e-04 - val_loss: 7.9286e-05\n",
      "Epoch 28/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.6941e-04 - val_loss: 7.7481e-05\n",
      "Epoch 29/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 7.5947e-04 - val_loss: 7.4347e-05\n",
      "Epoch 30/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.5671e-04 - val_loss: 6.9135e-05\n",
      "Epoch 31/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.7345e-04 - val_loss: 7.9670e-05\n",
      "Epoch 32/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.4945e-04 - val_loss: 6.7871e-05\n",
      "Epoch 33/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.5781e-04 - val_loss: 7.4664e-05\n",
      "Epoch 34/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 7.3962e-04 - val_loss: 1.0118e-04\n",
      "Epoch 35/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.4870e-04 - val_loss: 7.1633e-05\n",
      "Epoch 36/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.3682e-04 - val_loss: 6.1577e-05\n",
      "Epoch 37/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.4777e-04 - val_loss: 5.4169e-05\n",
      "Epoch 38/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 7.3625e-04 - val_loss: 6.1773e-05\n",
      "Epoch 39/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 7.3067e-04 - val_loss: 5.5368e-05\n",
      "Epoch 40/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.3898e-04 - val_loss: 5.9754e-05\n",
      "Epoch 41/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 7.3042e-04 - val_loss: 6.6394e-05\n",
      "Epoch 42/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.2630e-04 - val_loss: 5.7084e-05\n",
      "Epoch 43/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 7.2861e-04 - val_loss: 5.6035e-05\n",
      "Epoch 44/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 7.1328e-04 - val_loss: 5.8879e-05\n",
      "Epoch 45/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 7.1658e-04 - val_loss: 5.9339e-05\n",
      "Epoch 46/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.0878e-04 - val_loss: 5.5331e-05\n",
      "Epoch 47/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.1389e-04 - val_loss: 5.8257e-05\n",
      "Epoch 48/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.0151e-04 - val_loss: 7.4108e-05\n",
      "Epoch 49/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.1232e-04 - val_loss: 5.1847e-05\n",
      "Epoch 50/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.0844e-04 - val_loss: 5.5124e-05\n",
      "Thời gian huấn luyện:  15.88809847831726\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 10, 109)           48396     \n",
      "                                                                 \n",
      " flatten_42 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,487\n",
      "Trainable params: 49,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "38/38 [==============================] - 2s 15ms/step - loss: 0.0270 - val_loss: 9.0426e-04\n",
      "Epoch 2/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 1.4596e-04\n",
      "Epoch 3/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 7.3622e-04 - val_loss: 5.0655e-05\n",
      "Epoch 4/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.9324e-04 - val_loss: 5.1729e-05\n",
      "Epoch 5/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.9345e-04 - val_loss: 6.3311e-05\n",
      "Epoch 6/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.9618e-04 - val_loss: 5.2592e-05\n",
      "Epoch 7/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.8061e-04 - val_loss: 5.2936e-05\n",
      "Epoch 8/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.7935e-04 - val_loss: 5.9508e-05\n",
      "Epoch 9/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.7018e-04 - val_loss: 4.8516e-05\n",
      "Epoch 10/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.7027e-04 - val_loss: 4.9176e-05\n",
      "Epoch 11/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.7374e-04 - val_loss: 6.3374e-05\n",
      "Epoch 12/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.7023e-04 - val_loss: 6.3698e-05\n",
      "Epoch 13/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.7133e-04 - val_loss: 4.7813e-05\n",
      "Epoch 14/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.5930e-04 - val_loss: 5.1568e-05\n",
      "Epoch 15/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.5691e-04 - val_loss: 5.2093e-05\n",
      "Epoch 16/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.5832e-04 - val_loss: 4.6640e-05\n",
      "Epoch 17/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.6270e-04 - val_loss: 4.9131e-05\n",
      "Epoch 18/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.4600e-04 - val_loss: 4.9148e-05\n",
      "Epoch 19/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.3514e-04 - val_loss: 4.6483e-05\n",
      "Epoch 20/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.3393e-04 - val_loss: 4.5605e-05\n",
      "Epoch 21/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.3161e-04 - val_loss: 4.5265e-05\n",
      "Epoch 22/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.3043e-04 - val_loss: 4.8373e-05\n",
      "Epoch 23/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.3048e-04 - val_loss: 4.6210e-05\n",
      "Epoch 24/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.1460e-04 - val_loss: 4.8949e-05\n",
      "Epoch 25/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.1668e-04 - val_loss: 5.1221e-05\n",
      "Epoch 26/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.2170e-04 - val_loss: 4.5524e-05\n",
      "Epoch 27/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.1212e-04 - val_loss: 4.6765e-05\n",
      "Epoch 28/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.0644e-04 - val_loss: 4.7772e-05\n",
      "Epoch 29/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 6.0115e-04 - val_loss: 4.5349e-05\n",
      "Epoch 30/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 5.9198e-04 - val_loss: 5.6529e-05\n",
      "Epoch 31/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 5.9270e-04 - val_loss: 4.2917e-05\n",
      "Epoch 32/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.8908e-04 - val_loss: 5.6034e-05\n",
      "Epoch 33/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 5.8485e-04 - val_loss: 6.5878e-05\n",
      "Epoch 34/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 5.8453e-04 - val_loss: 4.7872e-05\n",
      "Epoch 35/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 5.8040e-04 - val_loss: 4.6020e-05\n",
      "Epoch 36/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 5.6808e-04 - val_loss: 5.8564e-05\n",
      "Epoch 37/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 5.7106e-04 - val_loss: 4.1643e-05\n",
      "Epoch 38/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 5.6527e-04 - val_loss: 4.7518e-05\n",
      "Epoch 39/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 5.5761e-04 - val_loss: 4.3822e-05\n",
      "Epoch 40/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 5.6239e-04 - val_loss: 4.3211e-05\n",
      "Epoch 41/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 5.5214e-04 - val_loss: 4.7444e-05\n",
      "Epoch 42/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 5.6971e-04 - val_loss: 4.2408e-05\n",
      "Epoch 43/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 5.7190e-04 - val_loss: 4.7440e-05\n",
      "Epoch 44/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 5.4663e-04 - val_loss: 4.2464e-05\n",
      "Epoch 45/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 5.4226e-04 - val_loss: 4.6959e-05\n",
      "Epoch 46/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 5.3699e-04 - val_loss: 4.9034e-05\n",
      "Epoch 47/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 5.3129e-04 - val_loss: 4.5376e-05\n",
      "Epoch 48/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 5.2163e-04 - val_loss: 5.0581e-05\n",
      "Epoch 49/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 5.1573e-04 - val_loss: 3.8253e-05\n",
      "Epoch 50/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 5.1528e-04 - val_loss: 4.7832e-05\n",
      "Thời gian huấn luyện:  14.677522420883179\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_10 (GRU)                (None, 10, 109)           36624     \n",
      "                                                                 \n",
      " flatten_43 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,715\n",
      "Trainable params: 37,715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "45/45 [==============================] - 0s 862us/step\n",
      "19/19 [==============================] - 0s 946us/step\n",
      "45/45 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "45/45 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "45/45 [==============================] - 1s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1051 - val_loss: 0.0352\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0344\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0265\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0183\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0121\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0083\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 8.8113e-04 - val_loss: 0.0017\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 7.6571e-04 - val_loss: 0.0012\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 7.0897e-04 - val_loss: 0.0010\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.8241e-04 - val_loss: 9.0602e-04\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.6804e-04 - val_loss: 7.7345e-04\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.5883e-04 - val_loss: 6.5549e-04\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.5583e-04 - val_loss: 6.8050e-04\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.5510e-04 - val_loss: 6.0555e-04\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.5403e-04 - val_loss: 6.0419e-04\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.5012e-04 - val_loss: 5.6653e-04\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.5088e-04 - val_loss: 5.9797e-04\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.4767e-04 - val_loss: 5.6377e-04\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.4674e-04 - val_loss: 5.3903e-04\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.4601e-04 - val_loss: 5.6099e-04\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.4869e-04 - val_loss: 4.7920e-04\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.5321e-04 - val_loss: 5.5617e-04\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.4111e-04 - val_loss: 5.3654e-04\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.4346e-04 - val_loss: 5.6013e-04\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.4027e-04 - val_loss: 5.2694e-04\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.3957e-04 - val_loss: 5.2561e-04\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.3783e-04 - val_loss: 5.4971e-04\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.3389e-04 - val_loss: 4.8060e-04\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.4145e-04 - val_loss: 5.3087e-04\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.4175e-04 - val_loss: 5.1768e-04\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.3291e-04 - val_loss: 5.6126e-04\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.3047e-04 - val_loss: 5.0625e-04\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.2984e-04 - val_loss: 5.0993e-04\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.2776e-04 - val_loss: 4.8021e-04\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.3032e-04 - val_loss: 5.0947e-04\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.2353e-04 - val_loss: 5.8271e-04\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.2667e-04 - val_loss: 4.8592e-04\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.2318e-04 - val_loss: 5.2737e-04\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.2568e-04 - val_loss: 5.2753e-04\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.1952e-04 - val_loss: 5.0450e-04\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.1714e-04 - val_loss: 5.1745e-04\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.1727e-04 - val_loss: 5.2740e-04\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.1636e-04 - val_loss: 4.9834e-04\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.1701e-04 - val_loss: 4.6923e-04\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.1524e-04 - val_loss: 4.6245e-04\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.1249e-04 - val_loss: 5.4117e-04\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.1942e-04 - val_loss: 5.1343e-04\n",
      "Thời gian huấn luyện:  4.134305477142334\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_55 (Dense)            (None, 10, 109)           218       \n",
      "                                                                 \n",
      " flatten_44 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,309\n",
      "Trainable params: 1,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 6.7886e-04\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 4.3052e-04\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.4092e-04 - val_loss: 2.6172e-04\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.8067e-04 - val_loss: 2.2106e-04\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.8911e-04 - val_loss: 2.0497e-04\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.5506e-04 - val_loss: 1.0112e-04\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.7018e-04 - val_loss: 7.6288e-05\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.7993e-04 - val_loss: 8.3109e-05\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.8774e-04 - val_loss: 6.0519e-05\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.8040e-04 - val_loss: 5.0365e-05\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.5323e-04 - val_loss: 4.3467e-05\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.4311e-04 - val_loss: 4.7148e-05\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.6894e-04 - val_loss: 4.0955e-05\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.9063e-04 - val_loss: 3.9764e-05\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.3071e-04 - val_loss: 4.2177e-05\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.1999e-04 - val_loss: 4.3191e-05\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.2511e-04 - val_loss: 6.1994e-05\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.1064e-04 - val_loss: 4.1857e-05\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8772e-04 - val_loss: 3.6412e-05\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.0862e-04 - val_loss: 5.3220e-05\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.1010e-04 - val_loss: 4.4416e-05\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8361e-04 - val_loss: 3.6396e-05\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6163e-04 - val_loss: 4.8154e-05\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.7697e-04 - val_loss: 5.3978e-05\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6979e-04 - val_loss: 5.0872e-05\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6430e-04 - val_loss: 4.5120e-05\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6636e-04 - val_loss: 4.8018e-05\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 4ms/step - loss: 4.5730e-04 - val_loss: 4.0580e-05\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3851e-04 - val_loss: 4.2193e-05\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3196e-04 - val_loss: 2.7973e-05\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8037e-04 - val_loss: 3.8816e-05\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3412e-04 - val_loss: 3.2425e-05\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2966e-04 - val_loss: 3.9120e-05\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8683e-04 - val_loss: 4.3093e-05\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2781e-04 - val_loss: 3.5359e-05\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6594e-04 - val_loss: 3.7121e-05\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.9981e-04 - val_loss: 2.6944e-05\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.1693e-04 - val_loss: 4.0832e-05\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 3.9372e-04 - val_loss: 5.0951e-05\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.0281e-04 - val_loss: 2.7448e-05\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.8914e-04 - val_loss: 3.5210e-05\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.0711e-04 - val_loss: 2.9293e-05\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.9848e-04 - val_loss: 2.7779e-05\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2071e-04 - val_loss: 4.0370e-05\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.8676e-04 - val_loss: 2.9208e-05\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.7570e-04 - val_loss: 2.6576e-05\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.9463e-04 - val_loss: 2.5776e-05\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.7437e-04 - val_loss: 2.7427e-05\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 3.9320e-04 - val_loss: 2.5338e-05\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.3626e-04 - val_loss: 2.6854e-05\n",
      "Thời gian huấn luyện:  7.317469120025635\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_11 (SimpleRNN)   (None, 10, 109)           12099     \n",
      "                                                                 \n",
      " flatten_45 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,190\n",
      "Trainable params: 13,190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 2s 17ms/step - loss: 0.0297 - val_loss: 0.0011\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 7.0442e-04\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 3.2812e-04\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 9.2172e-04 - val_loss: 1.7385e-04\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.9736e-04 - val_loss: 1.5464e-04\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.9707e-04 - val_loss: 1.3067e-04\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.8756e-04 - val_loss: 1.1367e-04\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.9856e-04 - val_loss: 1.3114e-04\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 9.0077e-04 - val_loss: 1.3756e-04\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.9179e-04 - val_loss: 1.6402e-04\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.9812e-04 - val_loss: 1.3761e-04\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.7506e-04 - val_loss: 1.4637e-04\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.8128e-04 - val_loss: 1.4184e-04\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.8451e-04 - val_loss: 1.0224e-04\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.8046e-04 - val_loss: 1.1992e-04\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.7412e-04 - val_loss: 1.0926e-04\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.6667e-04 - val_loss: 1.2500e-04\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.5603e-04 - val_loss: 1.3666e-04\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.6888e-04 - val_loss: 1.2306e-04\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.5638e-04 - val_loss: 1.3183e-04\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.5972e-04 - val_loss: 1.0870e-04\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.5845e-04 - val_loss: 1.4215e-04\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.5231e-04 - val_loss: 1.0831e-04\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.5578e-04 - val_loss: 9.3676e-05\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.5607e-04 - val_loss: 1.2121e-04\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 8.3764e-04 - val_loss: 8.8836e-05\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 8.4726e-04 - val_loss: 1.0784e-04\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 8.3407e-04 - val_loss: 1.0522e-04\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.3833e-04 - val_loss: 1.1614e-04\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.4502e-04 - val_loss: 1.0009e-04\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.3402e-04 - val_loss: 8.0851e-05\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.2309e-04 - val_loss: 1.0415e-04\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 8.2295e-04 - val_loss: 1.1141e-04\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.3391e-04 - val_loss: 1.1363e-04\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 8.1640e-04 - val_loss: 1.0249e-04\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 8.2853e-04 - val_loss: 9.9987e-05\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 8.1579e-04 - val_loss: 9.9019e-05\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.0610e-04 - val_loss: 1.0331e-04\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 8.0877e-04 - val_loss: 1.3381e-04\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 8.0025e-04 - val_loss: 9.2145e-05\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 8.1324e-04 - val_loss: 1.2538e-04\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.1593e-04 - val_loss: 8.7219e-05\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 8.0487e-04 - val_loss: 1.2372e-04\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.9701e-04 - val_loss: 9.1030e-05\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.1118e-04 - val_loss: 9.2974e-05\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.9275e-04 - val_loss: 9.8658e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.8431e-04 - val_loss: 1.0670e-04\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.8061e-04 - val_loss: 9.1431e-05\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.7285e-04 - val_loss: 1.0450e-04\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.7149e-04 - val_loss: 9.1390e-05\n",
      "Thời gian huấn luyện:  16.942439794540405\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_11 (LSTM)              (None, 10, 109)           48396     \n",
      "                                                                 \n",
      " flatten_46 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,487\n",
      "Trainable params: 49,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 2s 16ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Thời gian huấn luyện:  15.694035530090332\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_11 (GRU)                (None, 10, 109)           36624     \n",
      "                                                                 \n",
      " flatten_47 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,715\n",
      "Trainable params: 37,715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "45/45 [==============================] - 0s 955us/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "45/45 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "45/45 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "45/45 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 21/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 22/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 23/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 24/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 25/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 26/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 27/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 28/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 29/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 30/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 31/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 32/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 33/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 34/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 35/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 36/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 37/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 38/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 39/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 40/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 41/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 42/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 43/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 44/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 45/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 46/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 47/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 48/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 49/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 50/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 51/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 52/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 53/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 54/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 55/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 56/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 57/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 58/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 59/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 60/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 61/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 62/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 63/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 64/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 65/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 66/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 67/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 68/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 69/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 70/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 71/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 72/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 73/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 74/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 75/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 76/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 77/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 78/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 79/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 80/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 81/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 82/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 83/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 84/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 85/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 86/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 87/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 88/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 89/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 91/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 92/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 93/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 94/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 95/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 96/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 97/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 98/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 99/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 100/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Thời gian huấn luyện:  8.385029315948486\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_60 (Dense)            (None, 10, 109)           218       \n",
      "                                                                 \n",
      " flatten_48 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,309\n",
      "Trainable params: 1,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "41/41 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 2.8136e-04\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 8.0768e-04 - val_loss: 3.6204e-04\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 7.1669e-04 - val_loss: 3.2494e-04\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 6.8006e-04 - val_loss: 3.1705e-04\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 6.5867e-04 - val_loss: 2.0665e-04\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 6.1032e-04 - val_loss: 1.8560e-04\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.8092e-04 - val_loss: 1.7749e-04\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.7518e-04 - val_loss: 1.2413e-04\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.3834e-04 - val_loss: 1.0087e-04\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.2554e-04 - val_loss: 7.8269e-05\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.3474e-04 - val_loss: 7.1682e-05\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.2916e-04 - val_loss: 5.5235e-05\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.0235e-04 - val_loss: 4.3236e-05\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.8736e-04 - val_loss: 4.3826e-05\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.9259e-04 - val_loss: 4.6672e-05\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.5490e-04 - val_loss: 3.5535e-05\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.6155e-04 - val_loss: 3.3391e-05\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.7556e-04 - val_loss: 3.3629e-05\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.4605e-04 - val_loss: 2.8279e-05\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.5593e-04 - val_loss: 3.0136e-05\n",
      "Epoch 21/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.5414e-04 - val_loss: 2.7292e-05\n",
      "Epoch 22/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.3604e-04 - val_loss: 2.7483e-05\n",
      "Epoch 23/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.2314e-04 - val_loss: 2.7038e-05\n",
      "Epoch 24/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.2865e-04 - val_loss: 2.5785e-05\n",
      "Epoch 25/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.0531e-04 - val_loss: 2.5956e-05\n",
      "Epoch 26/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.9498e-04 - val_loss: 2.5043e-05\n",
      "Epoch 27/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.9355e-04 - val_loss: 2.6674e-05\n",
      "Epoch 28/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.9245e-04 - val_loss: 2.7129e-05\n",
      "Epoch 29/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.0610e-04 - val_loss: 2.3967e-05\n",
      "Epoch 30/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.8384e-04 - val_loss: 2.3801e-05\n",
      "Epoch 31/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.9090e-04 - val_loss: 2.3519e-05\n",
      "Epoch 32/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.8130e-04 - val_loss: 2.4108e-05\n",
      "Epoch 33/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.8447e-04 - val_loss: 2.3027e-05\n",
      "Epoch 34/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.8933e-04 - val_loss: 2.4045e-05\n",
      "Epoch 35/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.6441e-04 - val_loss: 2.2126e-05\n",
      "Epoch 36/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.7054e-04 - val_loss: 2.2407e-05\n",
      "Epoch 37/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.8334e-04 - val_loss: 2.2316e-05\n",
      "Epoch 38/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.7837e-04 - val_loss: 2.1592e-05\n",
      "Epoch 39/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.9226e-04 - val_loss: 2.1855e-05\n",
      "Epoch 40/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.7157e-04 - val_loss: 2.3207e-05\n",
      "Epoch 41/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.3905e-04 - val_loss: 2.1063e-05\n",
      "Epoch 42/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.7524e-04 - val_loss: 2.3589e-05\n",
      "Epoch 43/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.4947e-04 - val_loss: 3.1351e-05\n",
      "Epoch 44/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.5463e-04 - val_loss: 2.4147e-05\n",
      "Epoch 45/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.2859e-04 - val_loss: 2.0032e-05\n",
      "Epoch 46/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.3497e-04 - val_loss: 2.0189e-05\n",
      "Epoch 47/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.3832e-04 - val_loss: 2.1307e-05\n",
      "Epoch 48/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.3418e-04 - val_loss: 1.9312e-05\n",
      "Epoch 49/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.3783e-04 - val_loss: 2.1957e-05\n",
      "Epoch 50/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.4288e-04 - val_loss: 2.4341e-05\n",
      "Epoch 51/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.3291e-04 - val_loss: 2.1310e-05\n",
      "Epoch 52/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.1708e-04 - val_loss: 2.4677e-05\n",
      "Epoch 53/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.1506e-04 - val_loss: 2.3906e-05\n",
      "Epoch 54/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.2470e-04 - val_loss: 2.1344e-05\n",
      "Epoch 55/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.6950e-04 - val_loss: 2.3281e-05\n",
      "Epoch 56/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.1712e-04 - val_loss: 1.9511e-05\n",
      "Epoch 57/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.0484e-04 - val_loss: 1.8029e-05\n",
      "Epoch 58/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.1592e-04 - val_loss: 2.1257e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.1977e-04 - val_loss: 1.7825e-05\n",
      "Epoch 60/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.0943e-04 - val_loss: 1.9875e-05\n",
      "Epoch 61/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.0788e-04 - val_loss: 2.7343e-05\n",
      "Epoch 62/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.0915e-04 - val_loss: 2.1178e-05\n",
      "Epoch 63/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.1263e-04 - val_loss: 1.7195e-05\n",
      "Epoch 64/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.2023e-04 - val_loss: 1.9327e-05\n",
      "Epoch 65/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.1197e-04 - val_loss: 3.4411e-05\n",
      "Epoch 66/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.4154e-04 - val_loss: 2.2435e-05\n",
      "Epoch 67/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.0404e-04 - val_loss: 1.7233e-05\n",
      "Epoch 68/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.3573e-04 - val_loss: 2.5768e-05\n",
      "Epoch 69/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.0985e-04 - val_loss: 2.2045e-05\n",
      "Epoch 70/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.9796e-04 - val_loss: 2.2988e-05\n",
      "Epoch 71/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.3235e-04 - val_loss: 2.9300e-05\n",
      "Epoch 72/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.8716e-04 - val_loss: 1.9519e-05\n",
      "Epoch 73/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.7280e-04 - val_loss: 1.7675e-05\n",
      "Epoch 74/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.7751e-04 - val_loss: 1.7244e-05\n",
      "Epoch 75/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.4810e-04 - val_loss: 1.6197e-05\n",
      "Epoch 76/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.1711e-04 - val_loss: 1.7557e-05\n",
      "Epoch 77/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.9278e-04 - val_loss: 2.1547e-05\n",
      "Epoch 78/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.6763e-04 - val_loss: 2.2097e-05\n",
      "Epoch 79/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.3312e-04 - val_loss: 1.6045e-05\n",
      "Epoch 80/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.6777e-04 - val_loss: 1.8021e-05\n",
      "Epoch 81/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.9427e-04 - val_loss: 1.8323e-05\n",
      "Epoch 82/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.7117e-04 - val_loss: 1.7531e-05\n",
      "Epoch 83/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.6590e-04 - val_loss: 1.5549e-05\n",
      "Epoch 84/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.6828e-04 - val_loss: 1.7180e-05\n",
      "Epoch 85/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.7131e-04 - val_loss: 1.5523e-05\n",
      "Epoch 86/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.0565e-04 - val_loss: 1.7677e-05\n",
      "Epoch 87/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.1701e-04 - val_loss: 2.5648e-05\n",
      "Epoch 88/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.9015e-04 - val_loss: 1.6569e-05\n",
      "Epoch 89/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.5740e-04 - val_loss: 1.5919e-05\n",
      "Epoch 90/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.5348e-04 - val_loss: 2.0121e-05\n",
      "Epoch 91/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.5225e-04 - val_loss: 1.5089e-05\n",
      "Epoch 92/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.5184e-04 - val_loss: 1.5926e-05\n",
      "Epoch 93/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.5885e-04 - val_loss: 1.5656e-05\n",
      "Epoch 94/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.1073e-04 - val_loss: 1.5178e-05\n",
      "Epoch 95/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.9808e-04 - val_loss: 2.3524e-05\n",
      "Epoch 96/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.7215e-04 - val_loss: 1.4360e-05\n",
      "Epoch 97/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.5044e-04 - val_loss: 1.6712e-05\n",
      "Epoch 98/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.4670e-04 - val_loss: 1.4473e-05\n",
      "Epoch 99/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.7499e-04 - val_loss: 1.9167e-05\n",
      "Epoch 100/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.6993e-04 - val_loss: 2.2941e-05\n",
      "Thời gian huấn luyện:  14.313076734542847\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_12 (SimpleRNN)   (None, 10, 109)           12099     \n",
      "                                                                 \n",
      " flatten_49 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,190\n",
      "Trainable params: 13,190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "41/41 [==============================] - 2s 17ms/step - loss: 0.0361 - val_loss: 0.0017\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 4.2989e-04\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.0861e-04 - val_loss: 1.6662e-04\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.1553e-04 - val_loss: 1.2185e-04\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.0989e-04 - val_loss: 1.6293e-04\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.7905e-04 - val_loss: 9.2878e-05\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.8350e-04 - val_loss: 1.0612e-04\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.8332e-04 - val_loss: 1.3042e-04\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.9216e-04 - val_loss: 7.9321e-05\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.6250e-04 - val_loss: 8.9364e-05\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.5761e-04 - val_loss: 1.0968e-04\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.6202e-04 - val_loss: 8.5072e-05\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.5722e-04 - val_loss: 7.8157e-05\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.5676e-04 - val_loss: 8.4853e-05\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.6262e-04 - val_loss: 8.5579e-05\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.4441e-04 - val_loss: 6.4877e-05\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.4120e-04 - val_loss: 6.2857e-05\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.4067e-04 - val_loss: 6.2612e-05\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.3828e-04 - val_loss: 6.7689e-05\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.3613e-04 - val_loss: 7.0036e-05\n",
      "Epoch 21/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.3316e-04 - val_loss: 6.4916e-05\n",
      "Epoch 22/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.2743e-04 - val_loss: 5.7964e-05\n",
      "Epoch 23/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.2559e-04 - val_loss: 5.1836e-05\n",
      "Epoch 24/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.3634e-04 - val_loss: 6.0622e-05\n",
      "Epoch 25/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.3735e-04 - val_loss: 5.2663e-05\n",
      "Epoch 26/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.3188e-04 - val_loss: 5.2567e-05\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 9ms/step - loss: 7.1591e-04 - val_loss: 5.1507e-05\n",
      "Epoch 28/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.1732e-04 - val_loss: 5.4874e-05\n",
      "Epoch 29/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.2367e-04 - val_loss: 5.1608e-05\n",
      "Epoch 30/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.1764e-04 - val_loss: 5.5056e-05\n",
      "Epoch 31/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.0518e-04 - val_loss: 4.9995e-05\n",
      "Epoch 32/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.9608e-04 - val_loss: 5.0142e-05\n",
      "Epoch 33/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.9980e-04 - val_loss: 5.3420e-05\n",
      "Epoch 34/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.0465e-04 - val_loss: 5.0920e-05\n",
      "Epoch 35/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.9347e-04 - val_loss: 5.0055e-05\n",
      "Epoch 36/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.8835e-04 - val_loss: 5.0342e-05\n",
      "Epoch 37/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.2506e-04 - val_loss: 4.9243e-05\n",
      "Epoch 38/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.9229e-04 - val_loss: 4.9104e-05\n",
      "Epoch 39/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.8425e-04 - val_loss: 4.8906e-05\n",
      "Epoch 40/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.0095e-04 - val_loss: 4.8065e-05\n",
      "Epoch 41/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.8395e-04 - val_loss: 4.8409e-05\n",
      "Epoch 42/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.6822e-04 - val_loss: 4.8109e-05\n",
      "Epoch 43/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.6812e-04 - val_loss: 4.7417e-05\n",
      "Epoch 44/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.6503e-04 - val_loss: 4.7266e-05\n",
      "Epoch 45/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.7294e-04 - val_loss: 5.0355e-05\n",
      "Epoch 46/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.6851e-04 - val_loss: 4.8105e-05\n",
      "Epoch 47/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.5845e-04 - val_loss: 4.6663e-05\n",
      "Epoch 48/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.7673e-04 - val_loss: 5.0892e-05\n",
      "Epoch 49/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.4694e-04 - val_loss: 4.7795e-05\n",
      "Epoch 50/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.4969e-04 - val_loss: 4.8549e-05\n",
      "Epoch 51/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.6901e-04 - val_loss: 4.6422e-05\n",
      "Epoch 52/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.3965e-04 - val_loss: 4.6113e-05\n",
      "Epoch 53/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.5789e-04 - val_loss: 5.0556e-05\n",
      "Epoch 54/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.4196e-04 - val_loss: 4.5816e-05\n",
      "Epoch 55/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.3429e-04 - val_loss: 5.1742e-05\n",
      "Epoch 56/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.4180e-04 - val_loss: 4.4531e-05\n",
      "Epoch 57/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.2788e-04 - val_loss: 4.4561e-05\n",
      "Epoch 58/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.6349e-04 - val_loss: 4.4013e-05\n",
      "Epoch 59/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.4280e-04 - val_loss: 4.7755e-05\n",
      "Epoch 60/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.1749e-04 - val_loss: 5.9763e-05\n",
      "Epoch 61/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.2075e-04 - val_loss: 4.4003e-05\n",
      "Epoch 62/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.2009e-04 - val_loss: 4.8135e-05\n",
      "Epoch 63/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.1999e-04 - val_loss: 4.7439e-05\n",
      "Epoch 64/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.0409e-04 - val_loss: 4.9351e-05\n",
      "Epoch 65/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.0641e-04 - val_loss: 4.2831e-05\n",
      "Epoch 66/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.9666e-04 - val_loss: 4.6539e-05\n",
      "Epoch 67/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.1266e-04 - val_loss: 4.8141e-05\n",
      "Epoch 68/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.9521e-04 - val_loss: 4.8364e-05\n",
      "Epoch 69/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.9131e-04 - val_loss: 4.7736e-05\n",
      "Epoch 70/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.1666e-04 - val_loss: 4.1737e-05\n",
      "Epoch 71/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.1056e-04 - val_loss: 5.4370e-05\n",
      "Epoch 72/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.8468e-04 - val_loss: 5.1318e-05\n",
      "Epoch 73/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.2084e-04 - val_loss: 6.0843e-05\n",
      "Epoch 74/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.7457e-04 - val_loss: 5.6378e-05\n",
      "Epoch 75/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.9459e-04 - val_loss: 4.5321e-05\n",
      "Epoch 76/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.6215e-04 - val_loss: 5.1079e-05\n",
      "Epoch 77/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.0280e-04 - val_loss: 4.0049e-05\n",
      "Epoch 78/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.6132e-04 - val_loss: 5.3944e-05\n",
      "Epoch 79/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.7486e-04 - val_loss: 5.5274e-05\n",
      "Epoch 80/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.5412e-04 - val_loss: 3.9544e-05\n",
      "Epoch 81/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.6143e-04 - val_loss: 4.0016e-05\n",
      "Epoch 82/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.5532e-04 - val_loss: 4.0994e-05\n",
      "Epoch 83/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.5760e-04 - val_loss: 5.3006e-05\n",
      "Epoch 84/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.5136e-04 - val_loss: 5.6504e-05\n",
      "Epoch 85/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.5019e-04 - val_loss: 3.8497e-05\n",
      "Epoch 86/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.7571e-04 - val_loss: 4.3943e-05\n",
      "Epoch 87/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.8426e-04 - val_loss: 4.0105e-05\n",
      "Epoch 88/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.3746e-04 - val_loss: 4.6484e-05\n",
      "Epoch 89/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.2808e-04 - val_loss: 4.5429e-05\n",
      "Epoch 90/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.3258e-04 - val_loss: 4.5648e-05\n",
      "Epoch 91/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.1613e-04 - val_loss: 5.1366e-05\n",
      "Epoch 92/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.3307e-04 - val_loss: 5.9799e-05\n",
      "Epoch 93/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.4740e-04 - val_loss: 4.3355e-05\n",
      "Epoch 94/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.0957e-04 - val_loss: 3.6941e-05\n",
      "Epoch 95/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.1130e-04 - val_loss: 3.8553e-05\n",
      "Epoch 96/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.0776e-04 - val_loss: 5.4519e-05\n",
      "Epoch 97/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.9934e-04 - val_loss: 4.8997e-05\n",
      "Epoch 98/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.9520e-04 - val_loss: 4.1885e-05\n",
      "Epoch 99/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.2141e-04 - val_loss: 5.1212e-05\n",
      "Epoch 100/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.9213e-04 - val_loss: 4.2293e-05\n",
      "Thời gian huấn luyện:  38.960779666900635\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lstm_12 (LSTM)              (None, 10, 109)           48396     \n",
      "                                                                 \n",
      " flatten_50 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,487\n",
      "Trainable params: 49,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "41/41 [==============================] - 2s 16ms/step - loss: 0.0265 - val_loss: 6.5080e-04\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 5.5049e-05\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.3053e-04 - val_loss: 5.9226e-05\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.2760e-04 - val_loss: 5.9199e-05\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.1464e-04 - val_loss: 6.0348e-05\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.1418e-04 - val_loss: 7.7983e-05\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.1125e-04 - val_loss: 5.5579e-05\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.0081e-04 - val_loss: 5.8088e-05\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.0285e-04 - val_loss: 5.7869e-05\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.9227e-04 - val_loss: 5.7019e-05\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.9792e-04 - val_loss: 9.1014e-05\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.9209e-04 - val_loss: 6.4982e-05\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.8710e-04 - val_loss: 4.8807e-05\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.7612e-04 - val_loss: 5.5925e-05\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.6950e-04 - val_loss: 5.7807e-05\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.6903e-04 - val_loss: 5.2596e-05\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.6992e-04 - val_loss: 6.2908e-05\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.6052e-04 - val_loss: 5.2260e-05\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.5172e-04 - val_loss: 5.1470e-05\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.4835e-04 - val_loss: 5.8175e-05\n",
      "Epoch 21/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.6097e-04 - val_loss: 5.3066e-05\n",
      "Epoch 22/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.4876e-04 - val_loss: 8.0142e-05\n",
      "Epoch 23/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.3902e-04 - val_loss: 5.7784e-05\n",
      "Epoch 24/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.3798e-04 - val_loss: 6.3203e-05\n",
      "Epoch 25/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.7496e-04 - val_loss: 4.3805e-05\n",
      "Epoch 26/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.4470e-04 - val_loss: 6.0641e-05\n",
      "Epoch 27/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.2391e-04 - val_loss: 5.2520e-05\n",
      "Epoch 28/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.1331e-04 - val_loss: 7.8604e-05\n",
      "Epoch 29/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.0916e-04 - val_loss: 5.9449e-05\n",
      "Epoch 30/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.0409e-04 - val_loss: 5.3593e-05\n",
      "Epoch 31/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.9927e-04 - val_loss: 4.2145e-05\n",
      "Epoch 32/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.1296e-04 - val_loss: 5.9740e-05\n",
      "Epoch 33/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.9588e-04 - val_loss: 5.2091e-05\n",
      "Epoch 34/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.8813e-04 - val_loss: 5.2800e-05\n",
      "Epoch 35/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.7816e-04 - val_loss: 5.9114e-05\n",
      "Epoch 36/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.7807e-04 - val_loss: 6.4023e-05\n",
      "Epoch 37/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.6941e-04 - val_loss: 5.3925e-05\n",
      "Epoch 38/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.6900e-04 - val_loss: 6.0909e-05\n",
      "Epoch 39/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.6865e-04 - val_loss: 3.9408e-05\n",
      "Epoch 40/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.6331e-04 - val_loss: 4.9983e-05\n",
      "Epoch 41/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.6905e-04 - val_loss: 4.8762e-05\n",
      "Epoch 42/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.7343e-04 - val_loss: 7.7991e-05\n",
      "Epoch 43/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.8644e-04 - val_loss: 3.9476e-05\n",
      "Epoch 44/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.4266e-04 - val_loss: 3.7940e-05\n",
      "Epoch 45/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.6600e-04 - val_loss: 5.7307e-05\n",
      "Epoch 46/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.4297e-04 - val_loss: 7.6684e-05\n",
      "Epoch 47/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.3548e-04 - val_loss: 3.8754e-05\n",
      "Epoch 48/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.5500e-04 - val_loss: 9.1705e-05\n",
      "Epoch 49/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.2063e-04 - val_loss: 5.1809e-05\n",
      "Epoch 50/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.1206e-04 - val_loss: 5.9725e-05\n",
      "Epoch 51/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.0837e-04 - val_loss: 4.6101e-05\n",
      "Epoch 52/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.2676e-04 - val_loss: 8.0738e-05\n",
      "Epoch 53/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.0279e-04 - val_loss: 5.9065e-05\n",
      "Epoch 54/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.9468e-04 - val_loss: 6.7698e-05\n",
      "Epoch 55/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.9158e-04 - val_loss: 5.4267e-05\n",
      "Epoch 56/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.8821e-04 - val_loss: 5.0339e-05\n",
      "Epoch 57/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.7935e-04 - val_loss: 5.6111e-05\n",
      "Epoch 58/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.9597e-04 - val_loss: 4.1475e-05\n",
      "Epoch 59/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.6889e-04 - val_loss: 4.1050e-05\n",
      "Epoch 60/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.6834e-04 - val_loss: 4.9190e-05\n",
      "Epoch 61/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.5814e-04 - val_loss: 6.8029e-05\n",
      "Epoch 62/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.5800e-04 - val_loss: 4.6074e-05\n",
      "Epoch 63/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.5354e-04 - val_loss: 6.4624e-05\n",
      "Epoch 64/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.5718e-04 - val_loss: 5.5991e-05\n",
      "Epoch 65/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.6413e-04 - val_loss: 5.2501e-05\n",
      "Epoch 66/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.4009e-04 - val_loss: 6.2761e-05\n",
      "Epoch 67/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.4158e-04 - val_loss: 8.4798e-05\n",
      "Epoch 68/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.4306e-04 - val_loss: 4.6032e-05\n",
      "Epoch 69/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.3358e-04 - val_loss: 4.1724e-05\n",
      "Epoch 70/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.4379e-04 - val_loss: 4.7708e-05\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 8ms/step - loss: 4.3735e-04 - val_loss: 4.5413e-05\n",
      "Epoch 72/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.3831e-04 - val_loss: 7.6584e-05\n",
      "Epoch 73/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.1795e-04 - val_loss: 6.7753e-05\n",
      "Epoch 74/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.1176e-04 - val_loss: 5.0605e-05\n",
      "Epoch 75/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.1924e-04 - val_loss: 4.4780e-05\n",
      "Epoch 76/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.1330e-04 - val_loss: 7.0974e-05\n",
      "Epoch 77/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.4246e-04 - val_loss: 4.2338e-05\n",
      "Epoch 78/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 3.9985e-04 - val_loss: 4.5657e-05\n",
      "Epoch 79/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 3.9785e-04 - val_loss: 6.4807e-05\n",
      "Epoch 80/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.1550e-04 - val_loss: 6.9959e-05\n",
      "Epoch 81/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.0853e-04 - val_loss: 3.9228e-05\n",
      "Epoch 82/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 3.9443e-04 - val_loss: 4.0105e-05\n",
      "Epoch 83/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.0346e-04 - val_loss: 3.3588e-05\n",
      "Epoch 84/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 3.9102e-04 - val_loss: 3.8092e-05\n",
      "Epoch 85/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.0245e-04 - val_loss: 6.4297e-05\n",
      "Epoch 86/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 3.9019e-04 - val_loss: 6.6506e-05\n",
      "Epoch 87/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.0140e-04 - val_loss: 7.6685e-05\n",
      "Epoch 88/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 3.7598e-04 - val_loss: 3.2209e-05\n",
      "Epoch 89/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 3.9636e-04 - val_loss: 5.2414e-05\n",
      "Epoch 90/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 3.6942e-04 - val_loss: 3.7396e-05\n",
      "Epoch 91/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 3.6897e-04 - val_loss: 5.5348e-05\n",
      "Epoch 92/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 3.6697e-04 - val_loss: 2.6558e-05\n",
      "Epoch 93/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 3.6805e-04 - val_loss: 7.0437e-05\n",
      "Epoch 94/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 3.6434e-04 - val_loss: 6.2902e-05\n",
      "Epoch 95/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 3.6810e-04 - val_loss: 3.7284e-05\n",
      "Epoch 96/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 3.5696e-04 - val_loss: 3.9350e-05\n",
      "Epoch 97/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 3.5507e-04 - val_loss: 6.2682e-05\n",
      "Epoch 98/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 3.6527e-04 - val_loss: 4.2079e-05\n",
      "Epoch 99/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 3.6278e-04 - val_loss: 5.5033e-05\n",
      "Epoch 100/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 3.5226e-04 - val_loss: 5.4069e-05\n",
      "Thời gian huấn luyện:  35.85548162460327\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_12 (GRU)                (None, 10, 109)           36624     \n",
      "                                                                 \n",
      " flatten_51 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,715\n",
      "Trainable params: 37,715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "45/45 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "45/45 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "45/45 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "45/45 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0952 - val_loss: 0.0411\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0322\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0219\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0146\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0090\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 7.6915e-04 - val_loss: 0.0014\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.6609e-04 - val_loss: 0.0010\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.2485e-04 - val_loss: 8.1787e-04\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.0316e-04 - val_loss: 7.4245e-04\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.9724e-04 - val_loss: 6.2447e-04\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.9092e-04 - val_loss: 5.7367e-04\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.8873e-04 - val_loss: 5.2021e-04\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.8884e-04 - val_loss: 4.9229e-04\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.8777e-04 - val_loss: 4.5105e-04\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.8638e-04 - val_loss: 4.3834e-04\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.8548e-04 - val_loss: 4.4133e-04\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.7990e-04 - val_loss: 4.3578e-04\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.7880e-04 - val_loss: 3.9915e-04\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.8119e-04 - val_loss: 3.8819e-04\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.7903e-04 - val_loss: 3.9651e-04\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.7467e-04 - val_loss: 3.5318e-04\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.7252e-04 - val_loss: 3.9870e-04\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.7643e-04 - val_loss: 3.4510e-04\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.7120e-04 - val_loss: 3.1150e-04\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.6868e-04 - val_loss: 3.1673e-04\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.6710e-04 - val_loss: 2.7881e-04\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.7439e-04 - val_loss: 2.5208e-04\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.6958e-04 - val_loss: 2.8822e-04\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.6275e-04 - val_loss: 2.7176e-04\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.6356e-04 - val_loss: 2.5942e-04\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.6145e-04 - val_loss: 2.7895e-04\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.6052e-04 - val_loss: 2.6254e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.5594e-04 - val_loss: 2.2068e-04\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.6226e-04 - val_loss: 2.4193e-04\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.5544e-04 - val_loss: 2.6571e-04\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.5464e-04 - val_loss: 2.0177e-04\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.5570e-04 - val_loss: 2.2021e-04\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.5233e-04 - val_loss: 2.2070e-04\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.5570e-04 - val_loss: 2.2819e-04\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.4869e-04 - val_loss: 2.0953e-04\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.4578e-04 - val_loss: 2.3070e-04\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.4685e-04 - val_loss: 2.0651e-04\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.4482e-04 - val_loss: 2.0053e-04\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.4626e-04 - val_loss: 2.2043e-04\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.4621e-04 - val_loss: 1.8823e-04\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.3917e-04 - val_loss: 1.8453e-04\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.3813e-04 - val_loss: 1.9274e-04\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.3607e-04 - val_loss: 1.6824e-04\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.3849e-04 - val_loss: 1.9569e-04\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.3355e-04 - val_loss: 1.8896e-04\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.3195e-04 - val_loss: 1.7043e-04\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.2956e-04 - val_loss: 1.6691e-04\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.2687e-04 - val_loss: 1.7194e-04\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.2924e-04 - val_loss: 1.7761e-04\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.2826e-04 - val_loss: 1.7612e-04\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.2313e-04 - val_loss: 1.5088e-04\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.2410e-04 - val_loss: 1.6721e-04\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.2720e-04 - val_loss: 1.5594e-04\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.1957e-04 - val_loss: 1.5468e-04\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.1888e-04 - val_loss: 1.6166e-04\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.1681e-04 - val_loss: 1.4525e-04\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.2201e-04 - val_loss: 1.6259e-04\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.1997e-04 - val_loss: 1.4719e-04\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.1098e-04 - val_loss: 1.5913e-04\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.0965e-04 - val_loss: 1.5192e-04\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.0754e-04 - val_loss: 1.5207e-04\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.0150e-04 - val_loss: 1.2703e-04\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.0361e-04 - val_loss: 1.5564e-04\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.0176e-04 - val_loss: 1.4696e-04\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.0008e-04 - val_loss: 1.2578e-04\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.9794e-04 - val_loss: 1.4194e-04\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.9419e-04 - val_loss: 1.2545e-04\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.0115e-04 - val_loss: 1.3835e-04\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.9264e-04 - val_loss: 1.1911e-04\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.9344e-04 - val_loss: 1.4910e-04\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.8809e-04 - val_loss: 1.3499e-04\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.8875e-04 - val_loss: 1.5259e-04\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.8631e-04 - val_loss: 1.2710e-04\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.8265e-04 - val_loss: 1.2826e-04\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.8178e-04 - val_loss: 1.3389e-04\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.7969e-04 - val_loss: 1.1695e-04\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.7787e-04 - val_loss: 1.2589e-04\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.7960e-04 - val_loss: 1.1266e-04\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.7310e-04 - val_loss: 1.1377e-04\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.7899e-04 - val_loss: 1.3698e-04\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.7296e-04 - val_loss: 1.2795e-04\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.6779e-04 - val_loss: 1.3432e-04\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.6695e-04 - val_loss: 1.1281e-04\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.6738e-04 - val_loss: 1.1551e-04\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.6383e-04 - val_loss: 1.3156e-04\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.6232e-04 - val_loss: 1.0659e-04\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.7543e-04 - val_loss: 1.1947e-04\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.5634e-04 - val_loss: 1.2037e-04\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.6034e-04 - val_loss: 1.1853e-04\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.7881e-04 - val_loss: 1.2668e-04\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.5484e-04 - val_loss: 1.2493e-04\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.5545e-04 - val_loss: 1.1968e-04\n",
      "Thời gian huấn luyện:  7.833778619766235\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_65 (Dense)            (None, 10, 109)           218       \n",
      "                                                                 \n",
      " flatten_52 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,309\n",
      "Trainable params: 1,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 3.7603e-04\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 3.3899e-04\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.5018e-04 - val_loss: 2.4321e-04\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 4ms/step - loss: 8.8393e-04 - val_loss: 1.3785e-04\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.7287e-04 - val_loss: 1.1381e-04\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.8138e-04 - val_loss: 9.5800e-05\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.3036e-04 - val_loss: 7.5531e-05\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.8650e-04 - val_loss: 5.7975e-05\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.9785e-04 - val_loss: 5.1682e-05\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.4712e-04 - val_loss: 4.6978e-05\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.0652e-04 - val_loss: 4.9370e-05\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.1431e-04 - val_loss: 4.0153e-05\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.1999e-04 - val_loss: 3.6616e-05\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.7282e-04 - val_loss: 3.5671e-05\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.5066e-04 - val_loss: 3.5392e-05\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.8659e-04 - val_loss: 3.4374e-05\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.5763e-04 - val_loss: 3.6238e-05\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.1029e-04 - val_loss: 3.2903e-05\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.0418e-04 - val_loss: 3.0863e-05\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.3213e-04 - val_loss: 3.0248e-05\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.0142e-04 - val_loss: 3.0430e-05\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.7094e-04 - val_loss: 2.8884e-05\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.3109e-04 - val_loss: 2.8622e-05\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.8874e-04 - val_loss: 2.7212e-05\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.7828e-04 - val_loss: 2.8131e-05\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.4648e-04 - val_loss: 2.8322e-05\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.6399e-04 - val_loss: 2.5363e-05\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.3080e-04 - val_loss: 2.7102e-05\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.4773e-04 - val_loss: 2.5021e-05\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.2003e-04 - val_loss: 2.4369e-05\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.9735e-04 - val_loss: 2.4562e-05\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.6074e-04 - val_loss: 2.4705e-05\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.0600e-04 - val_loss: 2.9758e-05\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.2458e-04 - val_loss: 2.3406e-05\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.9325e-04 - val_loss: 2.2839e-05\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.9687e-04 - val_loss: 2.2663e-05\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.8542e-04 - val_loss: 2.3862e-05\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.9184e-04 - val_loss: 2.1622e-05\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.1890e-04 - val_loss: 2.7331e-05\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.9018e-04 - val_loss: 2.1764e-05\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.6996e-04 - val_loss: 2.0564e-05\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.6177e-04 - val_loss: 2.1505e-05\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.5013e-04 - val_loss: 1.9995e-05\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.4824e-04 - val_loss: 2.0628e-05\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.7462e-04 - val_loss: 1.9700e-05\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.6102e-04 - val_loss: 2.3064e-05\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.2979e-04 - val_loss: 2.2699e-05\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.2776e-04 - val_loss: 2.0392e-05\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.4143e-04 - val_loss: 2.0838e-05\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.6400e-04 - val_loss: 2.0115e-05\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.5005e-04 - val_loss: 1.9321e-05\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.4689e-04 - val_loss: 1.8118e-05\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.2572e-04 - val_loss: 1.8155e-05\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.1915e-04 - val_loss: 1.7454e-05\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.1483e-04 - val_loss: 1.9039e-05\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.0737e-04 - val_loss: 1.7614e-05\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.2880e-04 - val_loss: 1.7468e-05\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.0830e-04 - val_loss: 1.7232e-05\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.8764e-04 - val_loss: 2.4933e-05\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.1850e-04 - val_loss: 1.6720e-05\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.1870e-04 - val_loss: 1.8732e-05\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.1783e-04 - val_loss: 1.8506e-05\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.8685e-04 - val_loss: 1.6959e-05\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.3634e-04 - val_loss: 1.6890e-05\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.1882e-04 - val_loss: 1.8157e-05\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.9673e-04 - val_loss: 1.6482e-05\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.2780e-04 - val_loss: 1.7443e-05\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.7893e-04 - val_loss: 2.0577e-05\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.7369e-04 - val_loss: 1.9138e-05\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.6968e-04 - val_loss: 1.5617e-05\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.8254e-04 - val_loss: 1.6905e-05\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.7160e-04 - val_loss: 1.5579e-05\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.8194e-04 - val_loss: 1.6770e-05\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.6847e-04 - val_loss: 1.6903e-05\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.0463e-04 - val_loss: 1.5115e-05\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.2033e-04 - val_loss: 1.5716e-05\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.9434e-04 - val_loss: 1.5728e-05\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.8060e-04 - val_loss: 1.8317e-05\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.0205e-04 - val_loss: 1.5726e-05\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 4ms/step - loss: 2.6554e-04 - val_loss: 1.4709e-05\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.9031e-04 - val_loss: 1.6509e-05\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.6243e-04 - val_loss: 1.7358e-05\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.6011e-04 - val_loss: 1.4886e-05\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.5587e-04 - val_loss: 1.4014e-05\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.5147e-04 - val_loss: 1.4741e-05\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.0185e-04 - val_loss: 1.5103e-05\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.6775e-04 - val_loss: 1.5411e-05\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.5629e-04 - val_loss: 1.4867e-05\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.4664e-04 - val_loss: 1.4927e-05\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.4967e-04 - val_loss: 1.3636e-05\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.4418e-04 - val_loss: 1.8714e-05\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.1039e-04 - val_loss: 1.6112e-05\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.6843e-04 - val_loss: 1.4449e-05\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.2240e-04 - val_loss: 2.2158e-05\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.9224e-04 - val_loss: 1.6445e-05\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.5256e-04 - val_loss: 1.3624e-05\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2832e-04 - val_loss: 1.5508e-05\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.3437e-04 - val_loss: 1.3761e-05\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2865e-04 - val_loss: 1.5079e-05\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.4013e-04 - val_loss: 1.3651e-05\n",
      "Thời gian huấn luyện:  14.817404508590698\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_13 (SimpleRNN)   (None, 10, 109)           12099     \n",
      "                                                                 \n",
      " flatten_53 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,190\n",
      "Trainable params: 13,190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 2s 18ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Thời gian huấn luyện:  36.87930369377136\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_13 (LSTM)              (None, 10, 109)           48396     \n",
      "                                                                 \n",
      " flatten_54 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,487\n",
      "Trainable params: 49,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 2s 16ms/step - loss: 0.0291 - val_loss: 0.0014\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 1.6691e-04\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.1813e-04 - val_loss: 5.0094e-05\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.9233e-04 - val_loss: 6.6744e-05\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.9038e-04 - val_loss: 6.4541e-05\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.9391e-04 - val_loss: 5.5248e-05\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.8769e-04 - val_loss: 5.6592e-05\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.8225e-04 - val_loss: 5.2446e-05\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.7406e-04 - val_loss: 5.8546e-05\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.7376e-04 - val_loss: 5.1668e-05\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.6956e-04 - val_loss: 5.0255e-05\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.7198e-04 - val_loss: 5.0201e-05\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.7039e-04 - val_loss: 5.0836e-05\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.6181e-04 - val_loss: 4.7300e-05\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.6001e-04 - val_loss: 4.7292e-05\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.5626e-04 - val_loss: 4.7317e-05\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.4824e-04 - val_loss: 4.6523e-05\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.4565e-04 - val_loss: 4.9249e-05\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.3795e-04 - val_loss: 5.1190e-05\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.4336e-04 - val_loss: 5.6953e-05\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.3474e-04 - val_loss: 6.4116e-05\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.4757e-04 - val_loss: 5.0064e-05\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 8ms/step - loss: 6.2794e-04 - val_loss: 4.4863e-05\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.2933e-04 - val_loss: 5.5991e-05\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.1617e-04 - val_loss: 4.5393e-05\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.1718e-04 - val_loss: 5.4015e-05\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.2462e-04 - val_loss: 4.3696e-05\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.0990e-04 - val_loss: 4.7666e-05\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.0692e-04 - val_loss: 4.5316e-05\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.9710e-04 - val_loss: 4.2918e-05\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.9809e-04 - val_loss: 4.3046e-05\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.9203e-04 - val_loss: 4.2241e-05\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.8872e-04 - val_loss: 4.5755e-05\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.8145e-04 - val_loss: 5.7811e-05\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.7555e-04 - val_loss: 4.1541e-05\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.7319e-04 - val_loss: 4.1472e-05\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.7666e-04 - val_loss: 4.2787e-05\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.6993e-04 - val_loss: 4.4934e-05\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.6488e-04 - val_loss: 4.4185e-05\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.5970e-04 - val_loss: 4.7249e-05\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.6463e-04 - val_loss: 4.1836e-05\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.4727e-04 - val_loss: 4.5427e-05\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.5674e-04 - val_loss: 4.2513e-05\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.4904e-04 - val_loss: 4.5093e-05\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.2926e-04 - val_loss: 3.8756e-05\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.3720e-04 - val_loss: 5.6315e-05\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.4409e-04 - val_loss: 4.7007e-05\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.2218e-04 - val_loss: 3.8681e-05\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.2688e-04 - val_loss: 5.3375e-05\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.2655e-04 - val_loss: 3.9942e-05\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.1844e-04 - val_loss: 4.4963e-05\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.1701e-04 - val_loss: 4.6189e-05\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.2783e-04 - val_loss: 4.0278e-05\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 4.9949e-04 - val_loss: 3.7652e-05\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.0142e-04 - val_loss: 3.9486e-05\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.8716e-04 - val_loss: 3.6064e-05\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 4.8675e-04 - val_loss: 4.1165e-05\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.9560e-04 - val_loss: 4.5884e-05\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 4.7312e-04 - val_loss: 3.9283e-05\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 4.8273e-04 - val_loss: 3.4081e-05\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.6925e-04 - val_loss: 3.7960e-05\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 4.7301e-04 - val_loss: 5.6964e-05\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 4.8374e-04 - val_loss: 3.3898e-05\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 4.6883e-04 - val_loss: 4.4875e-05\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 4.6091e-04 - val_loss: 4.1139e-05\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 4.5506e-04 - val_loss: 4.4580e-05\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 4.5124e-04 - val_loss: 3.9721e-05\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 4.4621e-04 - val_loss: 3.6700e-05\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 4.5071e-04 - val_loss: 4.1876e-05\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 4.3450e-04 - val_loss: 5.9702e-05\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 4.3100e-04 - val_loss: 3.9896e-05\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 4.3000e-04 - val_loss: 3.7471e-05\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 4.3137e-04 - val_loss: 5.8243e-05\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.4006e-04 - val_loss: 3.2696e-05\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.2823e-04 - val_loss: 5.0670e-05\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 4.3588e-04 - val_loss: 3.8653e-05\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 4.1182e-04 - val_loss: 3.8940e-05\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 4.1653e-04 - val_loss: 3.8674e-05\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 4.0956e-04 - val_loss: 4.8272e-05\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.0699e-04 - val_loss: 4.8640e-05\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.9950e-04 - val_loss: 5.1051e-05\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 4.2319e-04 - val_loss: 3.8778e-05\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 3.9887e-04 - val_loss: 5.0876e-05\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 3.9069e-04 - val_loss: 3.3323e-05\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 4.0554e-04 - val_loss: 4.1304e-05\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.8721e-04 - val_loss: 5.8143e-05\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 3.8466e-04 - val_loss: 4.1058e-05\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 3.9512e-04 - val_loss: 4.0373e-05\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 3.8089e-04 - val_loss: 3.1873e-05\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 3.7741e-04 - val_loss: 4.4207e-05\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 3.7512e-04 - val_loss: 4.7183e-05\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 3.7289e-04 - val_loss: 3.1488e-05\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 3.9151e-04 - val_loss: 4.6489e-05\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 3.7214e-04 - val_loss: 3.7507e-05\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 3.6828e-04 - val_loss: 2.9425e-05\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 3.6158e-04 - val_loss: 5.9811e-05\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 3.5509e-04 - val_loss: 4.5143e-05\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 3.6106e-04 - val_loss: 5.3738e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 3.5544e-04 - val_loss: 5.6108e-05\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 3.5777e-04 - val_loss: 5.8190e-05\n",
      "Thời gian huấn luyện:  34.13023090362549\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_13 (GRU)                (None, 10, 109)           36624     \n",
      "                                                                 \n",
      " flatten_55 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,715\n",
      "Trainable params: 37,715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "45/45 [==============================] - 0s 909us/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "45/45 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "45/45 [==============================] - 1s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "45/45 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1042 - val_loss: 0.0321\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0341\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0237\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0175\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0125\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0086\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0062\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 9.9273e-04 - val_loss: 0.0033\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 8.0322e-04 - val_loss: 0.0026\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 7.1660e-04 - val_loss: 0.0022\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.6257e-04 - val_loss: 0.0018\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.3686e-04 - val_loss: 0.0016\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.2820e-04 - val_loss: 0.0014\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.2269e-04 - val_loss: 0.0013\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.1698e-04 - val_loss: 0.0013\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.1311e-04 - val_loss: 0.0012\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.1001e-04 - val_loss: 0.0013\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.2186e-04 - val_loss: 0.0011\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.0918e-04 - val_loss: 0.0011\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.0745e-04 - val_loss: 0.0011\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.1240e-04 - val_loss: 0.0010\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.0938e-04 - val_loss: 0.0011\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.0632e-04 - val_loss: 0.0011\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.0519e-04 - val_loss: 0.0011\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.0131e-04 - val_loss: 0.0010\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.0260e-04 - val_loss: 0.0011\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.0674e-04 - val_loss: 0.0011\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.0330e-04 - val_loss: 0.0010\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.9782e-04 - val_loss: 9.9200e-04\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.9778e-04 - val_loss: 9.8937e-04\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.9617e-04 - val_loss: 0.0010\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.9496e-04 - val_loss: 9.7464e-04\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.9416e-04 - val_loss: 9.9142e-04\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.9032e-04 - val_loss: 9.3291e-04\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.9102e-04 - val_loss: 9.7506e-04\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.9146e-04 - val_loss: 9.3911e-04\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.8975e-04 - val_loss: 9.6565e-04\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.8662e-04 - val_loss: 9.4559e-04\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.8544e-04 - val_loss: 9.8109e-04\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.8565e-04 - val_loss: 9.5181e-04\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.8639e-04 - val_loss: 9.2472e-04\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.8390e-04 - val_loss: 9.2063e-04\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.8096e-04 - val_loss: 9.4646e-04\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.7942e-04 - val_loss: 9.0857e-04\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.7993e-04 - val_loss: 9.0081e-04\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.7594e-04 - val_loss: 8.7602e-04\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.7868e-04 - val_loss: 9.2188e-04\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.7416e-04 - val_loss: 9.0705e-04\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.7189e-04 - val_loss: 9.2976e-04\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.7413e-04 - val_loss: 9.1665e-04\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.7932e-04 - val_loss: 9.5234e-04\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6828e-04 - val_loss: 8.9610e-04\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6747e-04 - val_loss: 9.4398e-04\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6641e-04 - val_loss: 8.9908e-04\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6448e-04 - val_loss: 8.3044e-04\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6188e-04 - val_loss: 9.2748e-04\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6189e-04 - val_loss: 8.4635e-04\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6224e-04 - val_loss: 8.0019e-04\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6815e-04 - val_loss: 8.3526e-04\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.5802e-04 - val_loss: 8.0499e-04\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.5880e-04 - val_loss: 8.9757e-04\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.5476e-04 - val_loss: 9.3008e-04\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step - loss: 5.5100e-04 - val_loss: 9.2612e-04\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.5452e-04 - val_loss: 8.7420e-04\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.5221e-04 - val_loss: 8.9741e-04\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4839e-04 - val_loss: 8.9135e-04\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4658e-04 - val_loss: 8.3404e-04\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4693e-04 - val_loss: 8.6650e-04\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4125e-04 - val_loss: 8.9093e-04\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4182e-04 - val_loss: 8.5558e-04\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4003e-04 - val_loss: 8.5848e-04\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3949e-04 - val_loss: 8.1588e-04\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4169e-04 - val_loss: 7.8677e-04\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3465e-04 - val_loss: 8.7338e-04\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3348e-04 - val_loss: 8.8315e-04\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3171e-04 - val_loss: 8.1342e-04\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3208e-04 - val_loss: 8.4307e-04\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3440e-04 - val_loss: 8.7473e-04\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2660e-04 - val_loss: 8.1562e-04\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2620e-04 - val_loss: 9.1920e-04\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3055e-04 - val_loss: 8.5215e-04\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.1960e-04 - val_loss: 8.7288e-04\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.1758e-04 - val_loss: 8.7900e-04\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.1640e-04 - val_loss: 7.5784e-04\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.1353e-04 - val_loss: 8.4612e-04\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.1602e-04 - val_loss: 7.8774e-04\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.1189e-04 - val_loss: 6.7988e-04\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3094e-04 - val_loss: 8.7160e-04\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0681e-04 - val_loss: 8.7481e-04\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0967e-04 - val_loss: 9.1983e-04\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0755e-04 - val_loss: 8.6635e-04\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0374e-04 - val_loss: 8.4578e-04\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0064e-04 - val_loss: 7.9117e-04\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9849e-04 - val_loss: 8.4411e-04\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9818e-04 - val_loss: 7.8920e-04\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9631e-04 - val_loss: 8.5516e-04\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9272e-04 - val_loss: 9.0767e-04\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9270e-04 - val_loss: 7.5409e-04\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.8940e-04 - val_loss: 8.3947e-04\n",
      "Thời gian huấn luyện:  7.921066761016846\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_70 (Dense)            (None, 10, 109)           218       \n",
      "                                                                 \n",
      " flatten_56 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,309\n",
      "Trainable params: 1,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "36/36 [==============================] - 1s 8ms/step - loss: 0.0275 - val_loss: 2.2949e-04\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 3.1475e-04\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 4.1575e-04\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.8674e-04 - val_loss: 3.6821e-04\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.7222e-04 - val_loss: 3.8570e-04\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.4298e-04 - val_loss: 3.3005e-04\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.7029e-04 - val_loss: 2.9048e-04\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.5106e-04 - val_loss: 2.4380e-04\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.1577e-04 - val_loss: 2.2463e-04\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.8775e-04 - val_loss: 2.0050e-04\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.6252e-04 - val_loss: 1.7149e-04\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.3266e-04 - val_loss: 1.5463e-04\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.6321e-04 - val_loss: 1.4169e-04\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.2450e-04 - val_loss: 1.2014e-04\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.8456e-04 - val_loss: 1.0704e-04\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.5064e-04 - val_loss: 9.4076e-05\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.3659e-04 - val_loss: 7.8589e-05\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.3596e-04 - val_loss: 7.6325e-05\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.1067e-04 - val_loss: 6.8087e-05\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.9717e-04 - val_loss: 6.2029e-05\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.4548e-04 - val_loss: 5.6860e-05\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.0236e-04 - val_loss: 5.3896e-05\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.8407e-04 - val_loss: 4.8687e-05\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.9229e-04 - val_loss: 4.5430e-05\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.4731e-04 - val_loss: 4.4606e-05\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.4331e-04 - val_loss: 4.5235e-05\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.2770e-04 - val_loss: 4.1497e-05\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.3055e-04 - val_loss: 5.2624e-05\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.7088e-04 - val_loss: 4.3079e-05\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.0360e-04 - val_loss: 4.0870e-05\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.0162e-04 - val_loss: 4.6249e-05\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 4ms/step - loss: 5.6923e-04 - val_loss: 3.4376e-05\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.9652e-04 - val_loss: 4.2080e-05\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8846e-04 - val_loss: 4.3958e-05\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6739e-04 - val_loss: 4.7080e-05\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6114e-04 - val_loss: 3.8429e-05\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6927e-04 - val_loss: 4.5211e-05\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.5354e-04 - val_loss: 4.7105e-05\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6562e-04 - val_loss: 4.9813e-05\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6471e-04 - val_loss: 5.3360e-05\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8975e-04 - val_loss: 3.6633e-05\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6054e-04 - val_loss: 3.7246e-05\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3974e-04 - val_loss: 3.5050e-05\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.2246e-04 - val_loss: 4.1154e-05\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3771e-04 - val_loss: 5.3408e-05\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6442e-04 - val_loss: 3.0312e-05\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6153e-04 - val_loss: 3.3848e-05\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.3730e-04 - val_loss: 4.5144e-05\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2543e-04 - val_loss: 5.0628e-05\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6836e-04 - val_loss: 4.6435e-05\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2833e-04 - val_loss: 3.3248e-05\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.0666e-04 - val_loss: 3.4406e-05\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.0258e-04 - val_loss: 3.6471e-05\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.0554e-04 - val_loss: 3.6525e-05\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2085e-04 - val_loss: 3.1150e-05\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.1795e-04 - val_loss: 3.6220e-05\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.8801e-04 - val_loss: 3.5802e-05\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.1165e-04 - val_loss: 2.9792e-05\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.9818e-04 - val_loss: 2.5796e-05\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.1735e-04 - val_loss: 4.5302e-05\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2853e-04 - val_loss: 2.6346e-05\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.7826e-04 - val_loss: 3.6823e-05\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.9416e-04 - val_loss: 2.4753e-05\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.9021e-04 - val_loss: 3.2841e-05\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.8156e-04 - val_loss: 3.8684e-05\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.0924e-04 - val_loss: 2.5732e-05\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.7475e-04 - val_loss: 2.4612e-05\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.6722e-04 - val_loss: 2.5387e-05\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.6377e-04 - val_loss: 2.7337e-05\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.4542e-04 - val_loss: 3.0173e-05\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.5213e-04 - val_loss: 3.4810e-05\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.8095e-04 - val_loss: 2.5500e-05\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.7583e-04 - val_loss: 2.5195e-05\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.4203e-04 - val_loss: 2.5985e-05\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.4736e-04 - val_loss: 2.4357e-05\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.4519e-04 - val_loss: 2.8177e-05\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.4848e-04 - val_loss: 2.3175e-05\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.5623e-04 - val_loss: 2.2637e-05\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.3696e-04 - val_loss: 2.4611e-05\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.4403e-04 - val_loss: 2.3955e-05\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.3021e-04 - val_loss: 2.3701e-05\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.5542e-04 - val_loss: 2.6013e-05\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.8795e-04 - val_loss: 2.6056e-05\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.2979e-04 - val_loss: 2.3735e-05\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.1688e-04 - val_loss: 2.4501e-05\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.2068e-04 - val_loss: 2.2436e-05\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.2229e-04 - val_loss: 2.2760e-05\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.2876e-04 - val_loss: 2.0432e-05\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.3776e-04 - val_loss: 2.2255e-05\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.0967e-04 - val_loss: 2.2901e-05\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.1815e-04 - val_loss: 2.6677e-05\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.4395e-04 - val_loss: 3.0843e-05\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.1580e-04 - val_loss: 2.0590e-05\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.0204e-04 - val_loss: 2.1112e-05\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.2360e-04 - val_loss: 2.1694e-05\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.4756e-04 - val_loss: 1.9892e-05\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.3547e-04 - val_loss: 2.5243e-05\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.0997e-04 - val_loss: 2.2370e-05\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.1337e-04 - val_loss: 2.1923e-05\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.0495e-04 - val_loss: 2.0215e-05\n",
      "Thời gian huấn luyện:  15.04387354850769\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_14 (SimpleRNN)   (None, 10, 109)           12099     \n",
      "                                                                 \n",
      " flatten_57 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,190\n",
      "Trainable params: 13,190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "36/36 [==============================] - 2s 19ms/step - loss: 0.0348 - val_loss: 0.0012\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 8.2998e-04\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 9.1100e-04 - val_loss: 4.9139e-04\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.7572e-04 - val_loss: 2.7535e-04\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.6929e-04 - val_loss: 2.1442e-04\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.7202e-04 - val_loss: 1.9873e-04\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.5746e-04 - val_loss: 2.2429e-04\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.4689e-04 - val_loss: 1.9259e-04\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.4111e-04 - val_loss: 1.6402e-04\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.6732e-04 - val_loss: 1.7100e-04\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.4810e-04 - val_loss: 1.8327e-04\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.4927e-04 - val_loss: 1.5724e-04\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.3488e-04 - val_loss: 1.5556e-04\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.4371e-04 - val_loss: 1.5186e-04\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.3437e-04 - val_loss: 1.7784e-04\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.2808e-04 - val_loss: 2.0328e-04\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.3237e-04 - val_loss: 1.7093e-04\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.2886e-04 - val_loss: 1.7090e-04\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.1907e-04 - val_loss: 1.8842e-04\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.3473e-04 - val_loss: 1.6923e-04\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.2155e-04 - val_loss: 1.5924e-04\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.1738e-04 - val_loss: 1.4778e-04\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.1808e-04 - val_loss: 1.7788e-04\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.1520e-04 - val_loss: 1.7165e-04\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.1121e-04 - val_loss: 1.6711e-04\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.2974e-04 - val_loss: 1.5411e-04\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.0390e-04 - val_loss: 1.3552e-04\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.0051e-04 - val_loss: 1.3050e-04\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.0213e-04 - val_loss: 1.5994e-04\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.9789e-04 - val_loss: 1.6908e-04\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.0228e-04 - val_loss: 1.3125e-04\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.9660e-04 - val_loss: 1.3010e-04\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.8965e-04 - val_loss: 1.1851e-04\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 8.0270e-04 - val_loss: 1.3964e-04\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.8584e-04 - val_loss: 1.2628e-04\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.8228e-04 - val_loss: 1.1738e-04\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.8115e-04 - val_loss: 1.3570e-04\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.7600e-04 - val_loss: 1.2848e-04\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.7274e-04 - val_loss: 1.2558e-04\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.7430e-04 - val_loss: 1.0663e-04\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.6447e-04 - val_loss: 1.7129e-04\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.7488e-04 - val_loss: 1.1690e-04\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.6923e-04 - val_loss: 1.0416e-04\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.7568e-04 - val_loss: 1.6909e-04\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.7537e-04 - val_loss: 1.2679e-04\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.6993e-04 - val_loss: 9.2210e-05\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.5156e-04 - val_loss: 1.1318e-04\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.4445e-04 - val_loss: 8.3288e-05\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.6218e-04 - val_loss: 1.2781e-04\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.4024e-04 - val_loss: 1.0386e-04\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.4156e-04 - val_loss: 1.1176e-04\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.3771e-04 - val_loss: 1.2881e-04\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 7.5317e-04 - val_loss: 9.5227e-05\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.2815e-04 - val_loss: 1.0855e-04\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.3063e-04 - val_loss: 9.9738e-05\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.4102e-04 - val_loss: 1.3429e-04\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.7333e-04 - val_loss: 1.0622e-04\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.3258e-04 - val_loss: 9.9384e-05\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.1924e-04 - val_loss: 9.1363e-05\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.1316e-04 - val_loss: 8.9682e-05\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.0937e-04 - val_loss: 1.0855e-04\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.1286e-04 - val_loss: 9.0173e-05\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.9928e-04 - val_loss: 9.0191e-05\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.1447e-04 - val_loss: 8.2735e-05\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.0164e-04 - val_loss: 8.4942e-05\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.2178e-04 - val_loss: 1.2295e-04\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.0854e-04 - val_loss: 1.4674e-04\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.2511e-04 - val_loss: 1.1008e-04\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.9030e-04 - val_loss: 6.5454e-05\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.8961e-04 - val_loss: 1.0540e-04\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.7634e-04 - val_loss: 1.0507e-04\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.8107e-04 - val_loss: 8.4966e-05\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.7567e-04 - val_loss: 7.2406e-05\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.8172e-04 - val_loss: 6.7071e-05\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 10ms/step - loss: 6.7593e-04 - val_loss: 9.2440e-05\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.6403e-04 - val_loss: 9.8951e-05\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.6996e-04 - val_loss: 6.9621e-05\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.6703e-04 - val_loss: 8.4484e-05\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.4990e-04 - val_loss: 8.5232e-05\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.6313e-04 - val_loss: 8.5966e-05\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.4576e-04 - val_loss: 9.2969e-05\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.5502e-04 - val_loss: 5.5995e-05\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.4791e-04 - val_loss: 8.0491e-05\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.2772e-04 - val_loss: 8.4233e-05\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.2756e-04 - val_loss: 6.6444e-05\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.3118e-04 - val_loss: 8.9974e-05\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.8676e-04 - val_loss: 5.8141e-05\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.2134e-04 - val_loss: 7.4504e-05\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.1559e-04 - val_loss: 6.5385e-05\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.3901e-04 - val_loss: 8.4555e-05\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.1292e-04 - val_loss: 7.1835e-05\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.1502e-04 - val_loss: 4.8915e-05\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.4260e-04 - val_loss: 7.4365e-05\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.9470e-04 - val_loss: 6.1538e-05\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.9268e-04 - val_loss: 5.8638e-05\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.0031e-04 - val_loss: 7.4606e-05\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.1250e-04 - val_loss: 6.9566e-05\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.9694e-04 - val_loss: 6.2616e-05\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.7395e-04 - val_loss: 5.1557e-05\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.0597e-04 - val_loss: 5.6536e-05\n",
      "Thời gian huấn luyện:  37.907236099243164\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_14 (LSTM)              (None, 10, 109)           48396     \n",
      "                                                                 \n",
      " flatten_58 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,487\n",
      "Trainable params: 49,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "36/36 [==============================] - 2s 18ms/step - loss: 0.0246 - val_loss: 0.0018\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 3.3390e-04\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 8.2739e-04 - val_loss: 1.2640e-04\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 7.5709e-04 - val_loss: 7.8141e-05\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 7.4266e-04 - val_loss: 6.9405e-05\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 7.3914e-04 - val_loss: 7.2969e-05\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 7.3969e-04 - val_loss: 6.7008e-05\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 7.4447e-04 - val_loss: 7.5537e-05\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 7.3997e-04 - val_loss: 6.5297e-05\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 7.4401e-04 - val_loss: 6.4535e-05\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 7.1969e-04 - val_loss: 6.5196e-05\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 7.1313e-04 - val_loss: 6.3752e-05\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 7.1564e-04 - val_loss: 7.1787e-05\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 7.0445e-04 - val_loss: 6.4319e-05\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 7.0420e-04 - val_loss: 6.2898e-05\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 7.0021e-04 - val_loss: 6.3203e-05\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.9572e-04 - val_loss: 6.3813e-05\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.8889e-04 - val_loss: 6.6940e-05\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.9371e-04 - val_loss: 6.4452e-05\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.8187e-04 - val_loss: 6.1622e-05\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.7756e-04 - val_loss: 6.1234e-05\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.7615e-04 - val_loss: 6.2544e-05\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.7654e-04 - val_loss: 6.4224e-05\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.6568e-04 - val_loss: 6.3751e-05\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.6301e-04 - val_loss: 5.8933e-05\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.5420e-04 - val_loss: 5.8557e-05\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.5351e-04 - val_loss: 6.0146e-05\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.4886e-04 - val_loss: 5.7531e-05\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.5412e-04 - val_loss: 6.3348e-05\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.4703e-04 - val_loss: 6.0662e-05\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.3467e-04 - val_loss: 5.7083e-05\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.2629e-04 - val_loss: 5.5699e-05\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.2090e-04 - val_loss: 5.6283e-05\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.2491e-04 - val_loss: 5.5622e-05\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.2523e-04 - val_loss: 5.4380e-05\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.1436e-04 - val_loss: 5.8568e-05\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.1050e-04 - val_loss: 5.3788e-05\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.1738e-04 - val_loss: 5.3458e-05\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.2008e-04 - val_loss: 5.3331e-05\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.0533e-04 - val_loss: 5.2063e-05\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.0098e-04 - val_loss: 5.4468e-05\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.8130e-04 - val_loss: 5.3527e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.7945e-04 - val_loss: 5.1343e-05\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.7851e-04 - val_loss: 5.0928e-05\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.6893e-04 - val_loss: 5.0746e-05\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.5944e-04 - val_loss: 5.0243e-05\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.5321e-04 - val_loss: 5.0705e-05\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.5604e-04 - val_loss: 5.0289e-05\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.4962e-04 - val_loss: 5.1711e-05\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.6361e-04 - val_loss: 5.1229e-05\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.5471e-04 - val_loss: 6.2107e-05\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.4621e-04 - val_loss: 4.9121e-05\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.3259e-04 - val_loss: 4.9430e-05\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.2951e-04 - val_loss: 5.5561e-05\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.3095e-04 - val_loss: 4.6786e-05\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.2188e-04 - val_loss: 4.7306e-05\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.1689e-04 - val_loss: 4.8008e-05\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.2728e-04 - val_loss: 4.6419e-05\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.1049e-04 - val_loss: 4.7507e-05\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.0584e-04 - val_loss: 4.7240e-05\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.9999e-04 - val_loss: 4.5961e-05\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.0470e-04 - val_loss: 4.6789e-05\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.0262e-04 - val_loss: 4.8636e-05\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.8565e-04 - val_loss: 4.4538e-05\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.9198e-04 - val_loss: 4.8960e-05\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.7800e-04 - val_loss: 4.6595e-05\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.8835e-04 - val_loss: 4.4190e-05\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.6932e-04 - val_loss: 4.3564e-05\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.5965e-04 - val_loss: 4.3501e-05\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.7620e-04 - val_loss: 4.4557e-05\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.6669e-04 - val_loss: 4.3232e-05\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.7032e-04 - val_loss: 4.1925e-05\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.5688e-04 - val_loss: 4.8048e-05\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.5701e-04 - val_loss: 4.9019e-05\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.4270e-04 - val_loss: 4.4400e-05\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.4926e-04 - val_loss: 4.2275e-05\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.6668e-04 - val_loss: 4.7006e-05\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.3638e-04 - val_loss: 4.1906e-05\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.4273e-04 - val_loss: 4.1810e-05\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.3231e-04 - val_loss: 4.7256e-05\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.2388e-04 - val_loss: 4.7067e-05\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.4201e-04 - val_loss: 4.0627e-05\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.2719e-04 - val_loss: 4.2211e-05\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.2727e-04 - val_loss: 4.2206e-05\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.1402e-04 - val_loss: 4.0355e-05\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.0970e-04 - val_loss: 4.1256e-05\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.1097e-04 - val_loss: 4.8835e-05\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.1644e-04 - val_loss: 5.5233e-05\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.2891e-04 - val_loss: 4.7413e-05\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.0474e-04 - val_loss: 4.6261e-05\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.0131e-04 - val_loss: 4.9234e-05\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.0119e-04 - val_loss: 4.0247e-05\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.1900e-04 - val_loss: 4.2806e-05\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.0096e-04 - val_loss: 4.0005e-05\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.0133e-04 - val_loss: 3.9646e-05\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.3986e-04 - val_loss: 4.2424e-05\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.0533e-04 - val_loss: 3.8360e-05\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 3.8678e-04 - val_loss: 4.3529e-05\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.9762e-04 - val_loss: 4.1863e-05\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.8772e-04 - val_loss: 4.0852e-05\n",
      "Thời gian huấn luyện:  35.176164627075195\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_14 (GRU)                (None, 10, 109)           36624     \n",
      "                                                                 \n",
      " flatten_59 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,715\n",
      "Trainable params: 37,715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "45/45 [==============================] - 0s 909us/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "45/45 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "45/45 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "45/45 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 89/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Thời gian huấn luyện:  16.096277713775635\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_75 (Dense)            (None, 10, 109)           218       \n",
      "                                                                 \n",
      " flatten_60 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,309\n",
      "Trainable params: 1,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 1s 7ms/step - loss: 0.0314 - val_loss: 1.4326e-04\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 3.2341e-04\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 4.2004e-04\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.9075e-04\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.5614e-04\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.5165e-04\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 2.9343e-04\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 2.7981e-04\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.4372e-04 - val_loss: 2.6634e-04\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.2001e-04 - val_loss: 2.2727e-04\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.8597e-04 - val_loss: 2.0642e-04\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.5326e-04 - val_loss: 1.9150e-04\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.2090e-04 - val_loss: 1.5516e-04\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.1460e-04 - val_loss: 1.5530e-04\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.1183e-04 - val_loss: 1.2090e-04\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.6628e-04 - val_loss: 1.1166e-04\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.3795e-04 - val_loss: 1.0700e-04\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.1708e-04 - val_loss: 7.9394e-05\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.2664e-04 - val_loss: 8.8822e-05\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.9395e-04 - val_loss: 6.9789e-05\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.1735e-04 - val_loss: 5.6391e-05\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.0979e-04 - val_loss: 6.1299e-05\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.5724e-04 - val_loss: 5.4382e-05\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.4587e-04 - val_loss: 5.1448e-05\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.4672e-04 - val_loss: 4.9209e-05\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.5223e-04 - val_loss: 4.5455e-05\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.2196e-04 - val_loss: 4.6346e-05\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.1791e-04 - val_loss: 4.4350e-05\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.2210e-04 - val_loss: 3.8826e-05\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.1351e-04 - val_loss: 3.8474e-05\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.8757e-04 - val_loss: 3.8122e-05\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.0722e-04 - val_loss: 3.7267e-05\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.3957e-04 - val_loss: 3.9898e-05\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.8004e-04 - val_loss: 4.3264e-05\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.9207e-04 - val_loss: 3.5900e-05\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.6705e-04 - val_loss: 3.6072e-05\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.6308e-04 - val_loss: 3.4189e-05\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.9544e-04 - val_loss: 3.3745e-05\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.7373e-04 - val_loss: 3.5833e-05\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 4ms/step - loss: 5.5418e-04 - val_loss: 3.6006e-05\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.3452e-04 - val_loss: 3.3488e-05\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.7144e-04 - val_loss: 3.3424e-05\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.2437e-04 - val_loss: 3.2150e-05\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.1921e-04 - val_loss: 3.2185e-05\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.1496e-04 - val_loss: 3.3215e-05\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.3081e-04 - val_loss: 4.0096e-05\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.1596e-04 - val_loss: 3.2993e-05\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.0285e-04 - val_loss: 3.0211e-05\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.0576e-04 - val_loss: 2.9897e-05\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.0132e-04 - val_loss: 2.9845e-05\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.1296e-04 - val_loss: 3.2998e-05\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.8045e-04 - val_loss: 2.8994e-05\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.9774e-04 - val_loss: 3.7469e-05\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.5039e-04 - val_loss: 3.9956e-05\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.9993e-04 - val_loss: 2.9011e-05\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.5793e-04 - val_loss: 3.5432e-05\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.6547e-04 - val_loss: 3.2191e-05\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.6622e-04 - val_loss: 2.8237e-05\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.6142e-04 - val_loss: 2.8350e-05\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.5019e-04 - val_loss: 2.9369e-05\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.4512e-04 - val_loss: 3.2095e-05\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.5142e-04 - val_loss: 2.9481e-05\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3002e-04 - val_loss: 3.0445e-05\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.2359e-04 - val_loss: 2.6187e-05\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.2986e-04 - val_loss: 2.8765e-05\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.2517e-04 - val_loss: 2.7772e-05\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3783e-04 - val_loss: 2.9491e-05\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3918e-04 - val_loss: 3.8252e-05\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3159e-04 - val_loss: 3.0314e-05\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.0937e-04 - val_loss: 2.5081e-05\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3667e-04 - val_loss: 2.6231e-05\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.0810e-04 - val_loss: 3.0282e-05\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.2297e-04 - val_loss: 2.3380e-05\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.1830e-04 - val_loss: 2.5729e-05\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.1386e-04 - val_loss: 3.3065e-05\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.0035e-04 - val_loss: 3.0582e-05\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.1182e-04 - val_loss: 3.6592e-05\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.8795e-04 - val_loss: 2.8142e-05\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.8806e-04 - val_loss: 2.4778e-05\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.7989e-04 - val_loss: 2.4414e-05\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.7028e-04 - val_loss: 2.5474e-05\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.0726e-04 - val_loss: 3.3681e-05\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.6713e-04 - val_loss: 2.1652e-05\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.9306e-04 - val_loss: 2.5891e-05\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.7151e-04 - val_loss: 2.4971e-05\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.8641e-04 - val_loss: 2.1431e-05\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.6452e-04 - val_loss: 3.1008e-05\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.6832e-04 - val_loss: 2.2370e-05\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.7017e-04 - val_loss: 2.3335e-05\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.5583e-04 - val_loss: 2.2990e-05\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.5261e-04 - val_loss: 2.1469e-05\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.9216e-04 - val_loss: 2.0668e-05\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.7892e-04 - val_loss: 2.1487e-05\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.8451e-04 - val_loss: 2.5174e-05\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.3973e-04 - val_loss: 3.2821e-05\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.3524e-04 - val_loss: 2.3136e-05\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.6847e-04 - val_loss: 2.8355e-05\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.3759e-04 - val_loss: 1.9613e-05\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.3279e-04 - val_loss: 2.3760e-05\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.3486e-04 - val_loss: 1.9435e-05\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.5038e-04 - val_loss: 2.4502e-05\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.2514e-04 - val_loss: 2.1512e-05\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.3028e-04 - val_loss: 1.8554e-05\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.1952e-04 - val_loss: 2.0441e-05\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.4664e-04 - val_loss: 2.0364e-05\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.1148e-04 - val_loss: 2.0367e-05\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.1435e-04 - val_loss: 2.5905e-05\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.4394e-04 - val_loss: 2.7398e-05\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.1696e-04 - val_loss: 1.8296e-05\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.3414e-04 - val_loss: 2.7186e-05\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.2618e-04 - val_loss: 2.4360e-05\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.9979e-04 - val_loss: 2.5033e-05\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.2353e-04 - val_loss: 2.7283e-05\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.2322e-04 - val_loss: 2.9561e-05\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.9067e-04 - val_loss: 1.7113e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.0408e-04 - val_loss: 2.4641e-05\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.3067e-04 - val_loss: 2.5942e-05\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.1583e-04 - val_loss: 2.4869e-05\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.9065e-04 - val_loss: 2.6299e-05\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.0098e-04 - val_loss: 1.9206e-05\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.9135e-04 - val_loss: 2.2091e-05\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.0158e-04 - val_loss: 1.6772e-05\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.8651e-04 - val_loss: 1.8471e-05\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.9312e-04 - val_loss: 2.1374e-05\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.1857e-04 - val_loss: 1.6442e-05\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.8755e-04 - val_loss: 2.0304e-05\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.7428e-04 - val_loss: 1.9839e-05\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.0835e-04 - val_loss: 2.0888e-05\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.8709e-04 - val_loss: 1.5905e-05\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.0506e-04 - val_loss: 1.5702e-05\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.9020e-04 - val_loss: 2.8611e-05\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.7042e-04 - val_loss: 1.5460e-05\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.0088e-04 - val_loss: 2.2543e-05\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.7963e-04 - val_loss: 1.6246e-05\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.6223e-04 - val_loss: 3.7448e-05\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.6870e-04 - val_loss: 1.5781e-05\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.6671e-04 - val_loss: 2.0291e-05\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.6777e-04 - val_loss: 1.4748e-05\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.1803e-04 - val_loss: 1.8375e-05\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.6151e-04 - val_loss: 3.2421e-05\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.6278e-04 - val_loss: 1.4782e-05\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.9604e-04 - val_loss: 1.4175e-05\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.1158e-04 - val_loss: 1.6350e-05\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.6024e-04 - val_loss: 1.4119e-05\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.7710e-04 - val_loss: 1.4284e-05\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.5591e-04 - val_loss: 2.0906e-05\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.5403e-04 - val_loss: 1.6332e-05\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.5827e-04 - val_loss: 1.4105e-05\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.6267e-04 - val_loss: 1.7630e-05\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.8704e-04 - val_loss: 1.6251e-05\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.5443e-04 - val_loss: 1.3940e-05\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.4801e-04 - val_loss: 1.3967e-05\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.4345e-04 - val_loss: 2.3915e-05\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.3904e-04 - val_loss: 2.9741e-05\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.6141e-04 - val_loss: 1.5188e-05\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.4421e-04 - val_loss: 1.3914e-05\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.9475e-04 - val_loss: 1.8251e-05\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.5906e-04 - val_loss: 1.6951e-05\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.6542e-04 - val_loss: 2.4826e-05\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.3288e-04 - val_loss: 1.4569e-05\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.4812e-04 - val_loss: 1.3314e-05\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.8033e-04 - val_loss: 2.1774e-05\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.7393e-04 - val_loss: 1.5765e-05\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.3236e-04 - val_loss: 1.5530e-05\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.5043e-04 - val_loss: 1.3541e-05\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.3681e-04 - val_loss: 1.3581e-05\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.6648e-04 - val_loss: 2.3509e-05\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.3566e-04 - val_loss: 1.5032e-05\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.3940e-04 - val_loss: 1.8871e-05\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.3742e-04 - val_loss: 1.5932e-05\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.2875e-04 - val_loss: 1.5301e-05\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.3410e-04 - val_loss: 1.5907e-05\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.4333e-04 - val_loss: 1.8939e-05\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.3148e-04 - val_loss: 1.8073e-05\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.2753e-04 - val_loss: 1.4587e-05\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.4098e-04 - val_loss: 2.2292e-05\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.4077e-04 - val_loss: 1.6667e-05\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.3521e-04 - val_loss: 1.4317e-05\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.3353e-04 - val_loss: 1.6238e-05\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.2573e-04 - val_loss: 2.6396e-05\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.1831e-04 - val_loss: 1.6562e-05\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.1984e-04 - val_loss: 1.5721e-05\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.2975e-04 - val_loss: 1.3777e-05\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.1152e-04 - val_loss: 1.6975e-05\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.2622e-04 - val_loss: 1.2060e-05\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.2086e-04 - val_loss: 1.7619e-05\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.2060e-04 - val_loss: 1.8616e-05\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.1519e-04 - val_loss: 1.2872e-05\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.1734e-04 - val_loss: 1.5552e-05\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.1951e-04 - val_loss: 1.9393e-05\n",
      "Epoch 191/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 4ms/step - loss: 2.1250e-04 - val_loss: 1.2187e-05\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.2810e-04 - val_loss: 1.2514e-05\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.0296e-04 - val_loss: 1.3036e-05\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.0767e-04 - val_loss: 1.4831e-05\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.0784e-04 - val_loss: 1.3325e-05\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.1184e-04 - val_loss: 1.3388e-05\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1.9922e-04 - val_loss: 1.2424e-05\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.1320e-04 - val_loss: 1.2769e-05\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.1174e-04 - val_loss: 2.4096e-05\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1.9768e-04 - val_loss: 1.1636e-05\n",
      "Thời gian huấn luyện:  31.597854614257812\n",
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_15 (SimpleRNN)   (None, 10, 109)           12099     \n",
      "                                                                 \n",
      " flatten_61 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,190\n",
      "Trainable params: 13,190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 2s 17ms/step - loss: 0.0347 - val_loss: 0.0014\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 3.4940e-04\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.0365e-04 - val_loss: 1.0131e-04\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.7308e-04 - val_loss: 6.1587e-05\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.1152e-04 - val_loss: 7.6932e-05\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.9011e-04 - val_loss: 9.7457e-05\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.8243e-04 - val_loss: 6.4821e-05\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.6354e-04 - val_loss: 5.6115e-05\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.6882e-04 - val_loss: 5.9752e-05\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.6470e-04 - val_loss: 5.7922e-05\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.6728e-04 - val_loss: 6.3397e-05\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.5506e-04 - val_loss: 6.3009e-05\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.5904e-04 - val_loss: 6.1639e-05\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.5244e-04 - val_loss: 5.3944e-05\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.4448e-04 - val_loss: 5.8469e-05\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.4257e-04 - val_loss: 6.7200e-05\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.3889e-04 - val_loss: 5.4995e-05\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.4735e-04 - val_loss: 5.4255e-05\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.5236e-04 - val_loss: 5.3133e-05\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.4417e-04 - val_loss: 5.5345e-05\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.4704e-04 - val_loss: 5.2228e-05\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.7412e-04 - val_loss: 5.7323e-05\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.3150e-04 - val_loss: 5.4593e-05\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.3595e-04 - val_loss: 5.1670e-05\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.2097e-04 - val_loss: 5.2222e-05\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.2045e-04 - val_loss: 5.2085e-05\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.2129e-04 - val_loss: 5.1921e-05\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.1851e-04 - val_loss: 5.1049e-05\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.0550e-04 - val_loss: 5.5703e-05\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.1725e-04 - val_loss: 5.3685e-05\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.4555e-04 - val_loss: 5.3891e-05\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.2475e-04 - val_loss: 5.0363e-05\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.0919e-04 - val_loss: 5.3469e-05\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.0452e-04 - val_loss: 4.9828e-05\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.9502e-04 - val_loss: 5.0701e-05\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.9999e-04 - val_loss: 5.3037e-05\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.1355e-04 - val_loss: 5.1337e-05\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.9504e-04 - val_loss: 4.9599e-05\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.8255e-04 - val_loss: 4.9706e-05\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.9199e-04 - val_loss: 5.5477e-05\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.9912e-04 - val_loss: 4.8327e-05\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.7551e-04 - val_loss: 5.2624e-05\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.7702e-04 - val_loss: 5.1426e-05\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.8119e-04 - val_loss: 4.9466e-05\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.7565e-04 - val_loss: 4.8386e-05\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.7320e-04 - val_loss: 5.0309e-05\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.6714e-04 - val_loss: 4.7988e-05\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.8651e-04 - val_loss: 5.1050e-05\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.7005e-04 - val_loss: 5.3187e-05\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.8278e-04 - val_loss: 4.6839e-05\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.5368e-04 - val_loss: 4.7339e-05\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.6422e-04 - val_loss: 4.8466e-05\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.4403e-04 - val_loss: 4.7306e-05\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.5330e-04 - val_loss: 5.7833e-05\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.5306e-04 - val_loss: 4.6048e-05\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.6671e-04 - val_loss: 4.5327e-05\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.5867e-04 - val_loss: 5.0501e-05\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.4575e-04 - val_loss: 5.3808e-05\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 9ms/step - loss: 6.3855e-04 - val_loss: 5.7135e-05\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.4268e-04 - val_loss: 5.3019e-05\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.2188e-04 - val_loss: 5.2566e-05\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.3092e-04 - val_loss: 5.2273e-05\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.1765e-04 - val_loss: 4.5905e-05\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.2616e-04 - val_loss: 4.8108e-05\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.1727e-04 - val_loss: 5.0825e-05\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.2356e-04 - val_loss: 4.6286e-05\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.0938e-04 - val_loss: 4.3118e-05\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.0700e-04 - val_loss: 5.3514e-05\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.0538e-04 - val_loss: 4.2377e-05\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.2278e-04 - val_loss: 4.4999e-05\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.9487e-04 - val_loss: 4.2454e-05\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.5627e-04 - val_loss: 4.6658e-05\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.0825e-04 - val_loss: 4.1555e-05\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.8597e-04 - val_loss: 4.6623e-05\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.8239e-04 - val_loss: 4.8603e-05\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.9897e-04 - val_loss: 4.5372e-05\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.8142e-04 - val_loss: 4.6407e-05\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.8543e-04 - val_loss: 5.4805e-05\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.7751e-04 - val_loss: 5.5081e-05\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.6132e-04 - val_loss: 5.0957e-05\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.6911e-04 - val_loss: 4.3950e-05\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.9422e-04 - val_loss: 5.8580e-05\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.4917e-04 - val_loss: 4.4547e-05\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.4906e-04 - val_loss: 4.1584e-05\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.4643e-04 - val_loss: 3.8921e-05\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.3806e-04 - val_loss: 4.4166e-05\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.4731e-04 - val_loss: 4.0836e-05\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.3160e-04 - val_loss: 4.1554e-05\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.3631e-04 - val_loss: 4.2010e-05\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.5541e-04 - val_loss: 5.1094e-05\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.6565e-04 - val_loss: 4.2954e-05\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.2936e-04 - val_loss: 3.7173e-05\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.3789e-04 - val_loss: 4.5487e-05\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.2931e-04 - val_loss: 3.9483e-05\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.4202e-04 - val_loss: 3.8612e-05\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.3087e-04 - val_loss: 3.9713e-05\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.1486e-04 - val_loss: 3.7626e-05\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.0422e-04 - val_loss: 5.4617e-05\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.0982e-04 - val_loss: 4.2337e-05\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.0618e-04 - val_loss: 5.3060e-05\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.9488e-04 - val_loss: 4.7352e-05\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.9789e-04 - val_loss: 4.6520e-05\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.9216e-04 - val_loss: 4.1104e-05\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.8401e-04 - val_loss: 5.5696e-05\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.2745e-04 - val_loss: 4.4366e-05\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.8106e-04 - val_loss: 5.6651e-05\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.8986e-04 - val_loss: 3.6855e-05\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.1264e-04 - val_loss: 4.7262e-05\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.9124e-04 - val_loss: 4.6198e-05\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.7079e-04 - val_loss: 4.4873e-05\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.8685e-04 - val_loss: 3.9421e-05\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.8475e-04 - val_loss: 4.2575e-05\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.6646e-04 - val_loss: 5.3135e-05\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.7353e-04 - val_loss: 3.7950e-05\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.9527e-04 - val_loss: 3.6731e-05\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.5329e-04 - val_loss: 5.9593e-05\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.5983e-04 - val_loss: 4.9676e-05\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.6869e-04 - val_loss: 3.7051e-05\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.6762e-04 - val_loss: 4.6460e-05\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.5856e-04 - val_loss: 5.6137e-05\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.8570e-04 - val_loss: 3.6299e-05\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.4987e-04 - val_loss: 4.2209e-05\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.7306e-04 - val_loss: 3.7763e-05\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.3624e-04 - val_loss: 3.2008e-05\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.4060e-04 - val_loss: 4.2994e-05\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.5179e-04 - val_loss: 3.3017e-05\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.5258e-04 - val_loss: 4.3774e-05\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.3657e-04 - val_loss: 4.1946e-05\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.4122e-04 - val_loss: 3.5790e-05\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.2867e-04 - val_loss: 3.4184e-05\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.2798e-04 - val_loss: 3.6025e-05\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.4551e-04 - val_loss: 3.2358e-05\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.2395e-04 - val_loss: 5.0195e-05\n",
      "Epoch 134/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 9ms/step - loss: 4.2996e-04 - val_loss: 3.1063e-05\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.2022e-04 - val_loss: 4.8928e-05\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.4018e-04 - val_loss: 3.0620e-05\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.3867e-04 - val_loss: 3.7041e-05\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.2645e-04 - val_loss: 3.4397e-05\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.2334e-04 - val_loss: 3.1530e-05\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.2327e-04 - val_loss: 3.0970e-05\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.4238e-04 - val_loss: 3.0220e-05\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.4943e-04 - val_loss: 4.2818e-05\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.1213e-04 - val_loss: 3.7941e-05\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.1631e-04 - val_loss: 4.0025e-05\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.0359e-04 - val_loss: 3.6803e-05\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.1749e-04 - val_loss: 4.4369e-05\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.2711e-04 - val_loss: 3.5374e-05\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.0985e-04 - val_loss: 2.9444e-05\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.2312e-04 - val_loss: 3.7528e-05\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.0525e-04 - val_loss: 3.3382e-05\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.0100e-04 - val_loss: 3.6550e-05\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.9722e-04 - val_loss: 2.9641e-05\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.1930e-04 - val_loss: 2.8853e-05\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.0245e-04 - val_loss: 3.7565e-05\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.2173e-04 - val_loss: 3.8436e-05\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.1115e-04 - val_loss: 2.9930e-05\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.0581e-04 - val_loss: 3.1234e-05\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.8560e-04 - val_loss: 3.0895e-05\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.9709e-04 - val_loss: 2.9964e-05\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.9196e-04 - val_loss: 3.6531e-05\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.0177e-04 - val_loss: 2.9377e-05\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.0450e-04 - val_loss: 3.2835e-05\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.9584e-04 - val_loss: 2.8860e-05\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.9801e-04 - val_loss: 3.8279e-05\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.8567e-04 - val_loss: 3.7937e-05\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.9429e-04 - val_loss: 2.8834e-05\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.7676e-04 - val_loss: 2.8623e-05\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.7629e-04 - val_loss: 2.9219e-05\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.9670e-04 - val_loss: 2.8916e-05\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.7633e-04 - val_loss: 3.5632e-05\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.7201e-04 - val_loss: 3.0418e-05\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.5068e-04 - val_loss: 5.1529e-05\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.0655e-04 - val_loss: 2.7972e-05\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.7668e-04 - val_loss: 3.0677e-05\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.2623e-04 - val_loss: 2.7245e-05\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.7963e-04 - val_loss: 3.3048e-05\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.7055e-04 - val_loss: 2.9960e-05\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.8535e-04 - val_loss: 3.1315e-05\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.7041e-04 - val_loss: 3.2356e-05\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.6651e-04 - val_loss: 2.8442e-05\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.0848e-04 - val_loss: 2.6954e-05\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.7138e-04 - val_loss: 2.8424e-05\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.5389e-04 - val_loss: 2.7028e-05\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.6751e-04 - val_loss: 3.5336e-05\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.2406e-04 - val_loss: 3.1294e-05\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.5859e-04 - val_loss: 2.6450e-05\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.7982e-04 - val_loss: 2.9767e-05\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.5236e-04 - val_loss: 3.3444e-05\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.5173e-04 - val_loss: 2.9365e-05\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.5636e-04 - val_loss: 2.7707e-05\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.6002e-04 - val_loss: 2.8195e-05\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.4492e-04 - val_loss: 2.6819e-05\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.5944e-04 - val_loss: 2.6058e-05\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.5542e-04 - val_loss: 2.7957e-05\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.4053e-04 - val_loss: 2.8246e-05\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.4951e-04 - val_loss: 3.0459e-05\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.4469e-04 - val_loss: 3.1685e-05\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.4814e-04 - val_loss: 2.6193e-05\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.4138e-04 - val_loss: 2.7382e-05\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.4160e-04 - val_loss: 2.5648e-05\n",
      "Thời gian huấn luyện:  78.03415393829346\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_15 (LSTM)              (None, 10, 109)           48396     \n",
      "                                                                 \n",
      " flatten_62 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,487\n",
      "Trainable params: 49,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 2s 16ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2017 - val_loss: 0.0014\n",
      "Thời gian huấn luyện:  69.71434879302979\n",
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_15 (GRU)                (None, 10, 109)           36624     \n",
      "                                                                 \n",
      " flatten_63 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,715\n",
      "Trainable params: 37,715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "45/45 [==============================] - 0s 929us/step\n",
      "19/19 [==============================] - 0s 944us/step\n",
      "45/45 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "45/45 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "45/45 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0866 - val_loss: 0.0433\n",
      "Epoch 2/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0288\n",
      "Epoch 3/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0192\n",
      "Epoch 4/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0127\n",
      "Epoch 5/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0077\n",
      "Epoch 6/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 7/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 8/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 8.8900e-04 - val_loss: 0.0018\n",
      "Epoch 9/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 7.3872e-04 - val_loss: 0.0014\n",
      "Epoch 10/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.7875e-04 - val_loss: 0.0010\n",
      "Epoch 11/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.5404e-04 - val_loss: 8.4136e-04\n",
      "Epoch 12/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.4281e-04 - val_loss: 7.4738e-04\n",
      "Epoch 13/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.4478e-04 - val_loss: 6.5095e-04\n",
      "Epoch 14/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.3324e-04 - val_loss: 6.8737e-04\n",
      "Epoch 15/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.3836e-04 - val_loss: 6.4468e-04\n",
      "Epoch 16/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.3244e-04 - val_loss: 5.8125e-04\n",
      "Epoch 17/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.2897e-04 - val_loss: 5.4541e-04\n",
      "Epoch 18/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.2733e-04 - val_loss: 5.5588e-04\n",
      "Epoch 19/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.2601e-04 - val_loss: 5.2539e-04\n",
      "Epoch 20/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.2274e-04 - val_loss: 4.8561e-04\n",
      "Epoch 21/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.2324e-04 - val_loss: 4.5504e-04\n",
      "Epoch 22/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.2112e-04 - val_loss: 4.8922e-04\n",
      "Epoch 23/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.2097e-04 - val_loss: 4.3998e-04\n",
      "Epoch 24/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.1771e-04 - val_loss: 3.9413e-04\n",
      "Epoch 25/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.1477e-04 - val_loss: 3.9983e-04\n",
      "Epoch 26/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.1420e-04 - val_loss: 3.8992e-04\n",
      "Epoch 27/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.1178e-04 - val_loss: 3.9599e-04\n",
      "Epoch 28/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.0960e-04 - val_loss: 3.6473e-04\n",
      "Epoch 29/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.1442e-04 - val_loss: 3.4712e-04\n",
      "Epoch 30/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.0949e-04 - val_loss: 3.4893e-04\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 2ms/step - loss: 6.0608e-04 - val_loss: 3.1003e-04\n",
      "Epoch 32/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.0451e-04 - val_loss: 3.0992e-04\n",
      "Epoch 33/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.0378e-04 - val_loss: 3.0862e-04\n",
      "Epoch 34/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.0154e-04 - val_loss: 2.9129e-04\n",
      "Epoch 35/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.1328e-04 - val_loss: 3.0168e-04\n",
      "Epoch 36/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.0229e-04 - val_loss: 3.0599e-04\n",
      "Epoch 37/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.0211e-04 - val_loss: 3.0773e-04\n",
      "Epoch 38/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.9556e-04 - val_loss: 2.8620e-04\n",
      "Epoch 39/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.9458e-04 - val_loss: 2.6176e-04\n",
      "Epoch 40/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.9275e-04 - val_loss: 2.8883e-04\n",
      "Epoch 41/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.9961e-04 - val_loss: 2.7848e-04\n",
      "Epoch 42/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.9349e-04 - val_loss: 2.6751e-04\n",
      "Epoch 43/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.9447e-04 - val_loss: 2.4027e-04\n",
      "Epoch 44/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.8624e-04 - val_loss: 2.6752e-04\n",
      "Epoch 45/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.8423e-04 - val_loss: 2.2033e-04\n",
      "Epoch 46/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.9083e-04 - val_loss: 2.4689e-04\n",
      "Epoch 47/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.8326e-04 - val_loss: 2.4711e-04\n",
      "Epoch 48/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.8638e-04 - val_loss: 2.3137e-04\n",
      "Epoch 49/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.8044e-04 - val_loss: 2.3619e-04\n",
      "Epoch 50/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.7759e-04 - val_loss: 2.2096e-04\n",
      "Epoch 51/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.7803e-04 - val_loss: 2.1546e-04\n",
      "Epoch 52/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.7194e-04 - val_loss: 2.3622e-04\n",
      "Epoch 53/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.7493e-04 - val_loss: 2.3192e-04\n",
      "Epoch 54/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.7618e-04 - val_loss: 2.1254e-04\n",
      "Epoch 55/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.6600e-04 - val_loss: 2.4664e-04\n",
      "Epoch 56/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.7557e-04 - val_loss: 2.1755e-04\n",
      "Epoch 57/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.6569e-04 - val_loss: 2.0372e-04\n",
      "Epoch 58/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.6661e-04 - val_loss: 2.0452e-04\n",
      "Epoch 59/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.6160e-04 - val_loss: 2.1075e-04\n",
      "Epoch 60/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.6504e-04 - val_loss: 2.0691e-04\n",
      "Epoch 61/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.5887e-04 - val_loss: 2.0236e-04\n",
      "Epoch 62/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.6890e-04 - val_loss: 2.0061e-04\n",
      "Epoch 63/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.5497e-04 - val_loss: 1.7992e-04\n",
      "Epoch 64/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.5710e-04 - val_loss: 1.9651e-04\n",
      "Epoch 65/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.5437e-04 - val_loss: 1.9867e-04\n",
      "Epoch 66/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.5241e-04 - val_loss: 1.9295e-04\n",
      "Epoch 67/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.4772e-04 - val_loss: 2.1822e-04\n",
      "Epoch 68/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.5039e-04 - val_loss: 1.8015e-04\n",
      "Epoch 69/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.5020e-04 - val_loss: 1.9965e-04\n",
      "Epoch 70/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.4866e-04 - val_loss: 1.7690e-04\n",
      "Epoch 71/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.4656e-04 - val_loss: 1.7266e-04\n",
      "Epoch 72/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.3999e-04 - val_loss: 1.6468e-04\n",
      "Epoch 73/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.3860e-04 - val_loss: 1.6142e-04\n",
      "Epoch 74/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.3891e-04 - val_loss: 1.8500e-04\n",
      "Epoch 75/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.3571e-04 - val_loss: 1.6306e-04\n",
      "Epoch 76/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.3794e-04 - val_loss: 1.8657e-04\n",
      "Epoch 77/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.3469e-04 - val_loss: 1.7389e-04\n",
      "Epoch 78/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.3075e-04 - val_loss: 1.6453e-04\n",
      "Epoch 79/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.2748e-04 - val_loss: 1.5955e-04\n",
      "Epoch 80/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.2691e-04 - val_loss: 1.7238e-04\n",
      "Epoch 81/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.2228e-04 - val_loss: 1.4291e-04\n",
      "Epoch 82/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.2437e-04 - val_loss: 1.4510e-04\n",
      "Epoch 83/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.2804e-04 - val_loss: 1.6671e-04\n",
      "Epoch 84/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.1953e-04 - val_loss: 1.9082e-04\n",
      "Epoch 85/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.1721e-04 - val_loss: 1.4917e-04\n",
      "Epoch 86/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.1758e-04 - val_loss: 1.6163e-04\n",
      "Epoch 87/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.1456e-04 - val_loss: 1.6891e-04\n",
      "Epoch 88/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.1726e-04 - val_loss: 1.7452e-04\n",
      "Epoch 89/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.1137e-04 - val_loss: 1.6378e-04\n",
      "Epoch 90/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.0936e-04 - val_loss: 1.8285e-04\n",
      "Epoch 91/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.1062e-04 - val_loss: 1.6581e-04\n",
      "Epoch 92/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.0609e-04 - val_loss: 1.8113e-04\n",
      "Epoch 93/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.0155e-04 - val_loss: 1.5657e-04\n",
      "Epoch 94/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.9952e-04 - val_loss: 1.5543e-04\n",
      "Epoch 95/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.9728e-04 - val_loss: 1.3753e-04\n",
      "Epoch 96/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.9455e-04 - val_loss: 1.6934e-04\n",
      "Epoch 97/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.9191e-04 - val_loss: 1.5055e-04\n",
      "Epoch 98/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.9179e-04 - val_loss: 1.4462e-04\n",
      "Epoch 99/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.9674e-04 - val_loss: 1.4709e-04\n",
      "Epoch 100/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.9183e-04 - val_loss: 1.3808e-04\n",
      "Epoch 101/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.8326e-04 - val_loss: 1.6740e-04\n",
      "Epoch 102/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.8261e-04 - val_loss: 1.6748e-04\n",
      "Epoch 103/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.9060e-04 - val_loss: 1.2765e-04\n",
      "Epoch 104/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.8211e-04 - val_loss: 1.5843e-04\n",
      "Epoch 105/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.7993e-04 - val_loss: 1.4460e-04\n",
      "Epoch 106/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.7290e-04 - val_loss: 1.3774e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.7100e-04 - val_loss: 1.5028e-04\n",
      "Epoch 108/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.6927e-04 - val_loss: 1.3046e-04\n",
      "Epoch 109/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.7645e-04 - val_loss: 1.4413e-04\n",
      "Epoch 110/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.6510e-04 - val_loss: 1.4370e-04\n",
      "Epoch 111/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.6274e-04 - val_loss: 1.4177e-04\n",
      "Epoch 112/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.6330e-04 - val_loss: 1.4793e-04\n",
      "Epoch 113/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.6177e-04 - val_loss: 1.4029e-04\n",
      "Epoch 114/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.6206e-04 - val_loss: 1.3066e-04\n",
      "Epoch 115/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.6176e-04 - val_loss: 1.5094e-04\n",
      "Epoch 116/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.5366e-04 - val_loss: 1.3175e-04\n",
      "Epoch 117/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.5337e-04 - val_loss: 1.5375e-04\n",
      "Epoch 118/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.5398e-04 - val_loss: 1.3493e-04\n",
      "Epoch 119/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.4791e-04 - val_loss: 1.4633e-04\n",
      "Epoch 120/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.5085e-04 - val_loss: 1.2543e-04\n",
      "Epoch 121/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.5476e-04 - val_loss: 1.5356e-04\n",
      "Epoch 122/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.4412e-04 - val_loss: 1.3746e-04\n",
      "Epoch 123/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.4587e-04 - val_loss: 1.6248e-04\n",
      "Epoch 124/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.4003e-04 - val_loss: 1.4476e-04\n",
      "Epoch 125/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.4179e-04 - val_loss: 1.1666e-04\n",
      "Epoch 126/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.3876e-04 - val_loss: 1.2646e-04\n",
      "Epoch 127/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.4072e-04 - val_loss: 1.2032e-04\n",
      "Epoch 128/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.3808e-04 - val_loss: 1.2244e-04\n",
      "Epoch 129/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.4465e-04 - val_loss: 1.4416e-04\n",
      "Epoch 130/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.3389e-04 - val_loss: 1.1964e-04\n",
      "Epoch 131/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.2440e-04 - val_loss: 1.4304e-04\n",
      "Epoch 132/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.3155e-04 - val_loss: 1.4972e-04\n",
      "Epoch 133/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.2310e-04 - val_loss: 1.3268e-04\n",
      "Epoch 134/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.2001e-04 - val_loss: 1.4184e-04\n",
      "Epoch 135/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.1698e-04 - val_loss: 1.2625e-04\n",
      "Epoch 136/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.1612e-04 - val_loss: 1.2284e-04\n",
      "Epoch 137/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.1441e-04 - val_loss: 1.2515e-04\n",
      "Epoch 138/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.2542e-04 - val_loss: 1.2392e-04\n",
      "Epoch 139/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.1829e-04 - val_loss: 1.1954e-04\n",
      "Epoch 140/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.0976e-04 - val_loss: 1.6017e-04\n",
      "Epoch 141/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.0912e-04 - val_loss: 1.4327e-04\n",
      "Epoch 142/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.0826e-04 - val_loss: 1.2585e-04\n",
      "Epoch 143/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.0333e-04 - val_loss: 1.2762e-04\n",
      "Epoch 144/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.0317e-04 - val_loss: 1.1877e-04\n",
      "Epoch 145/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.9601e-04 - val_loss: 9.9535e-05\n",
      "Epoch 146/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.0400e-04 - val_loss: 1.1818e-04\n",
      "Epoch 147/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.9672e-04 - val_loss: 1.2368e-04\n",
      "Epoch 148/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.9300e-04 - val_loss: 1.1739e-04\n",
      "Epoch 149/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.9904e-04 - val_loss: 1.0961e-04\n",
      "Epoch 150/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.9599e-04 - val_loss: 1.2193e-04\n",
      "Epoch 151/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.8564e-04 - val_loss: 1.0204e-04\n",
      "Epoch 152/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.9264e-04 - val_loss: 1.1803e-04\n",
      "Epoch 153/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.8537e-04 - val_loss: 1.2349e-04\n",
      "Epoch 154/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.8315e-04 - val_loss: 1.2760e-04\n",
      "Epoch 155/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.9109e-04 - val_loss: 1.1474e-04\n",
      "Epoch 156/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.8213e-04 - val_loss: 1.2015e-04\n",
      "Epoch 157/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.7754e-04 - val_loss: 1.3080e-04\n",
      "Epoch 158/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.7656e-04 - val_loss: 1.0519e-04\n",
      "Epoch 159/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.7636e-04 - val_loss: 1.1437e-04\n",
      "Epoch 160/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.7346e-04 - val_loss: 1.0837e-04\n",
      "Epoch 161/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.7145e-04 - val_loss: 9.7298e-05\n",
      "Epoch 162/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.7105e-04 - val_loss: 1.1194e-04\n",
      "Epoch 163/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.6767e-04 - val_loss: 1.0517e-04\n",
      "Epoch 164/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.6913e-04 - val_loss: 1.2503e-04\n",
      "Epoch 165/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.6447e-04 - val_loss: 9.8282e-05\n",
      "Epoch 166/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.7155e-04 - val_loss: 1.1771e-04\n",
      "Epoch 167/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.6593e-04 - val_loss: 1.4342e-04\n",
      "Epoch 168/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.6543e-04 - val_loss: 1.0753e-04\n",
      "Epoch 169/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.5950e-04 - val_loss: 1.0935e-04\n",
      "Epoch 170/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.5746e-04 - val_loss: 1.1191e-04\n",
      "Epoch 171/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.6755e-04 - val_loss: 1.0580e-04\n",
      "Epoch 172/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.5712e-04 - val_loss: 1.1833e-04\n",
      "Epoch 173/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.5279e-04 - val_loss: 1.0159e-04\n",
      "Epoch 174/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.5167e-04 - val_loss: 1.0723e-04\n",
      "Epoch 175/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.4885e-04 - val_loss: 1.0920e-04\n",
      "Epoch 176/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.5014e-04 - val_loss: 1.1366e-04\n",
      "Epoch 177/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.4297e-04 - val_loss: 1.2955e-04\n",
      "Epoch 178/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.4618e-04 - val_loss: 9.9720e-05\n",
      "Epoch 179/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.4350e-04 - val_loss: 1.1716e-04\n",
      "Epoch 180/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.4686e-04 - val_loss: 1.0604e-04\n",
      "Epoch 181/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.4252e-04 - val_loss: 1.1643e-04\n",
      "Epoch 182/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 2ms/step - loss: 3.3744e-04 - val_loss: 1.0152e-04\n",
      "Epoch 183/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.4669e-04 - val_loss: 1.3077e-04\n",
      "Epoch 184/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.4198e-04 - val_loss: 1.0012e-04\n",
      "Epoch 185/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.3860e-04 - val_loss: 1.0351e-04\n",
      "Epoch 186/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.3633e-04 - val_loss: 1.1057e-04\n",
      "Epoch 187/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.3485e-04 - val_loss: 1.2164e-04\n",
      "Epoch 188/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.3112e-04 - val_loss: 1.0625e-04\n",
      "Epoch 189/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.2872e-04 - val_loss: 9.3854e-05\n",
      "Epoch 190/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.2998e-04 - val_loss: 1.1083e-04\n",
      "Epoch 191/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.2480e-04 - val_loss: 8.7321e-05\n",
      "Epoch 192/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.4230e-04 - val_loss: 1.0446e-04\n",
      "Epoch 193/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.2440e-04 - val_loss: 1.0481e-04\n",
      "Epoch 194/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.3007e-04 - val_loss: 8.9429e-05\n",
      "Epoch 195/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.2716e-04 - val_loss: 1.0433e-04\n",
      "Epoch 196/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.1667e-04 - val_loss: 1.1865e-04\n",
      "Epoch 197/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.2213e-04 - val_loss: 1.0420e-04\n",
      "Epoch 198/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.2202e-04 - val_loss: 9.4505e-05\n",
      "Epoch 199/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.1735e-04 - val_loss: 1.0402e-04\n",
      "Epoch 200/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.1504e-04 - val_loss: 1.0384e-04\n",
      "Thời gian huấn luyện:  15.106115579605103\n",
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_80 (Dense)            (None, 10, 109)           218       \n",
      "                                                                 \n",
      " flatten_64 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,309\n",
      "Trainable params: 1,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "38/38 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 4.0694e-04\n",
      "Epoch 2/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 6.2188e-04\n",
      "Epoch 3/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.6386e-04 - val_loss: 4.8397e-04\n",
      "Epoch 4/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.9562e-04 - val_loss: 3.4404e-04\n",
      "Epoch 5/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.5170e-04 - val_loss: 2.8934e-04\n",
      "Epoch 6/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.3538e-04 - val_loss: 1.6106e-04\n",
      "Epoch 7/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.2814e-04 - val_loss: 1.4452e-04\n",
      "Epoch 8/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.7468e-04 - val_loss: 1.2233e-04\n",
      "Epoch 9/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.2921e-04 - val_loss: 8.2937e-05\n",
      "Epoch 10/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.1415e-04 - val_loss: 6.4427e-05\n",
      "Epoch 11/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.9240e-04 - val_loss: 5.4857e-05\n",
      "Epoch 12/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.1495e-04 - val_loss: 5.0569e-05\n",
      "Epoch 13/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.4133e-04 - val_loss: 4.3769e-05\n",
      "Epoch 14/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.3737e-04 - val_loss: 4.0797e-05\n",
      "Epoch 15/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.9782e-04 - val_loss: 3.8786e-05\n",
      "Epoch 16/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.7096e-04 - val_loss: 3.9432e-05\n",
      "Epoch 17/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.9754e-04 - val_loss: 3.7807e-05\n",
      "Epoch 18/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.3964e-04 - val_loss: 3.6946e-05\n",
      "Epoch 19/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.7395e-04 - val_loss: 3.4896e-05\n",
      "Epoch 20/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.6658e-04 - val_loss: 3.4144e-05\n",
      "Epoch 21/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.4656e-04 - val_loss: 3.4135e-05\n",
      "Epoch 22/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.3365e-04 - val_loss: 3.3090e-05\n",
      "Epoch 23/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.3484e-04 - val_loss: 3.4100e-05\n",
      "Epoch 24/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.1532e-04 - val_loss: 3.3192e-05\n",
      "Epoch 25/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.1696e-04 - val_loss: 3.1538e-05\n",
      "Epoch 26/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.2840e-04 - val_loss: 3.4998e-05\n",
      "Epoch 27/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.9641e-04 - val_loss: 2.9750e-05\n",
      "Epoch 28/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.8455e-04 - val_loss: 3.5689e-05\n",
      "Epoch 29/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.9772e-04 - val_loss: 2.9579e-05\n",
      "Epoch 30/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.9097e-04 - val_loss: 3.0259e-05\n",
      "Epoch 31/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.8051e-04 - val_loss: 2.8073e-05\n",
      "Epoch 32/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.9556e-04 - val_loss: 2.7026e-05\n",
      "Epoch 33/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.5168e-04 - val_loss: 2.8033e-05\n",
      "Epoch 34/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.9257e-04 - val_loss: 2.6551e-05\n",
      "Epoch 35/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.4013e-04 - val_loss: 2.6583e-05\n",
      "Epoch 36/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.5827e-04 - val_loss: 2.8787e-05\n",
      "Epoch 37/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.4169e-04 - val_loss: 2.5356e-05\n",
      "Epoch 38/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.2319e-04 - val_loss: 2.4913e-05\n",
      "Epoch 39/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.2350e-04 - val_loss: 2.5745e-05\n",
      "Epoch 40/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.4536e-04 - val_loss: 2.4666e-05\n",
      "Epoch 41/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.1508e-04 - val_loss: 2.3799e-05\n",
      "Epoch 42/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.2030e-04 - val_loss: 2.3246e-05\n",
      "Epoch 43/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.0059e-04 - val_loss: 2.4237e-05\n",
      "Epoch 44/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.0061e-04 - val_loss: 2.2833e-05\n",
      "Epoch 45/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.8247e-04 - val_loss: 2.3559e-05\n",
      "Epoch 46/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.9480e-04 - val_loss: 2.2105e-05\n",
      "Epoch 47/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.1392e-04 - val_loss: 2.2461e-05\n",
      "Epoch 48/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.1579e-04 - val_loss: 2.2816e-05\n",
      "Epoch 49/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.9161e-04 - val_loss: 2.1980e-05\n",
      "Epoch 50/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 4ms/step - loss: 3.6634e-04 - val_loss: 2.2115e-05\n",
      "Epoch 51/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.7403e-04 - val_loss: 2.1878e-05\n",
      "Epoch 52/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.8542e-04 - val_loss: 2.1452e-05\n",
      "Epoch 53/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.6752e-04 - val_loss: 2.1341e-05\n",
      "Epoch 54/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.7380e-04 - val_loss: 2.1018e-05\n",
      "Epoch 55/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.5083e-04 - val_loss: 2.0767e-05\n",
      "Epoch 56/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.6370e-04 - val_loss: 2.0972e-05\n",
      "Epoch 57/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.5076e-04 - val_loss: 2.1423e-05\n",
      "Epoch 58/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.4905e-04 - val_loss: 1.9942e-05\n",
      "Epoch 59/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.5252e-04 - val_loss: 2.1440e-05\n",
      "Epoch 60/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.4510e-04 - val_loss: 2.3942e-05\n",
      "Epoch 61/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.6897e-04 - val_loss: 2.5600e-05\n",
      "Epoch 62/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.5432e-04 - val_loss: 2.1937e-05\n",
      "Epoch 63/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.8365e-04 - val_loss: 2.1264e-05\n",
      "Epoch 64/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.3392e-04 - val_loss: 2.2108e-05\n",
      "Epoch 65/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.2848e-04 - val_loss: 2.5864e-05\n",
      "Epoch 66/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.7079e-04 - val_loss: 2.1323e-05\n",
      "Epoch 67/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.3988e-04 - val_loss: 2.1895e-05\n",
      "Epoch 68/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.2662e-04 - val_loss: 1.8291e-05\n",
      "Epoch 69/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.5005e-04 - val_loss: 1.9027e-05\n",
      "Epoch 70/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.2155e-04 - val_loss: 1.7881e-05\n",
      "Epoch 71/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.1994e-04 - val_loss: 2.1013e-05\n",
      "Epoch 72/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.8084e-04 - val_loss: 1.8242e-05\n",
      "Epoch 73/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.3268e-04 - val_loss: 2.1267e-05\n",
      "Epoch 74/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.3616e-04 - val_loss: 1.8093e-05\n",
      "Epoch 75/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.2151e-04 - val_loss: 2.4908e-05\n",
      "Epoch 76/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.1304e-04 - val_loss: 1.8288e-05\n",
      "Epoch 77/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.1652e-04 - val_loss: 2.0731e-05\n",
      "Epoch 78/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.0854e-04 - val_loss: 1.8806e-05\n",
      "Epoch 79/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.0930e-04 - val_loss: 2.3496e-05\n",
      "Epoch 80/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.0220e-04 - val_loss: 2.0869e-05\n",
      "Epoch 81/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.1490e-04 - val_loss: 1.9117e-05\n",
      "Epoch 82/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.1577e-04 - val_loss: 1.6993e-05\n",
      "Epoch 83/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.9091e-04 - val_loss: 1.9192e-05\n",
      "Epoch 84/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.8893e-04 - val_loss: 1.7418e-05\n",
      "Epoch 85/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.0424e-04 - val_loss: 1.7478e-05\n",
      "Epoch 86/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.8014e-04 - val_loss: 1.6341e-05\n",
      "Epoch 87/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.7317e-04 - val_loss: 1.5870e-05\n",
      "Epoch 88/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.9922e-04 - val_loss: 1.5913e-05\n",
      "Epoch 89/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.3083e-04 - val_loss: 2.0294e-05\n",
      "Epoch 90/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.0553e-04 - val_loss: 1.5939e-05\n",
      "Epoch 91/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.7880e-04 - val_loss: 1.8930e-05\n",
      "Epoch 92/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.9864e-04 - val_loss: 2.0170e-05\n",
      "Epoch 93/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.7828e-04 - val_loss: 1.5970e-05\n",
      "Epoch 94/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.7464e-04 - val_loss: 1.7271e-05\n",
      "Epoch 95/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.8411e-04 - val_loss: 1.9411e-05\n",
      "Epoch 96/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.6869e-04 - val_loss: 1.4763e-05\n",
      "Epoch 97/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.8944e-04 - val_loss: 1.8477e-05\n",
      "Epoch 98/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.6675e-04 - val_loss: 1.5728e-05\n",
      "Epoch 99/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.6975e-04 - val_loss: 1.5065e-05\n",
      "Epoch 100/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.7116e-04 - val_loss: 1.5414e-05\n",
      "Epoch 101/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.8509e-04 - val_loss: 1.5406e-05\n",
      "Epoch 102/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.6708e-04 - val_loss: 1.6824e-05\n",
      "Epoch 103/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.8436e-04 - val_loss: 1.5799e-05\n",
      "Epoch 104/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.1854e-04 - val_loss: 2.5521e-05\n",
      "Epoch 105/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.2336e-04 - val_loss: 1.5901e-05\n",
      "Epoch 106/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.8232e-04 - val_loss: 1.6191e-05\n",
      "Epoch 107/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.6593e-04 - val_loss: 1.5053e-05\n",
      "Epoch 108/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.7455e-04 - val_loss: 1.6899e-05\n",
      "Epoch 109/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.5140e-04 - val_loss: 1.4165e-05\n",
      "Epoch 110/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.4955e-04 - val_loss: 1.6593e-05\n",
      "Epoch 111/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.8384e-04 - val_loss: 1.5854e-05\n",
      "Epoch 112/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.6030e-04 - val_loss: 1.8268e-05\n",
      "Epoch 113/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.8542e-04 - val_loss: 1.3897e-05\n",
      "Epoch 114/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.8426e-04 - val_loss: 1.7604e-05\n",
      "Epoch 115/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.5847e-04 - val_loss: 2.0403e-05\n",
      "Epoch 116/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.7672e-04 - val_loss: 2.0068e-05\n",
      "Epoch 117/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.5684e-04 - val_loss: 1.5630e-05\n",
      "Epoch 118/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.4872e-04 - val_loss: 1.4082e-05\n",
      "Epoch 119/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.8736e-04 - val_loss: 1.4229e-05\n",
      "Epoch 120/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.5699e-04 - val_loss: 1.3833e-05\n",
      "Epoch 121/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.6013e-04 - val_loss: 1.5156e-05\n",
      "Epoch 122/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.6684e-04 - val_loss: 1.6727e-05\n",
      "Epoch 123/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.5337e-04 - val_loss: 1.7586e-05\n",
      "Epoch 124/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.6787e-04 - val_loss: 1.5292e-05\n",
      "Epoch 125/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 4ms/step - loss: 3.2712e-04 - val_loss: 1.7743e-05\n",
      "Epoch 126/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.6980e-04 - val_loss: 1.4601e-05\n",
      "Epoch 127/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.6937e-04 - val_loss: 1.7164e-05\n",
      "Epoch 128/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.4964e-04 - val_loss: 1.4388e-05\n",
      "Epoch 129/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.5903e-04 - val_loss: 1.7792e-05\n",
      "Epoch 130/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.5779e-04 - val_loss: 1.3526e-05\n",
      "Epoch 131/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.4399e-04 - val_loss: 1.3482e-05\n",
      "Epoch 132/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.4872e-04 - val_loss: 1.5884e-05\n",
      "Epoch 133/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2600e-04 - val_loss: 1.5416e-05\n",
      "Epoch 134/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.4928e-04 - val_loss: 2.1201e-05\n",
      "Epoch 135/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.8034e-04 - val_loss: 3.1451e-05\n",
      "Epoch 136/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.8834e-04 - val_loss: 1.4761e-05\n",
      "Epoch 137/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2974e-04 - val_loss: 1.2972e-05\n",
      "Epoch 138/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.7314e-04 - val_loss: 2.0441e-05\n",
      "Epoch 139/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.3763e-04 - val_loss: 1.2617e-05\n",
      "Epoch 140/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.3302e-04 - val_loss: 1.7813e-05\n",
      "Epoch 141/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2998e-04 - val_loss: 1.4576e-05\n",
      "Epoch 142/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.7351e-04 - val_loss: 1.2750e-05\n",
      "Epoch 143/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.4623e-04 - val_loss: 1.3714e-05\n",
      "Epoch 144/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.4957e-04 - val_loss: 2.0061e-05\n",
      "Epoch 145/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.6120e-04 - val_loss: 1.7676e-05\n",
      "Epoch 146/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2924e-04 - val_loss: 1.3741e-05\n",
      "Epoch 147/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.3725e-04 - val_loss: 1.4602e-05\n",
      "Epoch 148/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.3744e-04 - val_loss: 1.3089e-05\n",
      "Epoch 149/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.3069e-04 - val_loss: 1.5358e-05\n",
      "Epoch 150/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.3645e-04 - val_loss: 1.4142e-05\n",
      "Epoch 151/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.3476e-04 - val_loss: 1.2626e-05\n",
      "Epoch 152/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.1997e-04 - val_loss: 1.4511e-05\n",
      "Epoch 153/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.1900e-04 - val_loss: 1.4303e-05\n",
      "Epoch 154/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.8081e-04 - val_loss: 1.2681e-05\n",
      "Epoch 155/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.1442e-04 - val_loss: 1.5813e-05\n",
      "Epoch 156/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.6658e-04 - val_loss: 1.5650e-05\n",
      "Epoch 157/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.4512e-04 - val_loss: 1.5504e-05\n",
      "Epoch 158/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2495e-04 - val_loss: 1.3677e-05\n",
      "Epoch 159/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.1545e-04 - val_loss: 1.2210e-05\n",
      "Epoch 160/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2526e-04 - val_loss: 1.2032e-05\n",
      "Epoch 161/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2911e-04 - val_loss: 1.7424e-05\n",
      "Epoch 162/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2374e-04 - val_loss: 1.2496e-05\n",
      "Epoch 163/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2824e-04 - val_loss: 1.2498e-05\n",
      "Epoch 164/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2866e-04 - val_loss: 1.2365e-05\n",
      "Epoch 165/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2125e-04 - val_loss: 1.4305e-05\n",
      "Epoch 166/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.3823e-04 - val_loss: 1.3034e-05\n",
      "Epoch 167/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.1810e-04 - val_loss: 1.9761e-05\n",
      "Epoch 168/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2132e-04 - val_loss: 1.2407e-05\n",
      "Epoch 169/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0572e-04 - val_loss: 1.3294e-05\n",
      "Epoch 170/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2500e-04 - val_loss: 1.6010e-05\n",
      "Epoch 171/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2002e-04 - val_loss: 1.2661e-05\n",
      "Epoch 172/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.4961e-04 - val_loss: 1.3523e-05\n",
      "Epoch 173/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.1197e-04 - val_loss: 1.6723e-05\n",
      "Epoch 174/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0863e-04 - val_loss: 1.2296e-05\n",
      "Epoch 175/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0525e-04 - val_loss: 1.7326e-05\n",
      "Epoch 176/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2010e-04 - val_loss: 1.1729e-05\n",
      "Epoch 177/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0097e-04 - val_loss: 1.2302e-05\n",
      "Epoch 178/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.1947e-04 - val_loss: 1.4668e-05\n",
      "Epoch 179/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2587e-04 - val_loss: 1.5007e-05\n",
      "Epoch 180/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0656e-04 - val_loss: 1.2294e-05\n",
      "Epoch 181/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0820e-04 - val_loss: 1.2050e-05\n",
      "Epoch 182/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.1312e-04 - val_loss: 1.0981e-05\n",
      "Epoch 183/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2358e-04 - val_loss: 1.4724e-05\n",
      "Epoch 184/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0413e-04 - val_loss: 1.1362e-05\n",
      "Epoch 185/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.9668e-04 - val_loss: 1.2952e-05\n",
      "Epoch 186/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2137e-04 - val_loss: 1.1149e-05\n",
      "Epoch 187/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.1669e-04 - val_loss: 1.3750e-05\n",
      "Epoch 188/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.9997e-04 - val_loss: 1.2697e-05\n",
      "Epoch 189/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.1312e-04 - val_loss: 1.1420e-05\n",
      "Epoch 190/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0421e-04 - val_loss: 1.0768e-05\n",
      "Epoch 191/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0493e-04 - val_loss: 1.1957e-05\n",
      "Epoch 192/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.1047e-04 - val_loss: 1.2424e-05\n",
      "Epoch 193/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.4652e-04 - val_loss: 1.3668e-05\n",
      "Epoch 194/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.9953e-04 - val_loss: 1.7076e-05\n",
      "Epoch 195/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0154e-04 - val_loss: 1.0869e-05\n",
      "Epoch 196/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.1614e-04 - val_loss: 1.7289e-05\n",
      "Epoch 197/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.9293e-04 - val_loss: 1.3519e-05\n",
      "Epoch 198/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0811e-04 - val_loss: 1.8926e-05\n",
      "Epoch 199/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0982e-04 - val_loss: 1.0966e-05\n",
      "Epoch 200/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 4ms/step - loss: 2.1662e-04 - val_loss: 1.5989e-05\n",
      "Thời gian huấn luyện:  29.4842746257782\n",
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_16 (SimpleRNN)   (None, 10, 109)           12099     \n",
      "                                                                 \n",
      " flatten_65 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,190\n",
      "Trainable params: 13,190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "38/38 [==============================] - 2s 18ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 2/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 3/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 4/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 5/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 6/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 7/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 8/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 9/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 10/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 11/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 12/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 13/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 14/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 15/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 16/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 17/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 18/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 19/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 20/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 21/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 22/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 23/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 24/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 25/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 26/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 27/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 28/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 29/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 30/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 31/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 32/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 33/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 34/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 35/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 36/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 37/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 38/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 39/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 40/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 41/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 42/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 43/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 44/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 45/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 46/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 47/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 48/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 49/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 50/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 51/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 52/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 53/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 54/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 55/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 56/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 57/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 58/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 59/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 60/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 61/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 62/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 63/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 64/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 65/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 66/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 67/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 68/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 69/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 70/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 71/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 72/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 74/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 75/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 76/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 77/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 78/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 79/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 80/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 81/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 82/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 83/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 84/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 85/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 86/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 87/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 88/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 89/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 90/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 91/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 92/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 93/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 94/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 95/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 96/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 97/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 98/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 99/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 100/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 101/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 102/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 103/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 104/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 105/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 106/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 107/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 108/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 109/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 110/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 111/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 112/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 113/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 114/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 115/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 116/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 117/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 118/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 119/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 120/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 121/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 122/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 123/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 124/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 125/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 126/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 127/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 128/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 129/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 130/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 131/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 132/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 133/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 134/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 135/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 136/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 137/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 138/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 139/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 140/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 141/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 142/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 143/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 144/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 145/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 146/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 147/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 148/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 149/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 150/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 151/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 152/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 153/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 155/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 156/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 157/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 158/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 159/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 160/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 161/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 162/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 163/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 164/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 165/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 166/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 167/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 168/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 169/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 170/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 171/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 172/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 173/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 174/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 175/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 176/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 177/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 178/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 179/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 180/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 181/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 182/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 183/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 184/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 185/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 186/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 187/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 188/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 189/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 190/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 191/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 192/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 193/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 194/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 195/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 196/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 197/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 198/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 199/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Epoch 200/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2135 - val_loss: 0.0016\n",
      "Thời gian huấn luyện:  70.893563747406\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_16 (LSTM)              (None, 10, 109)           48396     \n",
      "                                                                 \n",
      " flatten_66 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,487\n",
      "Trainable params: 49,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "38/38 [==============================] - 2s 16ms/step - loss: 0.0305 - val_loss: 7.3954e-04\n",
      "Epoch 2/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 1.9700e-04\n",
      "Epoch 3/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.6044e-04 - val_loss: 4.4648e-05\n",
      "Epoch 4/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.5168e-04 - val_loss: 4.5021e-05\n",
      "Epoch 5/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.3916e-04 - val_loss: 4.6161e-05\n",
      "Epoch 6/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.5083e-04 - val_loss: 4.7501e-05\n",
      "Epoch 7/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.3683e-04 - val_loss: 4.7761e-05\n",
      "Epoch 8/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.3632e-04 - val_loss: 4.3817e-05\n",
      "Epoch 9/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.3181e-04 - val_loss: 4.4169e-05\n",
      "Epoch 10/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.2348e-04 - val_loss: 4.5032e-05\n",
      "Epoch 11/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.2479e-04 - val_loss: 4.4652e-05\n",
      "Epoch 12/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.1990e-04 - val_loss: 4.3280e-05\n",
      "Epoch 13/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.2396e-04 - val_loss: 4.7210e-05\n",
      "Epoch 14/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.1346e-04 - val_loss: 4.4741e-05\n",
      "Epoch 15/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.1589e-04 - val_loss: 4.4431e-05\n",
      "Epoch 16/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.0901e-04 - val_loss: 4.7310e-05\n",
      "Epoch 17/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.0972e-04 - val_loss: 4.5544e-05\n",
      "Epoch 18/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.1901e-04 - val_loss: 4.4245e-05\n",
      "Epoch 19/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.1199e-04 - val_loss: 4.3007e-05\n",
      "Epoch 20/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.0545e-04 - val_loss: 4.3239e-05\n",
      "Epoch 21/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.9585e-04 - val_loss: 4.1452e-05\n",
      "Epoch 22/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.9901e-04 - val_loss: 5.0897e-05\n",
      "Epoch 23/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.0974e-04 - val_loss: 4.2015e-05\n",
      "Epoch 24/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.9693e-04 - val_loss: 4.2371e-05\n",
      "Epoch 25/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 8ms/step - loss: 5.8940e-04 - val_loss: 4.4449e-05\n",
      "Epoch 26/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.8130e-04 - val_loss: 4.9715e-05\n",
      "Epoch 27/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.7839e-04 - val_loss: 4.0925e-05\n",
      "Epoch 28/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.7605e-04 - val_loss: 4.0359e-05\n",
      "Epoch 29/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.7692e-04 - val_loss: 5.4227e-05\n",
      "Epoch 30/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.7642e-04 - val_loss: 4.6902e-05\n",
      "Epoch 31/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.7354e-04 - val_loss: 4.1211e-05\n",
      "Epoch 32/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.6930e-04 - val_loss: 4.0958e-05\n",
      "Epoch 33/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.6929e-04 - val_loss: 4.0612e-05\n",
      "Epoch 34/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.7561e-04 - val_loss: 5.0390e-05\n",
      "Epoch 35/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.5735e-04 - val_loss: 3.8672e-05\n",
      "Epoch 36/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.6354e-04 - val_loss: 4.9708e-05\n",
      "Epoch 37/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.4967e-04 - val_loss: 3.9229e-05\n",
      "Epoch 38/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.5343e-04 - val_loss: 3.8770e-05\n",
      "Epoch 39/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.5371e-04 - val_loss: 5.0924e-05\n",
      "Epoch 40/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.5921e-04 - val_loss: 3.8013e-05\n",
      "Epoch 41/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.3731e-04 - val_loss: 4.4721e-05\n",
      "Epoch 42/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.5679e-04 - val_loss: 3.7847e-05\n",
      "Epoch 43/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.5099e-04 - val_loss: 3.7978e-05\n",
      "Epoch 44/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.4059e-04 - val_loss: 3.8672e-05\n",
      "Epoch 45/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.3027e-04 - val_loss: 3.6885e-05\n",
      "Epoch 46/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.2852e-04 - val_loss: 4.3955e-05\n",
      "Epoch 47/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.3205e-04 - val_loss: 3.6373e-05\n",
      "Epoch 48/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.2972e-04 - val_loss: 3.6109e-05\n",
      "Epoch 49/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.1331e-04 - val_loss: 4.1244e-05\n",
      "Epoch 50/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.1453e-04 - val_loss: 3.9513e-05\n",
      "Epoch 51/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.1490e-04 - val_loss: 3.6357e-05\n",
      "Epoch 52/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.1648e-04 - val_loss: 3.5720e-05\n",
      "Epoch 53/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.0634e-04 - val_loss: 3.5378e-05\n",
      "Epoch 54/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.0834e-04 - val_loss: 3.9936e-05\n",
      "Epoch 55/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.0137e-04 - val_loss: 3.4499e-05\n",
      "Epoch 56/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.1009e-04 - val_loss: 3.5668e-05\n",
      "Epoch 57/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.9358e-04 - val_loss: 3.4270e-05\n",
      "Epoch 58/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.9204e-04 - val_loss: 3.7541e-05\n",
      "Epoch 59/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.9683e-04 - val_loss: 5.3075e-05\n",
      "Epoch 60/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 5.0260e-04 - val_loss: 3.3784e-05\n",
      "Epoch 61/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.9761e-04 - val_loss: 3.3396e-05\n",
      "Epoch 62/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.8314e-04 - val_loss: 3.9146e-05\n",
      "Epoch 63/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.8505e-04 - val_loss: 5.3300e-05\n",
      "Epoch 64/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.7181e-04 - val_loss: 3.7089e-05\n",
      "Epoch 65/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.6619e-04 - val_loss: 3.2833e-05\n",
      "Epoch 66/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.6593e-04 - val_loss: 5.0181e-05\n",
      "Epoch 67/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.6845e-04 - val_loss: 3.3017e-05\n",
      "Epoch 68/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.6238e-04 - val_loss: 4.3235e-05\n",
      "Epoch 69/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.6111e-04 - val_loss: 3.5243e-05\n",
      "Epoch 70/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.6123e-04 - val_loss: 3.2823e-05\n",
      "Epoch 71/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.4969e-04 - val_loss: 3.0718e-05\n",
      "Epoch 72/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.4701e-04 - val_loss: 4.5209e-05\n",
      "Epoch 73/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.4366e-04 - val_loss: 4.0828e-05\n",
      "Epoch 74/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.5662e-04 - val_loss: 3.6227e-05\n",
      "Epoch 75/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.4096e-04 - val_loss: 3.5198e-05\n",
      "Epoch 76/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.3672e-04 - val_loss: 3.2416e-05\n",
      "Epoch 77/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.3409e-04 - val_loss: 2.9717e-05\n",
      "Epoch 78/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.4081e-04 - val_loss: 4.0996e-05\n",
      "Epoch 79/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.3288e-04 - val_loss: 3.6426e-05\n",
      "Epoch 80/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.2773e-04 - val_loss: 3.3599e-05\n",
      "Epoch 81/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.2129e-04 - val_loss: 3.1971e-05\n",
      "Epoch 82/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.1763e-04 - val_loss: 2.9053e-05\n",
      "Epoch 83/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.1366e-04 - val_loss: 5.0915e-05\n",
      "Epoch 84/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.1998e-04 - val_loss: 3.7693e-05\n",
      "Epoch 85/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.1662e-04 - val_loss: 3.1971e-05\n",
      "Epoch 86/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.1593e-04 - val_loss: 2.8511e-05\n",
      "Epoch 87/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.0960e-04 - val_loss: 4.9411e-05\n",
      "Epoch 88/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.0534e-04 - val_loss: 3.2517e-05\n",
      "Epoch 89/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.0212e-04 - val_loss: 3.2210e-05\n",
      "Epoch 90/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.0431e-04 - val_loss: 2.7587e-05\n",
      "Epoch 91/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.9784e-04 - val_loss: 3.3394e-05\n",
      "Epoch 92/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.0295e-04 - val_loss: 2.7153e-05\n",
      "Epoch 93/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.9118e-04 - val_loss: 3.7945e-05\n",
      "Epoch 94/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.9912e-04 - val_loss: 2.9451e-05\n",
      "Epoch 95/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.1686e-04 - val_loss: 2.8513e-05\n",
      "Epoch 96/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.8271e-04 - val_loss: 2.7701e-05\n",
      "Epoch 97/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.8772e-04 - val_loss: 3.9581e-05\n",
      "Epoch 98/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.8105e-04 - val_loss: 3.5995e-05\n",
      "Epoch 99/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.8194e-04 - val_loss: 4.0211e-05\n",
      "Epoch 100/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.7747e-04 - val_loss: 3.2990e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.9224e-04 - val_loss: 3.2307e-05\n",
      "Epoch 102/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.7364e-04 - val_loss: 2.5258e-05\n",
      "Epoch 103/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.6974e-04 - val_loss: 2.8471e-05\n",
      "Epoch 104/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.7830e-04 - val_loss: 2.5281e-05\n",
      "Epoch 105/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.7304e-04 - val_loss: 2.6129e-05\n",
      "Epoch 106/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.6403e-04 - val_loss: 4.5247e-05\n",
      "Epoch 107/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.7153e-04 - val_loss: 5.7336e-05\n",
      "Epoch 108/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.7206e-04 - val_loss: 3.1673e-05\n",
      "Epoch 109/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.5740e-04 - val_loss: 2.8082e-05\n",
      "Epoch 110/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.6493e-04 - val_loss: 2.7494e-05\n",
      "Epoch 111/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.5704e-04 - val_loss: 2.6193e-05\n",
      "Epoch 112/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.6560e-04 - val_loss: 5.8438e-05\n",
      "Epoch 113/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.5788e-04 - val_loss: 2.6205e-05\n",
      "Epoch 114/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.6812e-04 - val_loss: 4.2567e-05\n",
      "Epoch 115/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.4952e-04 - val_loss: 2.7095e-05\n",
      "Epoch 116/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.6541e-04 - val_loss: 2.8778e-05\n",
      "Epoch 117/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.4799e-04 - val_loss: 3.6083e-05\n",
      "Epoch 118/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.3961e-04 - val_loss: 5.9132e-05\n",
      "Epoch 119/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.3927e-04 - val_loss: 3.5195e-05\n",
      "Epoch 120/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.4129e-04 - val_loss: 2.8995e-05\n",
      "Epoch 121/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.3923e-04 - val_loss: 3.6998e-05\n",
      "Epoch 122/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.3882e-04 - val_loss: 2.4564e-05\n",
      "Epoch 123/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.4136e-04 - val_loss: 5.7426e-05\n",
      "Epoch 124/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.5091e-04 - val_loss: 3.1033e-05\n",
      "Epoch 125/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.3271e-04 - val_loss: 2.9615e-05\n",
      "Epoch 126/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.3398e-04 - val_loss: 2.7307e-05\n",
      "Epoch 127/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.4312e-04 - val_loss: 3.2218e-05\n",
      "Epoch 128/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.3086e-04 - val_loss: 3.2538e-05\n",
      "Epoch 129/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.2574e-04 - val_loss: 3.8310e-05\n",
      "Epoch 130/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.2298e-04 - val_loss: 4.3914e-05\n",
      "Epoch 131/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.2275e-04 - val_loss: 2.6250e-05\n",
      "Epoch 132/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.3312e-04 - val_loss: 2.8800e-05\n",
      "Epoch 133/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.1854e-04 - val_loss: 2.7485e-05\n",
      "Epoch 134/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.2379e-04 - val_loss: 2.7290e-05\n",
      "Epoch 135/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.2083e-04 - val_loss: 2.3764e-05\n",
      "Epoch 136/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.0875e-04 - val_loss: 3.0203e-05\n",
      "Epoch 137/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.2007e-04 - val_loss: 3.2720e-05\n",
      "Epoch 138/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.0565e-04 - val_loss: 2.1807e-05\n",
      "Epoch 139/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.1531e-04 - val_loss: 2.2817e-05\n",
      "Epoch 140/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.0704e-04 - val_loss: 5.1498e-05\n",
      "Epoch 141/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.3112e-04 - val_loss: 2.2951e-05\n",
      "Epoch 142/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.1477e-04 - val_loss: 2.9803e-05\n",
      "Epoch 143/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.0387e-04 - val_loss: 2.3813e-05\n",
      "Epoch 144/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.0007e-04 - val_loss: 2.3496e-05\n",
      "Epoch 145/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.0971e-04 - val_loss: 2.4981e-05\n",
      "Epoch 146/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.9991e-04 - val_loss: 2.2578e-05\n",
      "Epoch 147/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.0045e-04 - val_loss: 3.2677e-05\n",
      "Epoch 148/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.0377e-04 - val_loss: 3.1230e-05\n",
      "Epoch 149/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.9848e-04 - val_loss: 2.9622e-05\n",
      "Epoch 150/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.9849e-04 - val_loss: 3.1533e-05\n",
      "Epoch 151/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.9033e-04 - val_loss: 2.2421e-05\n",
      "Epoch 152/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.9137e-04 - val_loss: 1.9365e-05\n",
      "Epoch 153/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.9389e-04 - val_loss: 1.9426e-05\n",
      "Epoch 154/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.8470e-04 - val_loss: 2.2742e-05\n",
      "Epoch 155/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.8807e-04 - val_loss: 3.8167e-05\n",
      "Epoch 156/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.8761e-04 - val_loss: 2.3935e-05\n",
      "Epoch 157/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 2.9272e-04 - val_loss: 3.1017e-05\n",
      "Epoch 158/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.9871e-04 - val_loss: 2.4154e-05\n",
      "Epoch 159/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.7950e-04 - val_loss: 2.1811e-05\n",
      "Epoch 160/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.8012e-04 - val_loss: 3.4852e-05\n",
      "Epoch 161/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.9793e-04 - val_loss: 2.4834e-05\n",
      "Epoch 162/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.7741e-04 - val_loss: 2.5176e-05\n",
      "Epoch 163/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.9422e-04 - val_loss: 2.0184e-05\n",
      "Epoch 164/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.3458e-04 - val_loss: 4.2129e-05\n",
      "Epoch 165/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.7767e-04 - val_loss: 2.1143e-05\n",
      "Epoch 166/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.9258e-04 - val_loss: 2.3333e-05\n",
      "Epoch 167/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.7342e-04 - val_loss: 2.7663e-05\n",
      "Epoch 168/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.7091e-04 - val_loss: 2.8703e-05\n",
      "Epoch 169/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.6885e-04 - val_loss: 3.5911e-05\n",
      "Epoch 170/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.7719e-04 - val_loss: 2.1015e-05\n",
      "Epoch 171/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.7507e-04 - val_loss: 2.3595e-05\n",
      "Epoch 172/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.6383e-04 - val_loss: 2.2122e-05\n",
      "Epoch 173/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.6179e-04 - val_loss: 2.0234e-05\n",
      "Epoch 174/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.6770e-04 - val_loss: 4.5237e-05\n",
      "Epoch 175/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.7722e-04 - val_loss: 1.7753e-05\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 8ms/step - loss: 2.6774e-04 - val_loss: 1.7547e-05\n",
      "Epoch 177/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.6623e-04 - val_loss: 1.7685e-05\n",
      "Epoch 178/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.6522e-04 - val_loss: 1.7166e-05\n",
      "Epoch 179/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.6928e-04 - val_loss: 1.7908e-05\n",
      "Epoch 180/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.9335e-04 - val_loss: 2.5632e-05\n",
      "Epoch 181/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.5342e-04 - val_loss: 1.9512e-05\n",
      "Epoch 182/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.5811e-04 - val_loss: 3.3635e-05\n",
      "Epoch 183/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.8625e-04 - val_loss: 2.2851e-05\n",
      "Epoch 184/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.6269e-04 - val_loss: 3.4464e-05\n",
      "Epoch 185/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.8202e-04 - val_loss: 2.7591e-05\n",
      "Epoch 186/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.5623e-04 - val_loss: 1.6675e-05\n",
      "Epoch 187/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.4782e-04 - val_loss: 2.3595e-05\n",
      "Epoch 188/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.5043e-04 - val_loss: 1.7397e-05\n",
      "Epoch 189/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.5334e-04 - val_loss: 2.4326e-05\n",
      "Epoch 190/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.4601e-04 - val_loss: 2.4682e-05\n",
      "Epoch 191/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.4911e-04 - val_loss: 1.6345e-05\n",
      "Epoch 192/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.5519e-04 - val_loss: 1.9326e-05\n",
      "Epoch 193/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.4569e-04 - val_loss: 1.9508e-05\n",
      "Epoch 194/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.5190e-04 - val_loss: 2.3885e-05\n",
      "Epoch 195/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.3958e-04 - val_loss: 2.0444e-05\n",
      "Epoch 196/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.4243e-04 - val_loss: 1.8025e-05\n",
      "Epoch 197/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.4861e-04 - val_loss: 2.3171e-05\n",
      "Epoch 198/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.6074e-04 - val_loss: 1.8975e-05\n",
      "Epoch 199/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.5058e-04 - val_loss: 2.5954e-05\n",
      "Epoch 200/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.4113e-04 - val_loss: 1.8584e-05\n",
      "Thời gian huấn luyện:  64.07656526565552\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_16 (GRU)                (None, 10, 109)           36624     \n",
      "                                                                 \n",
      " flatten_67 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,715\n",
      "Trainable params: 37,715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "45/45 [==============================] - 0s 886us/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "45/45 [==============================] - 1s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "45/45 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "45/45 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1026 - val_loss: 0.0293\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0344\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0245\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0176\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0130\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0089\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0062\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 9.8822e-04 - val_loss: 0.0033\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 7.9743e-04 - val_loss: 0.0026\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.9857e-04 - val_loss: 0.0022\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.4970e-04 - val_loss: 0.0018\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.2762e-04 - val_loss: 0.0016\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.1474e-04 - val_loss: 0.0016\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.0988e-04 - val_loss: 0.0013\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.0823e-04 - val_loss: 0.0014\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.0242e-04 - val_loss: 0.0012\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.0422e-04 - val_loss: 0.0013\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.0248e-04 - val_loss: 0.0012\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.9957e-04 - val_loss: 0.0011\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.0114e-04 - val_loss: 0.0011\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.9868e-04 - val_loss: 0.0011\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.0005e-04 - val_loss: 0.0011\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.9855e-04 - val_loss: 0.0012\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.0259e-04 - val_loss: 0.0011\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.9984e-04 - val_loss: 0.0011\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.9178e-04 - val_loss: 9.8092e-04\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.9702e-04 - val_loss: 0.0010\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.9232e-04 - val_loss: 0.0010\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.8903e-04 - val_loss: 0.0010\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.8538e-04 - val_loss: 0.0010\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.8541e-04 - val_loss: 0.0010\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.8742e-04 - val_loss: 0.0011\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.8902e-04 - val_loss: 0.0010\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.8620e-04 - val_loss: 9.8115e-04\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.7954e-04 - val_loss: 9.6302e-04\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.8186e-04 - val_loss: 9.9557e-04\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.7962e-04 - val_loss: 0.0010\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.7777e-04 - val_loss: 8.9847e-04\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.8262e-04 - val_loss: 9.6811e-04\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step - loss: 5.7818e-04 - val_loss: 9.2576e-04\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.7495e-04 - val_loss: 9.4789e-04\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.7435e-04 - val_loss: 9.8877e-04\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.7045e-04 - val_loss: 0.0010\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.8711e-04 - val_loss: 9.9410e-04\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.7102e-04 - val_loss: 9.6006e-04\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.7263e-04 - val_loss: 9.1455e-04\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6450e-04 - val_loss: 9.7533e-04\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6535e-04 - val_loss: 9.4366e-04\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6383e-04 - val_loss: 9.4310e-04\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6165e-04 - val_loss: 9.8192e-04\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.6611e-04 - val_loss: 9.6209e-04\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.5987e-04 - val_loss: 9.4081e-04\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.5711e-04 - val_loss: 8.7430e-04\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.5737e-04 - val_loss: 9.1956e-04\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.5252e-04 - val_loss: 9.7464e-04\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.5632e-04 - val_loss: 9.4975e-04\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.5296e-04 - val_loss: 9.3340e-04\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.5456e-04 - val_loss: 9.6689e-04\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.5051e-04 - val_loss: 9.1603e-04\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4896e-04 - val_loss: 8.6667e-04\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4507e-04 - val_loss: 9.5414e-04\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4487e-04 - val_loss: 9.1373e-04\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4145e-04 - val_loss: 9.0598e-04\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4110e-04 - val_loss: 8.5154e-04\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4062e-04 - val_loss: 9.1323e-04\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3970e-04 - val_loss: 8.9144e-04\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3551e-04 - val_loss: 9.3114e-04\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4705e-04 - val_loss: 8.7443e-04\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3275e-04 - val_loss: 8.6729e-04\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3303e-04 - val_loss: 8.4501e-04\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.4594e-04 - val_loss: 8.3654e-04\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2985e-04 - val_loss: 8.7919e-04\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2705e-04 - val_loss: 7.6418e-04\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.3548e-04 - val_loss: 8.4206e-04\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2413e-04 - val_loss: 8.3420e-04\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2063e-04 - val_loss: 9.0602e-04\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.2236e-04 - val_loss: 8.9975e-04\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.1922e-04 - val_loss: 8.5292e-04\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.1606e-04 - val_loss: 8.5232e-04\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.1464e-04 - val_loss: 8.4849e-04\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.1306e-04 - val_loss: 9.2298e-04\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.1298e-04 - val_loss: 8.8214e-04\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0962e-04 - val_loss: 8.3004e-04\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0609e-04 - val_loss: 8.1122e-04\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.1120e-04 - val_loss: 8.3536e-04\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0522e-04 - val_loss: 8.1910e-04\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0491e-04 - val_loss: 7.5996e-04\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0151e-04 - val_loss: 9.0958e-04\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.0277e-04 - val_loss: 7.6815e-04\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9798e-04 - val_loss: 7.8726e-04\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9914e-04 - val_loss: 9.3809e-04\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9492e-04 - val_loss: 9.1915e-04\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9324e-04 - val_loss: 8.1872e-04\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9108e-04 - val_loss: 8.1073e-04\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.9439e-04 - val_loss: 8.9047e-04\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.8795e-04 - val_loss: 8.1273e-04\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.8871e-04 - val_loss: 8.8305e-04\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.8577e-04 - val_loss: 8.4939e-04\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.7850e-04 - val_loss: 8.4259e-04\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.7991e-04 - val_loss: 8.2948e-04\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.8091e-04 - val_loss: 9.3916e-04\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.7752e-04 - val_loss: 8.6517e-04\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.7271e-04 - val_loss: 8.5849e-04\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.7483e-04 - val_loss: 8.1451e-04\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.6743e-04 - val_loss: 8.4204e-04\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.6685e-04 - val_loss: 8.5600e-04\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.7538e-04 - val_loss: 7.9030e-04\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.6974e-04 - val_loss: 8.6049e-04\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.6100e-04 - val_loss: 8.8024e-04\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.6281e-04 - val_loss: 8.0176e-04\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.5834e-04 - val_loss: 8.8515e-04\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.5547e-04 - val_loss: 8.3817e-04\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.6277e-04 - val_loss: 8.6657e-04\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.5261e-04 - val_loss: 8.2168e-04\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.5027e-04 - val_loss: 8.0620e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.4716e-04 - val_loss: 8.3514e-04\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.4582e-04 - val_loss: 8.2813e-04\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.4387e-04 - val_loss: 8.1111e-04\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.4248e-04 - val_loss: 8.0173e-04\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.6790e-04 - val_loss: 8.2191e-04\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.3639e-04 - val_loss: 7.1602e-04\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.4350e-04 - val_loss: 7.5760e-04\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.4012e-04 - val_loss: 7.3987e-04\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.3653e-04 - val_loss: 7.8943e-04\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.2890e-04 - val_loss: 7.2738e-04\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.3135e-04 - val_loss: 8.2808e-04\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.3347e-04 - val_loss: 7.8592e-04\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.2844e-04 - val_loss: 7.2357e-04\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.2918e-04 - val_loss: 8.7148e-04\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.2370e-04 - val_loss: 8.0547e-04\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.2194e-04 - val_loss: 7.3697e-04\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1411e-04 - val_loss: 7.9148e-04\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1555e-04 - val_loss: 7.3654e-04\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1778e-04 - val_loss: 7.0477e-04\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1460e-04 - val_loss: 7.4836e-04\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1258e-04 - val_loss: 7.8647e-04\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.1397e-04 - val_loss: 7.7282e-04\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0740e-04 - val_loss: 7.9473e-04\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0565e-04 - val_loss: 8.3264e-04\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0354e-04 - val_loss: 7.8125e-04\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0115e-04 - val_loss: 7.5638e-04\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.9744e-04 - val_loss: 7.2710e-04\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.9809e-04 - val_loss: 7.6593e-04\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.9795e-04 - val_loss: 7.2593e-04\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.9441e-04 - val_loss: 7.7490e-04\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0351e-04 - val_loss: 8.3666e-04\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.9314e-04 - val_loss: 7.2892e-04\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.8718e-04 - val_loss: 7.0360e-04\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.9483e-04 - val_loss: 6.8846e-04\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.8581e-04 - val_loss: 7.3982e-04\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.8855e-04 - val_loss: 6.9424e-04\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.9204e-04 - val_loss: 7.8135e-04\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.8522e-04 - val_loss: 7.1011e-04\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.8014e-04 - val_loss: 7.1829e-04\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.7718e-04 - val_loss: 6.8598e-04\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.7396e-04 - val_loss: 7.1684e-04\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.7556e-04 - val_loss: 7.2068e-04\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.7098e-04 - val_loss: 7.1751e-04\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.7259e-04 - val_loss: 6.9684e-04\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.7068e-04 - val_loss: 7.5552e-04\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.6828e-04 - val_loss: 7.3416e-04\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.6896e-04 - val_loss: 6.7598e-04\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.6724e-04 - val_loss: 6.7901e-04\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.6253e-04 - val_loss: 7.4639e-04\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.6785e-04 - val_loss: 6.7353e-04\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.6520e-04 - val_loss: 6.0185e-04\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.6485e-04 - val_loss: 7.2789e-04\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.5782e-04 - val_loss: 5.6471e-04\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.6868e-04 - val_loss: 7.1177e-04\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.6002e-04 - val_loss: 6.8186e-04\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.5082e-04 - val_loss: 6.0895e-04\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.5042e-04 - val_loss: 6.3547e-04\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.5174e-04 - val_loss: 6.9523e-04\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.4691e-04 - val_loss: 7.1195e-04\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.5157e-04 - val_loss: 6.4409e-04\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.4576e-04 - val_loss: 7.0430e-04\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.4322e-04 - val_loss: 7.1509e-04\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.4189e-04 - val_loss: 6.4507e-04\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.4064e-04 - val_loss: 6.7115e-04\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.4990e-04 - val_loss: 7.1452e-04\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.3694e-04 - val_loss: 7.1294e-04\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.3737e-04 - val_loss: 6.8929e-04\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.3471e-04 - val_loss: 6.3962e-04\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.3337e-04 - val_loss: 6.6408e-04\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.3250e-04 - val_loss: 6.6984e-04\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.2991e-04 - val_loss: 6.7095e-04\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.2996e-04 - val_loss: 6.5681e-04\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.2860e-04 - val_loss: 6.1486e-04\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.2737e-04 - val_loss: 6.3630e-04\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.2528e-04 - val_loss: 6.6507e-04\n",
      "Epoch 192/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step - loss: 3.2821e-04 - val_loss: 6.8150e-04\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.2424e-04 - val_loss: 6.4524e-04\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.2100e-04 - val_loss: 6.2763e-04\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.2386e-04 - val_loss: 6.3373e-04\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.2264e-04 - val_loss: 5.8004e-04\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.1726e-04 - val_loss: 5.4784e-04\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.2799e-04 - val_loss: 6.1394e-04\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.2096e-04 - val_loss: 7.1606e-04\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.1700e-04 - val_loss: 5.7702e-04\n",
      "Thời gian huấn luyện:  15.131914854049683\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_85 (Dense)            (None, 10, 109)           218       \n",
      "                                                                 \n",
      " flatten_68 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,309\n",
      "Trainable params: 1,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 1s 8ms/step - loss: 0.0185 - val_loss: 5.2282e-04\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 8.4083e-04\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 7.3282e-04\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 7.5973e-04\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.8672e-04 - val_loss: 6.3304e-04\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.0751e-04 - val_loss: 5.7874e-04\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.5933e-04 - val_loss: 4.4878e-04\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.6938e-04 - val_loss: 4.0930e-04\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.9531e-04 - val_loss: 3.2778e-04\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.2899e-04 - val_loss: 2.6052e-04\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.5093e-04 - val_loss: 2.6503e-04\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.1358e-04 - val_loss: 2.3688e-04\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.1903e-04 - val_loss: 2.3316e-04\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.3823e-04 - val_loss: 1.6836e-04\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.6052e-04 - val_loss: 1.6396e-04\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.5868e-04 - val_loss: 1.1687e-04\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.5143e-04 - val_loss: 1.0386e-04\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.3429e-04 - val_loss: 8.7276e-05\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.1972e-04 - val_loss: 1.0632e-04\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.1370e-04 - val_loss: 6.7604e-05\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.1207e-04 - val_loss: 6.9885e-05\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.9913e-04 - val_loss: 6.1826e-05\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.7839e-04 - val_loss: 5.7146e-05\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.7351e-04 - val_loss: 5.0468e-05\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.7262e-04 - val_loss: 4.7723e-05\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.5704e-04 - val_loss: 4.9937e-05\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.7216e-04 - val_loss: 4.3922e-05\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.6439e-04 - val_loss: 4.3295e-05\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.3975e-04 - val_loss: 4.4484e-05\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.5884e-04 - val_loss: 4.0341e-05\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.3202e-04 - val_loss: 4.1617e-05\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.2132e-04 - val_loss: 3.8017e-05\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.3352e-04 - val_loss: 3.9033e-05\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.2154e-04 - val_loss: 4.0638e-05\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.2905e-04 - val_loss: 3.8905e-05\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.1081e-04 - val_loss: 3.9359e-05\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.2291e-04 - val_loss: 4.6887e-05\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.5600e-04 - val_loss: 3.9320e-05\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.0958e-04 - val_loss: 4.0948e-05\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.2531e-04 - val_loss: 3.5033e-05\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.7288e-04 - val_loss: 3.7479e-05\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.5116e-04 - val_loss: 3.4441e-05\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8903e-04 - val_loss: 3.3402e-05\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8151e-04 - val_loss: 3.7423e-05\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8947e-04 - val_loss: 3.9951e-05\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.4985e-04 - val_loss: 3.3112e-05\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6771e-04 - val_loss: 3.6206e-05\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.7681e-04 - val_loss: 3.4395e-05\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.5943e-04 - val_loss: 3.1754e-05\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.7569e-04 - val_loss: 3.1072e-05\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.4275e-04 - val_loss: 3.1443e-05\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.5397e-04 - val_loss: 3.9729e-05\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2771e-04 - val_loss: 3.2029e-05\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8494e-04 - val_loss: 3.4629e-05\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.6969e-04 - val_loss: 4.1118e-05\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.8578e-04 - val_loss: 3.3840e-05\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.1743e-04 - val_loss: 3.0055e-05\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2560e-04 - val_loss: 3.0014e-05\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.5850e-04 - val_loss: 3.1023e-05\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2306e-04 - val_loss: 3.1433e-05\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.0456e-04 - val_loss: 3.2096e-05\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.0816e-04 - val_loss: 3.1305e-05\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.1381e-04 - val_loss: 3.2129e-05\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.0794e-04 - val_loss: 2.9257e-05\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.0313e-04 - val_loss: 2.9589e-05\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.9849e-04 - val_loss: 2.9123e-05\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.0155e-04 - val_loss: 3.0404e-05\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.2170e-04 - val_loss: 2.7911e-05\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.9490e-04 - val_loss: 2.8136e-05\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.8393e-04 - val_loss: 2.6899e-05\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.7660e-04 - val_loss: 2.7187e-05\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.1175e-04 - val_loss: 3.1750e-05\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.8364e-04 - val_loss: 2.8400e-05\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.9493e-04 - val_loss: 3.0171e-05\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.0319e-04 - val_loss: 2.8126e-05\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.9946e-04 - val_loss: 2.6391e-05\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.6556e-04 - val_loss: 2.7452e-05\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.6099e-04 - val_loss: 2.6543e-05\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.7007e-04 - val_loss: 2.6586e-05\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.5449e-04 - val_loss: 2.8193e-05\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.7759e-04 - val_loss: 2.5377e-05\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.7249e-04 - val_loss: 2.7275e-05\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.1350e-04 - val_loss: 2.6622e-05\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.4641e-04 - val_loss: 2.5052e-05\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.6420e-04 - val_loss: 2.6482e-05\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.4050e-04 - val_loss: 2.8721e-05\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.5463e-04 - val_loss: 2.4217e-05\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.8461e-04 - val_loss: 2.5798e-05\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.4598e-04 - val_loss: 2.5326e-05\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.4883e-04 - val_loss: 2.2834e-05\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.5894e-04 - val_loss: 2.4509e-05\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.6981e-04 - val_loss: 2.3267e-05\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.4425e-04 - val_loss: 2.5212e-05\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.4611e-04 - val_loss: 2.6083e-05\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.5145e-04 - val_loss: 2.5316e-05\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 4.0308e-04 - val_loss: 3.0716e-05\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.6038e-04 - val_loss: 2.3156e-05\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.3120e-04 - val_loss: 2.5708e-05\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.6946e-04 - val_loss: 2.1505e-05\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.8059e-04 - val_loss: 2.4176e-05\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.1968e-04 - val_loss: 2.3646e-05\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.1420e-04 - val_loss: 2.2738e-05\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.0489e-04 - val_loss: 2.5293e-05\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.1500e-04 - val_loss: 2.1869e-05\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.1481e-04 - val_loss: 2.0984e-05\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.2196e-04 - val_loss: 2.0156e-05\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.2744e-04 - val_loss: 2.1629e-05\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.0892e-04 - val_loss: 2.1730e-05\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.0859e-04 - val_loss: 2.0918e-05\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.6272e-04 - val_loss: 2.2258e-05\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.1709e-04 - val_loss: 2.2244e-05\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.0512e-04 - val_loss: 2.4259e-05\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.1114e-04 - val_loss: 2.2652e-05\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.2791e-04 - val_loss: 2.1901e-05\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.3881e-04 - val_loss: 2.2117e-05\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.0678e-04 - val_loss: 2.1926e-05\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.0510e-04 - val_loss: 2.0708e-05\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.9927e-04 - val_loss: 1.9891e-05\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.0131e-04 - val_loss: 1.9380e-05\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.8388e-04 - val_loss: 2.2367e-05\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.1974e-04 - val_loss: 1.8860e-05\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.8875e-04 - val_loss: 1.9516e-05\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.7494e-04 - val_loss: 2.1129e-05\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.0296e-04 - val_loss: 2.1509e-05\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.8492e-04 - val_loss: 1.9996e-05\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.9283e-04 - val_loss: 2.0816e-05\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.6943e-04 - val_loss: 2.0076e-05\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.8620e-04 - val_loss: 2.1359e-05\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.8329e-04 - val_loss: 2.0210e-05\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.8025e-04 - val_loss: 2.3351e-05\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.0254e-04 - val_loss: 2.3687e-05\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.8133e-04 - val_loss: 1.8184e-05\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.8504e-04 - val_loss: 1.7845e-05\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.0694e-04 - val_loss: 2.4864e-05\n",
      "Epoch 135/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 4ms/step - loss: 2.8092e-04 - val_loss: 2.2329e-05\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.8852e-04 - val_loss: 1.8741e-05\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.7282e-04 - val_loss: 1.7965e-05\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.9229e-04 - val_loss: 1.9533e-05\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.5464e-04 - val_loss: 2.2222e-05\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.3802e-04 - val_loss: 1.7602e-05\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.7159e-04 - val_loss: 1.8839e-05\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.6057e-04 - val_loss: 1.9912e-05\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.6980e-04 - val_loss: 1.8111e-05\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.0036e-04 - val_loss: 1.7677e-05\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.5561e-04 - val_loss: 2.0754e-05\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.9816e-04 - val_loss: 2.0235e-05\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.6468e-04 - val_loss: 2.0831e-05\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.6391e-04 - val_loss: 1.7215e-05\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.5397e-04 - val_loss: 1.7223e-05\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.4282e-04 - val_loss: 1.7689e-05\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.7216e-04 - val_loss: 2.4080e-05\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.5493e-04 - val_loss: 1.6804e-05\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.4944e-04 - val_loss: 1.7299e-05\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.6184e-04 - val_loss: 1.6097e-05\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.5385e-04 - val_loss: 1.7977e-05\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.4477e-04 - val_loss: 1.6376e-05\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.5092e-04 - val_loss: 1.9439e-05\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.7679e-04 - val_loss: 1.8513e-05\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.3670e-04 - val_loss: 1.8499e-05\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.5326e-04 - val_loss: 1.6467e-05\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.4511e-04 - val_loss: 1.7847e-05\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.4550e-04 - val_loss: 1.7555e-05\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.5565e-04 - val_loss: 1.6361e-05\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 3.2737e-04 - val_loss: 1.6019e-05\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.4116e-04 - val_loss: 1.8777e-05\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.4330e-04 - val_loss: 1.7619e-05\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.3556e-04 - val_loss: 1.8577e-05\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.5528e-04 - val_loss: 1.9626e-05\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.3556e-04 - val_loss: 1.5693e-05\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.5322e-04 - val_loss: 1.5742e-05\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.3374e-04 - val_loss: 1.7258e-05\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.5546e-04 - val_loss: 1.6987e-05\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.4806e-04 - val_loss: 1.5537e-05\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.4706e-04 - val_loss: 1.7165e-05\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.3672e-04 - val_loss: 2.1539e-05\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.5549e-04 - val_loss: 1.4566e-05\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.4066e-04 - val_loss: 1.5779e-05\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.3054e-04 - val_loss: 1.7056e-05\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.3561e-04 - val_loss: 1.5606e-05\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.4982e-04 - val_loss: 1.4927e-05\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.2774e-04 - val_loss: 1.5875e-05\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.4234e-04 - val_loss: 1.5535e-05\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.3400e-04 - val_loss: 1.5927e-05\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.2690e-04 - val_loss: 1.6654e-05\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.3508e-04 - val_loss: 1.6137e-05\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.4200e-04 - val_loss: 1.4596e-05\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.7620e-04 - val_loss: 1.6520e-05\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.1482e-04 - val_loss: 1.4131e-05\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.2581e-04 - val_loss: 1.5481e-05\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.2803e-04 - val_loss: 1.5163e-05\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.2368e-04 - val_loss: 1.5090e-05\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.1505e-04 - val_loss: 1.5915e-05\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.5199e-04 - val_loss: 1.3996e-05\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.5068e-04 - val_loss: 1.5087e-05\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.2671e-04 - val_loss: 1.6031e-05\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.3402e-04 - val_loss: 1.4746e-05\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.5143e-04 - val_loss: 1.5294e-05\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.1966e-04 - val_loss: 1.4571e-05\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.2107e-04 - val_loss: 1.6151e-05\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 2.2319e-04 - val_loss: 1.3917e-05\n",
      "Thời gian huấn luyện:  29.145286560058594\n",
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_17 (SimpleRNN)   (None, 10, 109)           12099     \n",
      "                                                                 \n",
      " flatten_69 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,190\n",
      "Trainable params: 13,190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 2s 18ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.0036\n",
      "Thời gian huấn luyện:  68.15865111351013\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_17 (LSTM)              (None, 10, 109)           48396     \n",
      "                                                                 \n",
      " flatten_70 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,487\n",
      "Trainable params: 49,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 2s 17ms/step - loss: 0.0293 - val_loss: 9.7438e-04\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 3.0508e-04\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.5204e-04 - val_loss: 1.0323e-04\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.7867e-04 - val_loss: 8.2836e-05\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 7.7350e-04 - val_loss: 6.7707e-05\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.6518e-04 - val_loss: 7.3277e-05\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 7.6484e-04 - val_loss: 6.6497e-05\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.6036e-04 - val_loss: 6.6284e-05\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.5664e-04 - val_loss: 7.7236e-05\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.5818e-04 - val_loss: 6.6815e-05\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.4707e-04 - val_loss: 6.9300e-05\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.4029e-04 - val_loss: 6.4614e-05\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 7.4721e-04 - val_loss: 6.4473e-05\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.4366e-04 - val_loss: 6.7175e-05\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.3756e-04 - val_loss: 6.4445e-05\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.2652e-04 - val_loss: 6.3367e-05\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.2713e-04 - val_loss: 6.3906e-05\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.2857e-04 - val_loss: 6.5111e-05\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.1267e-04 - val_loss: 6.3533e-05\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.0702e-04 - val_loss: 6.8758e-05\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.1110e-04 - val_loss: 6.2764e-05\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.0555e-04 - val_loss: 6.3288e-05\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.1465e-04 - val_loss: 6.2712e-05\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.9670e-04 - val_loss: 6.6429e-05\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.8693e-04 - val_loss: 6.7122e-05\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.8824e-04 - val_loss: 5.9629e-05\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.9823e-04 - val_loss: 7.4410e-05\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.0960e-04 - val_loss: 5.9408e-05\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.8874e-04 - val_loss: 6.0732e-05\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.6564e-04 - val_loss: 5.9572e-05\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.6288e-04 - val_loss: 6.2768e-05\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.5865e-04 - val_loss: 5.7861e-05\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.6018e-04 - val_loss: 5.8059e-05\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.4729e-04 - val_loss: 5.7345e-05\n",
      "Epoch 35/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 8ms/step - loss: 6.5328e-04 - val_loss: 5.5741e-05\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.3377e-04 - val_loss: 5.8395e-05\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.3378e-04 - val_loss: 5.7888e-05\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.3572e-04 - val_loss: 5.7949e-05\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.4790e-04 - val_loss: 5.4969e-05\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.2240e-04 - val_loss: 5.4275e-05\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.3113e-04 - val_loss: 6.0096e-05\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.1046e-04 - val_loss: 5.4857e-05\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.1399e-04 - val_loss: 5.3441e-05\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.1526e-04 - val_loss: 5.3759e-05\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.9827e-04 - val_loss: 5.3380e-05\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.0636e-04 - val_loss: 5.1798e-05\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 6.1489e-04 - val_loss: 5.8276e-05\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.8346e-04 - val_loss: 5.1636e-05\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.9260e-04 - val_loss: 5.2824e-05\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.7191e-04 - val_loss: 5.0486e-05\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.7137e-04 - val_loss: 5.1395e-05\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.7065e-04 - val_loss: 5.0767e-05\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.7735e-04 - val_loss: 5.1920e-05\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.5810e-04 - val_loss: 5.0466e-05\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.5814e-04 - val_loss: 4.9685e-05\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.5280e-04 - val_loss: 4.9494e-05\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.4364e-04 - val_loss: 4.8218e-05\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.4723e-04 - val_loss: 5.3411e-05\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.4391e-04 - val_loss: 4.8613e-05\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.2781e-04 - val_loss: 5.0631e-05\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.5335e-04 - val_loss: 4.6919e-05\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.2243e-04 - val_loss: 5.3378e-05\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.3471e-04 - val_loss: 4.6481e-05\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.3144e-04 - val_loss: 6.3365e-05\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.5437e-04 - val_loss: 4.5468e-05\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.0616e-04 - val_loss: 4.6066e-05\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.2408e-04 - val_loss: 5.3650e-05\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.1314e-04 - val_loss: 4.5941e-05\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.9658e-04 - val_loss: 5.0543e-05\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.9251e-04 - val_loss: 4.4057e-05\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.8137e-04 - val_loss: 5.2893e-05\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.8923e-04 - val_loss: 4.4576e-05\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.7915e-04 - val_loss: 4.6313e-05\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.7028e-04 - val_loss: 4.7217e-05\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.6947e-04 - val_loss: 4.3543e-05\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.6634e-04 - val_loss: 4.8843e-05\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.8885e-04 - val_loss: 4.2479e-05\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.7580e-04 - val_loss: 4.5186e-05\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.7319e-04 - val_loss: 4.3330e-05\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.5525e-04 - val_loss: 4.1108e-05\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.4652e-04 - val_loss: 4.1851e-05\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.5099e-04 - val_loss: 4.5508e-05\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.4601e-04 - val_loss: 4.8614e-05\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.3849e-04 - val_loss: 4.3849e-05\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.3058e-04 - val_loss: 4.0810e-05\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.2616e-04 - val_loss: 5.1707e-05\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.3421e-04 - val_loss: 4.1484e-05\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.2181e-04 - val_loss: 4.4966e-05\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.1615e-04 - val_loss: 4.7812e-05\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.1590e-04 - val_loss: 3.8827e-05\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.1410e-04 - val_loss: 5.3640e-05\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.2461e-04 - val_loss: 4.4412e-05\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.0974e-04 - val_loss: 3.8623e-05\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.0526e-04 - val_loss: 4.7466e-05\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.0868e-04 - val_loss: 4.1827e-05\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.9667e-04 - val_loss: 4.2176e-05\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.0041e-04 - val_loss: 4.3281e-05\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.0110e-04 - val_loss: 4.3315e-05\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.9325e-04 - val_loss: 5.6401e-05\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.8813e-04 - val_loss: 3.9831e-05\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.8287e-04 - val_loss: 4.1660e-05\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.1419e-04 - val_loss: 5.4894e-05\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.7668e-04 - val_loss: 4.0662e-05\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.7756e-04 - val_loss: 5.6852e-05\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.7677e-04 - val_loss: 4.3358e-05\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.7363e-04 - val_loss: 3.9143e-05\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.6561e-04 - val_loss: 4.3124e-05\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.7331e-04 - val_loss: 4.6638e-05\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.6439e-04 - val_loss: 5.3970e-05\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.6825e-04 - val_loss: 3.7206e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.6326e-04 - val_loss: 5.1332e-05\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.6606e-04 - val_loss: 3.6556e-05\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.5994e-04 - val_loss: 4.3691e-05\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.4744e-04 - val_loss: 3.7299e-05\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.4722e-04 - val_loss: 4.6419e-05\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.5797e-04 - val_loss: 3.7423e-05\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.4812e-04 - val_loss: 4.3387e-05\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.5896e-04 - val_loss: 7.2754e-05\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.6790e-04 - val_loss: 3.5852e-05\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.3874e-04 - val_loss: 3.6122e-05\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.3864e-04 - val_loss: 3.3379e-05\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.7293e-04 - val_loss: 4.3007e-05\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.4910e-04 - val_loss: 4.3880e-05\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.2676e-04 - val_loss: 4.6151e-05\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.4381e-04 - val_loss: 5.1117e-05\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.2655e-04 - val_loss: 3.4463e-05\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.3134e-04 - val_loss: 3.6802e-05\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.2581e-04 - val_loss: 3.8933e-05\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.3433e-04 - val_loss: 3.4547e-05\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.2183e-04 - val_loss: 3.8035e-05\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.1964e-04 - val_loss: 3.3167e-05\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.2189e-04 - val_loss: 3.4621e-05\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.1844e-04 - val_loss: 4.6333e-05\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.2536e-04 - val_loss: 4.4465e-05\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.0846e-04 - val_loss: 3.0378e-05\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.3734e-04 - val_loss: 4.8730e-05\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.0223e-04 - val_loss: 3.1737e-05\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.0114e-04 - val_loss: 4.5948e-05\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.0842e-04 - val_loss: 4.2515e-05\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.1336e-04 - val_loss: 4.9230e-05\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.1894e-04 - val_loss: 2.8579e-05\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.9918e-04 - val_loss: 3.3655e-05\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.9209e-04 - val_loss: 2.8254e-05\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.9931e-04 - val_loss: 2.7388e-05\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.0653e-04 - val_loss: 3.0182e-05\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.9171e-04 - val_loss: 2.7302e-05\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.8732e-04 - val_loss: 3.4157e-05\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.9253e-04 - val_loss: 2.9505e-05\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.0395e-04 - val_loss: 2.7434e-05\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.9332e-04 - val_loss: 2.8051e-05\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.9259e-04 - val_loss: 3.2405e-05\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.9320e-04 - val_loss: 2.7307e-05\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.7955e-04 - val_loss: 2.6533e-05\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.9043e-04 - val_loss: 2.6501e-05\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.7807e-04 - val_loss: 2.7055e-05\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.8633e-04 - val_loss: 2.9112e-05\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.7433e-04 - val_loss: 2.6285e-05\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.7570e-04 - val_loss: 2.4880e-05\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.8158e-04 - val_loss: 3.2463e-05\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.9670e-04 - val_loss: 2.5260e-05\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.7161e-04 - val_loss: 2.4183e-05\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.7230e-04 - val_loss: 2.6814e-05\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.8471e-04 - val_loss: 2.6313e-05\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.7610e-04 - val_loss: 2.9190e-05\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.7514e-04 - val_loss: 2.3851e-05\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.6709e-04 - val_loss: 2.3926e-05\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.6148e-04 - val_loss: 2.5193e-05\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.6771e-04 - val_loss: 2.9009e-05\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.5992e-04 - val_loss: 2.6931e-05\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.9829e-04 - val_loss: 2.3933e-05\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.5654e-04 - val_loss: 2.3183e-05\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.6065e-04 - val_loss: 2.3525e-05\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.5215e-04 - val_loss: 2.4363e-05\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.5344e-04 - val_loss: 2.4333e-05\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.9689e-04 - val_loss: 2.4284e-05\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.5825e-04 - val_loss: 2.2059e-05\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.5328e-04 - val_loss: 2.3022e-05\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.5117e-04 - val_loss: 2.2870e-05\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.5075e-04 - val_loss: 2.1716e-05\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.4608e-04 - val_loss: 2.1759e-05\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.6068e-04 - val_loss: 2.6004e-05\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.7701e-04 - val_loss: 2.2532e-05\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.4409e-04 - val_loss: 2.1874e-05\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.4284e-04 - val_loss: 2.2614e-05\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.5298e-04 - val_loss: 2.5962e-05\n",
      "Epoch 186/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 8ms/step - loss: 2.5013e-04 - val_loss: 2.4579e-05\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.4078e-04 - val_loss: 2.1757e-05\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.5541e-04 - val_loss: 2.0129e-05\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.4008e-04 - val_loss: 2.7385e-05\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.4552e-04 - val_loss: 2.0437e-05\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.3308e-04 - val_loss: 2.1139e-05\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.3888e-04 - val_loss: 2.0297e-05\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.4546e-04 - val_loss: 2.1594e-05\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.5767e-04 - val_loss: 2.0727e-05\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.3557e-04 - val_loss: 2.0839e-05\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.3431e-04 - val_loss: 2.1170e-05\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.4676e-04 - val_loss: 2.1704e-05\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.3877e-04 - val_loss: 1.9377e-05\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.3460e-04 - val_loss: 2.0472e-05\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.2754e-04 - val_loss: 2.2293e-05\n",
      "Thời gian huấn luyện:  63.05192184448242\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_17 (GRU)                (None, 10, 109)           36624     \n",
      "                                                                 \n",
      " flatten_71 (Flatten)        (None, 1090)              0         \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 1)                 1091      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,715\n",
      "Trainable params: 37,715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "45/45 [==============================] - 0s 954us/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "45/45 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "45/45 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "45/45 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Thời gian huấn luyện:  4.615165710449219\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_90 (Dense)            (None, 10, 116)           232       \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " flatten_72 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "46/46 [==============================] - 1s 7ms/step - loss: 0.0273 - val_loss: 1.6398e-04\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.2992e-04 - val_loss: 8.5679e-05\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7213e-04 - val_loss: 1.2383e-04\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.4342e-04 - val_loss: 9.8908e-05\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.1834e-04 - val_loss: 7.9472e-05\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.8921e-04 - val_loss: 8.1220e-05\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.7687e-04 - val_loss: 7.0142e-05\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4317e-04 - val_loss: 6.5844e-05\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.2417e-04 - val_loss: 6.5496e-05\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.0378e-04 - val_loss: 6.1686e-05\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.0732e-04 - val_loss: 4.5518e-05\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.8675e-04 - val_loss: 4.5482e-05\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.7341e-04 - val_loss: 4.3688e-05\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.4165e-04 - val_loss: 3.9700e-05\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.2328e-04 - val_loss: 4.0822e-05\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3226e-04 - val_loss: 3.8231e-05\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.9958e-04 - val_loss: 3.2361e-05\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.9736e-04 - val_loss: 2.9554e-05\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.8120e-04 - val_loss: 2.8767e-05\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.7094e-04 - val_loss: 2.6317e-05\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4714e-04 - val_loss: 2.0911e-05\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6463e-04 - val_loss: 2.1374e-05\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3381e-04 - val_loss: 1.8174e-05\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3560e-04 - val_loss: 1.8875e-05\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3694e-04 - val_loss: 2.1776e-05\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2831e-04 - val_loss: 1.7941e-05\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1105e-04 - val_loss: 1.7779e-05\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2517e-04 - val_loss: 1.7689e-05\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1887e-04 - val_loss: 1.5767e-05\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8894e-04 - val_loss: 1.7672e-05\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.9872e-04 - val_loss: 1.4664e-05\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8484e-04 - val_loss: 1.3637e-05\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8170e-04 - val_loss: 1.3366e-05\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8471e-04 - val_loss: 1.4458e-05\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7842e-04 - val_loss: 1.3485e-05\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7436e-04 - val_loss: 1.3294e-05\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6997e-04 - val_loss: 1.3170e-05\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5227e-04 - val_loss: 1.2405e-05\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5793e-04 - val_loss: 1.2321e-05\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4597e-04 - val_loss: 1.1833e-05\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4545e-04 - val_loss: 1.3046e-05\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5216e-04 - val_loss: 1.1700e-05\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2838e-04 - val_loss: 1.1797e-05\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3273e-04 - val_loss: 1.2332e-05\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3816e-04 - val_loss: 1.1144e-05\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3557e-04 - val_loss: 1.0886e-05\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2088e-04 - val_loss: 1.1567e-05\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2423e-04 - val_loss: 1.2954e-05\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.1349e-04 - val_loss: 1.0621e-05\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.1545e-04 - val_loss: 1.0465e-05\n",
      "Thời gian huấn luyện:  9.150149583816528\n",
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_18 (SimpleRNN)   (None, 10, 116)           13688     \n",
      "                                                                 \n",
      " flatten_73 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,849\n",
      "Trainable params: 14,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "46/46 [==============================] - 2s 16ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Thời gian huấn luyện:  23.333674430847168\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_18 (LSTM)              (None, 10, 116)           54752     \n",
      "                                                                 \n",
      " flatten_74 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,913\n",
      "Trainable params: 55,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "46/46 [==============================] - 2s 15ms/step - loss: 0.0197 - val_loss: 2.9109e-04\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 7.1918e-04 - val_loss: 3.3838e-05\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.8300e-04 - val_loss: 2.5041e-05\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.8625e-04 - val_loss: 3.6562e-05\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.8610e-04 - val_loss: 2.3769e-05\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.7400e-04 - val_loss: 2.7135e-05\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.7500e-04 - val_loss: 2.6089e-05\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.6756e-04 - val_loss: 2.7896e-05\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.6781e-04 - val_loss: 2.5603e-05\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.6697e-04 - val_loss: 2.2619e-05\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.6650e-04 - val_loss: 2.5898e-05\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.5021e-04 - val_loss: 3.2911e-05\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.5162e-04 - val_loss: 2.6902e-05\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.4496e-04 - val_loss: 2.2333e-05\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.4121e-04 - val_loss: 2.9514e-05\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.4310e-04 - val_loss: 2.1732e-05\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.3428e-04 - val_loss: 2.2254e-05\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.4320e-04 - val_loss: 2.9444e-05\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.3891e-04 - val_loss: 2.6640e-05\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.2178e-04 - val_loss: 4.4673e-05\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.2136e-04 - val_loss: 2.4428e-05\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.2144e-04 - val_loss: 2.6064e-05\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.0770e-04 - val_loss: 2.0880e-05\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.1092e-04 - val_loss: 2.0472e-05\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.1103e-04 - val_loss: 2.1543e-05\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.0175e-04 - val_loss: 2.0235e-05\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.9803e-04 - val_loss: 2.1028e-05\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.9308e-04 - val_loss: 1.9963e-05\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.9047e-04 - val_loss: 2.0510e-05\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.8775e-04 - val_loss: 2.8494e-05\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.8629e-04 - val_loss: 2.7309e-05\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.8074e-04 - val_loss: 1.9166e-05\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.7560e-04 - val_loss: 2.8870e-05\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.7000e-04 - val_loss: 2.5515e-05\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.6340e-04 - val_loss: 1.8754e-05\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.5994e-04 - val_loss: 2.6253e-05\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 9ms/step - loss: 4.6409e-04 - val_loss: 2.6663e-05\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.5787e-04 - val_loss: 1.9394e-05\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.4642e-04 - val_loss: 2.0643e-05\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.4584e-04 - val_loss: 2.0421e-05\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.4013e-04 - val_loss: 2.4005e-05\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.5552e-04 - val_loss: 2.8841e-05\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.4465e-04 - val_loss: 2.2992e-05\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.2630e-04 - val_loss: 2.2140e-05\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.2717e-04 - val_loss: 1.9249e-05\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.1738e-04 - val_loss: 2.2525e-05\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.2973e-04 - val_loss: 1.8958e-05\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.1530e-04 - val_loss: 3.4817e-05\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.3029e-04 - val_loss: 1.7202e-05\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.1038e-04 - val_loss: 2.3274e-05\n",
      "Thời gian huấn luyện:  21.343032121658325\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_18 (GRU)                (None, 10, 116)           41412     \n",
      "                                                                 \n",
      " flatten_75 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,573\n",
      "Trainable params: 42,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 963us/step\n",
      "13/13 [==============================] - 0s 999us/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0655 - val_loss: 0.0388\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0132\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 9.7036e-04 - val_loss: 4.5825e-04\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 6.5019e-04 - val_loss: 1.3255e-04\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.7891e-04 - val_loss: 4.2648e-05\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.5345e-04 - val_loss: 2.9094e-05\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.4611e-04 - val_loss: 2.3850e-05\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.4372e-04 - val_loss: 2.4213e-05\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.3909e-04 - val_loss: 2.2974e-05\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.4152e-04 - val_loss: 2.8894e-05\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.4463e-04 - val_loss: 3.3299e-05\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.3757e-04 - val_loss: 2.3035e-05\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.3085e-04 - val_loss: 2.8056e-05\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.3049e-04 - val_loss: 2.5342e-05\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.2475e-04 - val_loss: 2.2885e-05\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.2651e-04 - val_loss: 2.8708e-05\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.2273e-04 - val_loss: 3.2608e-05\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.2290e-04 - val_loss: 2.3745e-05\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.2309e-04 - val_loss: 2.5368e-05\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.1859e-04 - val_loss: 2.9357e-05\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.1586e-04 - val_loss: 2.2998e-05\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.2022e-04 - val_loss: 2.3936e-05\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.2163e-04 - val_loss: 5.9083e-05\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.1577e-04 - val_loss: 2.3036e-05\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.1585e-04 - val_loss: 3.0476e-05\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.1048e-04 - val_loss: 4.1676e-05\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.0991e-04 - val_loss: 2.3122e-05\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.0939e-04 - val_loss: 2.8285e-05\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.0927e-04 - val_loss: 2.4878e-05\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.0986e-04 - val_loss: 2.2576e-05\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.0285e-04 - val_loss: 4.2393e-05\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.0253e-04 - val_loss: 3.5706e-05\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.0355e-04 - val_loss: 3.4200e-05\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.9903e-04 - val_loss: 2.3197e-05\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.0156e-04 - val_loss: 2.6822e-05\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.0035e-04 - val_loss: 3.2989e-05\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.9736e-04 - val_loss: 3.0400e-05\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.9185e-04 - val_loss: 2.5418e-05\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.9151e-04 - val_loss: 2.1730e-05\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.9083e-04 - val_loss: 2.5352e-05\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.9342e-04 - val_loss: 2.6486e-05\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.8964e-04 - val_loss: 2.4680e-05\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.8396e-04 - val_loss: 2.6374e-05\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.8306e-04 - val_loss: 2.4561e-05\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.8537e-04 - val_loss: 3.3129e-05\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.8100e-04 - val_loss: 2.4335e-05\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.8430e-04 - val_loss: 3.0486e-05\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.7982e-04 - val_loss: 2.1141e-05\n",
      "Thời gian huấn luyện:  4.683460235595703\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_95 (Dense)            (None, 10, 116)           232       \n",
      "                                                                 \n",
      " flatten_76 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "44/44 [==============================] - 1s 7ms/step - loss: 0.0068 - val_loss: 4.1342e-04\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.7236e-04 - val_loss: 1.9191e-04\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.3618e-04 - val_loss: 1.5442e-04\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.7465e-04 - val_loss: 1.1835e-04\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.0712e-04 - val_loss: 5.9405e-05\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.8269e-04 - val_loss: 5.0716e-05\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.6977e-04 - val_loss: 2.8705e-05\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.1798e-04 - val_loss: 2.3027e-05\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.1378e-04 - val_loss: 2.2602e-05\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.9583e-04 - val_loss: 2.5463e-05\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.6276e-04 - val_loss: 1.7885e-05\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.5341e-04 - val_loss: 1.9193e-05\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.6640e-04 - val_loss: 2.0228e-05\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.3636e-04 - val_loss: 1.7616e-05\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.3038e-04 - val_loss: 2.1919e-05\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.2105e-04 - val_loss: 1.8358e-05\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.3911e-04 - val_loss: 1.7618e-05\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.9467e-04 - val_loss: 1.5213e-05\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1183e-04 - val_loss: 1.7194e-05\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.7332e-04 - val_loss: 1.5434e-05\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.9586e-04 - val_loss: 1.8423e-05\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.8448e-04 - val_loss: 1.6189e-05\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.6205e-04 - val_loss: 1.5530e-05\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.6455e-04 - val_loss: 1.3749e-05\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.4952e-04 - val_loss: 1.3798e-05\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.4969e-04 - val_loss: 1.3379e-05\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.9880e-04 - val_loss: 1.3328e-05\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.7617e-04 - val_loss: 1.8144e-05\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.4089e-04 - val_loss: 1.3823e-05\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.4716e-04 - val_loss: 1.3099e-05\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.3024e-04 - val_loss: 1.2441e-05\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.1687e-04 - val_loss: 1.3629e-05\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.5712e-04 - val_loss: 1.4740e-05\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.2484e-04 - val_loss: 1.4270e-05\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.4899e-04 - val_loss: 1.3134e-05\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.1648e-04 - val_loss: 1.4429e-05\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.2359e-04 - val_loss: 2.0046e-05\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0913e-04 - val_loss: 1.2178e-05\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.1840e-04 - val_loss: 1.1361e-05\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9130e-04 - val_loss: 1.6001e-05\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0893e-04 - val_loss: 1.3223e-05\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.2064e-04 - val_loss: 1.1589e-05\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0238e-04 - val_loss: 1.1956e-05\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0225e-04 - val_loss: 1.3232e-05\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.8756e-04 - val_loss: 1.2553e-05\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9575e-04 - val_loss: 1.4298e-05\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9534e-04 - val_loss: 1.6036e-05\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.1427e-04 - val_loss: 1.1436e-05\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.3337e-04 - val_loss: 1.1187e-05\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9189e-04 - val_loss: 1.1198e-05\n",
      "Thời gian huấn luyện:  9.043164491653442\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_19 (SimpleRNN)   (None, 10, 116)           13688     \n",
      "                                                                 \n",
      " flatten_77 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,849\n",
      "Trainable params: 14,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "44/44 [==============================] - 2s 17ms/step - loss: 0.0350 - val_loss: 0.0012\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 1.2455e-04\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.6330e-04 - val_loss: 3.4937e-05\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.4955e-04 - val_loss: 3.5736e-05\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.5640e-04 - val_loss: 3.6512e-05\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.4945e-04 - val_loss: 3.5660e-05\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.5040e-04 - val_loss: 3.2051e-05\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.5070e-04 - val_loss: 3.8135e-05\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.4298e-04 - val_loss: 3.1852e-05\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.3382e-04 - val_loss: 3.4174e-05\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.3418e-04 - val_loss: 3.5112e-05\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.3747e-04 - val_loss: 3.5688e-05\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 10ms/step - loss: 7.3684e-04 - val_loss: 4.0179e-05\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 7.3520e-04 - val_loss: 3.1758e-05\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 7.3081e-04 - val_loss: 3.2079e-05\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 7.2950e-04 - val_loss: 3.1686e-05\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 7.2911e-04 - val_loss: 3.1485e-05\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.2807e-04 - val_loss: 3.3666e-05\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 7.1260e-04 - val_loss: 4.0561e-05\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.3020e-04 - val_loss: 3.1589e-05\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 7.2346e-04 - val_loss: 3.1432e-05\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.1324e-04 - val_loss: 3.3078e-05\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 7.1777e-04 - val_loss: 3.4202e-05\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.1725e-04 - val_loss: 3.1855e-05\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.0597e-04 - val_loss: 3.1469e-05\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.0263e-04 - val_loss: 3.1736e-05\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.9366e-04 - val_loss: 3.2758e-05\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.8844e-04 - val_loss: 3.6648e-05\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.9115e-04 - val_loss: 3.1211e-05\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.0081e-04 - val_loss: 3.4504e-05\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.2247e-04 - val_loss: 3.0996e-05\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.1049e-04 - val_loss: 3.4145e-05\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.8724e-04 - val_loss: 3.0916e-05\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.8450e-04 - val_loss: 3.2217e-05\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.0022e-04 - val_loss: 3.0342e-05\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.9433e-04 - val_loss: 3.0382e-05\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.8518e-04 - val_loss: 3.8013e-05\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.7111e-04 - val_loss: 3.1312e-05\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.7623e-04 - val_loss: 3.9292e-05\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.9451e-04 - val_loss: 2.9791e-05\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.6231e-04 - val_loss: 5.4681e-05\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.2546e-04 - val_loss: 3.0650e-05\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.5823e-04 - val_loss: 3.0077e-05\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.5986e-04 - val_loss: 2.9846e-05\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.5982e-04 - val_loss: 3.2581e-05\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.1015e-04 - val_loss: 3.1770e-05\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.4696e-04 - val_loss: 3.1248e-05\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.5708e-04 - val_loss: 3.5416e-05\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.4645e-04 - val_loss: 2.9026e-05\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.3882e-04 - val_loss: 3.7622e-05\n",
      "Thời gian huấn luyện:  22.098179578781128\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_19 (LSTM)              (None, 10, 116)           54752     \n",
      "                                                                 \n",
      " flatten_78 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,913\n",
      "Trainable params: 55,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "44/44 [==============================] - 2s 23ms/step - loss: 0.0264 - val_loss: 4.0176e-04\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.9621e-04 - val_loss: 3.2279e-05\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.7098e-04 - val_loss: 3.2931e-05\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.5354e-04 - val_loss: 3.4946e-05\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.6627e-04 - val_loss: 4.5491e-05\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.4596e-04 - val_loss: 2.9248e-05\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.4776e-04 - val_loss: 4.5566e-05\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.3702e-04 - val_loss: 3.7767e-05\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.3101e-04 - val_loss: 3.3386e-05\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.3230e-04 - val_loss: 3.1130e-05\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.2410e-04 - val_loss: 3.8353e-05\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.1619e-04 - val_loss: 2.7996e-05\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.2214e-04 - val_loss: 2.7811e-05\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.1883e-04 - val_loss: 4.1809e-05\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.1048e-04 - val_loss: 2.9678e-05\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.0540e-04 - val_loss: 2.8460e-05\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.0390e-04 - val_loss: 3.0012e-05\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.1960e-04 - val_loss: 3.1451e-05\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.9439e-04 - val_loss: 2.7479e-05\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.0080e-04 - val_loss: 2.7274e-05\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 5.8441e-04 - val_loss: 2.6340e-05\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 5.7990e-04 - val_loss: 3.7587e-05\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 5.7425e-04 - val_loss: 3.4412e-05\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.7478e-04 - val_loss: 3.2730e-05\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 5.7084e-04 - val_loss: 3.7257e-05\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 5.6567e-04 - val_loss: 2.5604e-05\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.5714e-04 - val_loss: 2.5314e-05\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 5.6598e-04 - val_loss: 3.0205e-05\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 5.5215e-04 - val_loss: 2.9516e-05\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 5.4493e-04 - val_loss: 2.7675e-05\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 9ms/step - loss: 5.5199e-04 - val_loss: 2.4957e-05\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.4006e-04 - val_loss: 2.7454e-05\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.3292e-04 - val_loss: 2.5030e-05\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.2778e-04 - val_loss: 3.9467e-05\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 5.2779e-04 - val_loss: 2.5357e-05\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.3064e-04 - val_loss: 2.8142e-05\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 5.1632e-04 - val_loss: 2.3370e-05\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.0761e-04 - val_loss: 2.4430e-05\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.2052e-04 - val_loss: 2.4036e-05\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.0859e-04 - val_loss: 2.6194e-05\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 4.9605e-04 - val_loss: 2.5016e-05\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.0022e-04 - val_loss: 2.9304e-05\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 4.8494e-04 - val_loss: 2.9111e-05\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.8234e-04 - val_loss: 3.5753e-05\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.8151e-04 - val_loss: 2.4413e-05\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.8296e-04 - val_loss: 2.2056e-05\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 4.9516e-04 - val_loss: 3.7908e-05\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.2276e-04 - val_loss: 3.9992e-05\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 4.9721e-04 - val_loss: 2.7557e-05\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.6483e-04 - val_loss: 2.3836e-05\n",
      "Thời gian huấn luyện:  20.78458881378174\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_19 (GRU)                (None, 10, 116)           41412     \n",
      "                                                                 \n",
      " flatten_79 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,573\n",
      "Trainable params: 42,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 983us/step\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0869 - val_loss: 0.0387\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0209\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0126\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0066\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 8.6867e-04 - val_loss: 7.8764e-04\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.9916e-04 - val_loss: 4.6446e-04\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.3930e-04 - val_loss: 2.6774e-04\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.1185e-04 - val_loss: 2.0715e-04\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.0795e-04 - val_loss: 1.5280e-04\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.9924e-04 - val_loss: 8.6190e-05\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.9855e-04 - val_loss: 8.1611e-05\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.8667e-04 - val_loss: 8.2870e-05\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.8340e-04 - val_loss: 6.9384e-05\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.8124e-04 - val_loss: 5.6315e-05\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7879e-04 - val_loss: 5.0467e-05\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7421e-04 - val_loss: 5.3694e-05\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7462e-04 - val_loss: 4.3977e-05\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7208e-04 - val_loss: 4.3800e-05\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7092e-04 - val_loss: 4.1360e-05\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6710e-04 - val_loss: 4.4218e-05\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6644e-04 - val_loss: 3.9024e-05\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6752e-04 - val_loss: 3.8197e-05\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6285e-04 - val_loss: 3.7158e-05\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6080e-04 - val_loss: 3.9445e-05\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6021e-04 - val_loss: 3.7040e-05\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5796e-04 - val_loss: 3.6849e-05\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5831e-04 - val_loss: 4.1054e-05\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5699e-04 - val_loss: 3.6860e-05\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5480e-04 - val_loss: 3.5108e-05\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5259e-04 - val_loss: 3.2996e-05\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5028e-04 - val_loss: 3.5233e-05\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4825e-04 - val_loss: 3.1855e-05\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4796e-04 - val_loss: 3.2472e-05\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4612e-04 - val_loss: 3.1220e-05\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4697e-04 - val_loss: 3.5767e-05\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4139e-04 - val_loss: 3.4034e-05\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4091e-04 - val_loss: 3.3001e-05\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3723e-04 - val_loss: 4.8298e-05\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4593e-04 - val_loss: 3.0900e-05\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3627e-04 - val_loss: 3.6605e-05\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3739e-04 - val_loss: 3.5309e-05\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3285e-04 - val_loss: 3.2685e-05\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2960e-04 - val_loss: 4.0921e-05\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3412e-04 - val_loss: 3.2624e-05\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3022e-04 - val_loss: 3.2711e-05\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2742e-04 - val_loss: 2.8407e-05\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2622e-04 - val_loss: 3.5514e-05\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2125e-04 - val_loss: 3.6723e-05\n",
      "Thời gian huấn luyện:  4.535413503646851\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_100 (Dense)           (None, 10, 116)           232       \n",
      "                                                                 \n",
      " flatten_80 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 1s 7ms/step - loss: 0.0298 - val_loss: 4.9888e-04\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 6.8153e-04\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 7.0271e-04\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 6.9602e-04\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 6.0950e-04\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 6.1264e-04\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 5.0226e-04\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 4.0995e-04\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 3.7698e-04\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.4457e-04 - val_loss: 3.7703e-04\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.2118e-04 - val_loss: 3.2972e-04\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.6564e-04 - val_loss: 2.9795e-04\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.6375e-04 - val_loss: 2.4630e-04\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.0169e-04 - val_loss: 2.1327e-04\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.6977e-04 - val_loss: 1.9469e-04\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.6311e-04 - val_loss: 1.9800e-04\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.7724e-04 - val_loss: 1.3401e-04\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.2250e-04 - val_loss: 1.3846e-04\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.9981e-04 - val_loss: 9.7328e-05\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.8844e-04 - val_loss: 9.4136e-05\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.6304e-04 - val_loss: 1.0234e-04\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.8813e-04 - val_loss: 6.2287e-05\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.4607e-04 - val_loss: 8.5112e-05\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.0791e-04 - val_loss: 5.9178e-05\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.8371e-04 - val_loss: 4.1055e-05\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.3145e-04 - val_loss: 6.8843e-05\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.9574e-04 - val_loss: 4.1086e-05\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.9991e-04 - val_loss: 5.4303e-05\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.6646e-04 - val_loss: 3.9554e-05\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.3060e-04 - val_loss: 3.5992e-05\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.3394e-04 - val_loss: 3.0336e-05\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.7930e-04 - val_loss: 3.3902e-05\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.1235e-04 - val_loss: 2.4784e-05\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.3908e-04 - val_loss: 3.0917e-05\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.2162e-04 - val_loss: 2.4741e-05\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.4759e-04 - val_loss: 2.3601e-05\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.0335e-04 - val_loss: 2.2518e-05\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.9608e-04 - val_loss: 2.2810e-05\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.8201e-04 - val_loss: 2.1503e-05\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.9338e-04 - val_loss: 2.0898e-05\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.8064e-04 - val_loss: 2.1211e-05\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.6986e-04 - val_loss: 2.3797e-05\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.0163e-04 - val_loss: 2.5542e-05\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.1214e-04 - val_loss: 1.9291e-05\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3803e-04 - val_loss: 2.4042e-05\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.5203e-04 - val_loss: 2.0530e-05\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3774e-04 - val_loss: 1.9518e-05\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3862e-04 - val_loss: 2.2798e-05\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.1801e-04 - val_loss: 1.9554e-05\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.2365e-04 - val_loss: 1.7824e-05\n",
      "Thời gian huấn luyện:  8.891568183898926\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_20 (SimpleRNN)   (None, 10, 116)           13688     \n",
      "                                                                 \n",
      " flatten_81 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,849\n",
      "Trainable params: 14,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 2s 17ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Thời gian huấn luyện:  20.64949655532837\n",
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_20 (LSTM)              (None, 10, 116)           54752     \n",
      "                                                                 \n",
      " flatten_82 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,913\n",
      "Trainable params: 55,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 2s 16ms/step - loss: 0.0223 - val_loss: 7.5646e-04\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 8.6521e-04 - val_loss: 3.4906e-05\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.6872e-04 - val_loss: 4.3045e-05\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.6948e-04 - val_loss: 4.4063e-05\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.6822e-04 - val_loss: 3.4004e-05\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.6087e-04 - val_loss: 3.5609e-05\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.5875e-04 - val_loss: 3.9134e-05\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.4749e-04 - val_loss: 3.2033e-05\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.4764e-04 - val_loss: 3.4523e-05\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.3664e-04 - val_loss: 3.0551e-05\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.3997e-04 - val_loss: 5.0951e-05\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.3450e-04 - val_loss: 4.0620e-05\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.3350e-04 - val_loss: 3.3649e-05\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.2386e-04 - val_loss: 3.6466e-05\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.1546e-04 - val_loss: 4.1960e-05\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.1586e-04 - val_loss: 4.0316e-05\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.0917e-04 - val_loss: 3.5396e-05\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.0357e-04 - val_loss: 3.8459e-05\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.0174e-04 - val_loss: 3.0020e-05\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.9521e-04 - val_loss: 4.0463e-05\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.9378e-04 - val_loss: 3.9038e-05\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.8391e-04 - val_loss: 3.1408e-05\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.8456e-04 - val_loss: 2.6950e-05\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.8212e-04 - val_loss: 2.8886e-05\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.7280e-04 - val_loss: 4.0459e-05\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.6961e-04 - val_loss: 3.0513e-05\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.6341e-04 - val_loss: 3.8811e-05\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.5989e-04 - val_loss: 3.7766e-05\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 8ms/step - loss: 5.5248e-04 - val_loss: 3.5769e-05\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.4541e-04 - val_loss: 3.7382e-05\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.6573e-04 - val_loss: 2.8043e-05\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.4939e-04 - val_loss: 3.9423e-05\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.3593e-04 - val_loss: 3.0322e-05\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.2839e-04 - val_loss: 2.8304e-05\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.2826e-04 - val_loss: 3.2868e-05\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.1956e-04 - val_loss: 2.7503e-05\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.1931e-04 - val_loss: 2.5263e-05\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.0940e-04 - val_loss: 2.7478e-05\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.1007e-04 - val_loss: 3.2111e-05\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.0009e-04 - val_loss: 3.0761e-05\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.9766e-04 - val_loss: 3.3779e-05\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.1279e-04 - val_loss: 2.5877e-05\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.9539e-04 - val_loss: 4.1493e-05\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.8734e-04 - val_loss: 2.7747e-05\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.8109e-04 - val_loss: 3.7038e-05\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.7516e-04 - val_loss: 4.2257e-05\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.6791e-04 - val_loss: 2.8516e-05\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.7493e-04 - val_loss: 3.5344e-05\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.7874e-04 - val_loss: 2.5175e-05\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.6061e-04 - val_loss: 2.5684e-05\n",
      "Thời gian huấn luyện:  19.14273762702942\n",
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_20 (GRU)                (None, 10, 116)           41412     \n",
      "                                                                 \n",
      " flatten_83 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,573\n",
      "Trainable params: 42,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 981us/step\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "52/52 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Thời gian huấn luyện:  8.771993637084961\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_105 (Dense)           (None, 10, 116)           232       \n",
      "                                                                 \n",
      " flatten_84 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 0.0306 - val_loss: 2.0371e-04\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 1.1757e-04\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.4032e-04 - val_loss: 1.4528e-04\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.8313e-04 - val_loss: 1.4106e-04\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7339e-04 - val_loss: 1.0472e-04\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.2393e-04 - val_loss: 1.0216e-04\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.0928e-04 - val_loss: 1.1379e-04\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8338e-04 - val_loss: 9.9569e-05\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7451e-04 - val_loss: 8.0141e-05\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3730e-04 - val_loss: 8.3384e-05\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.2010e-04 - val_loss: 8.8824e-05\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1540e-04 - val_loss: 7.7397e-05\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9414e-04 - val_loss: 7.0155e-05\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.7461e-04 - val_loss: 4.9266e-05\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6192e-04 - val_loss: 4.8895e-05\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3716e-04 - val_loss: 4.4731e-05\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.2824e-04 - val_loss: 5.4834e-05\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 6.1543e-04 - val_loss: 4.8390e-05\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1153e-04 - val_loss: 2.5525e-05\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1052e-04 - val_loss: 3.1787e-05\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.8919e-04 - val_loss: 2.8286e-05\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.6719e-04 - val_loss: 2.9826e-05\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5291e-04 - val_loss: 2.8977e-05\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3853e-04 - val_loss: 2.9105e-05\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3589e-04 - val_loss: 3.1938e-05\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.2357e-04 - val_loss: 2.4908e-05\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3607e-04 - val_loss: 2.2578e-05\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.1756e-04 - val_loss: 2.7303e-05\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.2052e-04 - val_loss: 3.1242e-05\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.9901e-04 - val_loss: 2.1018e-05\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.9434e-04 - val_loss: 2.0384e-05\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.9838e-04 - val_loss: 1.9435e-05\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7352e-04 - val_loss: 2.3460e-05\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.8742e-04 - val_loss: 1.7391e-05\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.7778e-04 - val_loss: 1.6976e-05\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6260e-04 - val_loss: 1.6695e-05\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7685e-04 - val_loss: 1.6797e-05\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7487e-04 - val_loss: 1.6285e-05\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.5070e-04 - val_loss: 1.6821e-05\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4944e-04 - val_loss: 1.7011e-05\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3603e-04 - val_loss: 1.6081e-05\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2261e-04 - val_loss: 1.5247e-05\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2525e-04 - val_loss: 1.5340e-05\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3070e-04 - val_loss: 1.7602e-05\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6868e-04 - val_loss: 1.4748e-05\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3229e-04 - val_loss: 1.5346e-05\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0838e-04 - val_loss: 1.7738e-05\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0648e-04 - val_loss: 1.4283e-05\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0629e-04 - val_loss: 1.5052e-05\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1887e-04 - val_loss: 1.4712e-05\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2000e-04 - val_loss: 1.3511e-05\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9941e-04 - val_loss: 1.7248e-05\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1981e-04 - val_loss: 1.3179e-05\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1466e-04 - val_loss: 1.3460e-05\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9578e-04 - val_loss: 1.3117e-05\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0372e-04 - val_loss: 1.3760e-05\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8959e-04 - val_loss: 2.9173e-05\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1456e-04 - val_loss: 1.2918e-05\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8780e-04 - val_loss: 1.2751e-05\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8408e-04 - val_loss: 2.0672e-05\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7046e-04 - val_loss: 1.2461e-05\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5252e-04 - val_loss: 1.2859e-05\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3948e-04 - val_loss: 1.3942e-05\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5077e-04 - val_loss: 1.2329e-05\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6289e-04 - val_loss: 1.2462e-05\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3979e-04 - val_loss: 1.2905e-05\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4320e-04 - val_loss: 1.1509e-05\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4624e-04 - val_loss: 1.1622e-05\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2454e-04 - val_loss: 1.4978e-05\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3221e-04 - val_loss: 1.1841e-05\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3492e-04 - val_loss: 1.4093e-05\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2963e-04 - val_loss: 1.0886e-05\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2203e-04 - val_loss: 1.0971e-05\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5411e-04 - val_loss: 1.3078e-05\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4922e-04 - val_loss: 1.0563e-05\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3483e-04 - val_loss: 1.1490e-05\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2503e-04 - val_loss: 1.1101e-05\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3573e-04 - val_loss: 1.1263e-05\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.1772e-04 - val_loss: 1.1731e-05\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2903e-04 - val_loss: 1.2291e-05\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5012e-04 - val_loss: 2.8397e-05\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4969e-04 - val_loss: 1.0266e-05\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1126e-04 - val_loss: 1.1861e-05\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8392e-04 - val_loss: 1.2022e-05\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.1521e-04 - val_loss: 1.1895e-05\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8059e-04 - val_loss: 9.7762e-06\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.7862e-04 - val_loss: 1.0815e-05\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8469e-04 - val_loss: 1.3661e-05\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8635e-04 - val_loss: 1.1365e-05\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2466e-04 - val_loss: 1.0014e-05\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.9383e-04 - val_loss: 1.1585e-05\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3255e-04 - val_loss: 1.0794e-05\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9219e-04 - val_loss: 9.2797e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.9425e-04 - val_loss: 9.4669e-06\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5911e-04 - val_loss: 9.5223e-06\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0845e-04 - val_loss: 9.9557e-06\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.9705e-04 - val_loss: 1.9464e-05\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8276e-04 - val_loss: 1.0567e-05\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.6247e-04 - val_loss: 9.7249e-06\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5741e-04 - val_loss: 1.1952e-05\n",
      "Thời gian huấn luyện:  16.933021068572998\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_21 (SimpleRNN)   (None, 10, 116)           13688     \n",
      "                                                                 \n",
      " flatten_85 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,849\n",
      "Trainable params: 14,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 16ms/step - loss: 0.0261 - val_loss: 9.6227e-04\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 8.9390e-04 - val_loss: 4.4316e-05\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 7.2324e-04 - val_loss: 3.9294e-05\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 7.2175e-04 - val_loss: 3.5345e-05\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 7.2029e-04 - val_loss: 3.6960e-05\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.9509e-04 - val_loss: 3.5742e-05\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.8642e-04 - val_loss: 2.7632e-05\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.9280e-04 - val_loss: 2.8640e-05\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.8384e-04 - val_loss: 2.9811e-05\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.8346e-04 - val_loss: 2.6745e-05\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.8468e-04 - val_loss: 3.4310e-05\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.7367e-04 - val_loss: 2.8560e-05\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 6.7771e-04 - val_loss: 3.2097e-05\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.7742e-04 - val_loss: 3.5907e-05\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.7867e-04 - val_loss: 3.3234e-05\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.8071e-04 - val_loss: 2.7257e-05\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 7.0172e-04 - val_loss: 2.6659e-05\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.5208e-04 - val_loss: 3.2155e-05\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.5036e-04 - val_loss: 3.0953e-05\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.6157e-04 - val_loss: 2.6095e-05\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.5077e-04 - val_loss: 2.6091e-05\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.6361e-04 - val_loss: 2.7331e-05\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.5053e-04 - val_loss: 2.5824e-05\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.4307e-04 - val_loss: 2.5714e-05\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.4702e-04 - val_loss: 2.6227e-05\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.4171e-04 - val_loss: 2.5654e-05\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.4305e-04 - val_loss: 3.0261e-05\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3820e-04 - val_loss: 2.5390e-05\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3417e-04 - val_loss: 2.5159e-05\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.5121e-04 - val_loss: 2.8411e-05\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.4977e-04 - val_loss: 2.5796e-05\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3463e-04 - val_loss: 2.7144e-05\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 6.3360e-04 - val_loss: 3.1311e-05\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.4437e-04 - val_loss: 2.5166e-05\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.2873e-04 - val_loss: 2.5321e-05\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.1789e-04 - val_loss: 2.9764e-05\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.0513e-04 - val_loss: 2.4969e-05\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.2730e-04 - val_loss: 2.8991e-05\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.1668e-04 - val_loss: 2.5596e-05\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.0639e-04 - val_loss: 2.5740e-05\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.0230e-04 - val_loss: 2.6303e-05\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.0594e-04 - val_loss: 3.1222e-05\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.0244e-04 - val_loss: 2.3751e-05\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.9313e-04 - val_loss: 2.6369e-05\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 6.0148e-04 - val_loss: 2.3648e-05\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.9857e-04 - val_loss: 2.6802e-05\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.8684e-04 - val_loss: 2.7584e-05\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.7936e-04 - val_loss: 2.4628e-05\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.8554e-04 - val_loss: 2.3258e-05\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.8130e-04 - val_loss: 2.5089e-05\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.8227e-04 - val_loss: 2.2899e-05\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.6606e-04 - val_loss: 2.8010e-05\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.7007e-04 - val_loss: 2.3699e-05\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.6141e-04 - val_loss: 2.5754e-05\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.6240e-04 - val_loss: 3.2836e-05\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.5848e-04 - val_loss: 2.2057e-05\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.5148e-04 - val_loss: 2.2123e-05\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.5441e-04 - val_loss: 2.2338e-05\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.4748e-04 - val_loss: 2.3390e-05\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.5174e-04 - val_loss: 2.1643e-05\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.5358e-04 - val_loss: 2.5249e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.3129e-04 - val_loss: 2.1120e-05\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.3180e-04 - val_loss: 2.1069e-05\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.2911e-04 - val_loss: 2.5685e-05\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.2865e-04 - val_loss: 2.6969e-05\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.2748e-04 - val_loss: 2.4274e-05\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.2391e-04 - val_loss: 2.0743e-05\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.1703e-04 - val_loss: 2.8237e-05\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.2531e-04 - val_loss: 2.2300e-05\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.1907e-04 - val_loss: 2.6453e-05\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.2347e-04 - val_loss: 3.2204e-05\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.2774e-04 - val_loss: 2.6831e-05\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.1905e-04 - val_loss: 2.0898e-05\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.0626e-04 - val_loss: 2.0749e-05\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.1084e-04 - val_loss: 2.0158e-05\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.9522e-04 - val_loss: 2.6277e-05\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.8720e-04 - val_loss: 2.6751e-05\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.7972e-04 - val_loss: 1.9304e-05\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.0361e-04 - val_loss: 2.8030e-05\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.8150e-04 - val_loss: 2.3558e-05\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.6569e-04 - val_loss: 2.3089e-05\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.8537e-04 - val_loss: 1.9074e-05\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.7467e-04 - val_loss: 2.6119e-05\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.5805e-04 - val_loss: 2.2001e-05\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.9898e-04 - val_loss: 1.9039e-05\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.6598e-04 - val_loss: 2.0950e-05\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.6181e-04 - val_loss: 1.8395e-05\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.4471e-04 - val_loss: 1.7891e-05\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.5424e-04 - val_loss: 2.4079e-05\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.0421e-04 - val_loss: 2.2888e-05\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.6410e-04 - val_loss: 2.4219e-05\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.2974e-04 - val_loss: 1.8395e-05\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.4774e-04 - val_loss: 1.7528e-05\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.3798e-04 - val_loss: 1.8218e-05\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.4356e-04 - val_loss: 1.7928e-05\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.2866e-04 - val_loss: 1.8282e-05\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.3650e-04 - val_loss: 2.0245e-05\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.1458e-04 - val_loss: 1.7791e-05\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.1738e-04 - val_loss: 2.4609e-05\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.1559e-04 - val_loss: 1.8021e-05\n",
      "Thời gian huấn luyện:  41.69422149658203\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_21 (LSTM)              (None, 10, 116)           54752     \n",
      "                                                                 \n",
      " flatten_86 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,913\n",
      "Trainable params: 55,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 15ms/step - loss: 0.0204 - val_loss: 4.2807e-04\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 7.3502e-04 - val_loss: 4.2383e-05\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 6.2475e-04 - val_loss: 2.4781e-05\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 6.1898e-04 - val_loss: 2.4428e-05\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 6.0913e-04 - val_loss: 2.4248e-05\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 6.2107e-04 - val_loss: 2.5857e-05\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.9590e-04 - val_loss: 2.7356e-05\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.9599e-04 - val_loss: 2.3748e-05\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 6.0135e-04 - val_loss: 4.5713e-05\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 6.0203e-04 - val_loss: 2.4046e-05\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.9720e-04 - val_loss: 2.4462e-05\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.8162e-04 - val_loss: 2.7370e-05\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.7665e-04 - val_loss: 3.0662e-05\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.7493e-04 - val_loss: 2.5425e-05\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.7284e-04 - val_loss: 2.5724e-05\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.6412e-04 - val_loss: 2.8884e-05\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.6205e-04 - val_loss: 2.2913e-05\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.6323e-04 - val_loss: 2.2207e-05\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.6604e-04 - val_loss: 2.2235e-05\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.5110e-04 - val_loss: 2.1991e-05\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.4281e-04 - val_loss: 2.6497e-05\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.3778e-04 - val_loss: 2.3475e-05\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.3179e-04 - val_loss: 2.2987e-05\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.2929e-04 - val_loss: 2.1850e-05\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.3563e-04 - val_loss: 2.0914e-05\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.2027e-04 - val_loss: 2.0864e-05\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.1721e-04 - val_loss: 2.4366e-05\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.1183e-04 - val_loss: 2.0806e-05\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.0490e-04 - val_loss: 2.2069e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.0728e-04 - val_loss: 2.0474e-05\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.9955e-04 - val_loss: 2.2298e-05\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.9223e-04 - val_loss: 2.1964e-05\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.8727e-04 - val_loss: 2.3961e-05\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.8328e-04 - val_loss: 2.4419e-05\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.8360e-04 - val_loss: 2.0819e-05\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.8523e-04 - val_loss: 2.0616e-05\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.7336e-04 - val_loss: 1.9364e-05\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.8694e-04 - val_loss: 2.6155e-05\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.8321e-04 - val_loss: 1.8988e-05\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.5592e-04 - val_loss: 2.1715e-05\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.5699e-04 - val_loss: 2.1295e-05\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.5648e-04 - val_loss: 2.0017e-05\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.5294e-04 - val_loss: 1.9325e-05\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.3829e-04 - val_loss: 1.7678e-05\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.4042e-04 - val_loss: 2.3903e-05\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.3252e-04 - val_loss: 2.7922e-05\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.4012e-04 - val_loss: 3.8054e-05\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.3286e-04 - val_loss: 1.6782e-05\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.3617e-04 - val_loss: 1.7107e-05\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.2131e-04 - val_loss: 1.8030e-05\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.3033e-04 - val_loss: 3.2135e-05\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.1804e-04 - val_loss: 2.9696e-05\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.0835e-04 - val_loss: 2.7663e-05\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.9967e-04 - val_loss: 2.6137e-05\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.9494e-04 - val_loss: 1.6109e-05\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.8725e-04 - val_loss: 1.8900e-05\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.9424e-04 - val_loss: 2.5057e-05\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.9860e-04 - val_loss: 1.9643e-05\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.7843e-04 - val_loss: 1.5579e-05\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.7177e-04 - val_loss: 1.5094e-05\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.7570e-04 - val_loss: 1.8211e-05\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.7526e-04 - val_loss: 2.5575e-05\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.6531e-04 - val_loss: 1.4751e-05\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.5808e-04 - val_loss: 2.2303e-05\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.9760e-04 - val_loss: 4.6111e-05\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.6273e-04 - val_loss: 1.5677e-05\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.5344e-04 - val_loss: 2.0727e-05\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.5825e-04 - val_loss: 1.4332e-05\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.5132e-04 - val_loss: 1.6418e-05\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.4060e-04 - val_loss: 1.4618e-05\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.3938e-04 - val_loss: 1.5600e-05\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.6603e-04 - val_loss: 1.8802e-05\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.3109e-04 - val_loss: 1.6237e-05\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.3287e-04 - val_loss: 1.6230e-05\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.2772e-04 - val_loss: 1.5123e-05\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.2444e-04 - val_loss: 2.0149e-05\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.5213e-04 - val_loss: 1.9472e-05\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.3171e-04 - val_loss: 1.4638e-05\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.2712e-04 - val_loss: 2.0785e-05\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.1065e-04 - val_loss: 2.9675e-05\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.2130e-04 - val_loss: 2.4402e-05\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.2103e-04 - val_loss: 1.2680e-05\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.0786e-04 - val_loss: 3.0176e-05\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.0510e-04 - val_loss: 3.9388e-05\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.0105e-04 - val_loss: 1.5007e-05\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.0714e-04 - val_loss: 1.2596e-05\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.9805e-04 - val_loss: 1.6618e-05\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.9744e-04 - val_loss: 1.7868e-05\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.0648e-04 - val_loss: 1.3253e-05\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.9399e-04 - val_loss: 1.4217e-05\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.9476e-04 - val_loss: 3.6481e-05\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.0266e-04 - val_loss: 1.1886e-05\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.0471e-04 - val_loss: 1.3655e-05\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.9469e-04 - val_loss: 1.1975e-05\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.9692e-04 - val_loss: 1.1613e-05\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.7912e-04 - val_loss: 7.3397e-05\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.9483e-04 - val_loss: 1.4578e-05\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.7576e-04 - val_loss: 2.3966e-05\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.8241e-04 - val_loss: 2.3925e-05\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.9162e-04 - val_loss: 1.2963e-05\n",
      "Thời gian huấn luyện:  37.632341146469116\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_21 (GRU)                (None, 10, 116)           41412     \n",
      "                                                                 \n",
      " flatten_87 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_109 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,573\n",
      "Trainable params: 42,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 865us/step\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "52/52 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0678 - val_loss: 0.0369\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0126\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 9.8272e-04 - val_loss: 4.7342e-04\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 6.5218e-04 - val_loss: 1.3751e-04\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.6602e-04 - val_loss: 7.1130e-05\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.4551e-04 - val_loss: 4.4499e-05\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.3898e-04 - val_loss: 2.6265e-05\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.2977e-04 - val_loss: 2.7152e-05\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.3166e-04 - val_loss: 2.3719e-05\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.2512e-04 - val_loss: 2.3302e-05\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.2502e-04 - val_loss: 2.4788e-05\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.2163e-04 - val_loss: 2.2892e-05\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.1767e-04 - val_loss: 2.4347e-05\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.1788e-04 - val_loss: 3.3879e-05\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.1577e-04 - val_loss: 2.6931e-05\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.1338e-04 - val_loss: 3.3884e-05\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.1612e-04 - val_loss: 3.3620e-05\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.1119e-04 - val_loss: 2.7740e-05\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.0748e-04 - val_loss: 2.4858e-05\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.0814e-04 - val_loss: 2.5393e-05\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.0701e-04 - val_loss: 2.3358e-05\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.0500e-04 - val_loss: 3.0892e-05\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.0539e-04 - val_loss: 2.2492e-05\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.0449e-04 - val_loss: 2.3265e-05\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.0302e-04 - val_loss: 2.2617e-05\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.0154e-04 - val_loss: 2.4279e-05\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.9685e-04 - val_loss: 2.3995e-05\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.0254e-04 - val_loss: 3.4894e-05\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.9654e-04 - val_loss: 2.6359e-05\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.9267e-04 - val_loss: 2.9118e-05\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.9090e-04 - val_loss: 3.4101e-05\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.8983e-04 - val_loss: 2.9285e-05\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.9426e-04 - val_loss: 2.1884e-05\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.9489e-04 - val_loss: 2.6637e-05\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.8800e-04 - val_loss: 2.2594e-05\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.8458e-04 - val_loss: 2.5127e-05\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.8470e-04 - val_loss: 2.9544e-05\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.8414e-04 - val_loss: 2.2558e-05\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.8272e-04 - val_loss: 2.1603e-05\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.7907e-04 - val_loss: 2.4065e-05\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.7792e-04 - val_loss: 2.5113e-05\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.7747e-04 - val_loss: 2.7688e-05\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.7601e-04 - val_loss: 2.1422e-05\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.7110e-04 - val_loss: 2.2103e-05\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.6895e-04 - val_loss: 2.2610e-05\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.6632e-04 - val_loss: 4.7452e-05\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.7452e-04 - val_loss: 2.0854e-05\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.6719e-04 - val_loss: 2.8336e-05\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.6757e-04 - val_loss: 2.4831e-05\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.6668e-04 - val_loss: 2.7452e-05\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.7240e-04 - val_loss: 2.3745e-05\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.5946e-04 - val_loss: 2.3894e-05\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.5591e-04 - val_loss: 2.3759e-05\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.5396e-04 - val_loss: 2.3986e-05\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.5251e-04 - val_loss: 3.2148e-05\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.5971e-04 - val_loss: 3.0144e-05\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.5053e-04 - val_loss: 2.7216e-05\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.5125e-04 - val_loss: 2.0605e-05\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.5142e-04 - val_loss: 2.1177e-05\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.3984e-04 - val_loss: 4.1531e-05\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.5000e-04 - val_loss: 2.9603e-05\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.3780e-04 - val_loss: 2.2523e-05\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.3487e-04 - val_loss: 2.8293e-05\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.4111e-04 - val_loss: 1.9417e-05\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.3678e-04 - val_loss: 2.1724e-05\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.2921e-04 - val_loss: 3.0695e-05\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.3295e-04 - val_loss: 2.5675e-05\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 2ms/step - loss: 4.4339e-04 - val_loss: 3.3790e-05\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.2629e-04 - val_loss: 1.9213e-05\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.2349e-04 - val_loss: 1.9179e-05\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.2986e-04 - val_loss: 2.0785e-05\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.2191e-04 - val_loss: 2.0065e-05\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.1697e-04 - val_loss: 2.6463e-05\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.1561e-04 - val_loss: 3.1441e-05\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.1527e-04 - val_loss: 1.8911e-05\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.1150e-04 - val_loss: 2.2570e-05\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.1204e-04 - val_loss: 2.4391e-05\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.0966e-04 - val_loss: 4.7475e-05\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.0632e-04 - val_loss: 2.8989e-05\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.0257e-04 - val_loss: 1.8241e-05\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.0135e-04 - val_loss: 4.2476e-05\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.0555e-04 - val_loss: 2.2439e-05\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.9658e-04 - val_loss: 1.9132e-05\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.9435e-04 - val_loss: 1.9659e-05\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.9941e-04 - val_loss: 1.9422e-05\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.9265e-04 - val_loss: 2.5038e-05\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.8971e-04 - val_loss: 1.7519e-05\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.9532e-04 - val_loss: 2.0730e-05\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.7845e-04 - val_loss: 2.0087e-05\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.8223e-04 - val_loss: 3.6386e-05\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.8368e-04 - val_loss: 2.0891e-05\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.8050e-04 - val_loss: 3.2002e-05\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.8282e-04 - val_loss: 1.6552e-05\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.7315e-04 - val_loss: 2.1536e-05\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.7743e-04 - val_loss: 1.6380e-05\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.7260e-04 - val_loss: 1.7002e-05\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.6600e-04 - val_loss: 2.3269e-05\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.6814e-04 - val_loss: 1.7014e-05\n",
      "Thời gian huấn luyện:  8.820304155349731\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_110 (Dense)           (None, 10, 116)           232       \n",
      "                                                                 \n",
      " flatten_88 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 1.6156e-04\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.6241e-04 - val_loss: 1.6788e-04\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.2858e-04 - val_loss: 7.4460e-05\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.2105e-04 - val_loss: 3.4685e-05\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.7568e-04 - val_loss: 2.6344e-05\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.4510e-04 - val_loss: 2.5414e-05\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.8332e-04 - val_loss: 2.3487e-05\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.6609e-04 - val_loss: 2.2545e-05\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.6734e-04 - val_loss: 2.1589e-05\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.1829e-04 - val_loss: 2.5992e-05\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.9867e-04 - val_loss: 1.9652e-05\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.6839e-04 - val_loss: 1.8447e-05\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.8766e-04 - val_loss: 1.7485e-05\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.5846e-04 - val_loss: 2.1013e-05\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.0825e-04 - val_loss: 1.7748e-05\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.3396e-04 - val_loss: 1.7207e-05\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.5077e-04 - val_loss: 1.6611e-05\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.2176e-04 - val_loss: 1.6129e-05\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1977e-04 - val_loss: 1.5817e-05\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.2418e-04 - val_loss: 1.5926e-05\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.9640e-04 - val_loss: 1.7180e-05\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.2501e-04 - val_loss: 1.4787e-05\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.6219e-04 - val_loss: 1.4387e-05\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1650e-04 - val_loss: 2.4517e-05\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.2858e-04 - val_loss: 1.6695e-05\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.8442e-04 - val_loss: 1.3123e-05\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.8389e-04 - val_loss: 1.5136e-05\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.3714e-04 - val_loss: 1.3530e-05\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.5922e-04 - val_loss: 1.3243e-05\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.0074e-04 - val_loss: 1.3485e-05\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.4011e-04 - val_loss: 1.4114e-05\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.5652e-04 - val_loss: 1.4137e-05\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.5023e-04 - val_loss: 1.3883e-05\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.1048e-04 - val_loss: 1.2710e-05\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.2379e-04 - val_loss: 1.2237e-05\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.1268e-04 - val_loss: 1.3374e-05\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.7595e-04 - val_loss: 1.3015e-05\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0520e-04 - val_loss: 1.3711e-05\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9350e-04 - val_loss: 1.5171e-05\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9174e-04 - val_loss: 1.1696e-05\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0105e-04 - val_loss: 1.1358e-05\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9169e-04 - val_loss: 1.1074e-05\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0422e-04 - val_loss: 1.2430e-05\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.1168e-04 - val_loss: 2.0901e-05\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.1193e-04 - val_loss: 1.0610e-05\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7183e-04 - val_loss: 1.1241e-05\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6368e-04 - val_loss: 1.1774e-05\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8243e-04 - val_loss: 1.1242e-05\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5989e-04 - val_loss: 1.0756e-05\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5579e-04 - val_loss: 1.0389e-05\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7227e-04 - val_loss: 1.0663e-05\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6104e-04 - val_loss: 1.1698e-05\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7834e-04 - val_loss: 1.6984e-05\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8396e-04 - val_loss: 9.7972e-06\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7261e-04 - val_loss: 1.1878e-05\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9901e-04 - val_loss: 9.4776e-06\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5332e-04 - val_loss: 1.0525e-05\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6098e-04 - val_loss: 1.1435e-05\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6729e-04 - val_loss: 9.8413e-06\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6063e-04 - val_loss: 9.6334e-06\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5043e-04 - val_loss: 9.8351e-06\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5512e-04 - val_loss: 1.1687e-05\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.4453e-04 - val_loss: 9.3904e-06\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7170e-04 - val_loss: 1.1130e-05\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5220e-04 - val_loss: 8.9336e-06\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.4676e-04 - val_loss: 8.9896e-06\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.4386e-04 - val_loss: 1.1132e-05\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.4258e-04 - val_loss: 2.6134e-05\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3774e-04 - val_loss: 8.8727e-06\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5866e-04 - val_loss: 1.1007e-05\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7943e-04 - val_loss: 8.5729e-06\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6108e-04 - val_loss: 1.3453e-05\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2414e-04 - val_loss: 1.2621e-05\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2090e-04 - val_loss: 1.8910e-05\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5053e-04 - val_loss: 8.4172e-06\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2152e-04 - val_loss: 8.3740e-06\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2794e-04 - val_loss: 8.7531e-06\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2315e-04 - val_loss: 9.3032e-06\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3503e-04 - val_loss: 9.0611e-06\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5348e-04 - val_loss: 8.6060e-06\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.4704e-04 - val_loss: 8.9634e-06\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3514e-04 - val_loss: 9.5866e-06\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6978e-04 - val_loss: 1.8033e-05\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.4663e-04 - val_loss: 1.4907e-05\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2813e-04 - val_loss: 1.1227e-05\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1767e-04 - val_loss: 1.1029e-05\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0437e-04 - val_loss: 9.2419e-06\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1922e-04 - val_loss: 9.0861e-06\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3648e-04 - val_loss: 8.0449e-06\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0861e-04 - val_loss: 8.5079e-06\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1867e-04 - val_loss: 1.1231e-05\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3077e-04 - val_loss: 1.0736e-05\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1481e-04 - val_loss: 1.0706e-05\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2109e-04 - val_loss: 8.1786e-06\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0384e-04 - val_loss: 7.9156e-06\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9798e-04 - val_loss: 1.0643e-05\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9798e-04 - val_loss: 8.3317e-06\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9394e-04 - val_loss: 8.0480e-06\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0227e-04 - val_loss: 8.0296e-06\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0143e-04 - val_loss: 8.1278e-06\n",
      "Thời gian huấn luyện:  16.949541330337524\n",
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_22 (SimpleRNN)   (None, 10, 116)           13688     \n",
      "                                                                 \n",
      " flatten_89 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,849\n",
      "Trainable params: 14,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 2s 16ms/step - loss: 0.0231 - val_loss: 9.7181e-04\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 9.6231e-04 - val_loss: 4.4902e-05\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.7523e-04 - val_loss: 3.7320e-05\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.5342e-04 - val_loss: 3.2712e-05\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.5973e-04 - val_loss: 6.3451e-05\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 8ms/step - loss: 7.6373e-04 - val_loss: 3.2957e-05\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.5454e-04 - val_loss: 3.6204e-05\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.3683e-04 - val_loss: 3.2160e-05\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.3645e-04 - val_loss: 3.3284e-05\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.3985e-04 - val_loss: 3.3898e-05\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.4708e-04 - val_loss: 3.7375e-05\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.2708e-04 - val_loss: 3.2945e-05\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.2790e-04 - val_loss: 3.2293e-05\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.2612e-04 - val_loss: 3.1858e-05\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.2189e-04 - val_loss: 3.2156e-05\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.2135e-04 - val_loss: 4.6100e-05\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.2286e-04 - val_loss: 3.1927e-05\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.1027e-04 - val_loss: 3.6973e-05\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.1605e-04 - val_loss: 3.4146e-05\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.0699e-04 - val_loss: 3.2179e-05\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.3065e-04 - val_loss: 3.1788e-05\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.0116e-04 - val_loss: 3.1873e-05\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.0683e-04 - val_loss: 3.1713e-05\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.8463e-04 - val_loss: 3.7693e-05\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.1367e-04 - val_loss: 3.2370e-05\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.9219e-04 - val_loss: 3.0925e-05\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.8521e-04 - val_loss: 3.1274e-05\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.8960e-04 - val_loss: 3.2955e-05\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.7669e-04 - val_loss: 3.5512e-05\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.8587e-04 - val_loss: 3.0773e-05\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.8277e-04 - val_loss: 3.0377e-05\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.7388e-04 - val_loss: 3.4265e-05\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.6663e-04 - val_loss: 3.1352e-05\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.5863e-04 - val_loss: 3.0071e-05\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.7138e-04 - val_loss: 3.5641e-05\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.6269e-04 - val_loss: 3.2228e-05\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.7306e-04 - val_loss: 3.0080e-05\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.5772e-04 - val_loss: 3.0534e-05\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.7592e-04 - val_loss: 3.0117e-05\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.8153e-04 - val_loss: 3.6388e-05\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.7107e-04 - val_loss: 2.8975e-05\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.5242e-04 - val_loss: 2.9396e-05\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.5734e-04 - val_loss: 3.0612e-05\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.4066e-04 - val_loss: 3.9004e-05\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.5260e-04 - val_loss: 2.8828e-05\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.6876e-04 - val_loss: 2.8734e-05\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.2452e-04 - val_loss: 2.8255e-05\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.2280e-04 - val_loss: 2.9040e-05\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.2930e-04 - val_loss: 3.3695e-05\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.1187e-04 - val_loss: 3.0046e-05\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.2492e-04 - val_loss: 3.5904e-05\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.0916e-04 - val_loss: 2.7695e-05\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.2355e-04 - val_loss: 2.7399e-05\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.3055e-04 - val_loss: 3.3135e-05\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.0519e-04 - val_loss: 3.7381e-05\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.1280e-04 - val_loss: 2.8514e-05\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.8797e-04 - val_loss: 2.7203e-05\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.8262e-04 - val_loss: 3.3116e-05\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.1374e-04 - val_loss: 2.6652e-05\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.8648e-04 - val_loss: 3.3626e-05\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.9607e-04 - val_loss: 2.6216e-05\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.8117e-04 - val_loss: 4.6811e-05\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.7998e-04 - val_loss: 3.8769e-05\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.7700e-04 - val_loss: 2.6559e-05\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.7263e-04 - val_loss: 2.5877e-05\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.5833e-04 - val_loss: 2.7610e-05\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.9882e-04 - val_loss: 2.8284e-05\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.6821e-04 - val_loss: 2.7294e-05\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.5993e-04 - val_loss: 2.7706e-05\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.4717e-04 - val_loss: 2.5873e-05\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.5019e-04 - val_loss: 3.0064e-05\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.4477e-04 - val_loss: 2.5498e-05\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.3552e-04 - val_loss: 2.4750e-05\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.9833e-04 - val_loss: 2.5677e-05\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.4836e-04 - val_loss: 2.4164e-05\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.2401e-04 - val_loss: 2.7933e-05\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.1902e-04 - val_loss: 2.9792e-05\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.4431e-04 - val_loss: 2.6023e-05\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.2430e-04 - val_loss: 2.9479e-05\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.2017e-04 - val_loss: 2.5865e-05\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.3669e-04 - val_loss: 2.7590e-05\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 8ms/step - loss: 5.1046e-04 - val_loss: 2.4080e-05\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.0071e-04 - val_loss: 2.7341e-05\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.1459e-04 - val_loss: 2.4390e-05\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.1156e-04 - val_loss: 2.4913e-05\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.8662e-04 - val_loss: 2.7877e-05\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.8275e-04 - val_loss: 2.2487e-05\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.8188e-04 - val_loss: 2.5120e-05\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.9697e-04 - val_loss: 2.2633e-05\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.8363e-04 - val_loss: 2.6257e-05\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.7506e-04 - val_loss: 2.6497e-05\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.9366e-04 - val_loss: 2.3785e-05\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.7229e-04 - val_loss: 2.2625e-05\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.6347e-04 - val_loss: 2.3687e-05\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.6509e-04 - val_loss: 2.2835e-05\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.6986e-04 - val_loss: 2.1418e-05\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.6164e-04 - val_loss: 2.1565e-05\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.7248e-04 - val_loss: 2.7346e-05\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.9705e-04 - val_loss: 3.5054e-05\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.5169e-04 - val_loss: 2.2703e-05\n",
      "Thời gian huấn luyện:  38.15793013572693\n",
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_22 (LSTM)              (None, 10, 116)           54752     \n",
      "                                                                 \n",
      " flatten_90 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,913\n",
      "Trainable params: 55,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 2s 15ms/step - loss: 0.0190 - val_loss: 7.7541e-04\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.6596e-04 - val_loss: 5.9519e-05\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.3460e-04 - val_loss: 4.0969e-05\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.2755e-04 - val_loss: 2.8572e-05\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.2906e-04 - val_loss: 3.5720e-05\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.1685e-04 - val_loss: 2.7639e-05\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.1352e-04 - val_loss: 2.7731e-05\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.1097e-04 - val_loss: 2.7411e-05\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.0771e-04 - val_loss: 2.8073e-05\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.0786e-04 - val_loss: 3.3689e-05\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.9952e-04 - val_loss: 2.6718e-05\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.8928e-04 - val_loss: 2.7812e-05\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.8657e-04 - val_loss: 2.8233e-05\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.8854e-04 - val_loss: 2.6234e-05\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.8488e-04 - val_loss: 2.7102e-05\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.7595e-04 - val_loss: 2.6045e-05\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.7754e-04 - val_loss: 3.1210e-05\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.7157e-04 - val_loss: 3.3002e-05\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.6743e-04 - val_loss: 5.2236e-05\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.5868e-04 - val_loss: 4.0210e-05\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.5227e-04 - val_loss: 2.8101e-05\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.5102e-04 - val_loss: 2.4854e-05\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.4398e-04 - val_loss: 2.4825e-05\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.3949e-04 - val_loss: 2.9069e-05\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.4018e-04 - val_loss: 3.4944e-05\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.3099e-04 - val_loss: 3.7095e-05\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.4536e-04 - val_loss: 2.6757e-05\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.3072e-04 - val_loss: 2.4249e-05\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.2494e-04 - val_loss: 3.0870e-05\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.2122e-04 - val_loss: 3.0940e-05\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.1225e-04 - val_loss: 2.6449e-05\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.2912e-04 - val_loss: 2.3827e-05\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.1313e-04 - val_loss: 3.7838e-05\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 5.0215e-04 - val_loss: 2.9235e-05\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.9610e-04 - val_loss: 2.2834e-05\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.9494e-04 - val_loss: 2.4571e-05\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.9316e-04 - val_loss: 2.2123e-05\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.9308e-04 - val_loss: 2.4552e-05\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.9010e-04 - val_loss: 2.2226e-05\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.7939e-04 - val_loss: 2.2405e-05\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.9187e-04 - val_loss: 4.3687e-05\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.7407e-04 - val_loss: 2.3080e-05\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.5556e-04 - val_loss: 2.3441e-05\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.6330e-04 - val_loss: 3.3737e-05\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.6749e-04 - val_loss: 2.9027e-05\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.5645e-04 - val_loss: 2.3566e-05\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.5590e-04 - val_loss: 2.7150e-05\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.4049e-04 - val_loss: 2.1150e-05\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.3581e-04 - val_loss: 2.0302e-05\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 8ms/step - loss: 4.3727e-04 - val_loss: 2.2086e-05\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.3847e-04 - val_loss: 2.6644e-05\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.1726e-04 - val_loss: 3.1796e-05\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.2827e-04 - val_loss: 3.8685e-05\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.1754e-04 - val_loss: 2.5757e-05\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.1261e-04 - val_loss: 4.5060e-05\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.0635e-04 - val_loss: 3.5583e-05\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.0925e-04 - val_loss: 3.2536e-05\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.0730e-04 - val_loss: 2.5724e-05\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.0135e-04 - val_loss: 3.0510e-05\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.8475e-04 - val_loss: 1.8109e-05\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 4.0501e-04 - val_loss: 6.9171e-05\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.9698e-04 - val_loss: 3.4138e-05\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.7818e-04 - val_loss: 1.9213e-05\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.7824e-04 - val_loss: 3.8899e-05\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.8385e-04 - val_loss: 1.8889e-05\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.7989e-04 - val_loss: 1.7896e-05\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.7734e-04 - val_loss: 2.1789e-05\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.7383e-04 - val_loss: 2.5393e-05\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.7583e-04 - val_loss: 1.8480e-05\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.7183e-04 - val_loss: 5.0753e-05\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.6075e-04 - val_loss: 2.4827e-05\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.5841e-04 - val_loss: 4.5044e-05\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.5463e-04 - val_loss: 3.6021e-05\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.4802e-04 - val_loss: 1.8989e-05\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.5142e-04 - val_loss: 2.5504e-05\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.4681e-04 - val_loss: 1.8254e-05\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.4818e-04 - val_loss: 2.1902e-05\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.4566e-04 - val_loss: 4.2292e-05\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.4703e-04 - val_loss: 4.2332e-05\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.4066e-04 - val_loss: 1.7302e-05\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.5371e-04 - val_loss: 8.4381e-05\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.9319e-04 - val_loss: 1.8124e-05\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.3416e-04 - val_loss: 3.1174e-05\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.2654e-04 - val_loss: 1.9877e-05\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.1953e-04 - val_loss: 2.3330e-05\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.1385e-04 - val_loss: 3.7036e-05\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.2415e-04 - val_loss: 1.5576e-05\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.2281e-04 - val_loss: 1.5673e-05\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.1705e-04 - val_loss: 2.9138e-05\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.1569e-04 - val_loss: 2.4237e-05\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.0977e-04 - val_loss: 2.3053e-05\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.1686e-04 - val_loss: 1.4924e-05\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.0932e-04 - val_loss: 3.3021e-05\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.1075e-04 - val_loss: 2.5191e-05\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 2.9714e-04 - val_loss: 2.8754e-05\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.1307e-04 - val_loss: 1.8465e-05\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.0228e-04 - val_loss: 1.8097e-05\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.0149e-04 - val_loss: 1.8361e-05\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 2.9608e-04 - val_loss: 2.5061e-05\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 2.9304e-04 - val_loss: 2.3028e-05\n",
      "Thời gian huấn luyện:  36.06538796424866\n",
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_22 (GRU)                (None, 10, 116)           41412     \n",
      "                                                                 \n",
      " flatten_91 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,573\n",
      "Trainable params: 42,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 927us/step\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "41/41 [==============================] - 1s 4ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 21/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 22/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 23/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 24/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 25/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 26/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 27/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 28/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 29/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 30/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 31/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 32/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 33/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 34/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 35/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 36/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 37/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 38/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 39/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 40/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 41/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 42/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 43/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 44/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 45/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 46/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 47/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 48/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 49/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 50/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 51/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 52/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 53/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 54/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 55/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 56/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 57/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 58/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 59/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 60/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 61/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 62/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 63/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 64/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 65/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 66/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 67/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 68/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 69/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 70/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 71/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 72/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 73/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 74/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 75/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 76/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 77/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 78/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 79/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 80/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 81/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 82/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 83/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 84/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 85/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 86/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 87/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 88/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 89/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 90/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 91/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 92/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 93/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 94/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 95/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 96/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 98/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 99/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 100/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Thời gian huấn luyện:  8.893215417861938\n",
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_115 (Dense)           (None, 10, 116)           232       \n",
      "                                                                 \n",
      " flatten_92 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "41/41 [==============================] - 1s 7ms/step - loss: 0.0231 - val_loss: 9.1043e-04\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 9.1101e-04\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 6.5170e-04\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 6.4726e-04\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 5.2437e-04\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 4.4886e-04\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.7217e-04 - val_loss: 4.2934e-04\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.5382e-04 - val_loss: 3.9337e-04\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.9472e-04 - val_loss: 3.2878e-04\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.3577e-04 - val_loss: 2.5110e-04\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.0725e-04 - val_loss: 2.0432e-04\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.7885e-04 - val_loss: 2.1467e-04\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.6690e-04 - val_loss: 1.6032e-04\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.1898e-04 - val_loss: 1.5542e-04\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.9043e-04 - val_loss: 1.5090e-04\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.1584e-04 - val_loss: 1.0764e-04\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.4821e-04 - val_loss: 1.0751e-04\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.3661e-04 - val_loss: 7.2713e-05\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.1576e-04 - val_loss: 5.9355e-05\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.3575e-04 - val_loss: 7.0811e-05\n",
      "Epoch 21/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.5365e-04 - val_loss: 6.1491e-05\n",
      "Epoch 22/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.7368e-04 - val_loss: 4.2736e-05\n",
      "Epoch 23/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.6267e-04 - val_loss: 4.0410e-05\n",
      "Epoch 24/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.6758e-04 - val_loss: 4.8982e-05\n",
      "Epoch 25/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.5963e-04 - val_loss: 2.8393e-05\n",
      "Epoch 26/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.6133e-04 - val_loss: 3.9770e-05\n",
      "Epoch 27/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.2684e-04 - val_loss: 3.2225e-05\n",
      "Epoch 28/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.1642e-04 - val_loss: 3.8185e-05\n",
      "Epoch 29/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.2992e-04 - val_loss: 2.5398e-05\n",
      "Epoch 30/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.0266e-04 - val_loss: 2.2418e-05\n",
      "Epoch 31/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.2660e-04 - val_loss: 2.3873e-05\n",
      "Epoch 32/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.7154e-04 - val_loss: 3.6751e-05\n",
      "Epoch 33/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.0285e-04 - val_loss: 2.1762e-05\n",
      "Epoch 34/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.6993e-04 - val_loss: 2.8674e-05\n",
      "Epoch 35/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.8148e-04 - val_loss: 2.0626e-05\n",
      "Epoch 36/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.8629e-04 - val_loss: 2.2746e-05\n",
      "Epoch 37/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.9218e-04 - val_loss: 2.0538e-05\n",
      "Epoch 38/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.8943e-04 - val_loss: 3.2878e-05\n",
      "Epoch 39/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.2823e-04 - val_loss: 2.3129e-05\n",
      "Epoch 40/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.6653e-04 - val_loss: 2.2355e-05\n",
      "Epoch 41/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.2931e-04 - val_loss: 1.9216e-05\n",
      "Epoch 42/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.2487e-04 - val_loss: 1.8358e-05\n",
      "Epoch 43/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.4186e-04 - val_loss: 1.9010e-05\n",
      "Epoch 44/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.2916e-04 - val_loss: 2.0469e-05\n",
      "Epoch 45/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.1271e-04 - val_loss: 1.8229e-05\n",
      "Epoch 46/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.0558e-04 - val_loss: 1.6594e-05\n",
      "Epoch 47/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.5476e-04 - val_loss: 1.6380e-05\n",
      "Epoch 48/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.0416e-04 - val_loss: 2.2246e-05\n",
      "Epoch 49/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.2364e-04 - val_loss: 1.6794e-05\n",
      "Epoch 50/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.9469e-04 - val_loss: 1.5965e-05\n",
      "Epoch 51/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.1637e-04 - val_loss: 1.6479e-05\n",
      "Epoch 52/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.8103e-04 - val_loss: 1.8658e-05\n",
      "Epoch 53/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.7776e-04 - val_loss: 1.5641e-05\n",
      "Epoch 54/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.8128e-04 - val_loss: 1.5574e-05\n",
      "Epoch 55/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.6834e-04 - val_loss: 1.5213e-05\n",
      "Epoch 56/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.6083e-04 - val_loss: 1.7013e-05\n",
      "Epoch 57/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.8208e-04 - val_loss: 1.4886e-05\n",
      "Epoch 58/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.7088e-04 - val_loss: 1.5507e-05\n",
      "Epoch 59/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.5305e-04 - val_loss: 1.4510e-05\n",
      "Epoch 60/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.6647e-04 - val_loss: 1.5967e-05\n",
      "Epoch 61/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.5911e-04 - val_loss: 1.4563e-05\n",
      "Epoch 62/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.9361e-04 - val_loss: 1.7287e-05\n",
      "Epoch 63/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.6596e-04 - val_loss: 1.4700e-05\n",
      "Epoch 64/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.2820e-04 - val_loss: 1.9113e-05\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 4ms/step - loss: 3.4859e-04 - val_loss: 1.5124e-05\n",
      "Epoch 66/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.4629e-04 - val_loss: 1.8582e-05\n",
      "Epoch 67/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.4463e-04 - val_loss: 1.4622e-05\n",
      "Epoch 68/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.3156e-04 - val_loss: 1.3359e-05\n",
      "Epoch 69/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.3461e-04 - val_loss: 1.5754e-05\n",
      "Epoch 70/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.5237e-04 - val_loss: 1.7160e-05\n",
      "Epoch 71/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.2876e-04 - val_loss: 1.3603e-05\n",
      "Epoch 72/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.3283e-04 - val_loss: 1.4378e-05\n",
      "Epoch 73/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.3245e-04 - val_loss: 1.7807e-05\n",
      "Epoch 74/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.1508e-04 - val_loss: 1.4368e-05\n",
      "Epoch 75/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.1271e-04 - val_loss: 1.3710e-05\n",
      "Epoch 76/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.0662e-04 - val_loss: 1.5961e-05\n",
      "Epoch 77/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.2624e-04 - val_loss: 1.3067e-05\n",
      "Epoch 78/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.5322e-04 - val_loss: 2.0482e-05\n",
      "Epoch 79/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.4903e-04 - val_loss: 1.2900e-05\n",
      "Epoch 80/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.0123e-04 - val_loss: 1.2547e-05\n",
      "Epoch 81/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.3346e-04 - val_loss: 1.9291e-05\n",
      "Epoch 82/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.0647e-04 - val_loss: 1.4241e-05\n",
      "Epoch 83/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.0374e-04 - val_loss: 1.4923e-05\n",
      "Epoch 84/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.9448e-04 - val_loss: 1.2356e-05\n",
      "Epoch 85/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.1020e-04 - val_loss: 1.2767e-05\n",
      "Epoch 86/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.0509e-04 - val_loss: 1.8523e-05\n",
      "Epoch 87/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.2431e-04 - val_loss: 1.5909e-05\n",
      "Epoch 88/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.9719e-04 - val_loss: 1.2250e-05\n",
      "Epoch 89/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.7370e-04 - val_loss: 1.2785e-05\n",
      "Epoch 90/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.9114e-04 - val_loss: 1.1754e-05\n",
      "Epoch 91/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.0240e-04 - val_loss: 1.2208e-05\n",
      "Epoch 92/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.7787e-04 - val_loss: 1.9210e-05\n",
      "Epoch 93/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.9310e-04 - val_loss: 1.1497e-05\n",
      "Epoch 94/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.7952e-04 - val_loss: 1.2434e-05\n",
      "Epoch 95/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.7056e-04 - val_loss: 1.2824e-05\n",
      "Epoch 96/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.8083e-04 - val_loss: 1.0642e-05\n",
      "Epoch 97/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.8710e-04 - val_loss: 1.4006e-05\n",
      "Epoch 98/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.9457e-04 - val_loss: 1.2791e-05\n",
      "Epoch 99/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.6997e-04 - val_loss: 1.3017e-05\n",
      "Epoch 100/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.6471e-04 - val_loss: 1.1257e-05\n",
      "Thời gian huấn luyện:  16.84501314163208\n",
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_23 (SimpleRNN)   (None, 10, 116)           13688     \n",
      "                                                                 \n",
      " flatten_93 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,849\n",
      "Trainable params: 14,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "41/41 [==============================] - 2s 18ms/step - loss: 0.0316 - val_loss: 0.0015\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 2.9688e-04\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 8.1710e-04 - val_loss: 8.0885e-05\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 8.0363e-04 - val_loss: 8.1226e-05\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.8917e-04 - val_loss: 6.5871e-05\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.8284e-04 - val_loss: 4.1994e-05\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.7926e-04 - val_loss: 6.2127e-05\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.7667e-04 - val_loss: 6.3596e-05\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.7739e-04 - val_loss: 5.6383e-05\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.7293e-04 - val_loss: 6.0100e-05\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.6886e-04 - val_loss: 4.5198e-05\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.7991e-04 - val_loss: 3.6931e-05\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.7092e-04 - val_loss: 4.7806e-05\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.5651e-04 - val_loss: 3.2527e-05\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.6105e-04 - val_loss: 3.3638e-05\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.5389e-04 - val_loss: 3.7650e-05\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.4410e-04 - val_loss: 3.3301e-05\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.4310e-04 - val_loss: 3.1840e-05\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.7046e-04 - val_loss: 3.3699e-05\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.3791e-04 - val_loss: 3.4391e-05\n",
      "Epoch 21/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.3532e-04 - val_loss: 3.3065e-05\n",
      "Epoch 22/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.4541e-04 - val_loss: 3.3367e-05\n",
      "Epoch 23/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.3781e-04 - val_loss: 3.3544e-05\n",
      "Epoch 24/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.2862e-04 - val_loss: 3.2221e-05\n",
      "Epoch 25/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.2159e-04 - val_loss: 3.6087e-05\n",
      "Epoch 26/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.2965e-04 - val_loss: 3.5065e-05\n",
      "Epoch 27/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.7434e-04 - val_loss: 4.0149e-05\n",
      "Epoch 28/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.5042e-04 - val_loss: 3.1694e-05\n",
      "Epoch 29/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.1844e-04 - val_loss: 3.8991e-05\n",
      "Epoch 30/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.1292e-04 - val_loss: 3.1767e-05\n",
      "Epoch 31/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.0666e-04 - val_loss: 3.2244e-05\n",
      "Epoch 32/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.0524e-04 - val_loss: 3.4655e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.1804e-04 - val_loss: 3.5048e-05\n",
      "Epoch 34/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.9469e-04 - val_loss: 3.3612e-05\n",
      "Epoch 35/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.0342e-04 - val_loss: 3.2611e-05\n",
      "Epoch 36/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.8927e-04 - val_loss: 4.1860e-05\n",
      "Epoch 37/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.9573e-04 - val_loss: 3.6482e-05\n",
      "Epoch 38/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.9366e-04 - val_loss: 3.1919e-05\n",
      "Epoch 39/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.8593e-04 - val_loss: 4.0791e-05\n",
      "Epoch 40/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.8528e-04 - val_loss: 3.2560e-05\n",
      "Epoch 41/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.7557e-04 - val_loss: 3.3588e-05\n",
      "Epoch 42/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.7570e-04 - val_loss: 3.1922e-05\n",
      "Epoch 43/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.8097e-04 - val_loss: 3.2422e-05\n",
      "Epoch 44/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.7222e-04 - val_loss: 3.7182e-05\n",
      "Epoch 45/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.8834e-04 - val_loss: 3.5822e-05\n",
      "Epoch 46/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.7853e-04 - val_loss: 3.2945e-05\n",
      "Epoch 47/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.7518e-04 - val_loss: 4.1144e-05\n",
      "Epoch 48/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.5184e-04 - val_loss: 3.7505e-05\n",
      "Epoch 49/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.5669e-04 - val_loss: 3.1392e-05\n",
      "Epoch 50/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.5121e-04 - val_loss: 4.6648e-05\n",
      "Epoch 51/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.5342e-04 - val_loss: 3.3261e-05\n",
      "Epoch 52/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.3665e-04 - val_loss: 3.6116e-05\n",
      "Epoch 53/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.4087e-04 - val_loss: 3.4511e-05\n",
      "Epoch 54/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.4625e-04 - val_loss: 4.2486e-05\n",
      "Epoch 55/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.3172e-04 - val_loss: 4.0686e-05\n",
      "Epoch 56/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.2831e-04 - val_loss: 3.4937e-05\n",
      "Epoch 57/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.2452e-04 - val_loss: 3.0732e-05\n",
      "Epoch 58/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.4317e-04 - val_loss: 3.2339e-05\n",
      "Epoch 59/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.2291e-04 - val_loss: 3.0429e-05\n",
      "Epoch 60/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.2119e-04 - val_loss: 3.8829e-05\n",
      "Epoch 61/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.1766e-04 - val_loss: 3.4947e-05\n",
      "Epoch 62/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.1239e-04 - val_loss: 3.7718e-05\n",
      "Epoch 63/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.2956e-04 - val_loss: 4.1570e-05\n",
      "Epoch 64/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.0422e-04 - val_loss: 4.1948e-05\n",
      "Epoch 65/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.0326e-04 - val_loss: 3.5851e-05\n",
      "Epoch 66/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.1997e-04 - val_loss: 3.1463e-05\n",
      "Epoch 67/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.9353e-04 - val_loss: 3.8352e-05\n",
      "Epoch 68/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.9365e-04 - val_loss: 4.1815e-05\n",
      "Epoch 69/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.9415e-04 - val_loss: 4.1860e-05\n",
      "Epoch 70/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.8635e-04 - val_loss: 4.6549e-05\n",
      "Epoch 71/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.8802e-04 - val_loss: 3.6011e-05\n",
      "Epoch 72/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.7885e-04 - val_loss: 3.6225e-05\n",
      "Epoch 73/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.5861e-04 - val_loss: 2.9951e-05\n",
      "Epoch 74/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.5469e-04 - val_loss: 4.8767e-05\n",
      "Epoch 75/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.6910e-04 - val_loss: 6.5986e-05\n",
      "Epoch 76/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.7396e-04 - val_loss: 3.9348e-05\n",
      "Epoch 77/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.4250e-04 - val_loss: 3.4273e-05\n",
      "Epoch 78/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.3914e-04 - val_loss: 3.6286e-05\n",
      "Epoch 79/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.3698e-04 - val_loss: 2.6611e-05\n",
      "Epoch 80/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.3873e-04 - val_loss: 4.9627e-05\n",
      "Epoch 81/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.3403e-04 - val_loss: 3.9054e-05\n",
      "Epoch 82/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.4002e-04 - val_loss: 4.3852e-05\n",
      "Epoch 83/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.3325e-04 - val_loss: 4.7749e-05\n",
      "Epoch 84/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.1119e-04 - val_loss: 6.7106e-05\n",
      "Epoch 85/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.2045e-04 - val_loss: 3.7525e-05\n",
      "Epoch 86/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.2329e-04 - val_loss: 3.2646e-05\n",
      "Epoch 87/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.1535e-04 - val_loss: 4.8017e-05\n",
      "Epoch 88/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.2041e-04 - val_loss: 4.2378e-05\n",
      "Epoch 89/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.9291e-04 - val_loss: 2.6370e-05\n",
      "Epoch 90/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.9800e-04 - val_loss: 4.3556e-05\n",
      "Epoch 91/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.9998e-04 - val_loss: 3.4297e-05\n",
      "Epoch 92/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.9287e-04 - val_loss: 3.7173e-05\n",
      "Epoch 93/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.2510e-04 - val_loss: 6.0369e-05\n",
      "Epoch 94/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.4778e-04 - val_loss: 2.4279e-05\n",
      "Epoch 95/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.9136e-04 - val_loss: 2.5726e-05\n",
      "Epoch 96/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.8923e-04 - val_loss: 3.6456e-05\n",
      "Epoch 97/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.8504e-04 - val_loss: 3.4920e-05\n",
      "Epoch 98/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.7226e-04 - val_loss: 3.1487e-05\n",
      "Epoch 99/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.7519e-04 - val_loss: 2.5675e-05\n",
      "Epoch 100/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.5824e-04 - val_loss: 3.0785e-05\n",
      "Thời gian huấn luyện:  41.39924359321594\n",
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_23 (LSTM)              (None, 10, 116)           54752     \n",
      "                                                                 \n",
      " flatten_94 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,913\n",
      "Trainable params: 55,913\n",
      "Non-trainable params: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "41/41 [==============================] - 2s 16ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 21/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 22/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 23/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 24/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 25/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 26/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 27/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 28/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 29/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 30/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 31/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 32/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 33/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 34/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 35/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 36/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 37/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 38/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 39/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 40/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 41/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 42/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 43/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 44/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 45/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 46/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 47/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 48/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 49/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 50/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 51/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 52/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 53/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 54/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 55/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 56/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 57/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 58/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 59/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 60/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 61/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 62/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 63/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 64/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 65/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 66/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 67/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 68/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 69/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 70/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 71/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 72/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 73/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 74/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 75/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 76/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 77/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 78/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 79/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 80/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 81/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 83/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 84/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 85/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 86/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 87/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 88/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 89/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 90/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 91/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 92/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 93/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 94/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 95/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 96/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 97/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 98/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 99/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 100/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Thời gian huấn luyện:  38.19271755218506\n",
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_23 (GRU)                (None, 10, 116)           41412     \n",
      "                                                                 \n",
      " flatten_95 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,573\n",
      "Trainable params: 42,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 910us/step\n",
      "13/13 [==============================] - 0s 998us/step\n",
      "52/52 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 2/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 3/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 4/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 5/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 6/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 7/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 8/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 9/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 10/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 11/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 12/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 13/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 14/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 15/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 16/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 17/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 18/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 19/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 20/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 21/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 22/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 23/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 24/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 25/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 26/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 27/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 28/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 29/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 30/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 31/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 32/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 33/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 34/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 35/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 36/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 37/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 38/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 39/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 40/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 41/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 42/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 43/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 44/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 45/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 46/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 47/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 48/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 49/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 50/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 51/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 52/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 53/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 54/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 55/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 56/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 57/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 58/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 59/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 60/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 61/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 62/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 63/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 64/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 65/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 66/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 67/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 68/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 69/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 70/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 71/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 72/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 73/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 74/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 75/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 76/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 77/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 78/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 79/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 80/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 81/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 82/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 83/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 84/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 85/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 86/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 87/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 88/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 89/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 90/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 91/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 92/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 93/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 94/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 95/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 96/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 97/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 98/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 99/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 100/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 101/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 102/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 103/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 104/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 105/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 106/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 107/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 108/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 109/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 110/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 111/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 112/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 113/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 114/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 115/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 116/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 117/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 118/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 119/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 120/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 121/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 122/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 123/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 124/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 125/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 126/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 127/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 128/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 129/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 130/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 131/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 132/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 133/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 134/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 135/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 136/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 137/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 138/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 139/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 140/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 141/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 142/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 143/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 144/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 145/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 146/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 147/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 148/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 149/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 150/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 151/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 152/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 153/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 154/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 155/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 156/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 157/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 158/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 159/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 160/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 161/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 162/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 163/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 164/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 165/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 166/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 167/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 168/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 169/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 170/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 171/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 172/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 173/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 174/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 175/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 176/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 177/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 178/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 179/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 180/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 181/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 182/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 183/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 184/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 185/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 186/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 187/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 188/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 189/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 190/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 191/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 192/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 193/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 194/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 195/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 196/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 197/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 198/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 199/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 200/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Thời gian huấn luyện:  17.32113027572632\n",
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_120 (Dense)           (None, 10, 116)           232       \n",
      "                                                                 \n",
      " flatten_96 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "46/46 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 3.9411e-04\n",
      "Epoch 2/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.3795e-04 - val_loss: 2.3728e-04\n",
      "Epoch 3/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3786e-04 - val_loss: 1.2197e-04\n",
      "Epoch 4/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 6.2089e-04 - val_loss: 1.0911e-04\n",
      "Epoch 5/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5240e-04 - val_loss: 4.0936e-05\n",
      "Epoch 6/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.0392e-04 - val_loss: 2.9960e-05\n",
      "Epoch 7/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.7346e-04 - val_loss: 2.8808e-05\n",
      "Epoch 8/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4636e-04 - val_loss: 1.7107e-05\n",
      "Epoch 9/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4807e-04 - val_loss: 1.9194e-05\n",
      "Epoch 10/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2343e-04 - val_loss: 1.5073e-05\n",
      "Epoch 11/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1497e-04 - val_loss: 1.6015e-05\n",
      "Epoch 12/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.0194e-04 - val_loss: 1.4074e-05\n",
      "Epoch 13/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1384e-04 - val_loss: 1.5115e-05\n",
      "Epoch 14/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1812e-04 - val_loss: 1.3504e-05\n",
      "Epoch 15/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.0518e-04 - val_loss: 1.6214e-05\n",
      "Epoch 16/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.0360e-04 - val_loss: 1.3155e-05\n",
      "Epoch 17/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8421e-04 - val_loss: 1.4722e-05\n",
      "Epoch 18/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8476e-04 - val_loss: 1.2783e-05\n",
      "Epoch 19/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6857e-04 - val_loss: 1.2440e-05\n",
      "Epoch 20/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6194e-04 - val_loss: 1.3218e-05\n",
      "Epoch 21/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8280e-04 - val_loss: 1.1902e-05\n",
      "Epoch 22/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3184e-04 - val_loss: 1.2239e-05\n",
      "Epoch 23/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5424e-04 - val_loss: 1.2912e-05\n",
      "Epoch 24/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5443e-04 - val_loss: 1.3067e-05\n",
      "Epoch 25/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4506e-04 - val_loss: 1.2041e-05\n",
      "Epoch 26/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3562e-04 - val_loss: 1.2010e-05\n",
      "Epoch 27/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2026e-04 - val_loss: 1.8767e-05\n",
      "Epoch 28/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5426e-04 - val_loss: 1.3875e-05\n",
      "Epoch 29/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4116e-04 - val_loss: 1.4220e-05\n",
      "Epoch 30/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4829e-04 - val_loss: 1.0920e-05\n",
      "Epoch 31/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2614e-04 - val_loss: 1.2212e-05\n",
      "Epoch 32/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5874e-04 - val_loss: 1.3712e-05\n",
      "Epoch 33/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2778e-04 - val_loss: 1.1324e-05\n",
      "Epoch 34/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5290e-04 - val_loss: 1.2806e-05\n",
      "Epoch 35/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.1271e-04 - val_loss: 1.0409e-05\n",
      "Epoch 36/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.0331e-04 - val_loss: 1.0790e-05\n",
      "Epoch 37/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.1264e-04 - val_loss: 1.2618e-05\n",
      "Epoch 38/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.1595e-04 - val_loss: 1.1362e-05\n",
      "Epoch 39/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.9293e-04 - val_loss: 9.9941e-06\n",
      "Epoch 40/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.9075e-04 - val_loss: 9.8510e-06\n",
      "Epoch 41/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8674e-04 - val_loss: 1.0133e-05\n",
      "Epoch 42/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2543e-04 - val_loss: 1.3704e-05\n",
      "Epoch 43/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8113e-04 - val_loss: 1.3167e-05\n",
      "Epoch 44/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8338e-04 - val_loss: 1.5720e-05\n",
      "Epoch 45/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3871e-04 - val_loss: 1.2289e-05\n",
      "Epoch 46/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.0944e-04 - val_loss: 1.0889e-05\n",
      "Epoch 47/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.9824e-04 - val_loss: 1.1286e-05\n",
      "Epoch 48/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.7614e-04 - val_loss: 9.5493e-06\n",
      "Epoch 49/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.9365e-04 - val_loss: 9.8108e-06\n",
      "Epoch 50/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.9853e-04 - val_loss: 8.8140e-06\n",
      "Epoch 51/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.7795e-04 - val_loss: 8.9388e-06\n",
      "Epoch 52/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.6516e-04 - val_loss: 9.3612e-06\n",
      "Epoch 53/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5677e-04 - val_loss: 8.7005e-06\n",
      "Epoch 54/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.7992e-04 - val_loss: 1.0510e-05\n",
      "Epoch 55/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5153e-04 - val_loss: 8.5099e-06\n",
      "Epoch 56/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5630e-04 - val_loss: 9.1345e-06\n",
      "Epoch 57/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5941e-04 - val_loss: 8.5234e-06\n",
      "Epoch 58/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.7311e-04 - val_loss: 1.5663e-05\n",
      "Epoch 59/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5533e-04 - val_loss: 1.1314e-05\n",
      "Epoch 60/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3638e-04 - val_loss: 8.3463e-06\n",
      "Epoch 61/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4501e-04 - val_loss: 1.2904e-05\n",
      "Epoch 62/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8573e-04 - val_loss: 8.4525e-06\n",
      "Epoch 63/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5716e-04 - val_loss: 8.8195e-06\n",
      "Epoch 64/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.6926e-04 - val_loss: 8.4314e-06\n",
      "Epoch 65/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.6115e-04 - val_loss: 1.2524e-05\n",
      "Epoch 66/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.7921e-04 - val_loss: 8.9416e-06\n",
      "Epoch 67/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5816e-04 - val_loss: 1.2542e-05\n",
      "Epoch 68/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3885e-04 - val_loss: 7.9037e-06\n",
      "Epoch 69/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2564e-04 - val_loss: 9.2820e-06\n",
      "Epoch 70/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3949e-04 - val_loss: 9.8793e-06\n",
      "Epoch 71/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3838e-04 - val_loss: 1.1387e-05\n",
      "Epoch 72/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2909e-04 - val_loss: 8.8972e-06\n",
      "Epoch 73/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2136e-04 - val_loss: 9.7255e-06\n",
      "Epoch 74/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2591e-04 - val_loss: 1.2656e-05\n",
      "Epoch 75/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3083e-04 - val_loss: 7.3855e-06\n",
      "Epoch 76/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2681e-04 - val_loss: 7.9995e-06\n",
      "Epoch 77/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2074e-04 - val_loss: 7.9322e-06\n",
      "Epoch 78/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2531e-04 - val_loss: 7.2539e-06\n",
      "Epoch 79/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3694e-04 - val_loss: 7.6708e-06\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3081e-04 - val_loss: 1.0232e-05\n",
      "Epoch 81/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2019e-04 - val_loss: 8.4694e-06\n",
      "Epoch 82/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1904e-04 - val_loss: 8.1725e-06\n",
      "Epoch 83/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.7380e-04 - val_loss: 7.7536e-06\n",
      "Epoch 84/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2204e-04 - val_loss: 1.0816e-05\n",
      "Epoch 85/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0709e-04 - val_loss: 6.9789e-06\n",
      "Epoch 86/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0340e-04 - val_loss: 9.0796e-06\n",
      "Epoch 87/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3947e-04 - val_loss: 7.0414e-06\n",
      "Epoch 88/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.7008e-04 - val_loss: 1.0867e-05\n",
      "Epoch 89/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2411e-04 - val_loss: 8.1716e-06\n",
      "Epoch 90/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0851e-04 - val_loss: 7.4018e-06\n",
      "Epoch 91/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0916e-04 - val_loss: 6.8239e-06\n",
      "Epoch 92/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0406e-04 - val_loss: 1.4830e-05\n",
      "Epoch 93/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2750e-04 - val_loss: 7.1116e-06\n",
      "Epoch 94/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0925e-04 - val_loss: 7.6023e-06\n",
      "Epoch 95/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9781e-04 - val_loss: 7.0062e-06\n",
      "Epoch 96/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3337e-04 - val_loss: 1.2746e-05\n",
      "Epoch 97/200\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9888e-04 - val_loss: 6.7256e-06\n",
      "Epoch 98/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9773e-04 - val_loss: 7.0429e-06\n",
      "Epoch 99/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9394e-04 - val_loss: 6.5591e-06\n",
      "Epoch 100/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3736e-04 - val_loss: 1.2623e-05\n",
      "Epoch 101/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1495e-04 - val_loss: 7.8814e-06\n",
      "Epoch 102/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0346e-04 - val_loss: 6.3799e-06\n",
      "Epoch 103/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1321e-04 - val_loss: 6.5626e-06\n",
      "Epoch 104/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8929e-04 - val_loss: 1.0382e-05\n",
      "Epoch 105/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8841e-04 - val_loss: 6.4865e-06\n",
      "Epoch 106/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8538e-04 - val_loss: 6.2692e-06\n",
      "Epoch 107/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9524e-04 - val_loss: 6.5399e-06\n",
      "Epoch 108/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8723e-04 - val_loss: 6.8049e-06\n",
      "Epoch 109/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8927e-04 - val_loss: 7.0479e-06\n",
      "Epoch 110/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8627e-04 - val_loss: 6.2211e-06\n",
      "Epoch 111/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0754e-04 - val_loss: 6.7800e-06\n",
      "Epoch 112/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9967e-04 - val_loss: 1.5804e-05\n",
      "Epoch 113/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0312e-04 - val_loss: 5.9276e-06\n",
      "Epoch 114/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7644e-04 - val_loss: 6.9316e-06\n",
      "Epoch 115/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8784e-04 - val_loss: 9.4773e-06\n",
      "Epoch 116/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9325e-04 - val_loss: 8.4694e-06\n",
      "Epoch 117/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8820e-04 - val_loss: 6.0310e-06\n",
      "Epoch 118/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8140e-04 - val_loss: 1.1105e-05\n",
      "Epoch 119/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1315e-04 - val_loss: 5.9973e-06\n",
      "Epoch 120/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7994e-04 - val_loss: 5.8861e-06\n",
      "Epoch 121/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8811e-04 - val_loss: 1.0728e-05\n",
      "Epoch 122/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0205e-04 - val_loss: 6.1994e-06\n",
      "Epoch 123/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7773e-04 - val_loss: 6.1868e-06\n",
      "Epoch 124/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8822e-04 - val_loss: 5.6764e-06\n",
      "Epoch 125/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7427e-04 - val_loss: 8.6361e-06\n",
      "Epoch 126/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8509e-04 - val_loss: 7.2487e-06\n",
      "Epoch 127/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7862e-04 - val_loss: 5.8076e-06\n",
      "Epoch 128/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6691e-04 - val_loss: 6.9927e-06\n",
      "Epoch 129/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9283e-04 - val_loss: 5.9679e-06\n",
      "Epoch 130/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7781e-04 - val_loss: 6.0570e-06\n",
      "Epoch 131/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0505e-04 - val_loss: 6.3503e-06\n",
      "Epoch 132/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7334e-04 - val_loss: 1.1304e-05\n",
      "Epoch 133/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7198e-04 - val_loss: 5.7606e-06\n",
      "Epoch 134/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8342e-04 - val_loss: 5.9561e-06\n",
      "Epoch 135/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8654e-04 - val_loss: 5.6236e-06\n",
      "Epoch 136/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9324e-04 - val_loss: 8.0148e-06\n",
      "Epoch 137/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8819e-04 - val_loss: 5.9889e-06\n",
      "Epoch 138/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6593e-04 - val_loss: 6.7519e-06\n",
      "Epoch 139/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6108e-04 - val_loss: 5.5685e-06\n",
      "Epoch 140/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9309e-04 - val_loss: 7.4557e-06\n",
      "Epoch 141/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0333e-04 - val_loss: 5.7188e-06\n",
      "Epoch 142/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6524e-04 - val_loss: 1.0278e-05\n",
      "Epoch 143/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6508e-04 - val_loss: 1.2528e-05\n",
      "Epoch 144/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7005e-04 - val_loss: 6.0383e-06\n",
      "Epoch 145/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7915e-04 - val_loss: 1.0485e-05\n",
      "Epoch 146/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8808e-04 - val_loss: 5.4392e-06\n",
      "Epoch 147/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6503e-04 - val_loss: 6.2535e-06\n",
      "Epoch 148/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8111e-04 - val_loss: 5.5083e-06\n",
      "Epoch 149/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6532e-04 - val_loss: 5.5154e-06\n",
      "Epoch 150/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7536e-04 - val_loss: 5.3865e-06\n",
      "Epoch 151/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6670e-04 - val_loss: 6.3102e-06\n",
      "Epoch 152/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5913e-04 - val_loss: 5.7304e-06\n",
      "Epoch 153/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5629e-04 - val_loss: 6.9735e-06\n",
      "Epoch 154/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6359e-04 - val_loss: 6.4579e-06\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5642e-04 - val_loss: 6.2085e-06\n",
      "Epoch 156/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6810e-04 - val_loss: 7.6523e-06\n",
      "Epoch 157/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5962e-04 - val_loss: 5.2014e-06\n",
      "Epoch 158/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7128e-04 - val_loss: 5.2542e-06\n",
      "Epoch 159/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5842e-04 - val_loss: 5.1826e-06\n",
      "Epoch 160/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5328e-04 - val_loss: 7.5710e-06\n",
      "Epoch 161/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6036e-04 - val_loss: 6.5113e-06\n",
      "Epoch 162/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5135e-04 - val_loss: 6.0699e-06\n",
      "Epoch 163/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7095e-04 - val_loss: 6.2216e-06\n",
      "Epoch 164/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5450e-04 - val_loss: 5.2348e-06\n",
      "Epoch 165/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5319e-04 - val_loss: 5.3839e-06\n",
      "Epoch 166/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5596e-04 - val_loss: 5.2129e-06\n",
      "Epoch 167/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5056e-04 - val_loss: 5.1198e-06\n",
      "Epoch 168/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5340e-04 - val_loss: 5.4830e-06\n",
      "Epoch 169/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7968e-04 - val_loss: 7.0430e-06\n",
      "Epoch 170/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5234e-04 - val_loss: 6.2915e-06\n",
      "Epoch 171/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7314e-04 - val_loss: 5.1696e-06\n",
      "Epoch 172/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6629e-04 - val_loss: 6.5254e-06\n",
      "Epoch 173/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6532e-04 - val_loss: 6.2275e-06\n",
      "Epoch 174/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6143e-04 - val_loss: 5.2135e-06\n",
      "Epoch 175/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6179e-04 - val_loss: 7.0126e-06\n",
      "Epoch 176/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5262e-04 - val_loss: 5.4114e-06\n",
      "Epoch 177/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5509e-04 - val_loss: 5.0865e-06\n",
      "Epoch 178/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5220e-04 - val_loss: 6.0459e-06\n",
      "Epoch 179/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7529e-04 - val_loss: 8.3157e-06\n",
      "Epoch 180/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5619e-04 - val_loss: 7.6128e-06\n",
      "Epoch 181/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7106e-04 - val_loss: 8.1585e-06\n",
      "Epoch 182/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6792e-04 - val_loss: 5.1303e-06\n",
      "Epoch 183/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4980e-04 - val_loss: 5.1414e-06\n",
      "Epoch 184/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6000e-04 - val_loss: 8.4806e-06\n",
      "Epoch 185/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5536e-04 - val_loss: 4.9588e-06\n",
      "Epoch 186/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7152e-04 - val_loss: 7.8350e-06\n",
      "Epoch 187/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4729e-04 - val_loss: 5.1361e-06\n",
      "Epoch 188/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5726e-04 - val_loss: 6.4654e-06\n",
      "Epoch 189/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6952e-04 - val_loss: 5.2201e-06\n",
      "Epoch 190/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4030e-04 - val_loss: 7.7164e-06\n",
      "Epoch 191/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4669e-04 - val_loss: 5.4411e-06\n",
      "Epoch 192/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4537e-04 - val_loss: 9.2515e-06\n",
      "Epoch 193/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5077e-04 - val_loss: 5.0466e-06\n",
      "Epoch 194/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4350e-04 - val_loss: 4.8684e-06\n",
      "Epoch 195/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4635e-04 - val_loss: 1.0997e-05\n",
      "Epoch 196/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8120e-04 - val_loss: 6.7518e-06\n",
      "Epoch 197/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5083e-04 - val_loss: 5.2335e-06\n",
      "Epoch 198/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4436e-04 - val_loss: 4.8803e-06\n",
      "Epoch 199/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5036e-04 - val_loss: 7.8161e-06\n",
      "Epoch 200/200\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7972e-04 - val_loss: 1.1193e-05\n",
      "Thời gian huấn luyện:  34.20462226867676\n",
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_24 (SimpleRNN)   (None, 10, 116)           13688     \n",
      "                                                                 \n",
      " flatten_97 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,849\n",
      "Trainable params: 14,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "46/46 [==============================] - 2s 16ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 2/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 3/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 4/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 5/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 6/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 7/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 8/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 9/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 10/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 11/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 12/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 13/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 14/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 15/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 16/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 17/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 18/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 19/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 20/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 21/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 22/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 23/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 24/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 25/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 26/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 27/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 28/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 29/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 30/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 31/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 32/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 33/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 34/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 35/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 36/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 37/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 38/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 39/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 40/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 41/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 42/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 43/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 44/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 45/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 46/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 47/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 48/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 49/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 50/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 51/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 52/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 53/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 54/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 55/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 56/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 57/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 58/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 59/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 60/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 61/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 62/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 63/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 64/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 65/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 66/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 67/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 68/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 69/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 70/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 71/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 72/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 73/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 74/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 75/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 76/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 77/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 78/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 79/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 80/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 81/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 82/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 83/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 84/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 85/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 86/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 87/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 88/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 89/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 90/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 91/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 92/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 93/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 94/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 95/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 96/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 97/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 98/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 99/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 100/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 101/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 102/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 103/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 104/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 105/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 107/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 108/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 109/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 110/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 111/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 112/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 113/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 114/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 115/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 116/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 117/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 118/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 119/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 120/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 121/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 122/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 123/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 124/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 125/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 126/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 127/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 128/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 129/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 130/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 131/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 132/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 133/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 134/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 135/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 136/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 137/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 138/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 139/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 140/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 141/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 142/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 143/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 144/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 145/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 146/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 147/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 148/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 149/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 150/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 151/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 152/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 153/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 154/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 155/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 156/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 157/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 158/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 159/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 160/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 161/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 162/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 163/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 164/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 165/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 166/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 167/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 168/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 169/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 170/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 171/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 172/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 173/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 174/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 175/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 176/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 177/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 178/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 179/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 180/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 181/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 182/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 183/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 184/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 185/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 186/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 188/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 189/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 190/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 191/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 192/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 193/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 194/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 195/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 196/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 197/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 198/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 199/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Epoch 200/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1765 - val_loss: 0.0037\n",
      "Thời gian huấn luyện:  79.49873757362366\n",
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_24 (LSTM)              (None, 10, 116)           54752     \n",
      "                                                                 \n",
      " flatten_98 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,913\n",
      "Trainable params: 55,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "46/46 [==============================] - 2s 15ms/step - loss: 0.0202 - val_loss: 2.5693e-04\n",
      "Epoch 2/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 6.3158e-04 - val_loss: 2.7025e-05\n",
      "Epoch 3/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.7882e-04 - val_loss: 2.3219e-05\n",
      "Epoch 4/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.7689e-04 - val_loss: 2.3644e-05\n",
      "Epoch 5/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.7400e-04 - val_loss: 2.3335e-05\n",
      "Epoch 6/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.6777e-04 - val_loss: 3.3029e-05\n",
      "Epoch 7/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.7363e-04 - val_loss: 2.7250e-05\n",
      "Epoch 8/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.5997e-04 - val_loss: 2.3148e-05\n",
      "Epoch 9/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.5667e-04 - val_loss: 2.4768e-05\n",
      "Epoch 10/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.6246e-04 - val_loss: 2.3027e-05\n",
      "Epoch 11/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.5389e-04 - val_loss: 2.4078e-05\n",
      "Epoch 12/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.4554e-04 - val_loss: 2.1931e-05\n",
      "Epoch 13/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.4022e-04 - val_loss: 2.1647e-05\n",
      "Epoch 14/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.4862e-04 - val_loss: 3.4656e-05\n",
      "Epoch 15/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.4074e-04 - val_loss: 2.3109e-05\n",
      "Epoch 16/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.2872e-04 - val_loss: 2.1534e-05\n",
      "Epoch 17/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.3383e-04 - val_loss: 2.2111e-05\n",
      "Epoch 18/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.2312e-04 - val_loss: 2.2004e-05\n",
      "Epoch 19/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.1397e-04 - val_loss: 2.1111e-05\n",
      "Epoch 20/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.2574e-04 - val_loss: 2.5665e-05\n",
      "Epoch 21/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.1800e-04 - val_loss: 2.0265e-05\n",
      "Epoch 22/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.1135e-04 - val_loss: 2.0267e-05\n",
      "Epoch 23/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.1282e-04 - val_loss: 2.0484e-05\n",
      "Epoch 24/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 5.1101e-04 - val_loss: 2.0042e-05\n",
      "Epoch 25/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.9831e-04 - val_loss: 1.9838e-05\n",
      "Epoch 26/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.9279e-04 - val_loss: 1.9549e-05\n",
      "Epoch 27/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.8584e-04 - val_loss: 2.1787e-05\n",
      "Epoch 28/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.8619e-04 - val_loss: 1.9453e-05\n",
      "Epoch 29/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.7636e-04 - val_loss: 2.4294e-05\n",
      "Epoch 30/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.7594e-04 - val_loss: 1.8944e-05\n",
      "Epoch 31/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.7007e-04 - val_loss: 2.2095e-05\n",
      "Epoch 32/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.7082e-04 - val_loss: 1.9766e-05\n",
      "Epoch 33/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.6631e-04 - val_loss: 1.8830e-05\n",
      "Epoch 34/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.5723e-04 - val_loss: 2.1388e-05\n",
      "Epoch 35/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.5268e-04 - val_loss: 2.7985e-05\n",
      "Epoch 36/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.5657e-04 - val_loss: 3.1248e-05\n",
      "Epoch 37/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.5303e-04 - val_loss: 1.7825e-05\n",
      "Epoch 38/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.5053e-04 - val_loss: 1.9176e-05\n",
      "Epoch 39/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.2907e-04 - val_loss: 1.9688e-05\n",
      "Epoch 40/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.2914e-04 - val_loss: 1.9763e-05\n",
      "Epoch 41/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.2953e-04 - val_loss: 2.5373e-05\n",
      "Epoch 42/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.2262e-04 - val_loss: 1.6944e-05\n",
      "Epoch 43/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.3320e-04 - val_loss: 1.6941e-05\n",
      "Epoch 44/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.2081e-04 - val_loss: 1.6981e-05\n",
      "Epoch 45/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.1294e-04 - val_loss: 3.3912e-05\n",
      "Epoch 46/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.1434e-04 - val_loss: 4.2371e-05\n",
      "Epoch 47/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.0539e-04 - val_loss: 1.6772e-05\n",
      "Epoch 48/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.0095e-04 - val_loss: 1.5800e-05\n",
      "Epoch 49/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.9802e-04 - val_loss: 2.3592e-05\n",
      "Epoch 50/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.0715e-04 - val_loss: 1.5861e-05\n",
      "Epoch 51/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.8699e-04 - val_loss: 1.7255e-05\n",
      "Epoch 52/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.9572e-04 - val_loss: 1.7046e-05\n",
      "Epoch 53/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.9219e-04 - val_loss: 5.8722e-05\n",
      "Epoch 54/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.8222e-04 - val_loss: 2.8913e-05\n",
      "Epoch 55/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.6991e-04 - val_loss: 1.4859e-05\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 8ms/step - loss: 3.6722e-04 - val_loss: 1.4896e-05\n",
      "Epoch 57/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.8073e-04 - val_loss: 1.6262e-05\n",
      "Epoch 58/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.0896e-04 - val_loss: 1.7717e-05\n",
      "Epoch 59/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.6672e-04 - val_loss: 1.4610e-05\n",
      "Epoch 60/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.4939e-04 - val_loss: 2.2494e-05\n",
      "Epoch 61/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.4505e-04 - val_loss: 1.3975e-05\n",
      "Epoch 62/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.4560e-04 - val_loss: 1.3905e-05\n",
      "Epoch 63/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.4313e-04 - val_loss: 1.5020e-05\n",
      "Epoch 64/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.5655e-04 - val_loss: 1.4153e-05\n",
      "Epoch 65/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.4505e-04 - val_loss: 2.4620e-05\n",
      "Epoch 66/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.4759e-04 - val_loss: 2.1455e-05\n",
      "Epoch 67/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.5294e-04 - val_loss: 1.8952e-05\n",
      "Epoch 68/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.2730e-04 - val_loss: 1.5723e-05\n",
      "Epoch 69/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.3660e-04 - val_loss: 3.1713e-05\n",
      "Epoch 70/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.2484e-04 - val_loss: 2.2180e-05\n",
      "Epoch 71/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.2363e-04 - val_loss: 1.7477e-05\n",
      "Epoch 72/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.2340e-04 - val_loss: 1.8511e-05\n",
      "Epoch 73/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.2146e-04 - val_loss: 3.0429e-05\n",
      "Epoch 74/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.1295e-04 - val_loss: 2.8411e-05\n",
      "Epoch 75/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.1494e-04 - val_loss: 1.8274e-05\n",
      "Epoch 76/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.2020e-04 - val_loss: 1.2556e-05\n",
      "Epoch 77/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.1869e-04 - val_loss: 2.1626e-05\n",
      "Epoch 78/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.1434e-04 - val_loss: 2.3422e-05\n",
      "Epoch 79/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.0384e-04 - val_loss: 1.6257e-05\n",
      "Epoch 80/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.9632e-04 - val_loss: 2.1291e-05\n",
      "Epoch 81/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.0053e-04 - val_loss: 1.1893e-05\n",
      "Epoch 82/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.9564e-04 - val_loss: 1.5542e-05\n",
      "Epoch 83/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.9511e-04 - val_loss: 1.9717e-05\n",
      "Epoch 84/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.0180e-04 - val_loss: 1.6130e-05\n",
      "Epoch 85/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.8636e-04 - val_loss: 1.3408e-05\n",
      "Epoch 86/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.9033e-04 - val_loss: 3.2926e-05\n",
      "Epoch 87/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.8518e-04 - val_loss: 1.8301e-05\n",
      "Epoch 88/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.9102e-04 - val_loss: 2.6709e-05\n",
      "Epoch 89/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.8804e-04 - val_loss: 1.8418e-05\n",
      "Epoch 90/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.8308e-04 - val_loss: 1.1221e-05\n",
      "Epoch 91/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.8412e-04 - val_loss: 2.4643e-05\n",
      "Epoch 92/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.7669e-04 - val_loss: 1.2838e-05\n",
      "Epoch 93/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.8759e-04 - val_loss: 2.1410e-05\n",
      "Epoch 94/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.7527e-04 - val_loss: 1.7654e-05\n",
      "Epoch 95/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.8192e-04 - val_loss: 3.3337e-05\n",
      "Epoch 96/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.7871e-04 - val_loss: 1.0801e-05\n",
      "Epoch 97/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.6546e-04 - val_loss: 1.3542e-05\n",
      "Epoch 98/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.7174e-04 - val_loss: 1.1054e-05\n",
      "Epoch 99/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.7661e-04 - val_loss: 1.8326e-05\n",
      "Epoch 100/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.5951e-04 - val_loss: 1.2278e-05\n",
      "Epoch 101/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.5541e-04 - val_loss: 1.1305e-05\n",
      "Epoch 102/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.6103e-04 - val_loss: 1.0416e-05\n",
      "Epoch 103/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.5768e-04 - val_loss: 1.2134e-05\n",
      "Epoch 104/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.6557e-04 - val_loss: 1.2494e-05\n",
      "Epoch 105/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.5762e-04 - val_loss: 1.0313e-05\n",
      "Epoch 106/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.4850e-04 - val_loss: 1.3322e-05\n",
      "Epoch 107/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.5880e-04 - val_loss: 1.2389e-05\n",
      "Epoch 108/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.5790e-04 - val_loss: 1.2861e-05\n",
      "Epoch 109/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.5141e-04 - val_loss: 1.0638e-05\n",
      "Epoch 110/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.4433e-04 - val_loss: 1.1538e-05\n",
      "Epoch 111/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.5253e-04 - val_loss: 1.1563e-05\n",
      "Epoch 112/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.5404e-04 - val_loss: 1.0367e-05\n",
      "Epoch 113/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.4657e-04 - val_loss: 9.8133e-06\n",
      "Epoch 114/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.3917e-04 - val_loss: 1.0029e-05\n",
      "Epoch 115/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.3444e-04 - val_loss: 9.6730e-06\n",
      "Epoch 116/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.3440e-04 - val_loss: 3.8036e-05\n",
      "Epoch 117/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.4671e-04 - val_loss: 1.0570e-05\n",
      "Epoch 118/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.4142e-04 - val_loss: 1.4174e-05\n",
      "Epoch 119/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.3118e-04 - val_loss: 1.1809e-05\n",
      "Epoch 120/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.3596e-04 - val_loss: 1.0589e-05\n",
      "Epoch 121/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.3676e-04 - val_loss: 1.6492e-05\n",
      "Epoch 122/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.3074e-04 - val_loss: 9.4692e-06\n",
      "Epoch 123/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.4478e-04 - val_loss: 9.6566e-06\n",
      "Epoch 124/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.3417e-04 - val_loss: 9.7837e-06\n",
      "Epoch 125/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.2308e-04 - val_loss: 1.0666e-05\n",
      "Epoch 126/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.2980e-04 - val_loss: 1.4542e-05\n",
      "Epoch 127/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.2586e-04 - val_loss: 1.6322e-05\n",
      "Epoch 128/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.2166e-04 - val_loss: 1.7010e-05\n",
      "Epoch 129/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.2576e-04 - val_loss: 9.3921e-06\n",
      "Epoch 130/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.1997e-04 - val_loss: 1.0347e-05\n",
      "Epoch 131/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 8ms/step - loss: 2.1675e-04 - val_loss: 1.3349e-05\n",
      "Epoch 132/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.2067e-04 - val_loss: 8.8945e-06\n",
      "Epoch 133/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.1828e-04 - val_loss: 8.8553e-06\n",
      "Epoch 134/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.1320e-04 - val_loss: 8.6448e-06\n",
      "Epoch 135/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.2505e-04 - val_loss: 9.4973e-06\n",
      "Epoch 136/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.2150e-04 - val_loss: 1.2583e-05\n",
      "Epoch 137/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.2199e-04 - val_loss: 1.0017e-05\n",
      "Epoch 138/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.2662e-04 - val_loss: 8.8000e-06\n",
      "Epoch 139/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.1458e-04 - val_loss: 2.1033e-05\n",
      "Epoch 140/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.0975e-04 - val_loss: 9.4961e-06\n",
      "Epoch 141/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.1267e-04 - val_loss: 2.0679e-05\n",
      "Epoch 142/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.1590e-04 - val_loss: 9.0581e-06\n",
      "Epoch 143/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.1118e-04 - val_loss: 8.3021e-06\n",
      "Epoch 144/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.1349e-04 - val_loss: 8.7924e-06\n",
      "Epoch 145/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.1622e-04 - val_loss: 8.4210e-06\n",
      "Epoch 146/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.0850e-04 - val_loss: 9.5689e-06\n",
      "Epoch 147/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.0869e-04 - val_loss: 1.4377e-05\n",
      "Epoch 148/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.0732e-04 - val_loss: 8.4436e-06\n",
      "Epoch 149/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.1308e-04 - val_loss: 1.0963e-05\n",
      "Epoch 150/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.0505e-04 - val_loss: 9.0292e-06\n",
      "Epoch 151/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.0645e-04 - val_loss: 1.0391e-05\n",
      "Epoch 152/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.0228e-04 - val_loss: 2.0624e-05\n",
      "Epoch 153/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.0170e-04 - val_loss: 1.1212e-05\n",
      "Epoch 154/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.0083e-04 - val_loss: 8.0521e-06\n",
      "Epoch 155/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.0491e-04 - val_loss: 1.1611e-05\n",
      "Epoch 156/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.0597e-04 - val_loss: 1.4062e-05\n",
      "Epoch 157/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.0099e-04 - val_loss: 8.3778e-06\n",
      "Epoch 158/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.9764e-04 - val_loss: 1.0855e-05\n",
      "Epoch 159/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.0336e-04 - val_loss: 9.3402e-06\n",
      "Epoch 160/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.9469e-04 - val_loss: 8.3215e-06\n",
      "Epoch 161/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.9179e-04 - val_loss: 1.2563e-05\n",
      "Epoch 162/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.8797e-04 - val_loss: 1.0791e-05\n",
      "Epoch 163/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.9471e-04 - val_loss: 1.8996e-05\n",
      "Epoch 164/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.9495e-04 - val_loss: 8.5977e-06\n",
      "Epoch 165/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.8823e-04 - val_loss: 9.7849e-06\n",
      "Epoch 166/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.9079e-04 - val_loss: 8.9408e-06\n",
      "Epoch 167/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.9639e-04 - val_loss: 7.9039e-06\n",
      "Epoch 168/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.1261e-04 - val_loss: 8.0583e-06\n",
      "Epoch 169/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.8796e-04 - val_loss: 1.1568e-05\n",
      "Epoch 170/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.8660e-04 - val_loss: 8.0131e-06\n",
      "Epoch 171/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.8957e-04 - val_loss: 1.0048e-05\n",
      "Epoch 172/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.8312e-04 - val_loss: 9.0637e-06\n",
      "Epoch 173/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.9269e-04 - val_loss: 1.6822e-05\n",
      "Epoch 174/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.9883e-04 - val_loss: 3.9066e-05\n",
      "Epoch 175/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.0877e-04 - val_loss: 7.9306e-06\n",
      "Epoch 176/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.8910e-04 - val_loss: 7.4297e-06\n",
      "Epoch 177/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.8438e-04 - val_loss: 1.0329e-05\n",
      "Epoch 178/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.8565e-04 - val_loss: 8.9960e-06\n",
      "Epoch 179/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.8133e-04 - val_loss: 7.6051e-06\n",
      "Epoch 180/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.8353e-04 - val_loss: 7.2784e-06\n",
      "Epoch 181/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.7996e-04 - val_loss: 9.1475e-06\n",
      "Epoch 182/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.8138e-04 - val_loss: 8.8826e-06\n",
      "Epoch 183/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.7867e-04 - val_loss: 1.0152e-05\n",
      "Epoch 184/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.9393e-04 - val_loss: 8.5037e-06\n",
      "Epoch 185/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.8139e-04 - val_loss: 7.3820e-06\n",
      "Epoch 186/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.7576e-04 - val_loss: 7.6750e-06\n",
      "Epoch 187/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.7373e-04 - val_loss: 8.9918e-06\n",
      "Epoch 188/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.7198e-04 - val_loss: 7.1408e-06\n",
      "Epoch 189/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.8837e-04 - val_loss: 1.7658e-05\n",
      "Epoch 190/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.7505e-04 - val_loss: 7.8636e-06\n",
      "Epoch 191/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.7363e-04 - val_loss: 7.6907e-06\n",
      "Epoch 192/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.7452e-04 - val_loss: 8.2488e-06\n",
      "Epoch 193/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.7637e-04 - val_loss: 1.0724e-05\n",
      "Epoch 194/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.7238e-04 - val_loss: 7.0852e-06\n",
      "Epoch 195/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.7795e-04 - val_loss: 1.2479e-05\n",
      "Epoch 196/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.7269e-04 - val_loss: 7.9572e-06\n",
      "Epoch 197/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.7521e-04 - val_loss: 7.0653e-06\n",
      "Epoch 198/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.7413e-04 - val_loss: 8.3132e-06\n",
      "Epoch 199/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.6964e-04 - val_loss: 6.8142e-06\n",
      "Epoch 200/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.6914e-04 - val_loss: 8.1972e-06\n",
      "Thời gian huấn luyện:  79.45110940933228\n",
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_24 (GRU)                (None, 10, 116)           41412     \n",
      "                                                                 \n",
      " flatten_99 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 1)                 1161      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,573\n",
      "Trainable params: 42,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 961us/step\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "52/52 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0716 - val_loss: 0.0383\n",
      "Epoch 2/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0152\n",
      "Epoch 3/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 4/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 5/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 9.9227e-04\n",
      "Epoch 6/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 7.8955e-04 - val_loss: 3.0897e-04\n",
      "Epoch 7/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 6.3836e-04 - val_loss: 1.4030e-04\n",
      "Epoch 8/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.9749e-04 - val_loss: 5.2819e-05\n",
      "Epoch 9/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.8346e-04 - val_loss: 4.7644e-05\n",
      "Epoch 10/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.7994e-04 - val_loss: 3.1025e-05\n",
      "Epoch 11/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.6913e-04 - val_loss: 2.7250e-05\n",
      "Epoch 12/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.6777e-04 - val_loss: 2.7950e-05\n",
      "Epoch 13/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.6227e-04 - val_loss: 2.9295e-05\n",
      "Epoch 14/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.6017e-04 - val_loss: 2.4633e-05\n",
      "Epoch 15/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.5451e-04 - val_loss: 2.8175e-05\n",
      "Epoch 16/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.5273e-04 - val_loss: 2.7608e-05\n",
      "Epoch 17/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.5152e-04 - val_loss: 2.3919e-05\n",
      "Epoch 18/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.5206e-04 - val_loss: 2.7132e-05\n",
      "Epoch 19/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.5033e-04 - val_loss: 3.2623e-05\n",
      "Epoch 20/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.4671e-04 - val_loss: 3.2842e-05\n",
      "Epoch 21/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.4593e-04 - val_loss: 3.3253e-05\n",
      "Epoch 22/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.4401e-04 - val_loss: 2.4039e-05\n",
      "Epoch 23/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.4352e-04 - val_loss: 3.0850e-05\n",
      "Epoch 24/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.4510e-04 - val_loss: 2.6298e-05\n",
      "Epoch 25/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.4073e-04 - val_loss: 3.2039e-05\n",
      "Epoch 26/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.3630e-04 - val_loss: 2.8499e-05\n",
      "Epoch 27/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.3929e-04 - val_loss: 3.0586e-05\n",
      "Epoch 28/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.3377e-04 - val_loss: 3.2151e-05\n",
      "Epoch 29/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.3534e-04 - val_loss: 3.5092e-05\n",
      "Epoch 30/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.3362e-04 - val_loss: 3.6000e-05\n",
      "Epoch 31/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.3172e-04 - val_loss: 3.0154e-05\n",
      "Epoch 32/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.3033e-04 - val_loss: 3.2626e-05\n",
      "Epoch 33/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.2823e-04 - val_loss: 3.1477e-05\n",
      "Epoch 34/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.2412e-04 - val_loss: 3.0635e-05\n",
      "Epoch 35/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.2232e-04 - val_loss: 2.6080e-05\n",
      "Epoch 36/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.2359e-04 - val_loss: 2.5177e-05\n",
      "Epoch 37/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.2366e-04 - val_loss: 2.7626e-05\n",
      "Epoch 38/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.1676e-04 - val_loss: 2.3258e-05\n",
      "Epoch 39/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.2358e-04 - val_loss: 3.9676e-05\n",
      "Epoch 40/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.1506e-04 - val_loss: 4.1616e-05\n",
      "Epoch 41/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.1799e-04 - val_loss: 2.3981e-05\n",
      "Epoch 42/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.1377e-04 - val_loss: 2.8641e-05\n",
      "Epoch 43/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.1088e-04 - val_loss: 2.7327e-05\n",
      "Epoch 44/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.1011e-04 - val_loss: 3.5019e-05\n",
      "Epoch 45/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.0717e-04 - val_loss: 2.9340e-05\n",
      "Epoch 46/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.0957e-04 - val_loss: 2.3942e-05\n",
      "Epoch 47/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.0176e-04 - val_loss: 2.6313e-05\n",
      "Epoch 48/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.9920e-04 - val_loss: 2.7744e-05\n",
      "Epoch 49/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 5.0111e-04 - val_loss: 2.5014e-05\n",
      "Epoch 50/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.9753e-04 - val_loss: 2.2274e-05\n",
      "Epoch 51/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.9845e-04 - val_loss: 2.8183e-05\n",
      "Epoch 52/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.9100e-04 - val_loss: 3.7284e-05\n",
      "Epoch 53/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.9363e-04 - val_loss: 3.7264e-05\n",
      "Epoch 54/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.9252e-04 - val_loss: 3.0202e-05\n",
      "Epoch 55/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.8667e-04 - val_loss: 2.1801e-05\n",
      "Epoch 56/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.9417e-04 - val_loss: 2.6936e-05\n",
      "Epoch 57/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.8497e-04 - val_loss: 2.5096e-05\n",
      "Epoch 58/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.8842e-04 - val_loss: 2.1905e-05\n",
      "Epoch 59/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.8291e-04 - val_loss: 2.4987e-05\n",
      "Epoch 60/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.7880e-04 - val_loss: 2.6603e-05\n",
      "Epoch 61/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.7700e-04 - val_loss: 2.2280e-05\n",
      "Epoch 62/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.7588e-04 - val_loss: 2.8772e-05\n",
      "Epoch 63/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.7423e-04 - val_loss: 3.7430e-05\n",
      "Epoch 64/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.7426e-04 - val_loss: 2.0802e-05\n",
      "Epoch 65/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.7081e-04 - val_loss: 2.0960e-05\n",
      "Epoch 66/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.6986e-04 - val_loss: 2.6141e-05\n",
      "Epoch 67/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.6478e-04 - val_loss: 2.3354e-05\n",
      "Epoch 68/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.6742e-04 - val_loss: 3.4528e-05\n",
      "Epoch 69/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.7058e-04 - val_loss: 2.0566e-05\n",
      "Epoch 70/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.5916e-04 - val_loss: 2.2862e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.5492e-04 - val_loss: 2.0272e-05\n",
      "Epoch 72/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.5718e-04 - val_loss: 2.7885e-05\n",
      "Epoch 73/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.5732e-04 - val_loss: 1.9960e-05\n",
      "Epoch 74/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.5564e-04 - val_loss: 2.0060e-05\n",
      "Epoch 75/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.5079e-04 - val_loss: 2.5164e-05\n",
      "Epoch 76/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.4914e-04 - val_loss: 2.1987e-05\n",
      "Epoch 77/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.4573e-04 - val_loss: 2.9848e-05\n",
      "Epoch 78/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.4816e-04 - val_loss: 2.0854e-05\n",
      "Epoch 79/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.4075e-04 - val_loss: 2.1102e-05\n",
      "Epoch 80/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.3759e-04 - val_loss: 3.5899e-05\n",
      "Epoch 81/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.3479e-04 - val_loss: 2.3441e-05\n",
      "Epoch 82/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.3643e-04 - val_loss: 2.1035e-05\n",
      "Epoch 83/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.3033e-04 - val_loss: 2.9253e-05\n",
      "Epoch 84/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.3192e-04 - val_loss: 2.2729e-05\n",
      "Epoch 85/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.2454e-04 - val_loss: 3.4125e-05\n",
      "Epoch 86/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.2692e-04 - val_loss: 3.0189e-05\n",
      "Epoch 87/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.2133e-04 - val_loss: 1.8665e-05\n",
      "Epoch 88/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.2218e-04 - val_loss: 2.0688e-05\n",
      "Epoch 89/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.3160e-04 - val_loss: 2.2547e-05\n",
      "Epoch 90/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.1437e-04 - val_loss: 3.3259e-05\n",
      "Epoch 91/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.1617e-04 - val_loss: 3.2620e-05\n",
      "Epoch 92/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.1255e-04 - val_loss: 3.4228e-05\n",
      "Epoch 93/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.1421e-04 - val_loss: 1.8231e-05\n",
      "Epoch 94/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.0863e-04 - val_loss: 1.7804e-05\n",
      "Epoch 95/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.0486e-04 - val_loss: 2.2668e-05\n",
      "Epoch 96/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.0962e-04 - val_loss: 4.4696e-05\n",
      "Epoch 97/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.0675e-04 - val_loss: 1.7672e-05\n",
      "Epoch 98/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.0043e-04 - val_loss: 3.5311e-05\n",
      "Epoch 99/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.1774e-04 - val_loss: 1.7310e-05\n",
      "Epoch 100/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.0050e-04 - val_loss: 1.7849e-05\n",
      "Epoch 101/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.9764e-04 - val_loss: 2.9028e-05\n",
      "Epoch 102/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.9634e-04 - val_loss: 1.8735e-05\n",
      "Epoch 103/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.8977e-04 - val_loss: 1.7043e-05\n",
      "Epoch 104/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.9077e-04 - val_loss: 3.0327e-05\n",
      "Epoch 105/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.8422e-04 - val_loss: 1.7182e-05\n",
      "Epoch 106/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.8698e-04 - val_loss: 1.8256e-05\n",
      "Epoch 107/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.8228e-04 - val_loss: 2.2472e-05\n",
      "Epoch 108/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.7767e-04 - val_loss: 3.9522e-05\n",
      "Epoch 109/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.7855e-04 - val_loss: 1.8487e-05\n",
      "Epoch 110/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.7948e-04 - val_loss: 1.7975e-05\n",
      "Epoch 111/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.7237e-04 - val_loss: 3.1322e-05\n",
      "Epoch 112/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.6851e-04 - val_loss: 2.7583e-05\n",
      "Epoch 113/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.6731e-04 - val_loss: 1.7866e-05\n",
      "Epoch 114/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.6724e-04 - val_loss: 3.0453e-05\n",
      "Epoch 115/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.6543e-04 - val_loss: 2.1051e-05\n",
      "Epoch 116/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.6121e-04 - val_loss: 1.5911e-05\n",
      "Epoch 117/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.6416e-04 - val_loss: 2.0588e-05\n",
      "Epoch 118/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.6460e-04 - val_loss: 1.6387e-05\n",
      "Epoch 119/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.5779e-04 - val_loss: 2.0010e-05\n",
      "Epoch 120/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.5688e-04 - val_loss: 1.5444e-05\n",
      "Epoch 121/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.5326e-04 - val_loss: 2.6992e-05\n",
      "Epoch 122/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.5139e-04 - val_loss: 2.8164e-05\n",
      "Epoch 123/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.4721e-04 - val_loss: 2.2225e-05\n",
      "Epoch 124/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.4523e-04 - val_loss: 3.0707e-05\n",
      "Epoch 125/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.4536e-04 - val_loss: 1.6782e-05\n",
      "Epoch 126/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.4226e-04 - val_loss: 2.8723e-05\n",
      "Epoch 127/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.4954e-04 - val_loss: 2.7171e-05\n",
      "Epoch 128/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.6012e-04 - val_loss: 1.5018e-05\n",
      "Epoch 129/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.3743e-04 - val_loss: 1.6941e-05\n",
      "Epoch 130/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.3711e-04 - val_loss: 1.8885e-05\n",
      "Epoch 131/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.3436e-04 - val_loss: 1.6640e-05\n",
      "Epoch 132/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.2792e-04 - val_loss: 2.5986e-05\n",
      "Epoch 133/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.2924e-04 - val_loss: 1.4461e-05\n",
      "Epoch 134/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.2531e-04 - val_loss: 1.7329e-05\n",
      "Epoch 135/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.2613e-04 - val_loss: 2.1054e-05\n",
      "Epoch 136/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.2611e-04 - val_loss: 1.4500e-05\n",
      "Epoch 137/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.2312e-04 - val_loss: 3.0757e-05\n",
      "Epoch 138/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.1869e-04 - val_loss: 2.1502e-05\n",
      "Epoch 139/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.1972e-04 - val_loss: 1.5280e-05\n",
      "Epoch 140/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.1822e-04 - val_loss: 2.5915e-05\n",
      "Epoch 141/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.2151e-04 - val_loss: 1.4934e-05\n",
      "Epoch 142/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.1603e-04 - val_loss: 2.6201e-05\n",
      "Epoch 143/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.1329e-04 - val_loss: 3.3075e-05\n",
      "Epoch 144/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.1065e-04 - val_loss: 4.3403e-05\n",
      "Epoch 145/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.1433e-04 - val_loss: 2.9931e-05\n",
      "Epoch 146/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 2ms/step - loss: 3.1426e-04 - val_loss: 1.3299e-05\n",
      "Epoch 147/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.1162e-04 - val_loss: 1.8698e-05\n",
      "Epoch 148/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.0071e-04 - val_loss: 2.6279e-05\n",
      "Epoch 149/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.0474e-04 - val_loss: 1.3044e-05\n",
      "Epoch 150/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.0058e-04 - val_loss: 1.7274e-05\n",
      "Epoch 151/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.9977e-04 - val_loss: 1.8131e-05\n",
      "Epoch 152/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.0214e-04 - val_loss: 1.2762e-05\n",
      "Epoch 153/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.9903e-04 - val_loss: 1.3253e-05\n",
      "Epoch 154/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.9425e-04 - val_loss: 1.7487e-05\n",
      "Epoch 155/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.9703e-04 - val_loss: 2.1587e-05\n",
      "Epoch 156/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.9195e-04 - val_loss: 1.9486e-05\n",
      "Epoch 157/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.8746e-04 - val_loss: 1.2567e-05\n",
      "Epoch 158/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.9251e-04 - val_loss: 1.9492e-05\n",
      "Epoch 159/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.9093e-04 - val_loss: 1.9679e-05\n",
      "Epoch 160/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.8257e-04 - val_loss: 1.2325e-05\n",
      "Epoch 161/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.8516e-04 - val_loss: 1.2899e-05\n",
      "Epoch 162/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.8653e-04 - val_loss: 1.6629e-05\n",
      "Epoch 163/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.8809e-04 - val_loss: 2.7388e-05\n",
      "Epoch 164/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.8037e-04 - val_loss: 1.6001e-05\n",
      "Epoch 165/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.7651e-04 - val_loss: 1.9228e-05\n",
      "Epoch 166/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.8694e-04 - val_loss: 2.0433e-05\n",
      "Epoch 167/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.8279e-04 - val_loss: 1.2628e-05\n",
      "Epoch 168/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.7512e-04 - val_loss: 1.1879e-05\n",
      "Epoch 169/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.7211e-04 - val_loss: 1.3274e-05\n",
      "Epoch 170/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.7559e-04 - val_loss: 1.1722e-05\n",
      "Epoch 171/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.7565e-04 - val_loss: 1.4129e-05\n",
      "Epoch 172/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.7022e-04 - val_loss: 2.6274e-05\n",
      "Epoch 173/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.7040e-04 - val_loss: 2.3301e-05\n",
      "Epoch 174/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.6594e-04 - val_loss: 1.3183e-05\n",
      "Epoch 175/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.6759e-04 - val_loss: 1.5741e-05\n",
      "Epoch 176/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.6156e-04 - val_loss: 1.3319e-05\n",
      "Epoch 177/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.6159e-04 - val_loss: 1.3258e-05\n",
      "Epoch 178/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.6057e-04 - val_loss: 1.1629e-05\n",
      "Epoch 179/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.6350e-04 - val_loss: 1.1265e-05\n",
      "Epoch 180/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.6768e-04 - val_loss: 1.4048e-05\n",
      "Epoch 181/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.6066e-04 - val_loss: 1.1189e-05\n",
      "Epoch 182/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.6372e-04 - val_loss: 1.1568e-05\n",
      "Epoch 183/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.5835e-04 - val_loss: 1.1470e-05\n",
      "Epoch 184/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.5667e-04 - val_loss: 1.1290e-05\n",
      "Epoch 185/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.5606e-04 - val_loss: 1.8189e-05\n",
      "Epoch 186/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.5523e-04 - val_loss: 1.3560e-05\n",
      "Epoch 187/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.5260e-04 - val_loss: 1.7392e-05\n",
      "Epoch 188/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.5270e-04 - val_loss: 1.4279e-05\n",
      "Epoch 189/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.5157e-04 - val_loss: 1.0829e-05\n",
      "Epoch 190/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.4900e-04 - val_loss: 1.2735e-05\n",
      "Epoch 191/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.4941e-04 - val_loss: 1.3809e-05\n",
      "Epoch 192/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.5488e-04 - val_loss: 1.6149e-05\n",
      "Epoch 193/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.4736e-04 - val_loss: 2.6477e-05\n",
      "Epoch 194/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.4700e-04 - val_loss: 1.4039e-05\n",
      "Epoch 195/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.4329e-04 - val_loss: 1.2152e-05\n",
      "Epoch 196/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.4156e-04 - val_loss: 1.9499e-05\n",
      "Epoch 197/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.5179e-04 - val_loss: 1.0445e-05\n",
      "Epoch 198/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.4356e-04 - val_loss: 1.2527e-05\n",
      "Epoch 199/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.4271e-04 - val_loss: 1.2479e-05\n",
      "Epoch 200/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.4357e-04 - val_loss: 1.0809e-05\n",
      "Thời gian huấn luyện:  17.017330408096313\n",
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_125 (Dense)           (None, 10, 116)           232       \n",
      "                                                                 \n",
      " flatten_100 (Flatten)       (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "44/44 [==============================] - 1s 7ms/step - loss: 0.0191 - val_loss: 1.6336e-04\n",
      "Epoch 2/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.0275e-04\n",
      "Epoch 3/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.7138e-04 - val_loss: 2.3184e-04\n",
      "Epoch 4/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.1912e-04 - val_loss: 1.9910e-04\n",
      "Epoch 5/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.9633e-04 - val_loss: 1.2600e-04\n",
      "Epoch 6/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.5713e-04 - val_loss: 1.2977e-04\n",
      "Epoch 7/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.2399e-04 - val_loss: 1.1310e-04\n",
      "Epoch 8/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.0500e-04 - val_loss: 1.0482e-04\n",
      "Epoch 9/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.6621e-04 - val_loss: 8.3995e-05\n",
      "Epoch 10/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.3244e-04 - val_loss: 5.7479e-05\n",
      "Epoch 11/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.0695e-04 - val_loss: 8.9635e-05\n",
      "Epoch 12/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.9772e-04 - val_loss: 5.2861e-05\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 4ms/step - loss: 5.8112e-04 - val_loss: 6.3452e-05\n",
      "Epoch 14/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.5503e-04 - val_loss: 4.2893e-05\n",
      "Epoch 15/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.3728e-04 - val_loss: 3.6154e-05\n",
      "Epoch 16/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.1950e-04 - val_loss: 3.3991e-05\n",
      "Epoch 17/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.0047e-04 - val_loss: 2.7740e-05\n",
      "Epoch 18/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.1098e-04 - val_loss: 2.9998e-05\n",
      "Epoch 19/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.9981e-04 - val_loss: 2.8472e-05\n",
      "Epoch 20/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.7644e-04 - val_loss: 2.1897e-05\n",
      "Epoch 21/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.7964e-04 - val_loss: 2.1287e-05\n",
      "Epoch 22/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.8469e-04 - val_loss: 2.5738e-05\n",
      "Epoch 23/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.8766e-04 - val_loss: 1.9749e-05\n",
      "Epoch 24/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.8004e-04 - val_loss: 1.9688e-05\n",
      "Epoch 25/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.6038e-04 - val_loss: 1.9636e-05\n",
      "Epoch 26/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.6812e-04 - val_loss: 2.0042e-05\n",
      "Epoch 27/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.5979e-04 - val_loss: 1.7571e-05\n",
      "Epoch 28/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.3771e-04 - val_loss: 1.7148e-05\n",
      "Epoch 29/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.2204e-04 - val_loss: 1.6771e-05\n",
      "Epoch 30/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.0606e-04 - val_loss: 2.0487e-05\n",
      "Epoch 31/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1528e-04 - val_loss: 1.6600e-05\n",
      "Epoch 32/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1525e-04 - val_loss: 1.7790e-05\n",
      "Epoch 33/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.3023e-04 - val_loss: 1.6242e-05\n",
      "Epoch 34/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.0456e-04 - val_loss: 1.7660e-05\n",
      "Epoch 35/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.0968e-04 - val_loss: 1.6911e-05\n",
      "Epoch 36/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.0872e-04 - val_loss: 1.4925e-05\n",
      "Epoch 37/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.9804e-04 - val_loss: 1.5528e-05\n",
      "Epoch 38/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.8743e-04 - val_loss: 1.4819e-05\n",
      "Epoch 39/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.9345e-04 - val_loss: 1.6902e-05\n",
      "Epoch 40/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.7753e-04 - val_loss: 1.5163e-05\n",
      "Epoch 41/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.8040e-04 - val_loss: 1.4526e-05\n",
      "Epoch 42/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.5722e-04 - val_loss: 1.5466e-05\n",
      "Epoch 43/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.6530e-04 - val_loss: 1.5422e-05\n",
      "Epoch 44/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.8815e-04 - val_loss: 1.4376e-05\n",
      "Epoch 45/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.5369e-04 - val_loss: 1.3638e-05\n",
      "Epoch 46/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.5310e-04 - val_loss: 1.3463e-05\n",
      "Epoch 47/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.6408e-04 - val_loss: 1.3754e-05\n",
      "Epoch 48/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.5079e-04 - val_loss: 1.5866e-05\n",
      "Epoch 49/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.0270e-04 - val_loss: 1.3132e-05\n",
      "Epoch 50/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.3454e-04 - val_loss: 1.3153e-05\n",
      "Epoch 51/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.8397e-04 - val_loss: 1.8914e-05\n",
      "Epoch 52/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.3518e-04 - val_loss: 1.3697e-05\n",
      "Epoch 53/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.3476e-04 - val_loss: 1.3071e-05\n",
      "Epoch 54/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.3807e-04 - val_loss: 1.2494e-05\n",
      "Epoch 55/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.6290e-04 - val_loss: 1.2632e-05\n",
      "Epoch 56/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.3496e-04 - val_loss: 1.4337e-05\n",
      "Epoch 57/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.3703e-04 - val_loss: 1.5576e-05\n",
      "Epoch 58/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.3280e-04 - val_loss: 1.4256e-05\n",
      "Epoch 59/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.1051e-04 - val_loss: 1.2203e-05\n",
      "Epoch 60/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.2295e-04 - val_loss: 1.2641e-05\n",
      "Epoch 61/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.1794e-04 - val_loss: 1.4719e-05\n",
      "Epoch 62/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.5385e-04 - val_loss: 1.2358e-05\n",
      "Epoch 63/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.2742e-04 - val_loss: 1.2206e-05\n",
      "Epoch 64/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.2650e-04 - val_loss: 1.2057e-05\n",
      "Epoch 65/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0785e-04 - val_loss: 1.2539e-05\n",
      "Epoch 66/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.1035e-04 - val_loss: 1.2840e-05\n",
      "Epoch 67/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0006e-04 - val_loss: 1.2841e-05\n",
      "Epoch 68/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0172e-04 - val_loss: 1.1531e-05\n",
      "Epoch 69/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9660e-04 - val_loss: 1.3801e-05\n",
      "Epoch 70/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.2654e-04 - val_loss: 1.1942e-05\n",
      "Epoch 71/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.3519e-04 - val_loss: 2.1843e-05\n",
      "Epoch 72/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.1760e-04 - val_loss: 1.1569e-05\n",
      "Epoch 73/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9818e-04 - val_loss: 1.0943e-05\n",
      "Epoch 74/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7994e-04 - val_loss: 1.0931e-05\n",
      "Epoch 75/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9161e-04 - val_loss: 1.2080e-05\n",
      "Epoch 76/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8226e-04 - val_loss: 1.1436e-05\n",
      "Epoch 77/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9705e-04 - val_loss: 1.2939e-05\n",
      "Epoch 78/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0368e-04 - val_loss: 1.1278e-05\n",
      "Epoch 79/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9416e-04 - val_loss: 1.4259e-05\n",
      "Epoch 80/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0471e-04 - val_loss: 1.0640e-05\n",
      "Epoch 81/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7832e-04 - val_loss: 1.0833e-05\n",
      "Epoch 82/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.4139e-04 - val_loss: 1.4189e-05\n",
      "Epoch 83/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8977e-04 - val_loss: 1.1053e-05\n",
      "Epoch 84/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7426e-04 - val_loss: 1.0985e-05\n",
      "Epoch 85/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8000e-04 - val_loss: 1.0991e-05\n",
      "Epoch 86/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6993e-04 - val_loss: 1.0962e-05\n",
      "Epoch 87/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6445e-04 - val_loss: 1.0722e-05\n",
      "Epoch 88/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8922e-04 - val_loss: 1.1570e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7196e-04 - val_loss: 1.1045e-05\n",
      "Epoch 90/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9692e-04 - val_loss: 1.1356e-05\n",
      "Epoch 91/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6966e-04 - val_loss: 9.8883e-06\n",
      "Epoch 92/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5863e-04 - val_loss: 9.7580e-06\n",
      "Epoch 93/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7962e-04 - val_loss: 9.8043e-06\n",
      "Epoch 94/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.1664e-04 - val_loss: 1.2031e-05\n",
      "Epoch 95/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7505e-04 - val_loss: 1.6259e-05\n",
      "Epoch 96/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5865e-04 - val_loss: 1.2586e-05\n",
      "Epoch 97/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5477e-04 - val_loss: 1.1687e-05\n",
      "Epoch 98/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8808e-04 - val_loss: 1.8306e-05\n",
      "Epoch 99/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8750e-04 - val_loss: 1.0218e-05\n",
      "Epoch 100/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7262e-04 - val_loss: 9.8358e-06\n",
      "Epoch 101/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8761e-04 - val_loss: 9.5401e-06\n",
      "Epoch 102/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.4605e-04 - val_loss: 1.0350e-05\n",
      "Epoch 103/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5897e-04 - val_loss: 1.0064e-05\n",
      "Epoch 104/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.4704e-04 - val_loss: 1.0097e-05\n",
      "Epoch 105/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.4267e-04 - val_loss: 1.1357e-05\n",
      "Epoch 106/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3887e-04 - val_loss: 1.3831e-05\n",
      "Epoch 107/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6938e-04 - val_loss: 1.0580e-05\n",
      "Epoch 108/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.4522e-04 - val_loss: 1.1092e-05\n",
      "Epoch 109/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5756e-04 - val_loss: 9.6097e-06\n",
      "Epoch 110/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6372e-04 - val_loss: 9.2765e-06\n",
      "Epoch 111/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3807e-04 - val_loss: 8.8811e-06\n",
      "Epoch 112/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6228e-04 - val_loss: 1.0157e-05\n",
      "Epoch 113/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5431e-04 - val_loss: 1.7792e-05\n",
      "Epoch 114/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5326e-04 - val_loss: 9.7402e-06\n",
      "Epoch 115/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5477e-04 - val_loss: 9.7907e-06\n",
      "Epoch 116/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3479e-04 - val_loss: 8.7754e-06\n",
      "Epoch 117/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3738e-04 - val_loss: 1.2580e-05\n",
      "Epoch 118/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3220e-04 - val_loss: 9.0180e-06\n",
      "Epoch 119/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3301e-04 - val_loss: 1.1897e-05\n",
      "Epoch 120/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5001e-04 - val_loss: 1.2213e-05\n",
      "Epoch 121/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.4811e-04 - val_loss: 9.6737e-06\n",
      "Epoch 122/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3873e-04 - val_loss: 8.4391e-06\n",
      "Epoch 123/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2467e-04 - val_loss: 1.1027e-05\n",
      "Epoch 124/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8353e-04 - val_loss: 1.1258e-05\n",
      "Epoch 125/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2278e-04 - val_loss: 8.6142e-06\n",
      "Epoch 126/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3084e-04 - val_loss: 1.1229e-05\n",
      "Epoch 127/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1840e-04 - val_loss: 1.1311e-05\n",
      "Epoch 128/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3044e-04 - val_loss: 1.4164e-05\n",
      "Epoch 129/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2509e-04 - val_loss: 8.3607e-06\n",
      "Epoch 130/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2780e-04 - val_loss: 1.1696e-05\n",
      "Epoch 131/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1476e-04 - val_loss: 1.4019e-05\n",
      "Epoch 132/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5534e-04 - val_loss: 1.1815e-05\n",
      "Epoch 133/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3036e-04 - val_loss: 8.2665e-06\n",
      "Epoch 134/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2485e-04 - val_loss: 9.1490e-06\n",
      "Epoch 135/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.4168e-04 - val_loss: 8.2652e-06\n",
      "Epoch 136/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2609e-04 - val_loss: 8.6358e-06\n",
      "Epoch 137/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6337e-04 - val_loss: 8.3697e-06\n",
      "Epoch 138/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3393e-04 - val_loss: 1.1121e-05\n",
      "Epoch 139/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1211e-04 - val_loss: 1.0179e-05\n",
      "Epoch 140/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.4051e-04 - val_loss: 1.6946e-05\n",
      "Epoch 141/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0560e-04 - val_loss: 1.0019e-05\n",
      "Epoch 142/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0587e-04 - val_loss: 1.3050e-05\n",
      "Epoch 143/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0885e-04 - val_loss: 8.0030e-06\n",
      "Epoch 144/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1216e-04 - val_loss: 9.0224e-06\n",
      "Epoch 145/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2234e-04 - val_loss: 8.3547e-06\n",
      "Epoch 146/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9990e-04 - val_loss: 8.1212e-06\n",
      "Epoch 147/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1055e-04 - val_loss: 7.8924e-06\n",
      "Epoch 148/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0457e-04 - val_loss: 1.0080e-05\n",
      "Epoch 149/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2516e-04 - val_loss: 7.9011e-06\n",
      "Epoch 150/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0745e-04 - val_loss: 8.1941e-06\n",
      "Epoch 151/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0155e-04 - val_loss: 7.8667e-06\n",
      "Epoch 152/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9889e-04 - val_loss: 7.9022e-06\n",
      "Epoch 153/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1127e-04 - val_loss: 7.7885e-06\n",
      "Epoch 154/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2587e-04 - val_loss: 8.0231e-06\n",
      "Epoch 155/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1038e-04 - val_loss: 9.0023e-06\n",
      "Epoch 156/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0249e-04 - val_loss: 7.8068e-06\n",
      "Epoch 157/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9961e-04 - val_loss: 1.0003e-05\n",
      "Epoch 158/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9902e-04 - val_loss: 7.4644e-06\n",
      "Epoch 159/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9791e-04 - val_loss: 7.7726e-06\n",
      "Epoch 160/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0813e-04 - val_loss: 1.0085e-05\n",
      "Epoch 161/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8855e-04 - val_loss: 1.1457e-05\n",
      "Epoch 162/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9266e-04 - val_loss: 7.4545e-06\n",
      "Epoch 163/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0880e-04 - val_loss: 7.9833e-06\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9462e-04 - val_loss: 7.7905e-06\n",
      "Epoch 165/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9483e-04 - val_loss: 9.6034e-06\n",
      "Epoch 166/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9470e-04 - val_loss: 8.1652e-06\n",
      "Epoch 167/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3486e-04 - val_loss: 7.4102e-06\n",
      "Epoch 168/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0608e-04 - val_loss: 1.9154e-05\n",
      "Epoch 169/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.4124e-04 - val_loss: 1.2799e-05\n",
      "Epoch 170/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8632e-04 - val_loss: 9.1160e-06\n",
      "Epoch 171/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9332e-04 - val_loss: 7.3892e-06\n",
      "Epoch 172/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8272e-04 - val_loss: 1.1539e-05\n",
      "Epoch 173/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9477e-04 - val_loss: 7.5368e-06\n",
      "Epoch 174/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1004e-04 - val_loss: 8.4290e-06\n",
      "Epoch 175/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1145e-04 - val_loss: 1.0702e-05\n",
      "Epoch 176/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8277e-04 - val_loss: 9.2616e-06\n",
      "Epoch 177/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0984e-04 - val_loss: 7.0995e-06\n",
      "Epoch 178/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9122e-04 - val_loss: 7.3242e-06\n",
      "Epoch 179/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9652e-04 - val_loss: 8.5539e-06\n",
      "Epoch 180/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8729e-04 - val_loss: 7.2018e-06\n",
      "Epoch 181/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9497e-04 - val_loss: 7.0301e-06\n",
      "Epoch 182/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8986e-04 - val_loss: 8.3821e-06\n",
      "Epoch 183/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9016e-04 - val_loss: 8.9200e-06\n",
      "Epoch 184/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8303e-04 - val_loss: 7.7635e-06\n",
      "Epoch 185/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3839e-04 - val_loss: 9.4491e-06\n",
      "Epoch 186/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2474e-04 - val_loss: 1.5693e-05\n",
      "Epoch 187/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3113e-04 - val_loss: 7.0180e-06\n",
      "Epoch 188/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9260e-04 - val_loss: 1.0455e-05\n",
      "Epoch 189/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7950e-04 - val_loss: 7.9787e-06\n",
      "Epoch 190/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7889e-04 - val_loss: 6.7423e-06\n",
      "Epoch 191/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8085e-04 - val_loss: 7.1576e-06\n",
      "Epoch 192/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8297e-04 - val_loss: 7.3614e-06\n",
      "Epoch 193/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7730e-04 - val_loss: 7.1152e-06\n",
      "Epoch 194/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7750e-04 - val_loss: 8.8011e-06\n",
      "Epoch 195/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9822e-04 - val_loss: 1.0643e-05\n",
      "Epoch 196/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9394e-04 - val_loss: 6.7180e-06\n",
      "Epoch 197/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7466e-04 - val_loss: 7.4132e-06\n",
      "Epoch 198/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6976e-04 - val_loss: 7.9051e-06\n",
      "Epoch 199/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5706e-04 - val_loss: 8.8106e-06\n",
      "Epoch 200/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7311e-04 - val_loss: 7.9213e-06\n",
      "Thời gian huấn luyện:  33.44019865989685\n",
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_25 (SimpleRNN)   (None, 10, 116)           13688     \n",
      "                                                                 \n",
      " flatten_101 (Flatten)       (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,849\n",
      "Trainable params: 14,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "44/44 [==============================] - 2s 16ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 2/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 3/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 4/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 5/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 6/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 7/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 8/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 9/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 10/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 11/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 12/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 13/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 14/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 15/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 16/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 17/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 18/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 19/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 20/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 21/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 22/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 23/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 24/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 25/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 26/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 27/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 28/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 29/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 30/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 31/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 32/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 33/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 35/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 36/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 37/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 38/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 39/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 40/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 41/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 42/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 43/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 44/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 45/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 46/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 47/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 48/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 49/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 50/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 51/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 52/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 53/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 54/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 55/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 56/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 57/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 58/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 59/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 60/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 61/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 62/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 63/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 64/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 65/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 66/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 67/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 68/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 69/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 70/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 71/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 72/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 73/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 74/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 75/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 76/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 77/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 78/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 79/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 80/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 81/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 82/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 83/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 84/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 85/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 86/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 87/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 88/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 89/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 90/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 91/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 92/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 93/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 94/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 95/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 96/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 97/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 98/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 99/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 100/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 101/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 102/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 103/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 104/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 105/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 106/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 107/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 108/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 109/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 110/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 111/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 112/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 113/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 114/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 115/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 117/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 118/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 119/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 120/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 121/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 122/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 123/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 124/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 125/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 126/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 127/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 128/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 129/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 130/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 131/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 132/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 133/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 134/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 135/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 136/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 137/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 138/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 139/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 140/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 141/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 142/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 143/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 144/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 145/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 146/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 147/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 148/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 149/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 150/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 151/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 152/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 153/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 154/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 155/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 156/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 157/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 158/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 159/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 160/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 161/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 162/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 163/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 164/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 165/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 166/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 167/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 168/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 169/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 170/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 171/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 172/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 173/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 174/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 175/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 176/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 177/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 178/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 179/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 180/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 181/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 182/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 183/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 184/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 185/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 186/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 187/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 188/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 189/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 190/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 191/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 192/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 193/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 194/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 195/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 196/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 197/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 198/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 199/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 200/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Thời gian huấn luyện:  79.06441020965576\n",
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_25 (LSTM)              (None, 10, 116)           54752     \n",
      "                                                                 \n",
      " flatten_102 (Flatten)       (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,913\n",
      "Trainable params: 55,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "44/44 [==============================] - 2s 14ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 2/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 3/200\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 4/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 5/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 6/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 7/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 8/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 9/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 10/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 11/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 12/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 13/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 14/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 15/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 16/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 17/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 18/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 19/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 20/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 21/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 22/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 23/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 24/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 25/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 26/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 27/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 28/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 29/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 30/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 31/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 32/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 33/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 34/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 35/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 36/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 37/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 38/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 39/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 40/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 41/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 42/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 43/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 44/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 45/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 46/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 47/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 48/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 49/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 50/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 51/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 52/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 53/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 54/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 55/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 56/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 57/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 58/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 59/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 60/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 61/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 62/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 63/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 64/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 65/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 66/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 67/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 68/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 69/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 70/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 71/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 72/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 73/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 74/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 75/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 76/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 77/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 78/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 79/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 80/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 81/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 82/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 83/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 84/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 85/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 86/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 87/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 88/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 89/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 90/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 91/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 92/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 93/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 94/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 95/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 96/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 97/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 98/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 99/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 100/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 101/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 102/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 103/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 104/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 105/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 106/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 107/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 108/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 109/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 110/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 111/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 112/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 113/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 114/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 115/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 116/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 117/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 118/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 119/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 120/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 121/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 122/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 123/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 124/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 125/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 126/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 127/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 128/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 129/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 130/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 131/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 132/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 133/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 134/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 135/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 136/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 137/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 138/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 139/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 140/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 141/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 142/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 143/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 144/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 145/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 146/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 147/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 148/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 149/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 150/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 152/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 153/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 154/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 155/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 156/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 157/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 158/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 159/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 160/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 161/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 162/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 163/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 164/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 165/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 166/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 167/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 168/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 169/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 170/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 171/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 172/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 173/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 174/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 175/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 176/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 177/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 178/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 179/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 180/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 181/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 182/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 183/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 184/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 185/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 186/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 187/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 188/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 189/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 190/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 191/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 192/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 193/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 194/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 195/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 196/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 197/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 198/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 199/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Epoch 200/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.1868 - val_loss: 0.0035\n",
      "Thời gian huấn luyện:  70.50072145462036\n",
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_25 (GRU)                (None, 10, 116)           41412     \n",
      "                                                                 \n",
      " flatten_103 (Flatten)       (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,573\n",
      "Trainable params: 42,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 866us/step\n",
      "13/13 [==============================] - 0s 1000us/step\n",
      "52/52 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0745 - val_loss: 0.0416\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0189\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0105\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 7.7188e-04 - val_loss: 4.8688e-04\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.8161e-04 - val_loss: 3.1993e-04\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.5093e-04 - val_loss: 2.1795e-04\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.3631e-04 - val_loss: 1.5902e-04\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.3212e-04 - val_loss: 1.0395e-04\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.2515e-04 - val_loss: 9.9863e-05\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.1757e-04 - val_loss: 9.6191e-05\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.1684e-04 - val_loss: 7.2185e-05\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.1071e-04 - val_loss: 6.1606e-05\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.0953e-04 - val_loss: 6.1671e-05\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.0666e-04 - val_loss: 5.5468e-05\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.0292e-04 - val_loss: 4.9760e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.0399e-04 - val_loss: 4.7991e-05\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.9793e-04 - val_loss: 4.7110e-05\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.9703e-04 - val_loss: 4.5723e-05\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.9784e-04 - val_loss: 4.5113e-05\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.9565e-04 - val_loss: 4.3009e-05\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.9023e-04 - val_loss: 4.1681e-05\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.8844e-04 - val_loss: 4.2146e-05\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.8621e-04 - val_loss: 4.1512e-05\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.8644e-04 - val_loss: 4.1269e-05\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.8583e-04 - val_loss: 4.2491e-05\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.8395e-04 - val_loss: 4.6895e-05\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.8153e-04 - val_loss: 3.8669e-05\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7879e-04 - val_loss: 4.3355e-05\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.8081e-04 - val_loss: 5.1411e-05\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.8426e-04 - val_loss: 4.6733e-05\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7335e-04 - val_loss: 4.2778e-05\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7600e-04 - val_loss: 4.2829e-05\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6774e-04 - val_loss: 4.2018e-05\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6722e-04 - val_loss: 3.4067e-05\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6787e-04 - val_loss: 3.5756e-05\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6735e-04 - val_loss: 4.6656e-05\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6237e-04 - val_loss: 4.2593e-05\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7063e-04 - val_loss: 4.3052e-05\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6007e-04 - val_loss: 3.9586e-05\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5658e-04 - val_loss: 4.5064e-05\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5407e-04 - val_loss: 4.1799e-05\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5992e-04 - val_loss: 5.3810e-05\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5233e-04 - val_loss: 4.8564e-05\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6108e-04 - val_loss: 3.0677e-05\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4920e-04 - val_loss: 3.6630e-05\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4417e-04 - val_loss: 4.0079e-05\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4168e-04 - val_loss: 5.8312e-05\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4525e-04 - val_loss: 3.5303e-05\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3686e-04 - val_loss: 3.2434e-05\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3216e-04 - val_loss: 7.1273e-05\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3976e-04 - val_loss: 6.1885e-05\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4169e-04 - val_loss: 3.0825e-05\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3249e-04 - val_loss: 3.5992e-05\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2763e-04 - val_loss: 4.4565e-05\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2501e-04 - val_loss: 4.6784e-05\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2832e-04 - val_loss: 5.6867e-05\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2711e-04 - val_loss: 3.0825e-05\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.1754e-04 - val_loss: 4.2429e-05\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.1635e-04 - val_loss: 4.5307e-05\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.1858e-04 - val_loss: 2.7204e-05\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.0975e-04 - val_loss: 3.9107e-05\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.1101e-04 - val_loss: 3.2908e-05\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.1119e-04 - val_loss: 2.9402e-05\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.1172e-04 - val_loss: 2.6461e-05\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.0866e-04 - val_loss: 5.1900e-05\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.1150e-04 - val_loss: 2.8243e-05\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.0023e-04 - val_loss: 3.1312e-05\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.9723e-04 - val_loss: 3.0837e-05\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.9732e-04 - val_loss: 2.5128e-05\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.9365e-04 - val_loss: 2.8816e-05\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.9232e-04 - val_loss: 3.9983e-05\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.8767e-04 - val_loss: 2.7349e-05\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.8859e-04 - val_loss: 2.4634e-05\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.8566e-04 - val_loss: 2.4673e-05\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.8818e-04 - val_loss: 4.2703e-05\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.8452e-04 - val_loss: 5.0248e-05\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.7966e-04 - val_loss: 2.6097e-05\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.7443e-04 - val_loss: 3.5338e-05\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.7107e-04 - val_loss: 2.6769e-05\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.7003e-04 - val_loss: 3.6345e-05\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.6711e-04 - val_loss: 3.5058e-05\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.6220e-04 - val_loss: 2.3861e-05\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.6806e-04 - val_loss: 3.9131e-05\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.6784e-04 - val_loss: 2.2830e-05\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.6453e-04 - val_loss: 4.1473e-05\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.5705e-04 - val_loss: 3.3499e-05\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.5583e-04 - val_loss: 4.5071e-05\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.5366e-04 - val_loss: 3.1351e-05\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.5010e-04 - val_loss: 2.1857e-05\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.5752e-04 - val_loss: 6.2876e-05\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.4752e-04 - val_loss: 2.2780e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.4550e-04 - val_loss: 3.3689e-05\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.5046e-04 - val_loss: 3.6752e-05\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.4167e-04 - val_loss: 3.1223e-05\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.4004e-04 - val_loss: 2.4628e-05\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.3303e-04 - val_loss: 3.1291e-05\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.3487e-04 - val_loss: 2.0770e-05\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.3016e-04 - val_loss: 2.3065e-05\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.3227e-04 - val_loss: 2.5159e-05\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.2870e-04 - val_loss: 2.4162e-05\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.2815e-04 - val_loss: 2.0902e-05\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.2180e-04 - val_loss: 3.3546e-05\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.2109e-04 - val_loss: 5.7389e-05\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.1532e-04 - val_loss: 2.8988e-05\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.0725e-04 - val_loss: 3.5256e-05\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.0599e-04 - val_loss: 3.0875e-05\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.0552e-04 - val_loss: 2.2751e-05\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.0932e-04 - val_loss: 4.3061e-05\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.0570e-04 - val_loss: 2.3630e-05\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.0321e-04 - val_loss: 2.8062e-05\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.9985e-04 - val_loss: 3.9745e-05\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.9688e-04 - val_loss: 2.0279e-05\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.9224e-04 - val_loss: 2.4499e-05\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.9249e-04 - val_loss: 3.5836e-05\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.8784e-04 - val_loss: 2.7728e-05\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.8796e-04 - val_loss: 2.1108e-05\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.8457e-04 - val_loss: 2.6371e-05\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.8098e-04 - val_loss: 4.0863e-05\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.7778e-04 - val_loss: 3.1065e-05\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.8280e-04 - val_loss: 2.7724e-05\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.7663e-04 - val_loss: 1.7960e-05\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.7668e-04 - val_loss: 2.4889e-05\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.7233e-04 - val_loss: 2.1854e-05\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.6906e-04 - val_loss: 1.9054e-05\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.6613e-04 - val_loss: 2.5601e-05\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.6301e-04 - val_loss: 2.4655e-05\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.7031e-04 - val_loss: 2.9994e-05\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.6794e-04 - val_loss: 2.2711e-05\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5640e-04 - val_loss: 2.6175e-05\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5397e-04 - val_loss: 2.1143e-05\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5526e-04 - val_loss: 2.4769e-05\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5291e-04 - val_loss: 2.2846e-05\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5161e-04 - val_loss: 1.7022e-05\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4683e-04 - val_loss: 3.2562e-05\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4807e-04 - val_loss: 3.9832e-05\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4801e-04 - val_loss: 1.7190e-05\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5032e-04 - val_loss: 1.7144e-05\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4358e-04 - val_loss: 2.2920e-05\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4101e-04 - val_loss: 3.3006e-05\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3837e-04 - val_loss: 1.8261e-05\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3526e-04 - val_loss: 1.6000e-05\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3185e-04 - val_loss: 1.6015e-05\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2848e-04 - val_loss: 2.9506e-05\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3189e-04 - val_loss: 1.8045e-05\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2459e-04 - val_loss: 2.7923e-05\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2633e-04 - val_loss: 2.2168e-05\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1979e-04 - val_loss: 4.4890e-05\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2191e-04 - val_loss: 1.8848e-05\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1893e-04 - val_loss: 4.5678e-05\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1779e-04 - val_loss: 2.2789e-05\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1476e-04 - val_loss: 1.8407e-05\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1313e-04 - val_loss: 3.5988e-05\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1141e-04 - val_loss: 2.2436e-05\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0972e-04 - val_loss: 2.5198e-05\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0616e-04 - val_loss: 1.9191e-05\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0644e-04 - val_loss: 1.5769e-05\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0501e-04 - val_loss: 2.9573e-05\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0216e-04 - val_loss: 2.6537e-05\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0142e-04 - val_loss: 2.1361e-05\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9910e-04 - val_loss: 2.4309e-05\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9797e-04 - val_loss: 1.4961e-05\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9523e-04 - val_loss: 2.2761e-05\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9194e-04 - val_loss: 3.7786e-05\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0833e-04 - val_loss: 1.4952e-05\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9530e-04 - val_loss: 2.6646e-05\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8920e-04 - val_loss: 1.6463e-05\n",
      "Epoch 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8806e-04 - val_loss: 1.7785e-05\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8604e-04 - val_loss: 1.5986e-05\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8325e-04 - val_loss: 2.0166e-05\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8583e-04 - val_loss: 2.7751e-05\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7873e-04 - val_loss: 2.8905e-05\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7897e-04 - val_loss: 1.8124e-05\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8106e-04 - val_loss: 1.4713e-05\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7673e-04 - val_loss: 1.4385e-05\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7369e-04 - val_loss: 1.7993e-05\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7335e-04 - val_loss: 1.3068e-05\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7525e-04 - val_loss: 1.8314e-05\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7549e-04 - val_loss: 2.5202e-05\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7440e-04 - val_loss: 2.6553e-05\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6888e-04 - val_loss: 1.4957e-05\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6915e-04 - val_loss: 1.7886e-05\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6961e-04 - val_loss: 1.3640e-05\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7025e-04 - val_loss: 1.9033e-05\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6308e-04 - val_loss: 1.5006e-05\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6660e-04 - val_loss: 1.3537e-05\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6278e-04 - val_loss: 2.3631e-05\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5855e-04 - val_loss: 1.4667e-05\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6768e-04 - val_loss: 1.2109e-05\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5836e-04 - val_loss: 1.6752e-05\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5795e-04 - val_loss: 1.2169e-05\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6796e-04 - val_loss: 1.2189e-05\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5367e-04 - val_loss: 1.8417e-05\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5348e-04 - val_loss: 1.3318e-05\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5383e-04 - val_loss: 1.4976e-05\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5174e-04 - val_loss: 2.0058e-05\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5625e-04 - val_loss: 1.5584e-05\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5085e-04 - val_loss: 1.3697e-05\n",
      "Thời gian huấn luyện:  16.453669786453247\n",
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_130 (Dense)           (None, 10, 116)           232       \n",
      "                                                                 \n",
      " flatten_104 (Flatten)       (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 1s 7ms/step - loss: 0.0392 - val_loss: 3.2731e-04\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 5.1663e-04\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 5.7693e-04\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 5.6382e-04\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.9311e-04 - val_loss: 5.5131e-04\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.5885e-04 - val_loss: 4.9025e-04\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.2956e-04 - val_loss: 4.4741e-04\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.9394e-04 - val_loss: 4.0653e-04\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.7943e-04 - val_loss: 3.7835e-04\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.5060e-04 - val_loss: 3.7477e-04\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.2833e-04 - val_loss: 3.1665e-04\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.9742e-04 - val_loss: 3.2857e-04\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.9523e-04 - val_loss: 2.6523e-04\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.6531e-04 - val_loss: 2.8610e-04\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.8619e-04 - val_loss: 2.5206e-04\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.2260e-04 - val_loss: 1.9695e-04\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.1245e-04 - val_loss: 2.2287e-04\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.0687e-04 - val_loss: 2.3079e-04\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.9769e-04 - val_loss: 1.5959e-04\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.8877e-04 - val_loss: 1.6831e-04\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.4183e-04 - val_loss: 1.5960e-04\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.5881e-04 - val_loss: 1.6640e-04\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.5229e-04 - val_loss: 1.6877e-04\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.5059e-04 - val_loss: 1.4496e-04\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.9791e-04 - val_loss: 1.0044e-04\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.7776e-04 - val_loss: 9.5011e-05\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.6961e-04 - val_loss: 1.1073e-04\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.5460e-04 - val_loss: 8.4320e-05\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.4927e-04 - val_loss: 7.1200e-05\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.6145e-04 - val_loss: 6.9845e-05\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.2781e-04 - val_loss: 5.5860e-05\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.3260e-04 - val_loss: 4.6694e-05\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.2200e-04 - val_loss: 6.2789e-05\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.0925e-04 - val_loss: 6.4182e-05\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.0720e-04 - val_loss: 4.2483e-05\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.0250e-04 - val_loss: 4.2972e-05\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.9020e-04 - val_loss: 5.6261e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.8915e-04 - val_loss: 3.0667e-05\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.1163e-04 - val_loss: 4.1937e-05\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.7564e-04 - val_loss: 3.4721e-05\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.7430e-04 - val_loss: 3.1173e-05\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.6055e-04 - val_loss: 3.3425e-05\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.0705e-04 - val_loss: 2.6957e-05\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.7435e-04 - val_loss: 2.7768e-05\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.4439e-04 - val_loss: 3.0018e-05\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.5123e-04 - val_loss: 2.8674e-05\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.6637e-04 - val_loss: 2.0476e-05\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.4248e-04 - val_loss: 2.1250e-05\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.4471e-04 - val_loss: 1.8434e-05\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3559e-04 - val_loss: 2.1070e-05\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.2435e-04 - val_loss: 1.8121e-05\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.1685e-04 - val_loss: 2.0002e-05\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.1353e-04 - val_loss: 2.0843e-05\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3279e-04 - val_loss: 1.7514e-05\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.1322e-04 - val_loss: 1.7314e-05\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.2940e-04 - val_loss: 1.9379e-05\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.1107e-04 - val_loss: 2.3946e-05\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.9664e-04 - val_loss: 1.7857e-05\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3111e-04 - val_loss: 2.5779e-05\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.2808e-04 - val_loss: 1.6686e-05\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.0326e-04 - val_loss: 2.1947e-05\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.0171e-04 - val_loss: 1.6029e-05\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.7835e-04 - val_loss: 1.7486e-05\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3131e-04 - val_loss: 1.5991e-05\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.7815e-04 - val_loss: 1.5762e-05\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.8893e-04 - val_loss: 1.5577e-05\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.0232e-04 - val_loss: 2.0397e-05\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.7078e-04 - val_loss: 1.6045e-05\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.1934e-04 - val_loss: 1.5816e-05\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3158e-04 - val_loss: 1.5254e-05\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.0426e-04 - val_loss: 2.1412e-05\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.0014e-04 - val_loss: 1.8126e-05\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.8262e-04 - val_loss: 1.5964e-05\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.6552e-04 - val_loss: 1.7410e-05\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.4999e-04 - val_loss: 1.5914e-05\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.5119e-04 - val_loss: 1.5499e-05\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.5213e-04 - val_loss: 1.5407e-05\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.8723e-04 - val_loss: 1.4372e-05\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.3554e-04 - val_loss: 1.3894e-05\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.4453e-04 - val_loss: 1.4671e-05\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.4341e-04 - val_loss: 1.5913e-05\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.4224e-04 - val_loss: 1.6177e-05\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.2416e-04 - val_loss: 1.6211e-05\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.5129e-04 - val_loss: 1.4965e-05\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.2650e-04 - val_loss: 1.5935e-05\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.2710e-04 - val_loss: 1.3510e-05\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.2912e-04 - val_loss: 1.3313e-05\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.2060e-04 - val_loss: 1.4262e-05\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.1042e-04 - val_loss: 1.3894e-05\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.1244e-04 - val_loss: 1.5402e-05\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.4026e-04 - val_loss: 1.3482e-05\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.1800e-04 - val_loss: 1.3125e-05\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.5380e-04 - val_loss: 1.8961e-05\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.0984e-04 - val_loss: 1.3724e-05\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.0865e-04 - val_loss: 1.5235e-05\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.9894e-04 - val_loss: 1.5027e-05\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.0242e-04 - val_loss: 1.2609e-05\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.0237e-04 - val_loss: 1.2235e-05\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.9325e-04 - val_loss: 1.2275e-05\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.9555e-04 - val_loss: 1.3676e-05\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.9400e-04 - val_loss: 1.3656e-05\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.9906e-04 - val_loss: 2.0238e-05\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.0068e-04 - val_loss: 1.1846e-05\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.9807e-04 - val_loss: 1.5506e-05\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.1661e-04 - val_loss: 1.7805e-05\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.0327e-04 - val_loss: 1.3969e-05\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.0597e-04 - val_loss: 1.3742e-05\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.1780e-04 - val_loss: 1.4220e-05\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.7898e-04 - val_loss: 2.1641e-05\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.7602e-04 - val_loss: 1.2264e-05\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.7847e-04 - val_loss: 1.3646e-05\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.4324e-04 - val_loss: 2.3521e-05\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 4ms/step - loss: 2.7517e-04 - val_loss: 1.4797e-05\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.6881e-04 - val_loss: 1.6390e-05\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.8918e-04 - val_loss: 1.5417e-05\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.9925e-04 - val_loss: 1.1302e-05\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.7188e-04 - val_loss: 2.0896e-05\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.7200e-04 - val_loss: 1.9326e-05\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.7512e-04 - val_loss: 1.2443e-05\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.1437e-04 - val_loss: 1.0930e-05\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.6565e-04 - val_loss: 1.9787e-05\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.6721e-04 - val_loss: 1.3555e-05\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.9459e-04 - val_loss: 1.8545e-05\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.6324e-04 - val_loss: 1.2619e-05\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.7167e-04 - val_loss: 1.8464e-05\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.6627e-04 - val_loss: 1.2441e-05\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.5134e-04 - val_loss: 1.3352e-05\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.8628e-04 - val_loss: 1.2623e-05\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.7322e-04 - val_loss: 9.8545e-06\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.6802e-04 - val_loss: 1.2558e-05\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.6856e-04 - val_loss: 1.1204e-05\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.4767e-04 - val_loss: 2.9388e-05\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.5565e-04 - val_loss: 1.4549e-05\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.6100e-04 - val_loss: 1.1959e-05\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.5527e-04 - val_loss: 1.1425e-05\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.4691e-04 - val_loss: 1.0176e-05\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.5650e-04 - val_loss: 1.2678e-05\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.4147e-04 - val_loss: 1.0161e-05\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.5490e-04 - val_loss: 1.0476e-05\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.3102e-04 - val_loss: 1.4683e-05\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.3570e-04 - val_loss: 1.4905e-05\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.8590e-04 - val_loss: 1.0599e-05\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.7682e-04 - val_loss: 2.1812e-05\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.3958e-04 - val_loss: 1.0201e-05\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.3872e-04 - val_loss: 9.9430e-06\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.3921e-04 - val_loss: 1.2403e-05\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.2202e-04 - val_loss: 9.4644e-06\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.3552e-04 - val_loss: 1.0703e-05\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.7282e-04 - val_loss: 9.7612e-06\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.3131e-04 - val_loss: 1.3999e-05\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.5136e-04 - val_loss: 1.3537e-05\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.5733e-04 - val_loss: 1.1335e-05\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.2380e-04 - val_loss: 9.2549e-06\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.2508e-04 - val_loss: 1.1086e-05\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.2914e-04 - val_loss: 1.5523e-05\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.2123e-04 - val_loss: 9.7754e-06\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.5649e-04 - val_loss: 1.5955e-05\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.2850e-04 - val_loss: 1.2022e-05\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.3052e-04 - val_loss: 1.7287e-05\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.2113e-04 - val_loss: 1.1081e-05\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.2391e-04 - val_loss: 1.1409e-05\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.5508e-04 - val_loss: 1.3366e-05\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.5606e-04 - val_loss: 8.9216e-06\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.1902e-04 - val_loss: 8.8230e-06\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.1910e-04 - val_loss: 1.4690e-05\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.1682e-04 - val_loss: 9.2662e-06\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.2914e-04 - val_loss: 1.0435e-05\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.1399e-04 - val_loss: 9.6555e-06\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.3804e-04 - val_loss: 1.1801e-05\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.0511e-04 - val_loss: 1.2360e-05\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.0553e-04 - val_loss: 1.0891e-05\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.0927e-04 - val_loss: 1.5531e-05\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.0263e-04 - val_loss: 8.3456e-06\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.2156e-04 - val_loss: 9.4493e-06\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.1058e-04 - val_loss: 1.8909e-05\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.3247e-04 - val_loss: 1.9288e-05\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.3018e-04 - val_loss: 8.5676e-06\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.0409e-04 - val_loss: 1.0663e-05\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.1403e-04 - val_loss: 1.1947e-05\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.5004e-04 - val_loss: 1.1607e-05\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.1520e-04 - val_loss: 1.4241e-05\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.1641e-04 - val_loss: 1.0114e-05\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.0704e-04 - val_loss: 9.5996e-06\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.1286e-04 - val_loss: 1.3551e-05\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.1649e-04 - val_loss: 1.2335e-05\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.1376e-04 - val_loss: 1.1055e-05\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.0182e-04 - val_loss: 1.0156e-05\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 4ms/step - loss: 2.0038e-04 - val_loss: 7.7803e-06\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1.9364e-04 - val_loss: 1.0568e-05\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.0288e-04 - val_loss: 2.0621e-05\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.0872e-04 - val_loss: 2.2656e-05\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.2087e-04 - val_loss: 1.8307e-05\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1.9469e-04 - val_loss: 9.6928e-06\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.0642e-04 - val_loss: 8.2370e-06\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.0178e-04 - val_loss: 1.4197e-05\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1.9773e-04 - val_loss: 1.2810e-05\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1.9400e-04 - val_loss: 8.0038e-06\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1.8503e-04 - val_loss: 1.5508e-05\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.1595e-04 - val_loss: 8.7878e-06\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.0863e-04 - val_loss: 8.0362e-06\n",
      "Thời gian huấn luyện:  33.22654485702515\n",
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_26 (SimpleRNN)   (None, 10, 116)           13688     \n",
      "                                                                 \n",
      " flatten_105 (Flatten)       (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,849\n",
      "Trainable params: 14,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 2s 17ms/step - loss: 0.0297 - val_loss: 0.0013\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 1.9505e-04\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.1271e-04 - val_loss: 4.8867e-05\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.0203e-04 - val_loss: 3.6040e-05\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.8501e-04 - val_loss: 5.8748e-05\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.0359e-04 - val_loss: 4.9855e-05\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.8196e-04 - val_loss: 4.0635e-05\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.8276e-04 - val_loss: 3.8541e-05\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.7856e-04 - val_loss: 4.3217e-05\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.8031e-04 - val_loss: 3.4368e-05\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.7344e-04 - val_loss: 4.5519e-05\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.8465e-04 - val_loss: 3.4464e-05\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.6398e-04 - val_loss: 3.5564e-05\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.5472e-04 - val_loss: 3.2492e-05\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.5940e-04 - val_loss: 3.2743e-05\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.5912e-04 - val_loss: 3.2499e-05\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.5296e-04 - val_loss: 3.3327e-05\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.4499e-04 - val_loss: 3.3386e-05\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.4407e-04 - val_loss: 3.3173e-05\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.5129e-04 - val_loss: 3.2714e-05\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.4203e-04 - val_loss: 3.8992e-05\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.4071e-04 - val_loss: 3.4833e-05\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.2957e-04 - val_loss: 3.3189e-05\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.3694e-04 - val_loss: 3.2441e-05\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.2770e-04 - val_loss: 3.2424e-05\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.2824e-04 - val_loss: 3.2503e-05\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.2263e-04 - val_loss: 3.3472e-05\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.2684e-04 - val_loss: 3.2089e-05\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.2381e-04 - val_loss: 3.2106e-05\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.0223e-04 - val_loss: 3.5988e-05\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.1474e-04 - val_loss: 3.2037e-05\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.4285e-04 - val_loss: 3.4478e-05\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.0904e-04 - val_loss: 4.3108e-05\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.0021e-04 - val_loss: 4.0570e-05\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.9927e-04 - val_loss: 3.4022e-05\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.9816e-04 - val_loss: 3.3570e-05\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.9170e-04 - val_loss: 3.7558e-05\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.8950e-04 - val_loss: 3.1743e-05\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.8701e-04 - val_loss: 4.3284e-05\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.7998e-04 - val_loss: 3.4124e-05\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.7582e-04 - val_loss: 3.2499e-05\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.7657e-04 - val_loss: 4.0942e-05\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.8329e-04 - val_loss: 3.1652e-05\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.6369e-04 - val_loss: 3.9496e-05\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.6964e-04 - val_loss: 3.1123e-05\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.6175e-04 - val_loss: 3.3742e-05\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.7249e-04 - val_loss: 3.4421e-05\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.6140e-04 - val_loss: 4.1257e-05\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.9578e-04 - val_loss: 4.2687e-05\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.6484e-04 - val_loss: 3.5477e-05\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.5468e-04 - val_loss: 4.1723e-05\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.5147e-04 - val_loss: 4.9259e-05\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.4142e-04 - val_loss: 3.3983e-05\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.8204e-04 - val_loss: 4.5558e-05\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.5165e-04 - val_loss: 4.0092e-05\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 9ms/step - loss: 6.3427e-04 - val_loss: 3.4757e-05\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.1734e-04 - val_loss: 4.1654e-05\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.2050e-04 - val_loss: 2.9000e-05\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.4437e-04 - val_loss: 2.9362e-05\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.3698e-04 - val_loss: 3.2067e-05\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.2033e-04 - val_loss: 3.9408e-05\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.0528e-04 - val_loss: 3.2973e-05\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.9620e-04 - val_loss: 3.7891e-05\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.9806e-04 - val_loss: 3.0197e-05\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.9592e-04 - val_loss: 4.4436e-05\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.0018e-04 - val_loss: 4.5692e-05\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.1030e-04 - val_loss: 5.0945e-05\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.8200e-04 - val_loss: 3.4127e-05\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.0656e-04 - val_loss: 3.3746e-05\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.7183e-04 - val_loss: 3.2919e-05\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.7647e-04 - val_loss: 3.2313e-05\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.7391e-04 - val_loss: 4.3190e-05\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.7411e-04 - val_loss: 3.1672e-05\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.6338e-04 - val_loss: 2.9375e-05\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.6679e-04 - val_loss: 2.9788e-05\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.7857e-04 - val_loss: 4.6358e-05\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.6513e-04 - val_loss: 4.2143e-05\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.4850e-04 - val_loss: 3.9348e-05\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.6119e-04 - val_loss: 2.7988e-05\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.1840e-04 - val_loss: 3.3621e-05\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.8132e-04 - val_loss: 2.8047e-05\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.5282e-04 - val_loss: 3.6791e-05\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.3326e-04 - val_loss: 3.1134e-05\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.2594e-04 - val_loss: 3.5546e-05\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.2872e-04 - val_loss: 4.1586e-05\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.3347e-04 - val_loss: 4.0430e-05\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.3962e-04 - val_loss: 2.9385e-05\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.3645e-04 - val_loss: 3.6374e-05\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.1546e-04 - val_loss: 3.4947e-05\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.1701e-04 - val_loss: 3.7156e-05\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.1024e-04 - val_loss: 3.1699e-05\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.9263e-04 - val_loss: 2.4712e-05\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.1665e-04 - val_loss: 3.6310e-05\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.0721e-04 - val_loss: 2.6328e-05\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.9552e-04 - val_loss: 3.4777e-05\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.8786e-04 - val_loss: 3.0242e-05\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.9897e-04 - val_loss: 2.6546e-05\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.2392e-04 - val_loss: 2.6464e-05\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.7793e-04 - val_loss: 4.7034e-05\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.8507e-04 - val_loss: 3.5198e-05\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.8820e-04 - val_loss: 4.4417e-05\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.8884e-04 - val_loss: 2.3712e-05\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.7228e-04 - val_loss: 2.7938e-05\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.8413e-04 - val_loss: 2.3714e-05\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.7788e-04 - val_loss: 4.1088e-05\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.6119e-04 - val_loss: 2.5350e-05\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.6992e-04 - val_loss: 3.1946e-05\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.7464e-04 - val_loss: 2.6620e-05\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.4812e-04 - val_loss: 2.5837e-05\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.6294e-04 - val_loss: 2.8697e-05\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.5851e-04 - val_loss: 2.7573e-05\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.6221e-04 - val_loss: 4.8359e-05\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.4801e-04 - val_loss: 2.6429e-05\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.3804e-04 - val_loss: 4.7931e-05\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.4153e-04 - val_loss: 2.9681e-05\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.7224e-04 - val_loss: 2.5073e-05\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.3313e-04 - val_loss: 3.5596e-05\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.3586e-04 - val_loss: 2.1687e-05\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.4252e-04 - val_loss: 2.6106e-05\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.3386e-04 - val_loss: 4.1297e-05\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.5122e-04 - val_loss: 2.2499e-05\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.3968e-04 - val_loss: 2.2098e-05\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.4889e-04 - val_loss: 2.2900e-05\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.3516e-04 - val_loss: 3.2912e-05\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.2850e-04 - val_loss: 2.6311e-05\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.1199e-04 - val_loss: 3.1313e-05\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.2930e-04 - val_loss: 3.3112e-05\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.3002e-04 - val_loss: 4.1915e-05\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.2441e-04 - val_loss: 2.6269e-05\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.3411e-04 - val_loss: 2.8816e-05\n",
      "Epoch 131/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 9ms/step - loss: 4.4898e-04 - val_loss: 2.5504e-05\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.1150e-04 - val_loss: 2.2296e-05\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.1337e-04 - val_loss: 2.1692e-05\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.1916e-04 - val_loss: 3.2767e-05\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.1930e-04 - val_loss: 3.0291e-05\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.2599e-04 - val_loss: 2.7174e-05\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.2082e-04 - val_loss: 4.5154e-05\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.1480e-04 - val_loss: 1.9740e-05\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.0715e-04 - val_loss: 2.4161e-05\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.9900e-04 - val_loss: 2.0141e-05\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.9351e-04 - val_loss: 2.7698e-05\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.9281e-04 - val_loss: 2.2221e-05\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.9632e-04 - val_loss: 2.4137e-05\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.0340e-04 - val_loss: 3.0332e-05\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.0500e-04 - val_loss: 2.4065e-05\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.9032e-04 - val_loss: 2.7776e-05\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.0746e-04 - val_loss: 2.6635e-05\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.7650e-04 - val_loss: 1.9018e-05\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.8665e-04 - val_loss: 3.9093e-05\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.8481e-04 - val_loss: 1.9640e-05\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.7904e-04 - val_loss: 2.0470e-05\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.7764e-04 - val_loss: 1.8896e-05\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.8317e-04 - val_loss: 2.1487e-05\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.7342e-04 - val_loss: 2.3479e-05\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.0430e-04 - val_loss: 1.8798e-05\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.8135e-04 - val_loss: 3.1951e-05\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.6091e-04 - val_loss: 2.2242e-05\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.9081e-04 - val_loss: 2.0554e-05\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.7063e-04 - val_loss: 2.4809e-05\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.6938e-04 - val_loss: 2.0949e-05\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.7482e-04 - val_loss: 2.6761e-05\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.6213e-04 - val_loss: 1.9249e-05\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.8932e-04 - val_loss: 2.1129e-05\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.6354e-04 - val_loss: 1.8184e-05\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.6715e-04 - val_loss: 1.8729e-05\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.6746e-04 - val_loss: 2.1108e-05\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.5640e-04 - val_loss: 2.3324e-05\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.5470e-04 - val_loss: 3.2415e-05\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.7188e-04 - val_loss: 2.0273e-05\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.5183e-04 - val_loss: 2.3499e-05\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.5328e-04 - val_loss: 2.0784e-05\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.6328e-04 - val_loss: 2.7420e-05\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.4691e-04 - val_loss: 2.3727e-05\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.6449e-04 - val_loss: 2.1605e-05\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.5097e-04 - val_loss: 1.8011e-05\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.6290e-04 - val_loss: 1.9785e-05\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.4509e-04 - val_loss: 2.0875e-05\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.4702e-04 - val_loss: 2.9743e-05\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.5681e-04 - val_loss: 1.7191e-05\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.4132e-04 - val_loss: 2.9432e-05\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.5498e-04 - val_loss: 1.6970e-05\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.4255e-04 - val_loss: 1.8845e-05\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.4414e-04 - val_loss: 1.9005e-05\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.4829e-04 - val_loss: 1.9900e-05\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.3955e-04 - val_loss: 1.9986e-05\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.3045e-04 - val_loss: 1.7589e-05\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.5328e-04 - val_loss: 2.3809e-05\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.2717e-04 - val_loss: 2.1333e-05\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.3139e-04 - val_loss: 1.6886e-05\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.2164e-04 - val_loss: 1.8626e-05\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.2479e-04 - val_loss: 2.2275e-05\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.5419e-04 - val_loss: 1.9476e-05\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.3200e-04 - val_loss: 2.2814e-05\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.1987e-04 - val_loss: 1.8181e-05\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.2645e-04 - val_loss: 1.8957e-05\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.4705e-04 - val_loss: 1.8542e-05\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.3956e-04 - val_loss: 1.7002e-05\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.1653e-04 - val_loss: 1.7292e-05\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.1536e-04 - val_loss: 2.0157e-05\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.2136e-04 - val_loss: 1.6287e-05\n",
      "Thời gian huấn luyện:  77.09236884117126\n",
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_26 (LSTM)              (None, 10, 116)           54752     \n",
      "                                                                 \n",
      " flatten_106 (Flatten)       (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 1)                 1161      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,913\n",
      "Trainable params: 55,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 2s 16ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0029\n",
      "Thời gian huấn luyện:  71.58506107330322\n",
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_26 (GRU)                (None, 10, 116)           41412     \n",
      "                                                                 \n",
      " flatten_107 (Flatten)       (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,573\n",
      "Trainable params: 42,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 950us/step\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 8 elements, new values have 7 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14716\\4100752304.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0minformation_FFNN_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minformation_FFNN_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[0minformation_FFNN_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Training ratio'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'epcoch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Batch_size'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Validation'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MSE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MAE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[0minformation_RNN_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minformation_RNN_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5586\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5587\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5588\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5589\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5590\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    767\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 769\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    770\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;31m# Caller is responsible for ensuring we have an Index object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\base.py\u001b[0m in \u001b[0;36m_validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     70\u001b[0m                 \u001b[1;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[1;34mf\"values have {new_len} elements\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 8 elements, new values have 7 elements"
     ]
    }
   ],
   "source": [
    "#dataset_ratio, epoch, batch_size, validation\n",
    "information_FFNN_df = []\n",
    "information_RNN_df = []\n",
    "information_LSTM_df = []\n",
    "information_GRU_df = []\n",
    "params = [[0.6, 0.7, 0.8], [50, 100, 200], [32], [0.1, 0.15, 0.2]]\n",
    "# params = [[0.8], [1, 2], [32], [0.15]]\n",
    "params = get_combinations(params)\n",
    "for p in params:\n",
    "    ratio = p[0]\n",
    "    train_size = int(len(ds) * ratio)\n",
    "    test_size = len(ds) - train_size\n",
    "    train, test = ds[0:train_size,:], ds[train_size:len(ds)+1,:]\n",
    "    trainX, trainY, testX, testY = create_train_test_data(train, test, look_back)\n",
    "    \n",
    "    epochs = p[1]\n",
    "    batch_size= p[2]\n",
    "    validation_split= p[3]\n",
    "    \n",
    "    \n",
    "    delta_ffnn, model_ffnn = create_ffnn_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split)\n",
    "    delta_rnn, model_rnn = create_rnn_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split)\n",
    "    delta_lstm, model_lstm = create_lstm_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split)\n",
    "    delta_gru, model_gru =create_gru_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split)\n",
    "    \n",
    "    models_bag = {\n",
    "        \"FFNN\": model_ffnn,\n",
    "        \"RNN\": model_rnn,\n",
    "        \"LSTM\": model_lstm,\n",
    "        \"GRU\": model_gru\n",
    "    }\n",
    "    \n",
    "    accuracy_bag = {}\n",
    "    \n",
    "    for model_name, trained_model in models_bag.items():\n",
    "        if model_name == 'FFNN':\n",
    "            mse, mae, mape, rmse, trainPredict, testPredict = create_accuracy(trained_model, scaler, trainX, trainY, testX, testY)\n",
    "            info = [model_name] + list(p) + [mse, mae] + [delta_ffnn]\n",
    "            information_FFNN_df.append(info)\n",
    "        elif model_name == 'RNN':\n",
    "            mse, mae, mape, rmse, trainPredict, testPredict = create_accuracy(trained_model, scaler, trainX, trainY, testX, testY)\n",
    "            info = [model_name] + list(p) + [mse, mae] + [delta_rnn]\n",
    "            information_RNN_df.append(info)\n",
    "        elif model_name == 'LSTM':\n",
    "            mse, mae, mape, rmse, trainPredict, testPredict = create_accuracy(trained_model, scaler, trainX, trainY, testX, testY)\n",
    "            info = [model_name] + list(p) + [mse, mae] + [delta_lstm]\n",
    "            information_LSTM_df.append(info)\n",
    "        elif model_name == 'GRU':\n",
    "            mse, mae, mape, rmse, trainPredict, testPredict = create_accuracy(trained_model, scaler, trainX, trainY, testX, testY)\n",
    "            info = [model_name] + list(p) + [mse, mae] + [delta_gru]\n",
    "            information_GRU_df.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0f886a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "information_FFNN_df = pd.DataFrame(information_FFNN_df)\n",
    "information_FFNN_df.columns = ['Model', 'Training ratio', 'Epochs', 'Batch_size', 'Validation', 'MSE', 'MAE', 'Training Time']\n",
    "\n",
    "information_RNN_df = pd.DataFrame(information_RNN_df)\n",
    "information_RNN_df.columns = ['Model', 'Training ratio', 'Epochs', 'Batch_size', 'Validation', 'MSE', 'MAE', 'Training Time']\n",
    "\n",
    "information_LSTM_df = pd.DataFrame(information_LSTM_df)\n",
    "information_LSTM_df.columns = ['Model', 'Training ratio', 'Epochs', 'Batch_size', 'Validation', 'MSE', 'MAE', 'Training Time']\n",
    "\n",
    "information_GRU_df = pd.DataFrame(information_GRU_df)\n",
    "information_GRU_df.columns = ['Model', 'Training ratio', 'Epochs', 'Batch_size', 'Validation', 'MSE', 'MAE', 'Training Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c830b6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training ratio</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Batch_size</th>\n",
       "      <th>Validation</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20099.165</td>\n",
       "      <td>120.997</td>\n",
       "      <td>4.129396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>20099.165</td>\n",
       "      <td>120.997</td>\n",
       "      <td>3.571271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>20099.165</td>\n",
       "      <td>120.997</td>\n",
       "      <td>3.552512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20099.165</td>\n",
       "      <td>120.997</td>\n",
       "      <td>6.778774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>20099.165</td>\n",
       "      <td>120.997</td>\n",
       "      <td>7.752068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>64.329</td>\n",
       "      <td>5.635</td>\n",
       "      <td>7.286193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>37.655</td>\n",
       "      <td>3.878</td>\n",
       "      <td>13.795964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>34.533</td>\n",
       "      <td>3.658</td>\n",
       "      <td>14.260002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>40.362</td>\n",
       "      <td>4.221</td>\n",
       "      <td>13.914145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>45.090</td>\n",
       "      <td>4.058</td>\n",
       "      <td>5.086128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>17234.523</td>\n",
       "      <td>105.182</td>\n",
       "      <td>4.645605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>55.703</td>\n",
       "      <td>4.992</td>\n",
       "      <td>4.140301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>17234.523</td>\n",
       "      <td>105.182</td>\n",
       "      <td>8.392031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>37.599</td>\n",
       "      <td>3.758</td>\n",
       "      <td>7.838780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>52.778</td>\n",
       "      <td>5.013</td>\n",
       "      <td>7.926064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>17234.523</td>\n",
       "      <td>105.182</td>\n",
       "      <td>16.104271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>26.533</td>\n",
       "      <td>3.190</td>\n",
       "      <td>15.112117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>35.302</td>\n",
       "      <td>4.127</td>\n",
       "      <td>15.137909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>15105.370</td>\n",
       "      <td>94.230</td>\n",
       "      <td>4.621169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>38.596</td>\n",
       "      <td>3.583</td>\n",
       "      <td>4.690463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>40.392</td>\n",
       "      <td>3.692</td>\n",
       "      <td>4.543415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>15105.370</td>\n",
       "      <td>94.230</td>\n",
       "      <td>8.778990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>29.267</td>\n",
       "      <td>3.102</td>\n",
       "      <td>8.827304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>15105.370</td>\n",
       "      <td>94.230</td>\n",
       "      <td>8.901217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>15105.370</td>\n",
       "      <td>94.230</td>\n",
       "      <td>17.328132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>19.376</td>\n",
       "      <td>2.544</td>\n",
       "      <td>17.024330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>18.888</td>\n",
       "      <td>2.517</td>\n",
       "      <td>16.460673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Training ratio  Epochs  Batch_size  Validation        MSE      MAE  \\\n",
       "0   FFNN             0.6      50          32        0.10  20099.165  120.997   \n",
       "1   FFNN             0.6      50          32        0.15  20099.165  120.997   \n",
       "2   FFNN             0.6      50          32        0.20  20099.165  120.997   \n",
       "3   FFNN             0.6     100          32        0.10  20099.165  120.997   \n",
       "4   FFNN             0.6     100          32        0.15  20099.165  120.997   \n",
       "5   FFNN             0.6     100          32        0.20     64.329    5.635   \n",
       "6   FFNN             0.6     200          32        0.10     37.655    3.878   \n",
       "7   FFNN             0.6     200          32        0.15     34.533    3.658   \n",
       "8   FFNN             0.6     200          32        0.20     40.362    4.221   \n",
       "9   FFNN             0.7      50          32        0.10     45.090    4.058   \n",
       "10  FFNN             0.7      50          32        0.15  17234.523  105.182   \n",
       "11  FFNN             0.7      50          32        0.20     55.703    4.992   \n",
       "12  FFNN             0.7     100          32        0.10  17234.523  105.182   \n",
       "13  FFNN             0.7     100          32        0.15     37.599    3.758   \n",
       "14  FFNN             0.7     100          32        0.20     52.778    5.013   \n",
       "15  FFNN             0.7     200          32        0.10  17234.523  105.182   \n",
       "16  FFNN             0.7     200          32        0.15     26.533    3.190   \n",
       "17  FFNN             0.7     200          32        0.20     35.302    4.127   \n",
       "18  FFNN             0.8      50          32        0.10  15105.370   94.230   \n",
       "19  FFNN             0.8      50          32        0.15     38.596    3.583   \n",
       "20  FFNN             0.8      50          32        0.20     40.392    3.692   \n",
       "21  FFNN             0.8     100          32        0.10  15105.370   94.230   \n",
       "22  FFNN             0.8     100          32        0.15     29.267    3.102   \n",
       "23  FFNN             0.8     100          32        0.20  15105.370   94.230   \n",
       "24  FFNN             0.8     200          32        0.10  15105.370   94.230   \n",
       "25  FFNN             0.8     200          32        0.15     19.376    2.544   \n",
       "26  FFNN             0.8     200          32        0.20     18.888    2.517   \n",
       "\n",
       "    Training Time  \n",
       "0        4.129396  \n",
       "1        3.571271  \n",
       "2        3.552512  \n",
       "3        6.778774  \n",
       "4        7.752068  \n",
       "5        7.286193  \n",
       "6       13.795964  \n",
       "7       14.260002  \n",
       "8       13.914145  \n",
       "9        5.086128  \n",
       "10       4.645605  \n",
       "11       4.140301  \n",
       "12       8.392031  \n",
       "13       7.838780  \n",
       "14       7.926064  \n",
       "15      16.104271  \n",
       "16      15.112117  \n",
       "17      15.137909  \n",
       "18       4.621169  \n",
       "19       4.690463  \n",
       "20       4.543415  \n",
       "21       8.778990  \n",
       "22       8.827304  \n",
       "23       8.901217  \n",
       "24      17.328132  \n",
       "25      17.024330  \n",
       "26      16.460673  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_FFNN_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7adadef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training ratio</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Batch_size</th>\n",
       "      <th>Validation</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>32.891</td>\n",
       "      <td>3.571</td>\n",
       "      <td>6.333712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>31.594</td>\n",
       "      <td>3.495</td>\n",
       "      <td>5.931851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>37.294</td>\n",
       "      <td>3.829</td>\n",
       "      <td>6.264875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>22.547</td>\n",
       "      <td>2.947</td>\n",
       "      <td>11.545186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>28.587</td>\n",
       "      <td>3.323</td>\n",
       "      <td>12.358442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>29.988</td>\n",
       "      <td>3.436</td>\n",
       "      <td>11.969412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>19.529</td>\n",
       "      <td>2.794</td>\n",
       "      <td>24.062585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>18.021</td>\n",
       "      <td>2.668</td>\n",
       "      <td>23.179792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>20.911</td>\n",
       "      <td>2.929</td>\n",
       "      <td>23.708437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>37.169</td>\n",
       "      <td>3.778</td>\n",
       "      <td>7.995591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>27.394</td>\n",
       "      <td>3.133</td>\n",
       "      <td>7.468025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>27.131</td>\n",
       "      <td>3.118</td>\n",
       "      <td>7.324473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>23.427</td>\n",
       "      <td>3.068</td>\n",
       "      <td>14.319079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>17.697</td>\n",
       "      <td>2.549</td>\n",
       "      <td>14.825405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>23.273</td>\n",
       "      <td>2.904</td>\n",
       "      <td>15.051876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20.206</td>\n",
       "      <td>2.814</td>\n",
       "      <td>31.605858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>15.605</td>\n",
       "      <td>2.437</td>\n",
       "      <td>29.491276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>16.113</td>\n",
       "      <td>2.449</td>\n",
       "      <td>29.153287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>26.131</td>\n",
       "      <td>2.949</td>\n",
       "      <td>9.157152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>20.908</td>\n",
       "      <td>2.635</td>\n",
       "      <td>9.050166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>33.588</td>\n",
       "      <td>3.358</td>\n",
       "      <td>8.897568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20.982</td>\n",
       "      <td>2.674</td>\n",
       "      <td>16.939023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>18.539</td>\n",
       "      <td>2.609</td>\n",
       "      <td>16.955544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>19.328</td>\n",
       "      <td>2.560</td>\n",
       "      <td>16.852015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>14.350</td>\n",
       "      <td>2.442</td>\n",
       "      <td>34.211624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>13.425</td>\n",
       "      <td>2.171</td>\n",
       "      <td>33.446199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>14.842</td>\n",
       "      <td>2.266</td>\n",
       "      <td>33.232545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Training ratio  Epochs  Batch_size  Validation     MSE    MAE  \\\n",
       "0    RNN             0.6      50          32        0.10  32.891  3.571   \n",
       "1    RNN             0.6      50          32        0.15  31.594  3.495   \n",
       "2    RNN             0.6      50          32        0.20  37.294  3.829   \n",
       "3    RNN             0.6     100          32        0.10  22.547  2.947   \n",
       "4    RNN             0.6     100          32        0.15  28.587  3.323   \n",
       "5    RNN             0.6     100          32        0.20  29.988  3.436   \n",
       "6    RNN             0.6     200          32        0.10  19.529  2.794   \n",
       "7    RNN             0.6     200          32        0.15  18.021  2.668   \n",
       "8    RNN             0.6     200          32        0.20  20.911  2.929   \n",
       "9    RNN             0.7      50          32        0.10  37.169  3.778   \n",
       "10   RNN             0.7      50          32        0.15  27.394  3.133   \n",
       "11   RNN             0.7      50          32        0.20  27.131  3.118   \n",
       "12   RNN             0.7     100          32        0.10  23.427  3.068   \n",
       "13   RNN             0.7     100          32        0.15  17.697  2.549   \n",
       "14   RNN             0.7     100          32        0.20  23.273  2.904   \n",
       "15   RNN             0.7     200          32        0.10  20.206  2.814   \n",
       "16   RNN             0.7     200          32        0.15  15.605  2.437   \n",
       "17   RNN             0.7     200          32        0.20  16.113  2.449   \n",
       "18   RNN             0.8      50          32        0.10  26.131  2.949   \n",
       "19   RNN             0.8      50          32        0.15  20.908  2.635   \n",
       "20   RNN             0.8      50          32        0.20  33.588  3.358   \n",
       "21   RNN             0.8     100          32        0.10  20.982  2.674   \n",
       "22   RNN             0.8     100          32        0.15  18.539  2.609   \n",
       "23   RNN             0.8     100          32        0.20  19.328  2.560   \n",
       "24   RNN             0.8     200          32        0.10  14.350  2.442   \n",
       "25   RNN             0.8     200          32        0.15  13.425  2.171   \n",
       "26   RNN             0.8     200          32        0.20  14.842  2.266   \n",
       "\n",
       "    Training Time  \n",
       "0        6.333712  \n",
       "1        5.931851  \n",
       "2        6.264875  \n",
       "3       11.545186  \n",
       "4       12.358442  \n",
       "5       11.969412  \n",
       "6       24.062585  \n",
       "7       23.179792  \n",
       "8       23.708437  \n",
       "9        7.995591  \n",
       "10       7.468025  \n",
       "11       7.324473  \n",
       "12      14.319079  \n",
       "13      14.825405  \n",
       "14      15.051876  \n",
       "15      31.605858  \n",
       "16      29.491276  \n",
       "17      29.153287  \n",
       "18       9.157152  \n",
       "19       9.050166  \n",
       "20       8.897568  \n",
       "21      16.939023  \n",
       "22      16.955544  \n",
       "23      16.852015  \n",
       "24      34.211624  \n",
       "25      33.446199  \n",
       "26      33.232545  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_RNN_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52633989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training ratio</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Batch_size</th>\n",
       "      <th>Validation</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>67.922</td>\n",
       "      <td>5.201</td>\n",
       "      <td>12.862632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>20099.165</td>\n",
       "      <td>120.997</td>\n",
       "      <td>12.024877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>20099.165</td>\n",
       "      <td>120.997</td>\n",
       "      <td>13.436445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>54.634</td>\n",
       "      <td>4.552</td>\n",
       "      <td>28.886789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>20099.165</td>\n",
       "      <td>120.997</td>\n",
       "      <td>24.614227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>53.848</td>\n",
       "      <td>4.572</td>\n",
       "      <td>26.363524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>39.969</td>\n",
       "      <td>4.014</td>\n",
       "      <td>52.242441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>37.339</td>\n",
       "      <td>3.819</td>\n",
       "      <td>48.025488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>38.228</td>\n",
       "      <td>3.859</td>\n",
       "      <td>55.449567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>17234.523</td>\n",
       "      <td>105.182</td>\n",
       "      <td>19.894012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>56.449</td>\n",
       "      <td>4.471</td>\n",
       "      <td>15.895101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>59.748</td>\n",
       "      <td>4.640</td>\n",
       "      <td>16.948443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>41.527</td>\n",
       "      <td>3.889</td>\n",
       "      <td>38.966779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>17234.523</td>\n",
       "      <td>105.182</td>\n",
       "      <td>36.885304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>45.025</td>\n",
       "      <td>4.046</td>\n",
       "      <td>37.913238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>30.768</td>\n",
       "      <td>3.406</td>\n",
       "      <td>78.041159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>17234.523</td>\n",
       "      <td>105.182</td>\n",
       "      <td>70.900567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>17234.523</td>\n",
       "      <td>105.182</td>\n",
       "      <td>68.164654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>15105.370</td>\n",
       "      <td>94.230</td>\n",
       "      <td>23.339674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>52.852</td>\n",
       "      <td>4.207</td>\n",
       "      <td>22.105183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>15105.370</td>\n",
       "      <td>94.230</td>\n",
       "      <td>20.655497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>38.028</td>\n",
       "      <td>3.678</td>\n",
       "      <td>41.701227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>37.030</td>\n",
       "      <td>3.556</td>\n",
       "      <td>38.165932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>35.357</td>\n",
       "      <td>3.507</td>\n",
       "      <td>41.405243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>15105.370</td>\n",
       "      <td>94.230</td>\n",
       "      <td>79.505736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>15105.370</td>\n",
       "      <td>94.230</td>\n",
       "      <td>79.071411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>24.368</td>\n",
       "      <td>2.948</td>\n",
       "      <td>77.099370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Training ratio  Epochs  Batch_size  Validation        MSE      MAE  \\\n",
       "0   LSTM             0.6      50          32        0.10     67.922    5.201   \n",
       "1   LSTM             0.6      50          32        0.15  20099.165  120.997   \n",
       "2   LSTM             0.6      50          32        0.20  20099.165  120.997   \n",
       "3   LSTM             0.6     100          32        0.10     54.634    4.552   \n",
       "4   LSTM             0.6     100          32        0.15  20099.165  120.997   \n",
       "5   LSTM             0.6     100          32        0.20     53.848    4.572   \n",
       "6   LSTM             0.6     200          32        0.10     39.969    4.014   \n",
       "7   LSTM             0.6     200          32        0.15     37.339    3.819   \n",
       "8   LSTM             0.6     200          32        0.20     38.228    3.859   \n",
       "9   LSTM             0.7      50          32        0.10  17234.523  105.182   \n",
       "10  LSTM             0.7      50          32        0.15     56.449    4.471   \n",
       "11  LSTM             0.7      50          32        0.20     59.748    4.640   \n",
       "12  LSTM             0.7     100          32        0.10     41.527    3.889   \n",
       "13  LSTM             0.7     100          32        0.15  17234.523  105.182   \n",
       "14  LSTM             0.7     100          32        0.20     45.025    4.046   \n",
       "15  LSTM             0.7     200          32        0.10     30.768    3.406   \n",
       "16  LSTM             0.7     200          32        0.15  17234.523  105.182   \n",
       "17  LSTM             0.7     200          32        0.20  17234.523  105.182   \n",
       "18  LSTM             0.8      50          32        0.10  15105.370   94.230   \n",
       "19  LSTM             0.8      50          32        0.15     52.852    4.207   \n",
       "20  LSTM             0.8      50          32        0.20  15105.370   94.230   \n",
       "21  LSTM             0.8     100          32        0.10     38.028    3.678   \n",
       "22  LSTM             0.8     100          32        0.15     37.030    3.556   \n",
       "23  LSTM             0.8     100          32        0.20     35.357    3.507   \n",
       "24  LSTM             0.8     200          32        0.10  15105.370   94.230   \n",
       "25  LSTM             0.8     200          32        0.15  15105.370   94.230   \n",
       "26  LSTM             0.8     200          32        0.20     24.368    2.948   \n",
       "\n",
       "    Training Time  \n",
       "0       12.862632  \n",
       "1       12.024877  \n",
       "2       13.436445  \n",
       "3       28.886789  \n",
       "4       24.614227  \n",
       "5       26.363524  \n",
       "6       52.242441  \n",
       "7       48.025488  \n",
       "8       55.449567  \n",
       "9       19.894012  \n",
       "10      15.895101  \n",
       "11      16.948443  \n",
       "12      38.966779  \n",
       "13      36.885304  \n",
       "14      37.913238  \n",
       "15      78.041159  \n",
       "16      70.900567  \n",
       "17      68.164654  \n",
       "18      23.339674  \n",
       "19      22.105183  \n",
       "20      20.655497  \n",
       "21      41.701227  \n",
       "22      38.165932  \n",
       "23      41.405243  \n",
       "24      79.505736  \n",
       "25      79.071411  \n",
       "26      77.099370  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_LSTM_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "768ef36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training ratio</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Batch_size</th>\n",
       "      <th>Validation</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>45.834</td>\n",
       "      <td>4.164</td>\n",
       "      <td>11.887566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>20099.165</td>\n",
       "      <td>120.997</td>\n",
       "      <td>11.649777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>57.231</td>\n",
       "      <td>4.725</td>\n",
       "      <td>11.829023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>32.468</td>\n",
       "      <td>3.541</td>\n",
       "      <td>26.481973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>39.447</td>\n",
       "      <td>3.923</td>\n",
       "      <td>24.013381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>20099.165</td>\n",
       "      <td>120.997</td>\n",
       "      <td>23.373433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>22.862</td>\n",
       "      <td>3.085</td>\n",
       "      <td>50.538138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>23.061</td>\n",
       "      <td>3.067</td>\n",
       "      <td>43.393003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>24.532</td>\n",
       "      <td>3.138</td>\n",
       "      <td>49.328536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>17234.523</td>\n",
       "      <td>105.182</td>\n",
       "      <td>17.799010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>41.616</td>\n",
       "      <td>3.882</td>\n",
       "      <td>14.682523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>17234.523</td>\n",
       "      <td>105.182</td>\n",
       "      <td>15.700036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>29.925</td>\n",
       "      <td>3.360</td>\n",
       "      <td>35.862483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>28.577</td>\n",
       "      <td>3.324</td>\n",
       "      <td>34.137230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>29.624</td>\n",
       "      <td>3.340</td>\n",
       "      <td>35.188166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>17234.523</td>\n",
       "      <td>105.182</td>\n",
       "      <td>69.721352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>18.981</td>\n",
       "      <td>2.682</td>\n",
       "      <td>64.083565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>19.847</td>\n",
       "      <td>2.814</td>\n",
       "      <td>63.057923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>34.172</td>\n",
       "      <td>3.418</td>\n",
       "      <td>21.349034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>36.580</td>\n",
       "      <td>3.507</td>\n",
       "      <td>20.790591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>34.287</td>\n",
       "      <td>3.401</td>\n",
       "      <td>19.147740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>25.552</td>\n",
       "      <td>3.102</td>\n",
       "      <td>37.638341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>23.003</td>\n",
       "      <td>2.863</td>\n",
       "      <td>36.071392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>15105.370</td>\n",
       "      <td>94.230</td>\n",
       "      <td>38.199722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>15.661</td>\n",
       "      <td>2.439</td>\n",
       "      <td>79.457110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>15105.370</td>\n",
       "      <td>94.230</td>\n",
       "      <td>70.506722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>15105.370</td>\n",
       "      <td>94.230</td>\n",
       "      <td>71.591062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Training ratio  Epochs  Batch_size  Validation        MSE      MAE  \\\n",
       "0    GRU             0.6      50          32        0.10     45.834    4.164   \n",
       "1    GRU             0.6      50          32        0.15  20099.165  120.997   \n",
       "2    GRU             0.6      50          32        0.20     57.231    4.725   \n",
       "3    GRU             0.6     100          32        0.10     32.468    3.541   \n",
       "4    GRU             0.6     100          32        0.15     39.447    3.923   \n",
       "5    GRU             0.6     100          32        0.20  20099.165  120.997   \n",
       "6    GRU             0.6     200          32        0.10     22.862    3.085   \n",
       "7    GRU             0.6     200          32        0.15     23.061    3.067   \n",
       "8    GRU             0.6     200          32        0.20     24.532    3.138   \n",
       "9    GRU             0.7      50          32        0.10  17234.523  105.182   \n",
       "10   GRU             0.7      50          32        0.15     41.616    3.882   \n",
       "11   GRU             0.7      50          32        0.20  17234.523  105.182   \n",
       "12   GRU             0.7     100          32        0.10     29.925    3.360   \n",
       "13   GRU             0.7     100          32        0.15     28.577    3.324   \n",
       "14   GRU             0.7     100          32        0.20     29.624    3.340   \n",
       "15   GRU             0.7     200          32        0.10  17234.523  105.182   \n",
       "16   GRU             0.7     200          32        0.15     18.981    2.682   \n",
       "17   GRU             0.7     200          32        0.20     19.847    2.814   \n",
       "18   GRU             0.8      50          32        0.10     34.172    3.418   \n",
       "19   GRU             0.8      50          32        0.15     36.580    3.507   \n",
       "20   GRU             0.8      50          32        0.20     34.287    3.401   \n",
       "21   GRU             0.8     100          32        0.10     25.552    3.102   \n",
       "22   GRU             0.8     100          32        0.15     23.003    2.863   \n",
       "23   GRU             0.8     100          32        0.20  15105.370   94.230   \n",
       "24   GRU             0.8     200          32        0.10     15.661    2.439   \n",
       "25   GRU             0.8     200          32        0.15  15105.370   94.230   \n",
       "26   GRU             0.8     200          32        0.20  15105.370   94.230   \n",
       "\n",
       "    Training Time  \n",
       "0       11.887566  \n",
       "1       11.649777  \n",
       "2       11.829023  \n",
       "3       26.481973  \n",
       "4       24.013381  \n",
       "5       23.373433  \n",
       "6       50.538138  \n",
       "7       43.393003  \n",
       "8       49.328536  \n",
       "9       17.799010  \n",
       "10      14.682523  \n",
       "11      15.700036  \n",
       "12      35.862483  \n",
       "13      34.137230  \n",
       "14      35.188166  \n",
       "15      69.721352  \n",
       "16      64.083565  \n",
       "17      63.057923  \n",
       "18      21.349034  \n",
       "19      20.790591  \n",
       "20      19.147740  \n",
       "21      37.638341  \n",
       "22      36.071392  \n",
       "23      38.199722  \n",
       "24      79.457110  \n",
       "25      70.506722  \n",
       "26      71.591062  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_GRU_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42f959e",
   "metadata": {},
   "source": [
    "## Best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c148fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_best_params(info_df, ds, look_back, opt):\n",
    "    index = info_df.MSE.argmin()\n",
    "    ratio = info_df.iloc[index, 1]\n",
    "    epochs = info_df.iloc[index, 2]\n",
    "    batch_size = info_df.iloc[index, 3]\n",
    "    validation = info_df.iloc[index, 4]\n",
    "    \n",
    "    train_size = int(len(ds) * ratio)\n",
    "    test_size = len(ds) - train_size\n",
    "    train, test = ds[0:train_size,:], ds[train_size:len(ds)+1,:]\n",
    "    trainX, trainY, testX, testY = create_train_test_data(train, test, look_back)\n",
    "    \n",
    "    return [trainX, trainY, testX, testY], [trainX, trainY, look_back, opt, epochs, batch_size, validation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52707d6e",
   "metadata": {},
   "source": [
    "### Chose the best look_back in (1,3,5,10,20,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96cfdfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1442 - val_loss: 0.0026\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0746 - val_loss: 0.0154\n",
      "Epoch 3/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.0306\n",
      "Epoch 4/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0327 - val_loss: 0.0415\n",
      "Epoch 5/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.0460\n",
      "Epoch 6/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.0468\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0455\n",
      "Epoch 8/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.0435\n",
      "Epoch 9/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0413\n",
      "Epoch 10/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0385\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0354\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0335\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0305\n",
      "Epoch 14/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0279\n",
      "Epoch 15/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0260\n",
      "Epoch 16/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0238\n",
      "Epoch 17/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0213\n",
      "Epoch 18/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0192\n",
      "Epoch 19/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0177\n",
      "Epoch 20/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0159\n",
      "Epoch 21/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0140\n",
      "Epoch 22/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0123\n",
      "Epoch 23/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0109\n",
      "Epoch 24/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0094\n",
      "Epoch 25/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0082\n",
      "Epoch 26/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0072\n",
      "Epoch 27/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0062\n",
      "Epoch 28/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0055\n",
      "Epoch 29/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 30/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 31/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 32/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 33/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 34/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 35/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 9.2194e-04 - val_loss: 0.0015\n",
      "Epoch 36/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 7.8042e-04 - val_loss: 0.0012\n",
      "Epoch 37/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.5452e-04 - val_loss: 0.0010\n",
      "Epoch 38/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.5171e-04 - val_loss: 7.8528e-04\n",
      "Epoch 39/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.6914e-04 - val_loss: 6.4297e-04\n",
      "Epoch 40/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.0289e-04 - val_loss: 5.2668e-04\n",
      "Epoch 41/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.4905e-04 - val_loss: 4.2335e-04\n",
      "Epoch 42/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.0511e-04 - val_loss: 3.3586e-04\n",
      "Epoch 43/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.6998e-04 - val_loss: 2.6480e-04\n",
      "Epoch 44/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.4170e-04 - val_loss: 2.1318e-04\n",
      "Epoch 45/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.1864e-04 - val_loss: 1.6831e-04\n",
      "Epoch 46/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.0085e-04 - val_loss: 1.3344e-04\n",
      "Epoch 47/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.8755e-04 - val_loss: 1.0666e-04\n",
      "Epoch 48/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.7644e-04 - val_loss: 8.4671e-05\n",
      "Epoch 49/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.6858e-04 - val_loss: 6.8156e-05\n",
      "Epoch 50/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.6255e-04 - val_loss: 5.8195e-05\n",
      "Epoch 51/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.5792e-04 - val_loss: 4.7928e-05\n",
      "Epoch 52/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.5400e-04 - val_loss: 3.8318e-05\n",
      "Epoch 53/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.5109e-04 - val_loss: 3.2239e-05\n",
      "Epoch 54/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4934e-04 - val_loss: 2.8117e-05\n",
      "Epoch 55/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4771e-04 - val_loss: 2.5139e-05\n",
      "Epoch 56/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4699e-04 - val_loss: 2.3590e-05\n",
      "Epoch 57/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4616e-04 - val_loss: 2.1941e-05\n",
      "Epoch 58/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4581e-04 - val_loss: 2.0757e-05\n",
      "Epoch 59/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4572e-04 - val_loss: 1.8616e-05\n",
      "Epoch 60/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4483e-04 - val_loss: 1.7244e-05\n",
      "Epoch 61/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4512e-04 - val_loss: 1.6839e-05\n",
      "Epoch 62/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4484e-04 - val_loss: 1.6378e-05\n",
      "Epoch 63/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4469e-04 - val_loss: 1.6448e-05\n",
      "Epoch 64/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4471e-04 - val_loss: 1.5620e-05\n",
      "Epoch 65/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4515e-04 - val_loss: 1.5652e-05\n",
      "Epoch 66/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4460e-04 - val_loss: 1.5684e-05\n",
      "Epoch 67/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4481e-04 - val_loss: 1.5200e-05\n",
      "Epoch 68/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4475e-04 - val_loss: 1.5110e-05\n",
      "Epoch 69/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4446e-04 - val_loss: 1.4479e-05\n",
      "Epoch 70/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4448e-04 - val_loss: 1.4540e-05\n",
      "Epoch 71/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4452e-04 - val_loss: 1.4368e-05\n",
      "Epoch 72/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4427e-04 - val_loss: 1.4377e-05\n",
      "Epoch 73/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4444e-04 - val_loss: 1.4357e-05\n",
      "Epoch 74/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4415e-04 - val_loss: 1.3853e-05\n",
      "Epoch 75/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4417e-04 - val_loss: 1.3736e-05\n",
      "Epoch 76/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4420e-04 - val_loss: 1.3545e-05\n",
      "Epoch 77/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4410e-04 - val_loss: 1.3616e-05\n",
      "Epoch 78/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4406e-04 - val_loss: 1.3326e-05\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4476e-04 - val_loss: 1.3090e-05\n",
      "Epoch 80/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4447e-04 - val_loss: 1.3502e-05\n",
      "Epoch 81/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4424e-04 - val_loss: 1.3049e-05\n",
      "Epoch 82/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4407e-04 - val_loss: 1.2913e-05\n",
      "Epoch 83/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4389e-04 - val_loss: 1.2916e-05\n",
      "Epoch 84/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4398e-04 - val_loss: 1.2958e-05\n",
      "Epoch 85/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4427e-04 - val_loss: 1.2670e-05\n",
      "Epoch 86/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4396e-04 - val_loss: 1.2702e-05\n",
      "Epoch 87/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4434e-04 - val_loss: 1.2362e-05\n",
      "Epoch 88/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4400e-04 - val_loss: 1.2637e-05\n",
      "Epoch 89/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4419e-04 - val_loss: 1.2319e-05\n",
      "Epoch 90/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4420e-04 - val_loss: 1.2058e-05\n",
      "Epoch 91/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4423e-04 - val_loss: 1.1997e-05\n",
      "Epoch 92/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4392e-04 - val_loss: 1.2013e-05\n",
      "Epoch 93/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4424e-04 - val_loss: 1.2077e-05\n",
      "Epoch 94/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4411e-04 - val_loss: 1.1783e-05\n",
      "Epoch 95/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4435e-04 - val_loss: 1.1652e-05\n",
      "Epoch 96/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4395e-04 - val_loss: 1.1547e-05\n",
      "Epoch 97/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4448e-04 - val_loss: 1.1759e-05\n",
      "Epoch 98/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4429e-04 - val_loss: 1.1518e-05\n",
      "Epoch 99/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4389e-04 - val_loss: 1.1350e-05\n",
      "Epoch 100/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4368e-04 - val_loss: 1.1237e-05\n",
      "Epoch 101/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4396e-04 - val_loss: 1.1046e-05\n",
      "Epoch 102/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4357e-04 - val_loss: 1.0961e-05\n",
      "Epoch 103/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4394e-04 - val_loss: 1.0884e-05\n",
      "Epoch 104/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4372e-04 - val_loss: 1.0929e-05\n",
      "Epoch 105/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4416e-04 - val_loss: 1.1660e-05\n",
      "Epoch 106/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4392e-04 - val_loss: 1.0632e-05\n",
      "Epoch 107/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4457e-04 - val_loss: 1.1112e-05\n",
      "Epoch 108/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4440e-04 - val_loss: 1.0445e-05\n",
      "Epoch 109/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4350e-04 - val_loss: 1.0361e-05\n",
      "Epoch 110/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4365e-04 - val_loss: 1.0396e-05\n",
      "Epoch 111/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4342e-04 - val_loss: 1.0226e-05\n",
      "Epoch 112/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4375e-04 - val_loss: 1.0126e-05\n",
      "Epoch 113/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4333e-04 - val_loss: 1.0482e-05\n",
      "Epoch 114/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4447e-04 - val_loss: 9.9632e-06\n",
      "Epoch 115/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4482e-04 - val_loss: 1.1119e-05\n",
      "Epoch 116/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4476e-04 - val_loss: 9.8332e-06\n",
      "Epoch 117/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4353e-04 - val_loss: 9.8118e-06\n",
      "Epoch 118/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4346e-04 - val_loss: 9.9049e-06\n",
      "Epoch 119/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4656e-04 - val_loss: 9.8895e-06\n",
      "Epoch 120/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4438e-04 - val_loss: 9.7984e-06\n",
      "Epoch 121/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4432e-04 - val_loss: 9.3806e-06\n",
      "Epoch 122/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4389e-04 - val_loss: 9.6350e-06\n",
      "Epoch 123/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4306e-04 - val_loss: 1.0460e-05\n",
      "Epoch 124/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4350e-04 - val_loss: 9.1678e-06\n",
      "Epoch 125/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4359e-04 - val_loss: 1.0889e-05\n",
      "Epoch 126/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4380e-04 - val_loss: 9.0343e-06\n",
      "Epoch 127/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4395e-04 - val_loss: 9.7724e-06\n",
      "Epoch 128/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4367e-04 - val_loss: 8.8571e-06\n",
      "Epoch 129/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4415e-04 - val_loss: 9.0947e-06\n",
      "Epoch 130/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4393e-04 - val_loss: 8.8489e-06\n",
      "Epoch 131/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4524e-04 - val_loss: 8.8832e-06\n",
      "Epoch 132/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4372e-04 - val_loss: 8.5994e-06\n",
      "Epoch 133/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4335e-04 - val_loss: 8.5466e-06\n",
      "Epoch 134/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4429e-04 - val_loss: 9.3976e-06\n",
      "Epoch 135/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4481e-04 - val_loss: 8.4283e-06\n",
      "Epoch 136/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4428e-04 - val_loss: 8.3348e-06\n",
      "Epoch 137/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4424e-04 - val_loss: 8.2932e-06\n",
      "Epoch 138/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4520e-04 - val_loss: 9.3432e-06\n",
      "Epoch 139/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4341e-04 - val_loss: 1.5311e-05\n",
      "Epoch 140/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4585e-04 - val_loss: 8.1715e-06\n",
      "Epoch 141/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4482e-04 - val_loss: 8.7205e-06\n",
      "Epoch 142/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4348e-04 - val_loss: 8.8832e-06\n",
      "Epoch 143/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4560e-04 - val_loss: 9.1387e-06\n",
      "Epoch 144/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4454e-04 - val_loss: 8.2436e-06\n",
      "Epoch 145/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4468e-04 - val_loss: 8.0716e-06\n",
      "Epoch 146/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4366e-04 - val_loss: 8.1387e-06\n",
      "Epoch 147/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4409e-04 - val_loss: 7.8374e-06\n",
      "Epoch 148/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4396e-04 - val_loss: 8.2229e-06\n",
      "Epoch 149/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4343e-04 - val_loss: 8.2517e-06\n",
      "Epoch 150/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4411e-04 - val_loss: 8.0452e-06\n",
      "Epoch 151/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4417e-04 - val_loss: 7.6378e-06\n",
      "Epoch 152/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4366e-04 - val_loss: 7.5110e-06\n",
      "Epoch 153/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4372e-04 - val_loss: 7.5618e-06\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4363e-04 - val_loss: 7.8815e-06\n",
      "Epoch 155/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4368e-04 - val_loss: 7.4344e-06\n",
      "Epoch 156/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4347e-04 - val_loss: 8.4779e-06\n",
      "Epoch 157/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4496e-04 - val_loss: 7.9148e-06\n",
      "Epoch 158/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4412e-04 - val_loss: 7.3207e-06\n",
      "Epoch 159/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4578e-04 - val_loss: 7.2386e-06\n",
      "Epoch 160/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4639e-04 - val_loss: 7.4452e-06\n",
      "Epoch 161/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4502e-04 - val_loss: 7.1982e-06\n",
      "Epoch 162/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4352e-04 - val_loss: 7.2904e-06\n",
      "Epoch 163/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4354e-04 - val_loss: 7.1116e-06\n",
      "Epoch 164/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4783e-04 - val_loss: 7.7018e-06\n",
      "Epoch 165/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4478e-04 - val_loss: 7.3428e-06\n",
      "Epoch 166/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4321e-04 - val_loss: 7.0334e-06\n",
      "Epoch 167/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4299e-04 - val_loss: 7.0157e-06\n",
      "Epoch 168/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4427e-04 - val_loss: 7.0055e-06\n",
      "Epoch 169/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4422e-04 - val_loss: 7.0752e-06\n",
      "Epoch 170/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4577e-04 - val_loss: 6.9013e-06\n",
      "Epoch 171/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4506e-04 - val_loss: 6.8586e-06\n",
      "Epoch 172/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4334e-04 - val_loss: 8.4037e-06\n",
      "Epoch 173/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4423e-04 - val_loss: 7.0686e-06\n",
      "Epoch 174/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4377e-04 - val_loss: 7.0751e-06\n",
      "Epoch 175/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4435e-04 - val_loss: 9.9382e-06\n",
      "Epoch 176/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4355e-04 - val_loss: 8.4512e-06\n",
      "Epoch 177/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4412e-04 - val_loss: 7.2845e-06\n",
      "Epoch 178/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4596e-04 - val_loss: 6.8201e-06\n",
      "Epoch 179/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4393e-04 - val_loss: 7.5082e-06\n",
      "Epoch 180/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4972e-04 - val_loss: 8.5905e-06\n",
      "Epoch 181/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4688e-04 - val_loss: 6.9099e-06\n",
      "Epoch 182/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4554e-04 - val_loss: 7.4591e-06\n",
      "Epoch 183/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4382e-04 - val_loss: 6.5969e-06\n",
      "Epoch 184/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4366e-04 - val_loss: 6.5921e-06\n",
      "Epoch 185/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4382e-04 - val_loss: 6.7877e-06\n",
      "Epoch 186/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4325e-04 - val_loss: 6.9963e-06\n",
      "Epoch 187/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4419e-04 - val_loss: 6.5202e-06\n",
      "Epoch 188/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4352e-04 - val_loss: 6.5187e-06\n",
      "Epoch 189/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4496e-04 - val_loss: 6.5737e-06\n",
      "Epoch 190/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4314e-04 - val_loss: 7.0783e-06\n",
      "Epoch 191/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.5098e-04 - val_loss: 6.6036e-06\n",
      "Epoch 192/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4607e-04 - val_loss: 6.4067e-06\n",
      "Epoch 193/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4505e-04 - val_loss: 7.0709e-06\n",
      "Epoch 194/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4362e-04 - val_loss: 6.8141e-06\n",
      "Epoch 195/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4538e-04 - val_loss: 6.3656e-06\n",
      "Epoch 196/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4427e-04 - val_loss: 6.3524e-06\n",
      "Epoch 197/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4351e-04 - val_loss: 6.3848e-06\n",
      "Epoch 198/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4301e-04 - val_loss: 6.3510e-06\n",
      "Epoch 199/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4314e-04 - val_loss: 7.8837e-06\n",
      "Epoch 200/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4347e-04 - val_loss: 6.6545e-06\n",
      "Thời gian huấn luyện:  16.31682586669922\n",
      "Model: \"sequential_120\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_151 (Dense)           (None, 1, 117)            234       \n",
      "                                                                 \n",
      " flatten_120 (Flatten)       (None, 117)               0         \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 1)                 118       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 352\n",
      "Trainable params: 352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 959us/step\n",
      "13/13 [==============================] - 0s 833us/step\n",
      "Epoch 1/200\n",
      "44/44 [==============================] - 1s 6ms/step - loss: 0.0431 - val_loss: 0.0287\n",
      "Epoch 2/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0114\n",
      "Epoch 3/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0061\n",
      "Epoch 4/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 5/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 6/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 7.2393e-04 - val_loss: 6.8085e-04\n",
      "Epoch 7/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.0363e-04 - val_loss: 2.6680e-04\n",
      "Epoch 8/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.5262e-04 - val_loss: 1.0661e-04\n",
      "Epoch 9/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.8482e-04 - val_loss: 4.0210e-05\n",
      "Epoch 10/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.5631e-04 - val_loss: 1.7075e-05\n",
      "Epoch 11/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.4367e-04 - val_loss: 7.4889e-06\n",
      "Epoch 12/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3870e-04 - val_loss: 5.1404e-06\n",
      "Epoch 13/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3689e-04 - val_loss: 5.3680e-06\n",
      "Epoch 14/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.3572e-04 - val_loss: 5.1885e-06\n",
      "Epoch 15/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3597e-04 - val_loss: 5.6630e-06\n",
      "Epoch 16/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3557e-04 - val_loss: 7.1575e-06\n",
      "Epoch 17/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3661e-04 - val_loss: 5.8248e-06\n",
      "Epoch 18/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3559e-04 - val_loss: 9.3668e-06\n",
      "Epoch 19/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3594e-04 - val_loss: 6.8562e-06\n",
      "Epoch 20/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3555e-04 - val_loss: 6.9875e-06\n",
      "Epoch 21/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3557e-04 - val_loss: 6.5123e-06\n",
      "Epoch 22/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3587e-04 - val_loss: 8.5440e-06\n",
      "Epoch 23/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3586e-04 - val_loss: 6.0961e-06\n",
      "Epoch 24/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3575e-04 - val_loss: 6.9245e-06\n",
      "Epoch 25/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3572e-04 - val_loss: 8.1405e-06\n",
      "Epoch 26/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3626e-04 - val_loss: 6.3716e-06\n",
      "Epoch 27/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3560e-04 - val_loss: 8.2433e-06\n",
      "Epoch 28/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3581e-04 - val_loss: 9.4810e-06\n",
      "Epoch 29/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3596e-04 - val_loss: 6.2653e-06\n",
      "Epoch 30/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3628e-04 - val_loss: 6.2891e-06\n",
      "Epoch 31/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3581e-04 - val_loss: 7.5295e-06\n",
      "Epoch 32/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3555e-04 - val_loss: 6.9981e-06\n",
      "Epoch 33/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3590e-04 - val_loss: 7.8906e-06\n",
      "Epoch 34/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3578e-04 - val_loss: 7.8618e-06\n",
      "Epoch 35/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3591e-04 - val_loss: 7.6854e-06\n",
      "Epoch 36/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3591e-04 - val_loss: 8.4975e-06\n",
      "Epoch 37/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.3594e-04 - val_loss: 7.2846e-06\n",
      "Epoch 38/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.3633e-04 - val_loss: 7.3833e-06\n",
      "Epoch 39/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3629e-04 - val_loss: 5.7029e-06\n",
      "Epoch 40/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3568e-04 - val_loss: 8.2761e-06\n",
      "Epoch 41/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3585e-04 - val_loss: 9.5974e-06\n",
      "Epoch 42/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3587e-04 - val_loss: 8.5255e-06\n",
      "Epoch 43/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3680e-04 - val_loss: 6.7206e-06\n",
      "Epoch 44/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3619e-04 - val_loss: 7.6308e-06\n",
      "Epoch 45/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3568e-04 - val_loss: 8.4464e-06\n",
      "Epoch 46/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3582e-04 - val_loss: 5.6855e-06\n",
      "Epoch 47/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3598e-04 - val_loss: 8.5413e-06\n",
      "Epoch 48/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3658e-04 - val_loss: 7.6919e-06\n",
      "Epoch 49/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3698e-04 - val_loss: 6.7028e-06\n",
      "Epoch 50/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3659e-04 - val_loss: 7.7224e-06\n",
      "Epoch 51/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3582e-04 - val_loss: 6.7602e-06\n",
      "Epoch 52/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3638e-04 - val_loss: 9.4696e-06\n",
      "Epoch 53/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3636e-04 - val_loss: 1.1229e-05\n",
      "Epoch 54/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3671e-04 - val_loss: 1.5129e-05\n",
      "Epoch 55/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3731e-04 - val_loss: 6.0119e-06\n",
      "Epoch 56/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3656e-04 - val_loss: 6.0590e-06\n",
      "Epoch 57/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3631e-04 - val_loss: 5.9609e-06\n",
      "Epoch 58/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3628e-04 - val_loss: 6.8852e-06\n",
      "Epoch 59/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3623e-04 - val_loss: 6.1288e-06\n",
      "Epoch 60/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3669e-04 - val_loss: 6.7785e-06\n",
      "Epoch 61/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.3678e-04 - val_loss: 5.8888e-06\n",
      "Epoch 62/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.3591e-04 - val_loss: 5.5037e-06\n",
      "Epoch 63/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.3778e-04 - val_loss: 8.4955e-06\n",
      "Epoch 64/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.3672e-04 - val_loss: 8.7286e-06\n",
      "Epoch 65/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.3669e-04 - val_loss: 8.1836e-06\n",
      "Epoch 66/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3715e-04 - val_loss: 9.7124e-06\n",
      "Epoch 67/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3677e-04 - val_loss: 7.7017e-06\n",
      "Epoch 68/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3598e-04 - val_loss: 7.3268e-06\n",
      "Epoch 69/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3605e-04 - val_loss: 9.2560e-06\n",
      "Epoch 70/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3645e-04 - val_loss: 1.0451e-05\n",
      "Epoch 71/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3681e-04 - val_loss: 1.3464e-05\n",
      "Epoch 72/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3659e-04 - val_loss: 5.3743e-06\n",
      "Epoch 73/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3580e-04 - val_loss: 8.9305e-06\n",
      "Epoch 74/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.3688e-04 - val_loss: 6.2661e-06\n",
      "Epoch 75/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.3670e-04 - val_loss: 5.1720e-06\n",
      "Epoch 76/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3788e-04 - val_loss: 1.0370e-05\n",
      "Epoch 77/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3637e-04 - val_loss: 9.0851e-06\n",
      "Epoch 78/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.3731e-04 - val_loss: 8.9357e-06\n",
      "Epoch 79/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3870e-04 - val_loss: 1.7537e-05\n",
      "Epoch 80/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3769e-04 - val_loss: 5.7682e-06\n",
      "Epoch 81/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3764e-04 - val_loss: 5.3344e-06\n",
      "Epoch 82/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3694e-04 - val_loss: 6.9364e-06\n",
      "Epoch 83/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3721e-04 - val_loss: 7.4328e-06\n",
      "Epoch 84/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3620e-04 - val_loss: 7.0689e-06\n",
      "Epoch 85/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3618e-04 - val_loss: 8.9848e-06\n",
      "Epoch 86/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3735e-04 - val_loss: 8.8391e-06\n",
      "Epoch 87/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3606e-04 - val_loss: 6.7891e-06\n",
      "Epoch 88/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3670e-04 - val_loss: 5.6083e-06\n",
      "Epoch 89/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3662e-04 - val_loss: 5.2226e-06\n",
      "Epoch 90/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3585e-04 - val_loss: 7.7385e-06\n",
      "Epoch 91/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3808e-04 - val_loss: 9.4100e-06\n",
      "Epoch 92/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3748e-04 - val_loss: 5.7220e-06\n",
      "Epoch 93/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3639e-04 - val_loss: 5.8345e-06\n",
      "Epoch 94/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3732e-04 - val_loss: 7.6201e-06\n",
      "Epoch 95/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3770e-04 - val_loss: 8.9832e-06\n",
      "Epoch 96/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3806e-04 - val_loss: 8.0096e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3831e-04 - val_loss: 1.1553e-05\n",
      "Epoch 98/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3689e-04 - val_loss: 6.5979e-06\n",
      "Epoch 99/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3782e-04 - val_loss: 9.4632e-06\n",
      "Epoch 100/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3588e-04 - val_loss: 5.8292e-06\n",
      "Epoch 101/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3648e-04 - val_loss: 2.2152e-05\n",
      "Epoch 102/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3830e-04 - val_loss: 5.3481e-06\n",
      "Epoch 103/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3849e-04 - val_loss: 7.8990e-06\n",
      "Epoch 104/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3959e-04 - val_loss: 8.6461e-06\n",
      "Epoch 105/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3627e-04 - val_loss: 9.7406e-06\n",
      "Epoch 106/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3755e-04 - val_loss: 5.3291e-06\n",
      "Epoch 107/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3508e-04 - val_loss: 1.9104e-05\n",
      "Epoch 108/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3849e-04 - val_loss: 1.0382e-05\n",
      "Epoch 109/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3779e-04 - val_loss: 6.2566e-06\n",
      "Epoch 110/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3675e-04 - val_loss: 5.1697e-06\n",
      "Epoch 111/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3838e-04 - val_loss: 5.5533e-06\n",
      "Epoch 112/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3776e-04 - val_loss: 9.0194e-06\n",
      "Epoch 113/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3779e-04 - val_loss: 5.2517e-06\n",
      "Epoch 114/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3698e-04 - val_loss: 7.2862e-06\n",
      "Epoch 115/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3617e-04 - val_loss: 8.8602e-06\n",
      "Epoch 116/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.3848e-04 - val_loss: 6.9202e-06\n",
      "Epoch 117/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3793e-04 - val_loss: 8.3195e-06\n",
      "Epoch 118/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3772e-04 - val_loss: 8.1687e-06\n",
      "Epoch 119/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.3666e-04 - val_loss: 1.0649e-05\n",
      "Epoch 120/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3908e-04 - val_loss: 5.4050e-06\n",
      "Epoch 121/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3932e-04 - val_loss: 5.2705e-06\n",
      "Epoch 122/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3736e-04 - val_loss: 1.0868e-05\n",
      "Epoch 123/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3772e-04 - val_loss: 1.9287e-05\n",
      "Epoch 124/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3715e-04 - val_loss: 1.0625e-05\n",
      "Epoch 125/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3836e-04 - val_loss: 6.7714e-06\n",
      "Epoch 126/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.4235e-04 - val_loss: 6.3268e-06\n",
      "Epoch 127/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3599e-04 - val_loss: 1.2334e-05\n",
      "Epoch 128/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.4140e-04 - val_loss: 1.2238e-05\n",
      "Epoch 129/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3707e-04 - val_loss: 5.2655e-06\n",
      "Epoch 130/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3868e-04 - val_loss: 1.0066e-05\n",
      "Epoch 131/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.4117e-04 - val_loss: 9.6890e-06\n",
      "Epoch 132/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3683e-04 - val_loss: 5.1475e-06\n",
      "Epoch 133/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3990e-04 - val_loss: 1.2783e-05\n",
      "Epoch 134/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3694e-04 - val_loss: 5.2753e-06\n",
      "Epoch 135/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3877e-04 - val_loss: 6.8367e-06\n",
      "Epoch 136/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3735e-04 - val_loss: 7.0629e-06\n",
      "Epoch 137/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3864e-04 - val_loss: 9.9690e-06\n",
      "Epoch 138/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3787e-04 - val_loss: 5.2059e-06\n",
      "Epoch 139/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3734e-04 - val_loss: 9.8771e-06\n",
      "Epoch 140/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.4175e-04 - val_loss: 7.7248e-06\n",
      "Epoch 141/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3637e-04 - val_loss: 9.8115e-06\n",
      "Epoch 142/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.4005e-04 - val_loss: 8.6821e-06\n",
      "Epoch 143/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.4092e-04 - val_loss: 6.2776e-06\n",
      "Epoch 144/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.3647e-04 - val_loss: 8.0400e-06\n",
      "Epoch 145/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3684e-04 - val_loss: 5.8493e-06\n",
      "Epoch 146/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3758e-04 - val_loss: 8.7970e-06\n",
      "Epoch 147/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.3733e-04 - val_loss: 6.6652e-06\n",
      "Epoch 148/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3802e-04 - val_loss: 5.1919e-06\n",
      "Epoch 149/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3780e-04 - val_loss: 1.0978e-05\n",
      "Epoch 150/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3615e-04 - val_loss: 6.7347e-06\n",
      "Epoch 151/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3748e-04 - val_loss: 5.2788e-06\n",
      "Epoch 152/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3744e-04 - val_loss: 8.9526e-06\n",
      "Epoch 153/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3637e-04 - val_loss: 1.0434e-05\n",
      "Epoch 154/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3692e-04 - val_loss: 5.5406e-06\n",
      "Epoch 155/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3754e-04 - val_loss: 6.8676e-06\n",
      "Epoch 156/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3828e-04 - val_loss: 1.6216e-05\n",
      "Epoch 157/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3847e-04 - val_loss: 1.8814e-05\n",
      "Epoch 158/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3848e-04 - val_loss: 9.3589e-06\n",
      "Epoch 159/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3660e-04 - val_loss: 7.8099e-06\n",
      "Epoch 160/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3848e-04 - val_loss: 5.6797e-06\n",
      "Epoch 161/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3910e-04 - val_loss: 5.5554e-06\n",
      "Epoch 162/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3685e-04 - val_loss: 7.2933e-06\n",
      "Epoch 163/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3828e-04 - val_loss: 9.9484e-06\n",
      "Epoch 164/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3844e-04 - val_loss: 7.1604e-06\n",
      "Epoch 165/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3778e-04 - val_loss: 7.6099e-06\n",
      "Epoch 166/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3775e-04 - val_loss: 5.4031e-06\n",
      "Epoch 167/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3649e-04 - val_loss: 1.1111e-05\n",
      "Epoch 168/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3769e-04 - val_loss: 7.2337e-06\n",
      "Epoch 169/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.4449e-04 - val_loss: 3.2842e-05\n",
      "Epoch 170/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3939e-04 - val_loss: 1.1198e-05\n",
      "Epoch 171/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.3744e-04 - val_loss: 9.2392e-06\n",
      "Epoch 172/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 3ms/step - loss: 1.3736e-04 - val_loss: 5.1691e-06\n",
      "Epoch 173/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.3983e-04 - val_loss: 5.4980e-06\n",
      "Epoch 174/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3964e-04 - val_loss: 1.5589e-05\n",
      "Epoch 175/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3754e-04 - val_loss: 6.9530e-06\n",
      "Epoch 176/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3728e-04 - val_loss: 6.5668e-06\n",
      "Epoch 177/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3705e-04 - val_loss: 5.3230e-06\n",
      "Epoch 178/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.4814e-04 - val_loss: 2.5731e-05\n",
      "Epoch 179/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.4563e-04 - val_loss: 5.9806e-06\n",
      "Epoch 180/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.3822e-04 - val_loss: 8.5111e-06\n",
      "Epoch 181/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.3746e-04 - val_loss: 6.0839e-06\n",
      "Epoch 182/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3647e-04 - val_loss: 1.0764e-05\n",
      "Epoch 183/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.4321e-04 - val_loss: 5.4160e-06\n",
      "Epoch 184/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3977e-04 - val_loss: 1.1412e-05\n",
      "Epoch 185/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3661e-04 - val_loss: 8.3072e-06\n",
      "Epoch 186/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3673e-04 - val_loss: 1.0505e-05\n",
      "Epoch 187/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3855e-04 - val_loss: 5.1589e-06\n",
      "Epoch 188/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3826e-04 - val_loss: 6.3483e-06\n",
      "Epoch 189/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3774e-04 - val_loss: 5.4604e-06\n",
      "Epoch 190/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3909e-04 - val_loss: 5.3166e-06\n",
      "Epoch 191/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3774e-04 - val_loss: 6.8098e-06\n",
      "Epoch 192/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3652e-04 - val_loss: 1.0902e-05\n",
      "Epoch 193/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3769e-04 - val_loss: 1.7556e-05\n",
      "Epoch 194/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3719e-04 - val_loss: 2.0935e-05\n",
      "Epoch 195/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.4047e-04 - val_loss: 1.0399e-05\n",
      "Epoch 196/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.4215e-04 - val_loss: 5.1692e-06\n",
      "Epoch 197/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3736e-04 - val_loss: 5.9716e-06\n",
      "Epoch 198/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3721e-04 - val_loss: 7.3263e-06\n",
      "Epoch 199/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3748e-04 - val_loss: 1.4774e-05\n",
      "Epoch 200/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.4267e-04 - val_loss: 5.4052e-06\n",
      "Thời gian huấn luyện:  20.532149076461792\n",
      "Model: \"sequential_121\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_30 (SimpleRNN)   (None, 1, 117)            13923     \n",
      "                                                                 \n",
      " flatten_121 (Flatten)       (None, 117)               0         \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 1)                 118       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,041\n",
      "Trainable params: 14,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "42/42 [==============================] - 2s 12ms/step - loss: 0.1460 - val_loss: 0.0033\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0737 - val_loss: 0.0181\n",
      "Epoch 3/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0425 - val_loss: 0.0339\n",
      "Epoch 4/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.0436\n",
      "Epoch 5/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0474\n",
      "Epoch 6/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0465\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0434\n",
      "Epoch 8/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0407\n",
      "Epoch 9/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0369\n",
      "Epoch 10/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0341\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0311\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0281\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0252\n",
      "Epoch 14/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.0231\n",
      "Epoch 15/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.0207\n",
      "Epoch 16/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0180\n",
      "Epoch 17/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0162\n",
      "Epoch 18/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0141\n",
      "Epoch 19/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0123\n",
      "Epoch 20/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0105\n",
      "Epoch 21/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0090\n",
      "Epoch 22/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0077\n",
      "Epoch 23/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0066\n",
      "Epoch 24/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0055\n",
      "Epoch 25/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 26/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 27/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 28/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 29/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 8.8634e-04 - val_loss: 0.0022\n",
      "Epoch 30/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 7.2990e-04 - val_loss: 0.0018\n",
      "Epoch 31/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.0695e-04 - val_loss: 0.0015\n",
      "Epoch 32/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.0884e-04 - val_loss: 0.0013\n",
      "Epoch 33/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.3176e-04 - val_loss: 0.0011\n",
      "Epoch 34/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 3.7205e-04 - val_loss: 9.0644e-04\n",
      "Epoch 35/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 3.2666e-04 - val_loss: 7.3872e-04\n",
      "Epoch 36/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.9388e-04 - val_loss: 6.1494e-04\n",
      "Epoch 37/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.6981e-04 - val_loss: 5.3306e-04\n",
      "Epoch 38/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 2.5252e-04 - val_loss: 4.6435e-04\n",
      "Epoch 39/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.3978e-04 - val_loss: 4.1293e-04\n",
      "Epoch 40/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.3003e-04 - val_loss: 3.6890e-04\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 4ms/step - loss: 2.2357e-04 - val_loss: 3.3468e-04\n",
      "Epoch 42/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.1871e-04 - val_loss: 2.9706e-04\n",
      "Epoch 43/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.1481e-04 - val_loss: 2.7224e-04\n",
      "Epoch 44/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.1264e-04 - val_loss: 2.4901e-04\n",
      "Epoch 45/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.1085e-04 - val_loss: 2.3587e-04\n",
      "Epoch 46/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 2.0943e-04 - val_loss: 2.2211e-04\n",
      "Epoch 47/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.0851e-04 - val_loss: 2.1005e-04\n",
      "Epoch 48/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.0780e-04 - val_loss: 2.0093e-04\n",
      "Epoch 49/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 2.0730e-04 - val_loss: 1.9093e-04\n",
      "Epoch 50/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 2.0743e-04 - val_loss: 1.8772e-04\n",
      "Epoch 51/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 2.0701e-04 - val_loss: 1.9160e-04\n",
      "Epoch 52/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.0632e-04 - val_loss: 1.8246e-04\n",
      "Epoch 53/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.0633e-04 - val_loss: 1.7739e-04\n",
      "Epoch 54/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.0587e-04 - val_loss: 1.7689e-04\n",
      "Epoch 55/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 2.0620e-04 - val_loss: 1.6901e-04\n",
      "Epoch 56/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.0571e-04 - val_loss: 1.6958e-04\n",
      "Epoch 57/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 2.0541e-04 - val_loss: 1.7722e-04\n",
      "Epoch 58/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.0512e-04 - val_loss: 1.6545e-04\n",
      "Epoch 59/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.0476e-04 - val_loss: 1.6270e-04\n",
      "Epoch 60/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 2.0435e-04 - val_loss: 1.6604e-04\n",
      "Epoch 61/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 2.0418e-04 - val_loss: 1.7735e-04\n",
      "Epoch 62/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.0382e-04 - val_loss: 1.6635e-04\n",
      "Epoch 63/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 2.0381e-04 - val_loss: 1.6818e-04\n",
      "Epoch 64/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.0321e-04 - val_loss: 1.7564e-04\n",
      "Epoch 65/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 2.0321e-04 - val_loss: 1.6442e-04\n",
      "Epoch 66/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 2.0344e-04 - val_loss: 1.5913e-04\n",
      "Epoch 67/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.0242e-04 - val_loss: 1.5566e-04\n",
      "Epoch 68/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 2.0232e-04 - val_loss: 1.5508e-04\n",
      "Epoch 69/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 2.0250e-04 - val_loss: 1.7124e-04\n",
      "Epoch 70/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 2.0207e-04 - val_loss: 1.4979e-04\n",
      "Epoch 71/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.0149e-04 - val_loss: 1.6493e-04\n",
      "Epoch 72/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.0175e-04 - val_loss: 1.4606e-04\n",
      "Epoch 73/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.0057e-04 - val_loss: 1.6855e-04\n",
      "Epoch 74/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 2.0154e-04 - val_loss: 1.5345e-04\n",
      "Epoch 75/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.0058e-04 - val_loss: 1.4704e-04\n",
      "Epoch 76/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.0009e-04 - val_loss: 1.7327e-04\n",
      "Epoch 77/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.0117e-04 - val_loss: 1.4223e-04\n",
      "Epoch 78/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9930e-04 - val_loss: 1.4420e-04\n",
      "Epoch 79/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.0063e-04 - val_loss: 1.7079e-04\n",
      "Epoch 80/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 1.9980e-04 - val_loss: 1.4312e-04\n",
      "Epoch 81/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 1.9873e-04 - val_loss: 1.4913e-04\n",
      "Epoch 82/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9850e-04 - val_loss: 1.4037e-04\n",
      "Epoch 83/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 1.9817e-04 - val_loss: 1.5694e-04\n",
      "Epoch 84/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9803e-04 - val_loss: 1.5088e-04\n",
      "Epoch 85/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9719e-04 - val_loss: 1.5366e-04\n",
      "Epoch 86/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9679e-04 - val_loss: 1.3561e-04\n",
      "Epoch 87/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9727e-04 - val_loss: 1.3483e-04\n",
      "Epoch 88/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9715e-04 - val_loss: 1.3974e-04\n",
      "Epoch 89/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9706e-04 - val_loss: 1.4452e-04\n",
      "Epoch 90/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9507e-04 - val_loss: 1.3428e-04\n",
      "Epoch 91/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9580e-04 - val_loss: 1.3388e-04\n",
      "Epoch 92/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9481e-04 - val_loss: 1.3011e-04\n",
      "Epoch 93/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9423e-04 - val_loss: 1.2183e-04\n",
      "Epoch 94/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9497e-04 - val_loss: 1.3815e-04\n",
      "Epoch 95/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9395e-04 - val_loss: 1.1342e-04\n",
      "Epoch 96/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9364e-04 - val_loss: 1.3052e-04\n",
      "Epoch 97/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9268e-04 - val_loss: 1.3133e-04\n",
      "Epoch 98/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9209e-04 - val_loss: 1.3918e-04\n",
      "Epoch 99/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9203e-04 - val_loss: 1.3433e-04\n",
      "Epoch 100/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9123e-04 - val_loss: 1.3354e-04\n",
      "Epoch 101/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9122e-04 - val_loss: 1.3057e-04\n",
      "Epoch 102/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9058e-04 - val_loss: 1.3281e-04\n",
      "Epoch 103/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9084e-04 - val_loss: 1.1672e-04\n",
      "Epoch 104/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9015e-04 - val_loss: 1.1753e-04\n",
      "Epoch 105/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8926e-04 - val_loss: 1.3180e-04\n",
      "Epoch 106/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8911e-04 - val_loss: 1.3700e-04\n",
      "Epoch 107/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8941e-04 - val_loss: 1.1291e-04\n",
      "Epoch 108/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8823e-04 - val_loss: 1.1229e-04\n",
      "Epoch 109/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8763e-04 - val_loss: 9.6166e-05\n",
      "Epoch 110/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8801e-04 - val_loss: 1.1061e-04\n",
      "Epoch 111/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8658e-04 - val_loss: 1.3318e-04\n",
      "Epoch 112/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8696e-04 - val_loss: 1.3283e-04\n",
      "Epoch 113/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.9184e-04 - val_loss: 1.0819e-04\n",
      "Epoch 114/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8612e-04 - val_loss: 1.0916e-04\n",
      "Epoch 115/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8546e-04 - val_loss: 8.9558e-05\n",
      "Epoch 116/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8471e-04 - val_loss: 1.0038e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8704e-04 - val_loss: 1.0290e-04\n",
      "Epoch 118/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8503e-04 - val_loss: 9.5746e-05\n",
      "Epoch 119/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8325e-04 - val_loss: 1.1714e-04\n",
      "Epoch 120/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8206e-04 - val_loss: 8.5541e-05\n",
      "Epoch 121/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8288e-04 - val_loss: 9.7608e-05\n",
      "Epoch 122/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8224e-04 - val_loss: 9.7691e-05\n",
      "Epoch 123/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8172e-04 - val_loss: 9.7486e-05\n",
      "Epoch 124/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8099e-04 - val_loss: 1.0050e-04\n",
      "Epoch 125/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8047e-04 - val_loss: 8.9818e-05\n",
      "Epoch 126/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8297e-04 - val_loss: 1.0032e-04\n",
      "Epoch 127/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8049e-04 - val_loss: 1.0648e-04\n",
      "Epoch 128/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8096e-04 - val_loss: 1.0452e-04\n",
      "Epoch 129/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7919e-04 - val_loss: 9.6710e-05\n",
      "Epoch 130/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7902e-04 - val_loss: 9.1863e-05\n",
      "Epoch 131/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7799e-04 - val_loss: 1.0130e-04\n",
      "Epoch 132/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7919e-04 - val_loss: 1.3175e-04\n",
      "Epoch 133/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7817e-04 - val_loss: 8.2060e-05\n",
      "Epoch 134/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7696e-04 - val_loss: 9.2248e-05\n",
      "Epoch 135/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7660e-04 - val_loss: 7.6800e-05\n",
      "Epoch 136/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7596e-04 - val_loss: 8.6368e-05\n",
      "Epoch 137/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7540e-04 - val_loss: 6.5072e-05\n",
      "Epoch 138/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7527e-04 - val_loss: 7.6891e-05\n",
      "Epoch 139/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7418e-04 - val_loss: 6.4640e-05\n",
      "Epoch 140/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7441e-04 - val_loss: 7.5029e-05\n",
      "Epoch 141/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7415e-04 - val_loss: 6.8002e-05\n",
      "Epoch 142/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7392e-04 - val_loss: 8.5656e-05\n",
      "Epoch 143/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7242e-04 - val_loss: 5.4909e-05\n",
      "Epoch 144/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7314e-04 - val_loss: 6.5128e-05\n",
      "Epoch 145/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7304e-04 - val_loss: 6.9330e-05\n",
      "Epoch 146/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7168e-04 - val_loss: 8.1973e-05\n",
      "Epoch 147/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7093e-04 - val_loss: 8.4243e-05\n",
      "Epoch 148/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7241e-04 - val_loss: 7.4484e-05\n",
      "Epoch 149/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7152e-04 - val_loss: 6.1511e-05\n",
      "Epoch 150/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6934e-04 - val_loss: 8.1075e-05\n",
      "Epoch 151/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7187e-04 - val_loss: 7.8029e-05\n",
      "Epoch 152/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.7066e-04 - val_loss: 5.3293e-05\n",
      "Epoch 153/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6846e-04 - val_loss: 7.1374e-05\n",
      "Epoch 154/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6870e-04 - val_loss: 6.8242e-05\n",
      "Epoch 155/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6797e-04 - val_loss: 7.3629e-05\n",
      "Epoch 156/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6745e-04 - val_loss: 4.7593e-05\n",
      "Epoch 157/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6608e-04 - val_loss: 6.8741e-05\n",
      "Epoch 158/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6841e-04 - val_loss: 3.8784e-05\n",
      "Epoch 159/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6911e-04 - val_loss: 4.4656e-05\n",
      "Epoch 160/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6592e-04 - val_loss: 4.2585e-05\n",
      "Epoch 161/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6654e-04 - val_loss: 6.6951e-05\n",
      "Epoch 162/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6462e-04 - val_loss: 4.9124e-05\n",
      "Epoch 163/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6528e-04 - val_loss: 5.1700e-05\n",
      "Epoch 164/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6421e-04 - val_loss: 5.9805e-05\n",
      "Epoch 165/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6444e-04 - val_loss: 5.5795e-05\n",
      "Epoch 166/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6603e-04 - val_loss: 5.4522e-05\n",
      "Epoch 167/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6355e-04 - val_loss: 4.9689e-05\n",
      "Epoch 168/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6287e-04 - val_loss: 4.8062e-05\n",
      "Epoch 169/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6214e-04 - val_loss: 5.6268e-05\n",
      "Epoch 170/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6410e-04 - val_loss: 4.8516e-05\n",
      "Epoch 171/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6159e-04 - val_loss: 4.9966e-05\n",
      "Epoch 172/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6199e-04 - val_loss: 3.4752e-05\n",
      "Epoch 173/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6472e-04 - val_loss: 6.1290e-05\n",
      "Epoch 174/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6118e-04 - val_loss: 4.7276e-05\n",
      "Epoch 175/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6064e-04 - val_loss: 4.9334e-05\n",
      "Epoch 176/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5992e-04 - val_loss: 3.9411e-05\n",
      "Epoch 177/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5982e-04 - val_loss: 3.9989e-05\n",
      "Epoch 178/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5954e-04 - val_loss: 4.5626e-05\n",
      "Epoch 179/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6063e-04 - val_loss: 4.2057e-05\n",
      "Epoch 180/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6099e-04 - val_loss: 3.1189e-05\n",
      "Epoch 181/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6123e-04 - val_loss: 4.2062e-05\n",
      "Epoch 182/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5781e-04 - val_loss: 5.9502e-05\n",
      "Epoch 183/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5919e-04 - val_loss: 3.1400e-05\n",
      "Epoch 184/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5842e-04 - val_loss: 1.4172e-05\n",
      "Epoch 185/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5985e-04 - val_loss: 3.8990e-05\n",
      "Epoch 186/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5730e-04 - val_loss: 3.1585e-05\n",
      "Epoch 187/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5695e-04 - val_loss: 2.8091e-05\n",
      "Epoch 188/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5867e-04 - val_loss: 4.8397e-05\n",
      "Epoch 189/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5667e-04 - val_loss: 2.8565e-05\n",
      "Epoch 190/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5578e-04 - val_loss: 3.7834e-05\n",
      "Epoch 191/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5610e-04 - val_loss: 2.9364e-05\n",
      "Epoch 192/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5639e-04 - val_loss: 3.4899e-05\n",
      "Epoch 193/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5649e-04 - val_loss: 2.3161e-05\n",
      "Epoch 194/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5726e-04 - val_loss: 1.9836e-05\n",
      "Epoch 195/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5549e-04 - val_loss: 4.5494e-05\n",
      "Epoch 196/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5603e-04 - val_loss: 2.3508e-05\n",
      "Epoch 197/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5510e-04 - val_loss: 2.9166e-05\n",
      "Epoch 198/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5478e-04 - val_loss: 2.6933e-05\n",
      "Epoch 199/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5402e-04 - val_loss: 2.5839e-05\n",
      "Epoch 200/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5563e-04 - val_loss: 1.2812e-05\n",
      "Thời gian huấn luyện:  29.11375379562378\n",
      "Model: \"sequential_122\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_30 (LSTM)              (None, 1, 117)            55692     \n",
      "                                                                 \n",
      " flatten_122 (Flatten)       (None, 117)               0         \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 1)                 118       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,810\n",
      "Trainable params: 55,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "47/47 [==============================] - 2s 9ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 2/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 3/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 4/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 5/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 6/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 7/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 8/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 9/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 10/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 11/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 12/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 13/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 14/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 15/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 16/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 17/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 18/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 19/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 20/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 21/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 22/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 23/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 24/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 25/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 26/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 27/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 28/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 29/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 30/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 31/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 32/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 33/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 34/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 35/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 36/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 37/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 38/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 39/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 40/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 41/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 42/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 43/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 44/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 45/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 46/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 47/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 48/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 49/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 50/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 51/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 52/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 53/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 54/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 55/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 56/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 57/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 58/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 59/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 60/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 61/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 62/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 64/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 65/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 66/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 67/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 68/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 69/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 70/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 71/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 72/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 73/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 74/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 75/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 76/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 77/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 78/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 79/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 80/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 81/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 82/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 83/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 84/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 85/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 86/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 87/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 88/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 89/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 90/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 91/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 92/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 93/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 94/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 95/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 96/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 97/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 98/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 99/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 100/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 101/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 102/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 103/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 104/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 105/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 106/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 107/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 108/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 109/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 110/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 111/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 112/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 113/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 114/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 115/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 116/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 117/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 118/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 119/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 120/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 121/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 122/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 123/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 124/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 125/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 126/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 127/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 128/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 129/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 130/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 131/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 132/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 133/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 134/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 135/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 136/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 137/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 138/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 139/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 140/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 141/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 142/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 143/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 144/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 145/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 146/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 147/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 148/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 149/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 150/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 151/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 152/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 153/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 154/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 155/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 156/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 157/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 158/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 159/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 160/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 161/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 162/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 163/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 164/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 165/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 166/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 167/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 168/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 169/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 170/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 171/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 172/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 173/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 174/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 175/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 176/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 177/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 178/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 179/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 180/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 181/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 182/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 183/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 184/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 185/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 186/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 187/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 188/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 189/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 190/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 191/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 192/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 193/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 194/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 195/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 196/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 197/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 198/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 199/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Epoch 200/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.0037\n",
      "Thời gian huấn luyện:  29.00760817527771\n",
      "Model: \"sequential_123\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_29 (GRU)                (None, 1, 117)            42120     \n",
      "                                                                 \n",
      " flatten_123 (Flatten)       (None, 117)               0         \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 1)                 118       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,238\n",
      "Trainable params: 42,238\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.1315 - val_loss: 0.0073\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0383 - val_loss: 0.0404\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0431\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0365\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0300\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0242\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0195\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0153\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0115\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0089\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0068\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 7.6737e-04 - val_loss: 0.0013\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.8829e-04 - val_loss: 9.7788e-04\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.6918e-04 - val_loss: 6.8420e-04\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.9129e-04 - val_loss: 5.0479e-04\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4112e-04 - val_loss: 3.7413e-04\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1048e-04 - val_loss: 2.8531e-04\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9073e-04 - val_loss: 2.2123e-04\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7825e-04 - val_loss: 1.8595e-04\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7097e-04 - val_loss: 1.4106e-04\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6572e-04 - val_loss: 1.2726e-04\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6264e-04 - val_loss: 1.0667e-04\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6050e-04 - val_loss: 9.4114e-05\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5882e-04 - val_loss: 8.2744e-05\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5764e-04 - val_loss: 7.3172e-05\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5648e-04 - val_loss: 6.9385e-05\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5659e-04 - val_loss: 6.0900e-05\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5528e-04 - val_loss: 6.0339e-05\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5452e-04 - val_loss: 5.6612e-05\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5452e-04 - val_loss: 5.5540e-05\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5451e-04 - val_loss: 4.8357e-05\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5320e-04 - val_loss: 4.6625e-05\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5238e-04 - val_loss: 4.5034e-05\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5182e-04 - val_loss: 4.0166e-05\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5211e-04 - val_loss: 4.1168e-05\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5087e-04 - val_loss: 3.7983e-05\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5078e-04 - val_loss: 3.6318e-05\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5020e-04 - val_loss: 3.6112e-05\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5125e-04 - val_loss: 3.5871e-05\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5003e-04 - val_loss: 3.3254e-05\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4917e-04 - val_loss: 3.1945e-05\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4921e-04 - val_loss: 3.1142e-05\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4949e-04 - val_loss: 3.0763e-05\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4896e-04 - val_loss: 3.0363e-05\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4875e-04 - val_loss: 2.9137e-05\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4816e-04 - val_loss: 2.8660e-05\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4849e-04 - val_loss: 2.8133e-05\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4870e-04 - val_loss: 2.7233e-05\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4762e-04 - val_loss: 2.6728e-05\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4726e-04 - val_loss: 2.6193e-05\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4813e-04 - val_loss: 2.7079e-05\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4722e-04 - val_loss: 2.5637e-05\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4714e-04 - val_loss: 2.5042e-05\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4943e-04 - val_loss: 2.5103e-05\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4732e-04 - val_loss: 2.4153e-05\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4859e-04 - val_loss: 2.3605e-05\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4841e-04 - val_loss: 2.3168e-05\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4609e-04 - val_loss: 2.4179e-05\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4637e-04 - val_loss: 2.2847e-05\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4650e-04 - val_loss: 2.4785e-05\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4785e-04 - val_loss: 2.3319e-05\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4594e-04 - val_loss: 2.1645e-05\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4572e-04 - val_loss: 2.1372e-05\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4474e-04 - val_loss: 2.2566e-05\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4530e-04 - val_loss: 2.0504e-05\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4507e-04 - val_loss: 2.0493e-05\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4493e-04 - val_loss: 2.0279e-05\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4502e-04 - val_loss: 2.0517e-05\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4554e-04 - val_loss: 2.1716e-05\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4556e-04 - val_loss: 1.9137e-05\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4461e-04 - val_loss: 1.8908e-05\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4359e-04 - val_loss: 2.0087e-05\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4506e-04 - val_loss: 2.0797e-05\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4544e-04 - val_loss: 1.9190e-05\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4468e-04 - val_loss: 1.9026e-05\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4661e-04 - val_loss: 1.7840e-05\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4293e-04 - val_loss: 1.9078e-05\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4284e-04 - val_loss: 1.7849e-05\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4327e-04 - val_loss: 1.7746e-05\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4504e-04 - val_loss: 1.7385e-05\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4348e-04 - val_loss: 1.9268e-05\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4446e-04 - val_loss: 1.8875e-05\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4393e-04 - val_loss: 1.6449e-05\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4485e-04 - val_loss: 1.6240e-05\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4228e-04 - val_loss: 1.7266e-05\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4503e-04 - val_loss: 1.5930e-05\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4186e-04 - val_loss: 1.8410e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4198e-04 - val_loss: 1.6520e-05\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4152e-04 - val_loss: 1.6555e-05\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4085e-04 - val_loss: 1.7093e-05\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4159e-04 - val_loss: 1.5240e-05\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4220e-04 - val_loss: 1.6674e-05\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4104e-04 - val_loss: 1.4915e-05\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4140e-04 - val_loss: 1.5267e-05\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3991e-04 - val_loss: 1.7350e-05\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4150e-04 - val_loss: 1.4925e-05\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4054e-04 - val_loss: 1.5041e-05\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4018e-04 - val_loss: 1.4667e-05\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4146e-04 - val_loss: 2.1971e-05\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4010e-04 - val_loss: 1.6610e-05\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4083e-04 - val_loss: 1.4095e-05\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4045e-04 - val_loss: 1.6253e-05\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4090e-04 - val_loss: 1.3840e-05\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3916e-04 - val_loss: 1.3712e-05\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4028e-04 - val_loss: 1.5596e-05\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3834e-04 - val_loss: 1.8349e-05\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4148e-04 - val_loss: 1.3509e-05\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3795e-04 - val_loss: 1.4108e-05\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3830e-04 - val_loss: 1.4618e-05\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3775e-04 - val_loss: 1.6266e-05\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4073e-04 - val_loss: 1.3867e-05\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.4160e-04 - val_loss: 1.7601e-05\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3839e-04 - val_loss: 1.4493e-05\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3921e-04 - val_loss: 1.6380e-05\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3884e-04 - val_loss: 1.5951e-05\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3705e-04 - val_loss: 1.5448e-05\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3865e-04 - val_loss: 1.5370e-05\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3801e-04 - val_loss: 1.2586e-05\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3626e-04 - val_loss: 1.2479e-05\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3626e-04 - val_loss: 1.2433e-05\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3676e-04 - val_loss: 1.2351e-05\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3686e-04 - val_loss: 1.4371e-05\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3559e-04 - val_loss: 1.4331e-05\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3576e-04 - val_loss: 1.7750e-05\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3588e-04 - val_loss: 1.2774e-05\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3581e-04 - val_loss: 1.2578e-05\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3454e-04 - val_loss: 1.2471e-05\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3680e-04 - val_loss: 1.2023e-05\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3476e-04 - val_loss: 1.2709e-05\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3488e-04 - val_loss: 1.4174e-05\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3308e-04 - val_loss: 1.5624e-05\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3500e-04 - val_loss: 1.3195e-05\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3468e-04 - val_loss: 1.5399e-05\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3375e-04 - val_loss: 1.5306e-05\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3280e-04 - val_loss: 1.1501e-05\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3312e-04 - val_loss: 1.2333e-05\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3465e-04 - val_loss: 1.7045e-05\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3570e-04 - val_loss: 1.2037e-05\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3363e-04 - val_loss: 1.1306e-05\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3374e-04 - val_loss: 1.1584e-05\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3429e-04 - val_loss: 1.1442e-05\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3205e-04 - val_loss: 1.4686e-05\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3654e-04 - val_loss: 1.3627e-05\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3036e-04 - val_loss: 1.1185e-05\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3013e-04 - val_loss: 2.2222e-05\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3260e-04 - val_loss: 1.6704e-05\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3271e-04 - val_loss: 1.4620e-05\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3002e-04 - val_loss: 1.1017e-05\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3130e-04 - val_loss: 1.1541e-05\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3095e-04 - val_loss: 1.5061e-05\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3094e-04 - val_loss: 1.2833e-05\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2990e-04 - val_loss: 1.1123e-05\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2941e-04 - val_loss: 1.7202e-05\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2870e-04 - val_loss: 1.0688e-05\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3143e-04 - val_loss: 1.3101e-05\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2974e-04 - val_loss: 1.1040e-05\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2969e-04 - val_loss: 1.0566e-05\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3064e-04 - val_loss: 1.0988e-05\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2951e-04 - val_loss: 1.3532e-05\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2826e-04 - val_loss: 1.1313e-05\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3058e-04 - val_loss: 1.0323e-05\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3162e-04 - val_loss: 1.9667e-05\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3036e-04 - val_loss: 1.0303e-05\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2664e-04 - val_loss: 1.2131e-05\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2875e-04 - val_loss: 1.0459e-05\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2918e-04 - val_loss: 1.2624e-05\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2891e-04 - val_loss: 1.4693e-05\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.3127e-04 - val_loss: 1.3012e-05\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2866e-04 - val_loss: 1.2079e-05\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2752e-04 - val_loss: 1.0438e-05\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2604e-04 - val_loss: 1.2909e-05\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2762e-04 - val_loss: 1.2411e-05\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2600e-04 - val_loss: 1.1886e-05\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2751e-04 - val_loss: 9.9590e-06\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2620e-04 - val_loss: 1.0041e-05\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2602e-04 - val_loss: 1.2979e-05\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2677e-04 - val_loss: 1.0832e-05\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2648e-04 - val_loss: 1.2240e-05\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2339e-04 - val_loss: 9.9249e-06\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2438e-04 - val_loss: 1.0512e-05\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2771e-04 - val_loss: 1.0820e-05\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2398e-04 - val_loss: 9.9326e-06\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2349e-04 - val_loss: 9.7426e-06\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2473e-04 - val_loss: 1.3720e-05\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2263e-04 - val_loss: 1.0562e-05\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2275e-04 - val_loss: 9.6317e-06\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2400e-04 - val_loss: 1.1889e-05\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2684e-04 - val_loss: 9.6020e-06\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2196e-04 - val_loss: 9.9852e-06\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2264e-04 - val_loss: 1.2269e-05\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2080e-04 - val_loss: 1.0626e-05\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2236e-04 - val_loss: 1.0725e-05\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2061e-04 - val_loss: 9.4721e-06\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2085e-04 - val_loss: 9.4486e-06\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2029e-04 - val_loss: 1.9910e-05\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2249e-04 - val_loss: 1.0760e-05\n",
      "Thời gian huấn luyện:  15.310782432556152\n",
      "Model: \"sequential_124\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_156 (Dense)           (None, 3, 116)            232       \n",
      "                                                                 \n",
      " flatten_124 (Flatten)       (None, 348)               0         \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 1)                 349       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 581\n",
      "Trainable params: 581\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 941us/step\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "44/44 [==============================] - 1s 6ms/step - loss: 0.0080 - val_loss: 1.9709e-05\n",
      "Epoch 2/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 4.8915e-04 - val_loss: 5.2549e-05\n",
      "Epoch 3/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 4.6119e-04 - val_loss: 4.8776e-05\n",
      "Epoch 4/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 4.5381e-04 - val_loss: 4.9125e-05\n",
      "Epoch 5/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 4.4577e-04 - val_loss: 2.7741e-05\n",
      "Epoch 6/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 4.5434e-04 - val_loss: 3.5447e-05\n",
      "Epoch 7/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.4079e-04 - val_loss: 4.5201e-05\n",
      "Epoch 8/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 4.3165e-04 - val_loss: 4.8089e-05\n",
      "Epoch 9/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 4.3239e-04 - val_loss: 3.1546e-05\n",
      "Epoch 10/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 4.2406e-04 - val_loss: 4.6360e-05\n",
      "Epoch 11/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 4.1895e-04 - val_loss: 2.6710e-05\n",
      "Epoch 12/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.2240e-04 - val_loss: 2.6572e-05\n",
      "Epoch 13/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.1526e-04 - val_loss: 4.0819e-05\n",
      "Epoch 14/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.0900e-04 - val_loss: 3.8777e-05\n",
      "Epoch 15/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.1230e-04 - val_loss: 3.1262e-05\n",
      "Epoch 16/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.9792e-04 - val_loss: 3.1877e-05\n",
      "Epoch 17/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.8910e-04 - val_loss: 3.6695e-05\n",
      "Epoch 18/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.9838e-04 - val_loss: 3.5297e-05\n",
      "Epoch 19/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.8178e-04 - val_loss: 2.3770e-05\n",
      "Epoch 20/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.8246e-04 - val_loss: 2.7902e-05\n",
      "Epoch 21/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.7627e-04 - val_loss: 3.5890e-05\n",
      "Epoch 22/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.7507e-04 - val_loss: 3.1413e-05\n",
      "Epoch 23/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.6564e-04 - val_loss: 3.5498e-05\n",
      "Epoch 24/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.6873e-04 - val_loss: 3.2221e-05\n",
      "Epoch 25/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.5995e-04 - val_loss: 5.2117e-05\n",
      "Epoch 26/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.5601e-04 - val_loss: 3.1290e-05\n",
      "Epoch 27/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.6592e-04 - val_loss: 1.8294e-05\n",
      "Epoch 28/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.6880e-04 - val_loss: 3.4254e-05\n",
      "Epoch 29/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.4903e-04 - val_loss: 2.8624e-05\n",
      "Epoch 30/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.4579e-04 - val_loss: 1.5469e-05\n",
      "Epoch 31/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.4706e-04 - val_loss: 2.6005e-05\n",
      "Epoch 32/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.5138e-04 - val_loss: 2.7358e-05\n",
      "Epoch 33/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.3797e-04 - val_loss: 3.2746e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.3371e-04 - val_loss: 1.9261e-05\n",
      "Epoch 35/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.3466e-04 - val_loss: 2.7142e-05\n",
      "Epoch 36/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.3124e-04 - val_loss: 2.9524e-05\n",
      "Epoch 37/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.2697e-04 - val_loss: 3.8648e-05\n",
      "Epoch 38/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.1675e-04 - val_loss: 3.0782e-05\n",
      "Epoch 39/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.1998e-04 - val_loss: 2.1690e-05\n",
      "Epoch 40/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.2088e-04 - val_loss: 1.8258e-05\n",
      "Epoch 41/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.1500e-04 - val_loss: 2.4645e-05\n",
      "Epoch 42/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.0717e-04 - val_loss: 3.1443e-05\n",
      "Epoch 43/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.0926e-04 - val_loss: 2.7930e-05\n",
      "Epoch 44/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.1509e-04 - val_loss: 2.0410e-05\n",
      "Epoch 45/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.0136e-04 - val_loss: 2.6069e-05\n",
      "Epoch 46/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.0092e-04 - val_loss: 2.6756e-05\n",
      "Epoch 47/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.0317e-04 - val_loss: 2.9112e-05\n",
      "Epoch 48/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.0658e-04 - val_loss: 3.1548e-05\n",
      "Epoch 49/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.9275e-04 - val_loss: 1.5066e-05\n",
      "Epoch 50/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.9249e-04 - val_loss: 2.3063e-05\n",
      "Epoch 51/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.9743e-04 - val_loss: 3.1037e-05\n",
      "Epoch 52/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.9358e-04 - val_loss: 1.9839e-05\n",
      "Epoch 53/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.8880e-04 - val_loss: 1.4965e-05\n",
      "Epoch 54/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.9119e-04 - val_loss: 1.8678e-05\n",
      "Epoch 55/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.8308e-04 - val_loss: 1.3327e-05\n",
      "Epoch 56/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.1974e-04 - val_loss: 1.9811e-05\n",
      "Epoch 57/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.7219e-04 - val_loss: 1.6161e-05\n",
      "Epoch 58/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.7228e-04 - val_loss: 1.1888e-05\n",
      "Epoch 59/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.7706e-04 - val_loss: 1.5956e-05\n",
      "Epoch 60/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.9436e-04 - val_loss: 1.8388e-05\n",
      "Epoch 61/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.7404e-04 - val_loss: 1.4394e-05\n",
      "Epoch 62/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.6864e-04 - val_loss: 1.8352e-05\n",
      "Epoch 63/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.7523e-04 - val_loss: 1.3177e-05\n",
      "Epoch 64/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.7662e-04 - val_loss: 2.4160e-05\n",
      "Epoch 65/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.6848e-04 - val_loss: 1.2071e-05\n",
      "Epoch 66/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.7324e-04 - val_loss: 1.1211e-05\n",
      "Epoch 67/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.7813e-04 - val_loss: 1.2631e-05\n",
      "Epoch 68/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.8611e-04 - val_loss: 2.5482e-05\n",
      "Epoch 69/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.6496e-04 - val_loss: 1.5320e-05\n",
      "Epoch 70/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.8848e-04 - val_loss: 1.1890e-05\n",
      "Epoch 71/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.5521e-04 - val_loss: 1.4177e-05\n",
      "Epoch 72/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.6687e-04 - val_loss: 3.3400e-05\n",
      "Epoch 73/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.4867e-04 - val_loss: 1.7446e-05\n",
      "Epoch 74/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.5510e-04 - val_loss: 1.7624e-05\n",
      "Epoch 75/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.4372e-04 - val_loss: 2.5861e-05\n",
      "Epoch 76/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.5627e-04 - val_loss: 2.1326e-05\n",
      "Epoch 77/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.4780e-04 - val_loss: 1.0787e-05\n",
      "Epoch 78/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.4660e-04 - val_loss: 2.0966e-05\n",
      "Epoch 79/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.5660e-04 - val_loss: 1.9100e-05\n",
      "Epoch 80/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.5832e-04 - val_loss: 1.0031e-05\n",
      "Epoch 81/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.4107e-04 - val_loss: 1.6424e-05\n",
      "Epoch 82/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.4795e-04 - val_loss: 9.5539e-06\n",
      "Epoch 83/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.4288e-04 - val_loss: 1.8756e-05\n",
      "Epoch 84/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.4596e-04 - val_loss: 1.3082e-05\n",
      "Epoch 85/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.5042e-04 - val_loss: 1.5746e-05\n",
      "Epoch 86/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.3121e-04 - val_loss: 1.3148e-05\n",
      "Epoch 87/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.4260e-04 - val_loss: 9.4431e-06\n",
      "Epoch 88/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.2805e-04 - val_loss: 2.4717e-05\n",
      "Epoch 89/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.3736e-04 - val_loss: 1.0770e-05\n",
      "Epoch 90/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.2950e-04 - val_loss: 9.3160e-06\n",
      "Epoch 91/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.3465e-04 - val_loss: 1.2908e-05\n",
      "Epoch 92/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.2841e-04 - val_loss: 1.0319e-05\n",
      "Epoch 93/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.3344e-04 - val_loss: 1.4812e-05\n",
      "Epoch 94/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.6331e-04 - val_loss: 9.1734e-06\n",
      "Epoch 95/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.3490e-04 - val_loss: 1.7085e-05\n",
      "Epoch 96/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.2932e-04 - val_loss: 1.2723e-05\n",
      "Epoch 97/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.2904e-04 - val_loss: 9.0265e-06\n",
      "Epoch 98/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.2049e-04 - val_loss: 1.1627e-05\n",
      "Epoch 99/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.2080e-04 - val_loss: 1.2768e-05\n",
      "Epoch 100/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.2247e-04 - val_loss: 1.5217e-05\n",
      "Epoch 101/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.2086e-04 - val_loss: 9.7801e-06\n",
      "Epoch 102/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.3906e-04 - val_loss: 1.3250e-05\n",
      "Epoch 103/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.2014e-04 - val_loss: 1.3058e-05\n",
      "Epoch 104/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.2305e-04 - val_loss: 8.9171e-06\n",
      "Epoch 105/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.1530e-04 - val_loss: 1.2376e-05\n",
      "Epoch 106/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.4315e-04 - val_loss: 1.4394e-05\n",
      "Epoch 107/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.3073e-04 - val_loss: 1.3060e-05\n",
      "Epoch 108/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.3646e-04 - val_loss: 1.7534e-05\n",
      "Epoch 109/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.1964e-04 - val_loss: 9.5455e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.0611e-04 - val_loss: 1.1998e-05\n",
      "Epoch 111/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.0795e-04 - val_loss: 1.0528e-05\n",
      "Epoch 112/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.0334e-04 - val_loss: 2.0362e-05\n",
      "Epoch 113/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.1213e-04 - val_loss: 1.2725e-05\n",
      "Epoch 114/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.2761e-04 - val_loss: 1.8936e-05\n",
      "Epoch 115/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.1879e-04 - val_loss: 9.4175e-06\n",
      "Epoch 116/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.0564e-04 - val_loss: 1.0773e-05\n",
      "Epoch 117/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0516e-04 - val_loss: 1.4728e-05\n",
      "Epoch 118/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0996e-04 - val_loss: 1.2071e-05\n",
      "Epoch 119/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.9967e-04 - val_loss: 8.1819e-06\n",
      "Epoch 120/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0844e-04 - val_loss: 1.0211e-05\n",
      "Epoch 121/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.0953e-04 - val_loss: 9.6932e-06\n",
      "Epoch 122/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.0349e-04 - val_loss: 1.0363e-05\n",
      "Epoch 123/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.9958e-04 - val_loss: 8.0684e-06\n",
      "Epoch 124/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0629e-04 - val_loss: 1.0596e-05\n",
      "Epoch 125/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0033e-04 - val_loss: 8.0006e-06\n",
      "Epoch 126/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.1604e-04 - val_loss: 7.8905e-06\n",
      "Epoch 127/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.0089e-04 - val_loss: 8.2533e-06\n",
      "Epoch 128/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.9847e-04 - val_loss: 1.0871e-05\n",
      "Epoch 129/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.9993e-04 - val_loss: 9.2322e-06\n",
      "Epoch 130/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.9696e-04 - val_loss: 1.8903e-05\n",
      "Epoch 131/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.9828e-04 - val_loss: 1.5043e-05\n",
      "Epoch 132/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.0014e-04 - val_loss: 1.1303e-05\n",
      "Epoch 133/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.9379e-04 - val_loss: 9.2068e-06\n",
      "Epoch 134/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.8669e-04 - val_loss: 9.3322e-06\n",
      "Epoch 135/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.2826e-04 - val_loss: 2.9151e-05\n",
      "Epoch 136/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0113e-04 - val_loss: 1.3402e-05\n",
      "Epoch 137/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.1223e-04 - val_loss: 7.8068e-06\n",
      "Epoch 138/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.9267e-04 - val_loss: 1.0228e-05\n",
      "Epoch 139/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.1726e-04 - val_loss: 1.1946e-05\n",
      "Epoch 140/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.0693e-04 - val_loss: 1.0547e-05\n",
      "Epoch 141/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.9293e-04 - val_loss: 7.5223e-06\n",
      "Epoch 142/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.9160e-04 - val_loss: 1.1412e-05\n",
      "Epoch 143/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.1720e-04 - val_loss: 7.9459e-06\n",
      "Epoch 144/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.8242e-04 - val_loss: 9.0132e-06\n",
      "Epoch 145/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.8595e-04 - val_loss: 9.4730e-06\n",
      "Epoch 146/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.9176e-04 - val_loss: 1.5237e-05\n",
      "Epoch 147/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.8718e-04 - val_loss: 7.4260e-06\n",
      "Epoch 148/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.8265e-04 - val_loss: 8.0473e-06\n",
      "Epoch 149/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.0277e-04 - val_loss: 8.2420e-06\n",
      "Epoch 150/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.8832e-04 - val_loss: 1.1872e-05\n",
      "Epoch 151/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.9065e-04 - val_loss: 7.9705e-06\n",
      "Epoch 152/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.8261e-04 - val_loss: 8.5046e-06\n",
      "Epoch 153/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.7779e-04 - val_loss: 8.6198e-06\n",
      "Epoch 154/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.7796e-04 - val_loss: 1.9543e-05\n",
      "Epoch 155/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.8650e-04 - val_loss: 1.0914e-05\n",
      "Epoch 156/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.8850e-04 - val_loss: 7.8433e-06\n",
      "Epoch 157/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.8414e-04 - val_loss: 7.0467e-06\n",
      "Epoch 158/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.9111e-04 - val_loss: 9.7228e-06\n",
      "Epoch 159/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.8130e-04 - val_loss: 1.0740e-05\n",
      "Epoch 160/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.8290e-04 - val_loss: 8.3437e-06\n",
      "Epoch 161/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.7786e-04 - val_loss: 9.3417e-06\n",
      "Epoch 162/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.7857e-04 - val_loss: 7.9594e-06\n",
      "Epoch 163/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.7918e-04 - val_loss: 9.5191e-06\n",
      "Epoch 164/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.7066e-04 - val_loss: 6.7638e-06\n",
      "Epoch 165/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.7719e-04 - val_loss: 7.8879e-06\n",
      "Epoch 166/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.8105e-04 - val_loss: 9.4782e-06\n",
      "Epoch 167/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.7592e-04 - val_loss: 1.0511e-05\n",
      "Epoch 168/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.7217e-04 - val_loss: 6.7686e-06\n",
      "Epoch 169/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.9046e-04 - val_loss: 7.8022e-06\n",
      "Epoch 170/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.7544e-04 - val_loss: 9.0539e-06\n",
      "Epoch 171/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.7035e-04 - val_loss: 1.2276e-05\n",
      "Epoch 172/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.7030e-04 - val_loss: 9.1220e-06\n",
      "Epoch 173/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.7552e-04 - val_loss: 7.8709e-06\n",
      "Epoch 174/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.7121e-04 - val_loss: 9.0337e-06\n",
      "Epoch 175/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.7250e-04 - val_loss: 8.9518e-06\n",
      "Epoch 176/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.8271e-04 - val_loss: 7.8175e-06\n",
      "Epoch 177/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.7343e-04 - val_loss: 1.0201e-05\n",
      "Epoch 178/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.8219e-04 - val_loss: 7.3957e-06\n",
      "Epoch 179/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.7229e-04 - val_loss: 6.7122e-06\n",
      "Epoch 180/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.9099e-04 - val_loss: 6.6755e-06\n",
      "Epoch 181/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.7179e-04 - val_loss: 7.8848e-06\n",
      "Epoch 182/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.7388e-04 - val_loss: 6.4187e-06\n",
      "Epoch 183/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.6184e-04 - val_loss: 8.3149e-06\n",
      "Epoch 184/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.7145e-04 - val_loss: 6.7277e-06\n",
      "Epoch 185/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 2ms/step - loss: 1.7260e-04 - val_loss: 7.0468e-06\n",
      "Epoch 186/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.8199e-04 - val_loss: 1.0707e-05\n",
      "Epoch 187/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.7430e-04 - val_loss: 6.4821e-06\n",
      "Epoch 188/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.6033e-04 - val_loss: 6.5059e-06\n",
      "Epoch 189/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.7472e-04 - val_loss: 7.1127e-06\n",
      "Epoch 190/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.7408e-04 - val_loss: 6.6980e-06\n",
      "Epoch 191/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.6832e-04 - val_loss: 6.4313e-06\n",
      "Epoch 192/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.6783e-04 - val_loss: 8.8459e-06\n",
      "Epoch 193/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.6151e-04 - val_loss: 1.0582e-05\n",
      "Epoch 194/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.6794e-04 - val_loss: 6.3779e-06\n",
      "Epoch 195/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.6360e-04 - val_loss: 6.4763e-06\n",
      "Epoch 196/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.5694e-04 - val_loss: 6.2769e-06\n",
      "Epoch 197/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.6373e-04 - val_loss: 6.1571e-06\n",
      "Epoch 198/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.5718e-04 - val_loss: 7.0966e-06\n",
      "Epoch 199/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.5444e-04 - val_loss: 6.1401e-06\n",
      "Epoch 200/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.5462e-04 - val_loss: 6.8514e-06\n",
      "Thời gian huấn luyện:  23.335357189178467\n",
      "Model: \"sequential_125\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_31 (SimpleRNN)   (None, 3, 116)            13688     \n",
      "                                                                 \n",
      " flatten_125 (Flatten)       (None, 348)               0         \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 1)                 349       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,037\n",
      "Trainable params: 14,037\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 2s 12ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 137/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.0029\n",
      "Thời gian huấn luyện:  35.961538314819336\n",
      "Model: \"sequential_126\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_31 (LSTM)              (None, 3, 116)            54752     \n",
      "                                                                 \n",
      " flatten_126 (Flatten)       (None, 348)               0         \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 1)                 349       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,101\n",
      "Trainable params: 55,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 1s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "47/47 [==============================] - 2s 12ms/step - loss: 0.0329 - val_loss: 0.0059\n",
      "Epoch 2/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 4.0299e-04\n",
      "Epoch 3/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.5631e-04 - val_loss: 3.8748e-05\n",
      "Epoch 4/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.0490e-04 - val_loss: 1.9978e-05\n",
      "Epoch 5/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.0487e-04 - val_loss: 2.6009e-05\n",
      "Epoch 6/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.0759e-04 - val_loss: 2.9124e-05\n",
      "Epoch 7/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.0155e-04 - val_loss: 1.7912e-05\n",
      "Epoch 8/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 4ms/step - loss: 3.0359e-04 - val_loss: 1.8026e-05\n",
      "Epoch 9/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.0076e-04 - val_loss: 2.0277e-05\n",
      "Epoch 10/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.0043e-04 - val_loss: 1.8838e-05\n",
      "Epoch 11/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.9685e-04 - val_loss: 2.8137e-05\n",
      "Epoch 12/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.9691e-04 - val_loss: 3.4731e-05\n",
      "Epoch 13/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.9712e-04 - val_loss: 2.3701e-05\n",
      "Epoch 14/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.9420e-04 - val_loss: 2.1831e-05\n",
      "Epoch 15/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.9422e-04 - val_loss: 2.7158e-05\n",
      "Epoch 16/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.9382e-04 - val_loss: 1.6554e-05\n",
      "Epoch 17/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.9090e-04 - val_loss: 2.2509e-05\n",
      "Epoch 18/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.9047e-04 - val_loss: 1.4081e-05\n",
      "Epoch 19/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.9270e-04 - val_loss: 2.0164e-05\n",
      "Epoch 20/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.8927e-04 - val_loss: 2.4559e-05\n",
      "Epoch 21/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.9122e-04 - val_loss: 1.7877e-05\n",
      "Epoch 22/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.9055e-04 - val_loss: 1.0719e-05\n",
      "Epoch 23/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.9007e-04 - val_loss: 3.4940e-05\n",
      "Epoch 24/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.8740e-04 - val_loss: 2.3065e-05\n",
      "Epoch 25/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.8733e-04 - val_loss: 9.6690e-06\n",
      "Epoch 26/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.8945e-04 - val_loss: 1.2644e-05\n",
      "Epoch 27/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.8521e-04 - val_loss: 1.1607e-05\n",
      "Epoch 28/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.8197e-04 - val_loss: 3.4781e-05\n",
      "Epoch 29/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.8363e-04 - val_loss: 1.4811e-05\n",
      "Epoch 30/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.8116e-04 - val_loss: 1.3180e-05\n",
      "Epoch 31/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.8223e-04 - val_loss: 1.1448e-05\n",
      "Epoch 32/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.8393e-04 - val_loss: 1.0341e-05\n",
      "Epoch 33/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.8137e-04 - val_loss: 1.2133e-05\n",
      "Epoch 34/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7929e-04 - val_loss: 1.2181e-05\n",
      "Epoch 35/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7890e-04 - val_loss: 1.0490e-05\n",
      "Epoch 36/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7838e-04 - val_loss: 1.0000e-05\n",
      "Epoch 37/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7971e-04 - val_loss: 1.0375e-05\n",
      "Epoch 38/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7905e-04 - val_loss: 1.9992e-05\n",
      "Epoch 39/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.8429e-04 - val_loss: 1.4585e-05\n",
      "Epoch 40/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7724e-04 - val_loss: 9.9801e-06\n",
      "Epoch 41/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7591e-04 - val_loss: 9.8201e-06\n",
      "Epoch 42/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7604e-04 - val_loss: 1.2447e-05\n",
      "Epoch 43/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7873e-04 - val_loss: 9.7995e-06\n",
      "Epoch 44/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7592e-04 - val_loss: 9.5694e-06\n",
      "Epoch 45/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7665e-04 - val_loss: 9.2275e-06\n",
      "Epoch 46/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7723e-04 - val_loss: 9.5184e-06\n",
      "Epoch 47/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.7640e-04 - val_loss: 1.4670e-05\n",
      "Epoch 48/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.7024e-04 - val_loss: 1.1987e-05\n",
      "Epoch 49/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7539e-04 - val_loss: 1.1431e-05\n",
      "Epoch 50/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.7440e-04 - val_loss: 9.1154e-06\n",
      "Epoch 51/200\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 2.7588e-04 - val_loss: 9.6384e-06\n",
      "Epoch 52/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.7667e-04 - val_loss: 1.3156e-05\n",
      "Epoch 53/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7429e-04 - val_loss: 1.1273e-05\n",
      "Epoch 54/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7311e-04 - val_loss: 1.0284e-05\n",
      "Epoch 55/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.6880e-04 - val_loss: 1.2788e-05\n",
      "Epoch 56/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7282e-04 - val_loss: 9.1027e-06\n",
      "Epoch 57/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7136e-04 - val_loss: 9.2368e-06\n",
      "Epoch 58/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.6919e-04 - val_loss: 1.3148e-05\n",
      "Epoch 59/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7156e-04 - val_loss: 9.1289e-06\n",
      "Epoch 60/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7110e-04 - val_loss: 9.5109e-06\n",
      "Epoch 61/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7134e-04 - val_loss: 1.2090e-05\n",
      "Epoch 62/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.6827e-04 - val_loss: 1.0409e-05\n",
      "Epoch 63/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.6925e-04 - val_loss: 1.0859e-05\n",
      "Epoch 64/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.6615e-04 - val_loss: 9.3542e-06\n",
      "Epoch 65/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.6573e-04 - val_loss: 1.1844e-05\n",
      "Epoch 66/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.6583e-04 - val_loss: 1.3203e-05\n",
      "Epoch 67/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7882e-04 - val_loss: 9.2912e-06\n",
      "Epoch 68/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.6315e-04 - val_loss: 1.0205e-05\n",
      "Epoch 69/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.6577e-04 - val_loss: 1.1681e-05\n",
      "Epoch 70/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.6720e-04 - val_loss: 1.2828e-05\n",
      "Epoch 71/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.6761e-04 - val_loss: 9.1159e-06\n",
      "Epoch 72/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.6215e-04 - val_loss: 1.0011e-05\n",
      "Epoch 73/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.6261e-04 - val_loss: 1.1680e-05\n",
      "Epoch 74/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.6996e-04 - val_loss: 1.1297e-05\n",
      "Epoch 75/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7223e-04 - val_loss: 1.3972e-05\n",
      "Epoch 76/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.6758e-04 - val_loss: 9.0742e-06\n",
      "Epoch 77/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.5814e-04 - val_loss: 1.1024e-05\n",
      "Epoch 78/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.6792e-04 - val_loss: 9.0268e-06\n",
      "Epoch 79/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.6701e-04 - val_loss: 1.0110e-05\n",
      "Epoch 80/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.6099e-04 - val_loss: 9.0575e-06\n",
      "Epoch 81/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.6084e-04 - val_loss: 1.2059e-05\n",
      "Epoch 82/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.5968e-04 - val_loss: 9.1124e-06\n",
      "Epoch 83/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.6129e-04 - val_loss: 1.7960e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.6180e-04 - val_loss: 1.1460e-05\n",
      "Epoch 85/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.5886e-04 - val_loss: 8.7634e-06\n",
      "Epoch 86/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.5660e-04 - val_loss: 8.7792e-06\n",
      "Epoch 87/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.5853e-04 - val_loss: 8.8297e-06\n",
      "Epoch 88/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.6350e-04 - val_loss: 1.1624e-05\n",
      "Epoch 89/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.5525e-04 - val_loss: 8.6768e-06\n",
      "Epoch 90/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.5433e-04 - val_loss: 8.9345e-06\n",
      "Epoch 91/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.6066e-04 - val_loss: 8.6674e-06\n",
      "Epoch 92/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.5857e-04 - val_loss: 2.3442e-05\n",
      "Epoch 93/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.6343e-04 - val_loss: 1.3993e-05\n",
      "Epoch 94/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.5948e-04 - val_loss: 9.0415e-06\n",
      "Epoch 95/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.5655e-04 - val_loss: 1.5069e-05\n",
      "Epoch 96/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.5403e-04 - val_loss: 9.2276e-06\n",
      "Epoch 97/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.5693e-04 - val_loss: 8.5957e-06\n",
      "Epoch 98/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.5006e-04 - val_loss: 9.2149e-06\n",
      "Epoch 99/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.5619e-04 - val_loss: 8.5626e-06\n",
      "Epoch 100/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4854e-04 - val_loss: 8.6115e-06\n",
      "Epoch 101/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.4935e-04 - val_loss: 8.5132e-06\n",
      "Epoch 102/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4996e-04 - val_loss: 1.0584e-05\n",
      "Epoch 103/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4991e-04 - val_loss: 8.8849e-06\n",
      "Epoch 104/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.4763e-04 - val_loss: 8.4561e-06\n",
      "Epoch 105/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4611e-04 - val_loss: 9.0714e-06\n",
      "Epoch 106/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.5149e-04 - val_loss: 2.2906e-05\n",
      "Epoch 107/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.5104e-04 - val_loss: 8.9667e-06\n",
      "Epoch 108/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4911e-04 - val_loss: 9.2625e-06\n",
      "Epoch 109/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4966e-04 - val_loss: 1.1592e-05\n",
      "Epoch 110/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4957e-04 - val_loss: 1.2702e-05\n",
      "Epoch 111/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4479e-04 - val_loss: 1.1493e-05\n",
      "Epoch 112/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4278e-04 - val_loss: 9.1351e-06\n",
      "Epoch 113/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4895e-04 - val_loss: 2.2246e-05\n",
      "Epoch 114/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.4411e-04 - val_loss: 1.1613e-05\n",
      "Epoch 115/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4677e-04 - val_loss: 8.2961e-06\n",
      "Epoch 116/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4189e-04 - val_loss: 9.3736e-06\n",
      "Epoch 117/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.5781e-04 - val_loss: 1.1151e-05\n",
      "Epoch 118/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4065e-04 - val_loss: 8.3045e-06\n",
      "Epoch 119/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4013e-04 - val_loss: 1.6113e-05\n",
      "Epoch 120/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.4057e-04 - val_loss: 1.6873e-05\n",
      "Epoch 121/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.5603e-04 - val_loss: 1.5641e-05\n",
      "Epoch 122/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4498e-04 - val_loss: 8.5551e-06\n",
      "Epoch 123/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4322e-04 - val_loss: 1.0278e-05\n",
      "Epoch 124/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.3537e-04 - val_loss: 1.1864e-05\n",
      "Epoch 125/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4241e-04 - val_loss: 9.0280e-06\n",
      "Epoch 126/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.3583e-04 - val_loss: 1.2906e-05\n",
      "Epoch 127/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.4284e-04 - val_loss: 1.0192e-05\n",
      "Epoch 128/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4055e-04 - val_loss: 9.4581e-06\n",
      "Epoch 129/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4526e-04 - val_loss: 1.7066e-05\n",
      "Epoch 130/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.3541e-04 - val_loss: 1.3691e-05\n",
      "Epoch 131/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.3895e-04 - val_loss: 8.2810e-06\n",
      "Epoch 132/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.3489e-04 - val_loss: 8.1285e-06\n",
      "Epoch 133/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.3093e-04 - val_loss: 2.0332e-05\n",
      "Epoch 134/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.3506e-04 - val_loss: 7.9763e-06\n",
      "Epoch 135/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.2998e-04 - val_loss: 8.7317e-06\n",
      "Epoch 136/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.3411e-04 - val_loss: 8.5187e-06\n",
      "Epoch 137/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.3530e-04 - val_loss: 1.8044e-05\n",
      "Epoch 138/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.2971e-04 - val_loss: 1.8116e-05\n",
      "Epoch 139/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.2947e-04 - val_loss: 3.6302e-05\n",
      "Epoch 140/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.4258e-04 - val_loss: 7.9014e-06\n",
      "Epoch 141/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.2891e-04 - val_loss: 9.5876e-06\n",
      "Epoch 142/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.3194e-04 - val_loss: 1.0008e-05\n",
      "Epoch 143/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.3058e-04 - val_loss: 8.4058e-06\n",
      "Epoch 144/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.2526e-04 - val_loss: 8.7112e-06\n",
      "Epoch 145/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.2863e-04 - val_loss: 8.0179e-06\n",
      "Epoch 146/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.2862e-04 - val_loss: 9.7667e-06\n",
      "Epoch 147/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.3525e-04 - val_loss: 8.0906e-06\n",
      "Epoch 148/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.2353e-04 - val_loss: 1.2826e-05\n",
      "Epoch 149/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.2770e-04 - val_loss: 9.2056e-06\n",
      "Epoch 150/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.3100e-04 - val_loss: 1.1654e-05\n",
      "Epoch 151/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.2245e-04 - val_loss: 9.2481e-06\n",
      "Epoch 152/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.2329e-04 - val_loss: 8.2256e-06\n",
      "Epoch 153/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.2248e-04 - val_loss: 1.1477e-05\n",
      "Epoch 154/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.2874e-04 - val_loss: 1.1589e-05\n",
      "Epoch 155/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.1971e-04 - val_loss: 9.1682e-06\n",
      "Epoch 156/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.1905e-04 - val_loss: 1.6456e-05\n",
      "Epoch 157/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.3029e-04 - val_loss: 1.6113e-05\n",
      "Epoch 158/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.2183e-04 - val_loss: 7.9425e-06\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 5ms/step - loss: 2.1674e-04 - val_loss: 7.6305e-06\n",
      "Epoch 160/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.1660e-04 - val_loss: 9.9041e-06\n",
      "Epoch 161/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.1717e-04 - val_loss: 8.5024e-06\n",
      "Epoch 162/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.1239e-04 - val_loss: 8.8757e-06\n",
      "Epoch 163/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.1730e-04 - val_loss: 9.7234e-06\n",
      "Epoch 164/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.2026e-04 - val_loss: 8.6465e-06\n",
      "Epoch 165/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.2000e-04 - val_loss: 1.0330e-05\n",
      "Epoch 166/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.1601e-04 - val_loss: 8.3733e-06\n",
      "Epoch 167/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.2534e-04 - val_loss: 8.2922e-06\n",
      "Epoch 168/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.1239e-04 - val_loss: 9.0169e-06\n",
      "Epoch 169/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.1372e-04 - val_loss: 8.2235e-06\n",
      "Epoch 170/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.1233e-04 - val_loss: 8.8270e-06\n",
      "Epoch 171/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.1141e-04 - val_loss: 7.3174e-06\n",
      "Epoch 172/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0776e-04 - val_loss: 8.0280e-06\n",
      "Epoch 173/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.1275e-04 - val_loss: 7.3874e-06\n",
      "Epoch 174/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.0985e-04 - val_loss: 1.4702e-05\n",
      "Epoch 175/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.1770e-04 - val_loss: 1.5820e-05\n",
      "Epoch 176/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0793e-04 - val_loss: 8.9191e-06\n",
      "Epoch 177/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0929e-04 - val_loss: 7.5955e-06\n",
      "Epoch 178/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0901e-04 - val_loss: 7.9608e-06\n",
      "Epoch 179/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0584e-04 - val_loss: 9.2070e-06\n",
      "Epoch 180/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.0755e-04 - val_loss: 8.9179e-06\n",
      "Epoch 181/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0424e-04 - val_loss: 1.1047e-05\n",
      "Epoch 182/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.1079e-04 - val_loss: 2.3583e-05\n",
      "Epoch 183/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0303e-04 - val_loss: 7.0522e-06\n",
      "Epoch 184/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0420e-04 - val_loss: 8.1169e-06\n",
      "Epoch 185/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.0538e-04 - val_loss: 8.4052e-06\n",
      "Epoch 186/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0506e-04 - val_loss: 2.7436e-05\n",
      "Epoch 187/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0455e-04 - val_loss: 8.9481e-06\n",
      "Epoch 188/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0812e-04 - val_loss: 8.1705e-06\n",
      "Epoch 189/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0060e-04 - val_loss: 7.4638e-06\n",
      "Epoch 190/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.0054e-04 - val_loss: 1.0220e-05\n",
      "Epoch 191/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.0586e-04 - val_loss: 6.9622e-06\n",
      "Epoch 192/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.2308e-04 - val_loss: 1.4535e-05\n",
      "Epoch 193/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.9862e-04 - val_loss: 1.1142e-05\n",
      "Epoch 194/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.9890e-04 - val_loss: 7.2112e-06\n",
      "Epoch 195/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.0005e-04 - val_loss: 7.8541e-06\n",
      "Epoch 196/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.9943e-04 - val_loss: 6.9736e-06\n",
      "Epoch 197/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.9819e-04 - val_loss: 8.3438e-06\n",
      "Epoch 198/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.9738e-04 - val_loss: 1.0285e-05\n",
      "Epoch 199/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.9691e-04 - val_loss: 7.7084e-06\n",
      "Epoch 200/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.9405e-04 - val_loss: 8.4296e-06\n",
      "Thời gian huấn luyện:  47.94492816925049\n",
      "Model: \"sequential_127\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_30 (GRU)                (None, 3, 116)            41412     \n",
      "                                                                 \n",
      " flatten_127 (Flatten)       (None, 348)               0         \n",
      "                                                                 \n",
      " dense_160 (Dense)           (None, 1)                 349       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,761\n",
      "Trainable params: 41,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1375 - val_loss: 0.0104\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.0444\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0307\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0227\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0163\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0111\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0074\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 7.3099e-04 - val_loss: 0.0011\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5483e-04 - val_loss: 7.1616e-04\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.6299e-04 - val_loss: 5.2313e-04\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.1790e-04 - val_loss: 3.4111e-04\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.9489e-04 - val_loss: 2.6849e-04\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.8325e-04 - val_loss: 2.1065e-04\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.7655e-04 - val_loss: 1.6643e-04\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.7280e-04 - val_loss: 1.3743e-04\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.6724e-04 - val_loss: 1.1618e-04\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.6490e-04 - val_loss: 9.3694e-05\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.6348e-04 - val_loss: 8.2280e-05\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.6228e-04 - val_loss: 8.0983e-05\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5984e-04 - val_loss: 6.7805e-05\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5798e-04 - val_loss: 6.5837e-05\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5702e-04 - val_loss: 5.8257e-05\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5572e-04 - val_loss: 5.1302e-05\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5484e-04 - val_loss: 5.3098e-05\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5570e-04 - val_loss: 4.9230e-05\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5286e-04 - val_loss: 4.2232e-05\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5465e-04 - val_loss: 4.0241e-05\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5211e-04 - val_loss: 4.3148e-05\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5951e-04 - val_loss: 4.2371e-05\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5036e-04 - val_loss: 3.7034e-05\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4982e-04 - val_loss: 3.8110e-05\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4952e-04 - val_loss: 3.4527e-05\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4809e-04 - val_loss: 3.3345e-05\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4814e-04 - val_loss: 3.2608e-05\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5219e-04 - val_loss: 3.1671e-05\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4733e-04 - val_loss: 3.1250e-05\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4721e-04 - val_loss: 3.0295e-05\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4786e-04 - val_loss: 2.9721e-05\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4713e-04 - val_loss: 2.8856e-05\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4527e-04 - val_loss: 3.1163e-05\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4583e-04 - val_loss: 2.7496e-05\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4380e-04 - val_loss: 2.7146e-05\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4357e-04 - val_loss: 2.6890e-05\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4321e-04 - val_loss: 2.6787e-05\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4294e-04 - val_loss: 2.7221e-05\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4322e-04 - val_loss: 2.8010e-05\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4339e-04 - val_loss: 2.5485e-05\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4237e-04 - val_loss: 2.4243e-05\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4079e-04 - val_loss: 2.5523e-05\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4154e-04 - val_loss: 2.3302e-05\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4006e-04 - val_loss: 2.4553e-05\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4444e-04 - val_loss: 2.4773e-05\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4162e-04 - val_loss: 2.4978e-05\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4141e-04 - val_loss: 2.2192e-05\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3904e-04 - val_loss: 2.2728e-05\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3736e-04 - val_loss: 2.4082e-05\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3732e-04 - val_loss: 2.1499e-05\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3798e-04 - val_loss: 2.2390e-05\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3744e-04 - val_loss: 2.0746e-05\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3588e-04 - val_loss: 2.3602e-05\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3493e-04 - val_loss: 2.0437e-05\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3511e-04 - val_loss: 2.4586e-05\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3528e-04 - val_loss: 2.2196e-05\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3466e-04 - val_loss: 2.1338e-05\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3973e-04 - val_loss: 2.2305e-05\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3290e-04 - val_loss: 2.4624e-05\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3521e-04 - val_loss: 2.7432e-05\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3867e-04 - val_loss: 1.9127e-05\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3165e-04 - val_loss: 2.2272e-05\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3142e-04 - val_loss: 2.7336e-05\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3248e-04 - val_loss: 2.0977e-05\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3041e-04 - val_loss: 1.8144e-05\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2965e-04 - val_loss: 1.9933e-05\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3167e-04 - val_loss: 1.7788e-05\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2938e-04 - val_loss: 1.7521e-05\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2961e-04 - val_loss: 2.5499e-05\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.2975e-04 - val_loss: 1.9771e-05\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3499e-04 - val_loss: 1.8577e-05\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2836e-04 - val_loss: 1.7567e-05\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2827e-04 - val_loss: 2.2772e-05\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3011e-04 - val_loss: 1.9318e-05\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2548e-04 - val_loss: 2.0957e-05\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2622e-04 - val_loss: 1.6878e-05\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2770e-04 - val_loss: 1.6368e-05\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2498e-04 - val_loss: 1.6880e-05\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2459e-04 - val_loss: 1.6749e-05\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2259e-04 - val_loss: 1.7284e-05\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.2300e-04 - val_loss: 1.6492e-05\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.2446e-04 - val_loss: 1.6741e-05\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.2205e-04 - val_loss: 2.0852e-05\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2244e-04 - val_loss: 1.7741e-05\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1974e-04 - val_loss: 1.9433e-05\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1979e-04 - val_loss: 1.8488e-05\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2062e-04 - val_loss: 1.6565e-05\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2258e-04 - val_loss: 1.5530e-05\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2471e-04 - val_loss: 1.6663e-05\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.2255e-04 - val_loss: 2.5162e-05\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3.1799e-04 - val_loss: 1.5122e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.1483e-04 - val_loss: 1.9972e-05\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.1513e-04 - val_loss: 1.9123e-05\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.1901e-04 - val_loss: 1.5904e-05\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.2024e-04 - val_loss: 2.3580e-05\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1790e-04 - val_loss: 1.4877e-05\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1436e-04 - val_loss: 2.2519e-05\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1213e-04 - val_loss: 2.0409e-05\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1200e-04 - val_loss: 1.7396e-05\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1254e-04 - val_loss: 1.5358e-05\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.1207e-04 - val_loss: 1.4680e-05\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.1195e-04 - val_loss: 2.1284e-05\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1125e-04 - val_loss: 1.6943e-05\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1334e-04 - val_loss: 2.5314e-05\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1544e-04 - val_loss: 2.0534e-05\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0809e-04 - val_loss: 2.9004e-05\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0952e-04 - val_loss: 1.4910e-05\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0809e-04 - val_loss: 1.6137e-05\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.0509e-04 - val_loss: 1.5672e-05\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.0726e-04 - val_loss: 1.4097e-05\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0529e-04 - val_loss: 1.3914e-05\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.0531e-04 - val_loss: 1.4123e-05\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.0740e-04 - val_loss: 1.4469e-05\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.0378e-04 - val_loss: 1.5088e-05\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.0308e-04 - val_loss: 1.8970e-05\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0302e-04 - val_loss: 1.3526e-05\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0200e-04 - val_loss: 1.7603e-05\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0508e-04 - val_loss: 1.3802e-05\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0147e-04 - val_loss: 1.5593e-05\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9873e-04 - val_loss: 2.0266e-05\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0039e-04 - val_loss: 1.6377e-05\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9880e-04 - val_loss: 1.5834e-05\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0072e-04 - val_loss: 1.9805e-05\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9874e-04 - val_loss: 1.4765e-05\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9689e-04 - val_loss: 1.4525e-05\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9534e-04 - val_loss: 1.3572e-05\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.9513e-04 - val_loss: 2.3087e-05\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9532e-04 - val_loss: 1.6270e-05\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9647e-04 - val_loss: 1.3632e-05\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9213e-04 - val_loss: 2.2884e-05\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9336e-04 - val_loss: 1.2756e-05\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9374e-04 - val_loss: 1.2990e-05\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.9127e-04 - val_loss: 1.2956e-05\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9513e-04 - val_loss: 1.2642e-05\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.9095e-04 - val_loss: 1.6213e-05\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8978e-04 - val_loss: 1.2583e-05\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.8780e-04 - val_loss: 1.2688e-05\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.8960e-04 - val_loss: 1.2658e-05\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8764e-04 - val_loss: 1.4171e-05\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.9053e-04 - val_loss: 1.2381e-05\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8642e-04 - val_loss: 1.3482e-05\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8580e-04 - val_loss: 1.2752e-05\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8779e-04 - val_loss: 2.0175e-05\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.8643e-04 - val_loss: 1.4512e-05\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.8592e-04 - val_loss: 1.2461e-05\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.8394e-04 - val_loss: 1.5120e-05\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.8378e-04 - val_loss: 1.8284e-05\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8359e-04 - val_loss: 1.4370e-05\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.8375e-04 - val_loss: 1.2687e-05\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8125e-04 - val_loss: 1.2548e-05\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8131e-04 - val_loss: 1.4906e-05\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8199e-04 - val_loss: 1.2068e-05\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7874e-04 - val_loss: 1.5176e-05\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8045e-04 - val_loss: 1.1904e-05\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7962e-04 - val_loss: 1.7575e-05\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7952e-04 - val_loss: 1.1925e-05\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8126e-04 - val_loss: 2.4356e-05\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8065e-04 - val_loss: 1.4796e-05\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7614e-04 - val_loss: 2.5631e-05\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7668e-04 - val_loss: 1.1777e-05\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7508e-04 - val_loss: 1.9043e-05\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7619e-04 - val_loss: 2.0226e-05\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7678e-04 - val_loss: 1.3373e-05\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7557e-04 - val_loss: 1.2308e-05\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7390e-04 - val_loss: 1.8049e-05\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7299e-04 - val_loss: 1.9969e-05\n",
      "Epoch 177/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7796e-04 - val_loss: 1.1744e-05\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7083e-04 - val_loss: 1.2292e-05\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.7456e-04 - val_loss: 1.1405e-05\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7072e-04 - val_loss: 1.3176e-05\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6879e-04 - val_loss: 1.1961e-05\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.6806e-04 - val_loss: 1.2592e-05\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6727e-04 - val_loss: 2.0174e-05\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6980e-04 - val_loss: 2.2198e-05\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7052e-04 - val_loss: 1.1437e-05\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6647e-04 - val_loss: 1.3298e-05\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7050e-04 - val_loss: 1.4707e-05\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6697e-04 - val_loss: 1.4510e-05\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6485e-04 - val_loss: 1.1888e-05\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6546e-04 - val_loss: 1.2590e-05\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6376e-04 - val_loss: 2.0490e-05\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6479e-04 - val_loss: 1.1224e-05\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6358e-04 - val_loss: 2.0705e-05\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6201e-04 - val_loss: 1.1162e-05\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6552e-04 - val_loss: 1.3059e-05\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5932e-04 - val_loss: 1.8735e-05\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6119e-04 - val_loss: 1.1265e-05\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5987e-04 - val_loss: 1.7981e-05\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5976e-04 - val_loss: 1.0880e-05\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5811e-04 - val_loss: 1.1730e-05\n",
      "Thời gian huấn luyện:  18.383041858673096\n",
      "Model: \"sequential_128\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_161 (Dense)           (None, 5, 116)            232       \n",
      "                                                                 \n",
      " flatten_128 (Flatten)       (None, 580)               0         \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 1)                 581       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 813\n",
      "Trainable params: 813\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 882us/step\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "44/44 [==============================] - 1s 6ms/step - loss: 0.0226 - val_loss: 2.8316e-05\n",
      "Epoch 2/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.1057e-04 - val_loss: 8.6402e-05\n",
      "Epoch 3/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 6.0779e-04 - val_loss: 9.7423e-05\n",
      "Epoch 4/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 6.0487e-04 - val_loss: 1.3973e-04\n",
      "Epoch 5/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 5.8424e-04 - val_loss: 9.1657e-05\n",
      "Epoch 6/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 5.6524e-04 - val_loss: 1.2142e-04\n",
      "Epoch 7/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 5.5981e-04 - val_loss: 7.8994e-05\n",
      "Epoch 8/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 5.7137e-04 - val_loss: 9.1656e-05\n",
      "Epoch 9/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 5.4952e-04 - val_loss: 1.1086e-04\n",
      "Epoch 10/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 5.3863e-04 - val_loss: 7.4686e-05\n",
      "Epoch 11/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 5.2835e-04 - val_loss: 8.3418e-05\n",
      "Epoch 12/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 5.2422e-04 - val_loss: 8.1443e-05\n",
      "Epoch 13/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 5.2082e-04 - val_loss: 8.7278e-05\n",
      "Epoch 14/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 5.0608e-04 - val_loss: 7.6552e-05\n",
      "Epoch 15/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 4.9641e-04 - val_loss: 8.5379e-05\n",
      "Epoch 16/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 4.8383e-04 - val_loss: 8.9313e-05\n",
      "Epoch 17/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 4.8258e-04 - val_loss: 6.6629e-05\n",
      "Epoch 18/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 4.7978e-04 - val_loss: 7.5055e-05\n",
      "Epoch 19/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 4.7279e-04 - val_loss: 8.8420e-05\n",
      "Epoch 20/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 4.7057e-04 - val_loss: 6.4747e-05\n",
      "Epoch 21/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 4.5242e-04 - val_loss: 7.5991e-05\n",
      "Epoch 22/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.4515e-04 - val_loss: 5.2054e-05\n",
      "Epoch 23/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.5062e-04 - val_loss: 4.9196e-05\n",
      "Epoch 24/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.4610e-04 - val_loss: 5.7493e-05\n",
      "Epoch 25/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.2189e-04 - val_loss: 5.3897e-05\n",
      "Epoch 26/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1356e-04 - val_loss: 4.4771e-05\n",
      "Epoch 27/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.0629e-04 - val_loss: 7.3393e-05\n",
      "Epoch 28/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 4.0480e-04 - val_loss: 5.2317e-05\n",
      "Epoch 29/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.9550e-04 - val_loss: 4.8831e-05\n",
      "Epoch 30/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.9496e-04 - val_loss: 3.5938e-05\n",
      "Epoch 31/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.9125e-04 - val_loss: 4.1248e-05\n",
      "Epoch 32/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 4.0012e-04 - val_loss: 7.0958e-05\n",
      "Epoch 33/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.9207e-04 - val_loss: 3.0882e-05\n",
      "Epoch 34/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.8317e-04 - val_loss: 4.4837e-05\n",
      "Epoch 35/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.8619e-04 - val_loss: 2.9597e-05\n",
      "Epoch 36/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.7021e-04 - val_loss: 6.0493e-05\n",
      "Epoch 37/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.6168e-04 - val_loss: 2.6846e-05\n",
      "Epoch 38/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.5218e-04 - val_loss: 3.0979e-05\n",
      "Epoch 39/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.5738e-04 - val_loss: 4.0152e-05\n",
      "Epoch 40/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.4848e-04 - val_loss: 4.4496e-05\n",
      "Epoch 41/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.6107e-04 - val_loss: 2.9747e-05\n",
      "Epoch 42/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.3441e-04 - val_loss: 3.7639e-05\n",
      "Epoch 43/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.2708e-04 - val_loss: 3.5264e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.2520e-04 - val_loss: 3.3434e-05\n",
      "Epoch 45/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.2324e-04 - val_loss: 3.0535e-05\n",
      "Epoch 46/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.2122e-04 - val_loss: 2.1546e-05\n",
      "Epoch 47/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.4975e-04 - val_loss: 2.1012e-05\n",
      "Epoch 48/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.2976e-04 - val_loss: 2.8846e-05\n",
      "Epoch 49/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.1361e-04 - val_loss: 2.3536e-05\n",
      "Epoch 50/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.0204e-04 - val_loss: 2.1217e-05\n",
      "Epoch 51/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.3030e-04 - val_loss: 2.0695e-05\n",
      "Epoch 52/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.1548e-04 - val_loss: 2.0651e-05\n",
      "Epoch 53/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.0838e-04 - val_loss: 1.7762e-05\n",
      "Epoch 54/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.1198e-04 - val_loss: 1.5100e-05\n",
      "Epoch 55/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.0314e-04 - val_loss: 3.7328e-05\n",
      "Epoch 56/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 3.1513e-04 - val_loss: 2.4086e-05\n",
      "Epoch 57/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.9971e-04 - val_loss: 3.8404e-05\n",
      "Epoch 58/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.9855e-04 - val_loss: 1.3363e-05\n",
      "Epoch 59/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.8700e-04 - val_loss: 1.3944e-05\n",
      "Epoch 60/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.9062e-04 - val_loss: 2.0943e-05\n",
      "Epoch 61/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.7782e-04 - val_loss: 1.6120e-05\n",
      "Epoch 62/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.8279e-04 - val_loss: 2.4721e-05\n",
      "Epoch 63/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.7955e-04 - val_loss: 1.7908e-05\n",
      "Epoch 64/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.7616e-04 - val_loss: 1.4344e-05\n",
      "Epoch 65/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.7494e-04 - val_loss: 1.2320e-05\n",
      "Epoch 66/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.7088e-04 - val_loss: 1.3090e-05\n",
      "Epoch 67/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.8608e-04 - val_loss: 1.1871e-05\n",
      "Epoch 68/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.6561e-04 - val_loss: 1.1034e-05\n",
      "Epoch 69/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.6647e-04 - val_loss: 1.4533e-05\n",
      "Epoch 70/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.9029e-04 - val_loss: 1.3163e-05\n",
      "Epoch 71/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.5814e-04 - val_loss: 1.4100e-05\n",
      "Epoch 72/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.6987e-04 - val_loss: 1.2708e-05\n",
      "Epoch 73/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.4805e-04 - val_loss: 1.1762e-05\n",
      "Epoch 74/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.5782e-04 - val_loss: 1.6697e-05\n",
      "Epoch 75/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.8420e-04 - val_loss: 1.1875e-05\n",
      "Epoch 76/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.6999e-04 - val_loss: 1.5075e-05\n",
      "Epoch 77/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.6167e-04 - val_loss: 1.3733e-05\n",
      "Epoch 78/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.6159e-04 - val_loss: 1.6236e-05\n",
      "Epoch 79/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.5031e-04 - val_loss: 1.3702e-05\n",
      "Epoch 80/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.4349e-04 - val_loss: 1.0421e-05\n",
      "Epoch 81/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.3779e-04 - val_loss: 1.3597e-05\n",
      "Epoch 82/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.4358e-04 - val_loss: 1.4514e-05\n",
      "Epoch 83/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.4815e-04 - val_loss: 1.7505e-05\n",
      "Epoch 84/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.4680e-04 - val_loss: 1.0662e-05\n",
      "Epoch 85/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.5127e-04 - val_loss: 1.1616e-05\n",
      "Epoch 86/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.6266e-04 - val_loss: 9.2191e-06\n",
      "Epoch 87/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.5844e-04 - val_loss: 1.4236e-05\n",
      "Epoch 88/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.4144e-04 - val_loss: 1.0978e-05\n",
      "Epoch 89/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.4807e-04 - val_loss: 1.4549e-05\n",
      "Epoch 90/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.2781e-04 - val_loss: 9.0429e-06\n",
      "Epoch 91/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.2892e-04 - val_loss: 1.1346e-05\n",
      "Epoch 92/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.4663e-04 - val_loss: 1.0728e-05\n",
      "Epoch 93/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.4898e-04 - val_loss: 8.8104e-06\n",
      "Epoch 94/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.2422e-04 - val_loss: 9.3021e-06\n",
      "Epoch 95/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.3076e-04 - val_loss: 8.9103e-06\n",
      "Epoch 96/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.3369e-04 - val_loss: 1.0274e-05\n",
      "Epoch 97/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.3018e-04 - val_loss: 1.0623e-05\n",
      "Epoch 98/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.1852e-04 - val_loss: 1.0808e-05\n",
      "Epoch 99/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.3118e-04 - val_loss: 8.5151e-06\n",
      "Epoch 100/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.4943e-04 - val_loss: 8.4419e-06\n",
      "Epoch 101/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.3250e-04 - val_loss: 1.0916e-05\n",
      "Epoch 102/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.2894e-04 - val_loss: 1.1016e-05\n",
      "Epoch 103/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.3218e-04 - val_loss: 9.7528e-06\n",
      "Epoch 104/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.5012e-04 - val_loss: 1.0915e-05\n",
      "Epoch 105/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.1421e-04 - val_loss: 8.0656e-06\n",
      "Epoch 106/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.3436e-04 - val_loss: 8.3030e-06\n",
      "Epoch 107/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.1556e-04 - val_loss: 8.2619e-06\n",
      "Epoch 108/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.4299e-04 - val_loss: 1.1310e-05\n",
      "Epoch 109/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.1951e-04 - val_loss: 1.4937e-05\n",
      "Epoch 110/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.4387e-04 - val_loss: 8.6118e-06\n",
      "Epoch 111/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.1818e-04 - val_loss: 8.1269e-06\n",
      "Epoch 112/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.1556e-04 - val_loss: 8.9494e-06\n",
      "Epoch 113/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.2551e-04 - val_loss: 1.0931e-05\n",
      "Epoch 114/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0551e-04 - val_loss: 8.3455e-06\n",
      "Epoch 115/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.1097e-04 - val_loss: 8.1507e-06\n",
      "Epoch 116/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0375e-04 - val_loss: 8.7215e-06\n",
      "Epoch 117/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0153e-04 - val_loss: 9.3449e-06\n",
      "Epoch 118/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.1232e-04 - val_loss: 8.4273e-06\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0786e-04 - val_loss: 9.7765e-06\n",
      "Epoch 120/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0190e-04 - val_loss: 7.7647e-06\n",
      "Epoch 121/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0294e-04 - val_loss: 7.9278e-06\n",
      "Epoch 122/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.1804e-04 - val_loss: 7.8860e-06\n",
      "Epoch 123/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.3045e-04 - val_loss: 1.0638e-05\n",
      "Epoch 124/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0492e-04 - val_loss: 8.0030e-06\n",
      "Epoch 125/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.1049e-04 - val_loss: 2.2446e-05\n",
      "Epoch 126/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0661e-04 - val_loss: 7.8368e-06\n",
      "Epoch 127/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0541e-04 - val_loss: 1.2873e-05\n",
      "Epoch 128/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0773e-04 - val_loss: 1.1545e-05\n",
      "Epoch 129/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0240e-04 - val_loss: 1.2584e-05\n",
      "Epoch 130/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.9249e-04 - val_loss: 1.0575e-05\n",
      "Epoch 131/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0033e-04 - val_loss: 7.5629e-06\n",
      "Epoch 132/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0178e-04 - val_loss: 7.8008e-06\n",
      "Epoch 133/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.9943e-04 - val_loss: 9.0193e-06\n",
      "Epoch 134/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0367e-04 - val_loss: 7.5117e-06\n",
      "Epoch 135/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0078e-04 - val_loss: 7.4058e-06\n",
      "Epoch 136/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.9880e-04 - val_loss: 8.5715e-06\n",
      "Epoch 137/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.3502e-04 - val_loss: 1.3352e-05\n",
      "Epoch 138/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.9708e-04 - val_loss: 1.2805e-05\n",
      "Epoch 139/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0437e-04 - val_loss: 9.9420e-06\n",
      "Epoch 140/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.8873e-04 - val_loss: 8.7187e-06\n",
      "Epoch 141/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.9234e-04 - val_loss: 1.0173e-05\n",
      "Epoch 142/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.8358e-04 - val_loss: 7.7977e-06\n",
      "Epoch 143/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0639e-04 - val_loss: 1.0008e-05\n",
      "Epoch 144/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0293e-04 - val_loss: 7.2348e-06\n",
      "Epoch 145/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.8604e-04 - val_loss: 7.4967e-06\n",
      "Epoch 146/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.8866e-04 - val_loss: 7.6742e-06\n",
      "Epoch 147/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.9165e-04 - val_loss: 7.4957e-06\n",
      "Epoch 148/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.8565e-04 - val_loss: 9.2436e-06\n",
      "Epoch 149/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.8977e-04 - val_loss: 7.2115e-06\n",
      "Epoch 150/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.8317e-04 - val_loss: 8.9924e-06\n",
      "Epoch 151/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.9084e-04 - val_loss: 7.2551e-06\n",
      "Epoch 152/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.8575e-04 - val_loss: 7.9516e-06\n",
      "Epoch 153/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.8631e-04 - val_loss: 7.6189e-06\n",
      "Epoch 154/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.9646e-04 - val_loss: 7.1213e-06\n",
      "Epoch 155/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.9839e-04 - val_loss: 7.4047e-06\n",
      "Epoch 156/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0661e-04 - val_loss: 8.2062e-06\n",
      "Epoch 157/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.8497e-04 - val_loss: 7.4533e-06\n",
      "Epoch 158/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.8721e-04 - val_loss: 1.4492e-05\n",
      "Epoch 159/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.9308e-04 - val_loss: 7.3126e-06\n",
      "Epoch 160/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.1635e-04 - val_loss: 1.0103e-05\n",
      "Epoch 161/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8901e-04 - val_loss: 6.8654e-06\n",
      "Epoch 162/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7927e-04 - val_loss: 7.8360e-06\n",
      "Epoch 163/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0337e-04 - val_loss: 7.5038e-06\n",
      "Epoch 164/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.8471e-04 - val_loss: 7.6708e-06\n",
      "Epoch 165/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.8637e-04 - val_loss: 6.9870e-06\n",
      "Epoch 166/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7282e-04 - val_loss: 8.4909e-06\n",
      "Epoch 167/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.7513e-04 - val_loss: 9.3002e-06\n",
      "Epoch 168/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.7216e-04 - val_loss: 6.7717e-06\n",
      "Epoch 169/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7061e-04 - val_loss: 1.1769e-05\n",
      "Epoch 170/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.8594e-04 - val_loss: 7.4194e-06\n",
      "Epoch 171/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.9171e-04 - val_loss: 8.1282e-06\n",
      "Epoch 172/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.8991e-04 - val_loss: 6.5189e-06\n",
      "Epoch 173/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.7440e-04 - val_loss: 7.5423e-06\n",
      "Epoch 174/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7611e-04 - val_loss: 9.4036e-06\n",
      "Epoch 175/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.6793e-04 - val_loss: 9.5506e-06\n",
      "Epoch 176/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.8432e-04 - val_loss: 1.0854e-05\n",
      "Epoch 177/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.9105e-04 - val_loss: 7.3260e-06\n",
      "Epoch 178/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0055e-04 - val_loss: 7.5675e-06\n",
      "Epoch 179/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.8208e-04 - val_loss: 6.6067e-06\n",
      "Epoch 180/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.7767e-04 - val_loss: 6.6248e-06\n",
      "Epoch 181/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.7894e-04 - val_loss: 6.4649e-06\n",
      "Epoch 182/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.7159e-04 - val_loss: 7.6326e-06\n",
      "Epoch 183/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.7106e-04 - val_loss: 7.9748e-06\n",
      "Epoch 184/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.6898e-04 - val_loss: 7.3721e-06\n",
      "Epoch 185/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.7166e-04 - val_loss: 7.6441e-06\n",
      "Epoch 186/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.6982e-04 - val_loss: 8.0045e-06\n",
      "Epoch 187/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6283e-04 - val_loss: 1.0366e-05\n",
      "Epoch 188/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 2.0241e-04 - val_loss: 6.6939e-06\n",
      "Epoch 189/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.6034e-04 - val_loss: 6.4363e-06\n",
      "Epoch 190/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.7429e-04 - val_loss: 7.3452e-06\n",
      "Epoch 191/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.8819e-04 - val_loss: 6.9667e-06\n",
      "Epoch 192/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8223e-04 - val_loss: 1.1866e-05\n",
      "Epoch 193/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.7261e-04 - val_loss: 7.5602e-06\n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 3ms/step - loss: 1.7627e-04 - val_loss: 1.0564e-05\n",
      "Epoch 195/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.6902e-04 - val_loss: 6.1949e-06\n",
      "Epoch 196/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.7508e-04 - val_loss: 6.2056e-06\n",
      "Epoch 197/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.7778e-04 - val_loss: 6.3746e-06\n",
      "Epoch 198/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.7029e-04 - val_loss: 6.4352e-06\n",
      "Epoch 199/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.5856e-04 - val_loss: 8.7861e-06\n",
      "Epoch 200/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.7353e-04 - val_loss: 6.3144e-06\n",
      "Thời gian huấn luyện:  28.29496145248413\n",
      "Model: \"sequential_129\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_32 (SimpleRNN)   (None, 5, 116)            13688     \n",
      "                                                                 \n",
      " flatten_129 (Flatten)       (None, 580)               0         \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 1)                 581       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,269\n",
      "Trainable params: 14,269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 2s 15ms/step - loss: 0.0384 - val_loss: 0.0055\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 7.1065e-04 - val_loss: 5.3326e-04\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.5226e-04 - val_loss: 2.7167e-04\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.3058e-04 - val_loss: 1.5402e-04\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.2999e-04 - val_loss: 1.8586e-04\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.2199e-04 - val_loss: 1.7397e-04\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.2105e-04 - val_loss: 1.4986e-04\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.1929e-04 - val_loss: 1.4473e-04\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.1397e-04 - val_loss: 1.1142e-04\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.0869e-04 - val_loss: 1.3647e-04\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.0187e-04 - val_loss: 9.2392e-05\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.0358e-04 - val_loss: 1.0599e-04\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.9817e-04 - val_loss: 8.6485e-05\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.9595e-04 - val_loss: 7.2132e-05\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.0064e-04 - val_loss: 5.2689e-05\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.9191e-04 - val_loss: 1.0993e-04\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.9824e-04 - val_loss: 8.7397e-05\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 4.8700e-04 - val_loss: 6.1505e-05\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.8472e-04 - val_loss: 7.3322e-05\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.8152e-04 - val_loss: 7.0874e-05\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 4.7762e-04 - val_loss: 6.2147e-05\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.7779e-04 - val_loss: 5.2894e-05\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 4.7898e-04 - val_loss: 3.2086e-05\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.7359e-04 - val_loss: 7.8612e-05\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 4.7632e-04 - val_loss: 6.5101e-05\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 4.8361e-04 - val_loss: 2.8123e-05\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.6737e-04 - val_loss: 4.5392e-05\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 4.6675e-04 - val_loss: 3.9898e-05\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 4.6370e-04 - val_loss: 2.8156e-05\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.6371e-04 - val_loss: 3.5666e-05\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.6061e-04 - val_loss: 2.4821e-05\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.5962e-04 - val_loss: 3.6508e-05\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.6121e-04 - val_loss: 2.9543e-05\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.6326e-04 - val_loss: 2.9649e-05\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.5719e-04 - val_loss: 2.1567e-05\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.6140e-04 - val_loss: 2.6046e-05\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.6578e-04 - val_loss: 1.8081e-05\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.7456e-04 - val_loss: 3.3776e-05\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.5922e-04 - val_loss: 2.1205e-05\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.6383e-04 - val_loss: 1.7814e-05\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.5239e-04 - val_loss: 2.1317e-05\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.5287e-04 - val_loss: 2.8619e-05\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.5235e-04 - val_loss: 3.0259e-05\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.5216e-04 - val_loss: 2.1704e-05\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.4830e-04 - val_loss: 1.8206e-05\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 4.4764e-04 - val_loss: 1.8278e-05\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.5307e-04 - val_loss: 1.9391e-05\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.4519e-04 - val_loss: 1.8088e-05\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.4271e-04 - val_loss: 2.0353e-05\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 4.4869e-04 - val_loss: 2.0103e-05\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.7194e-04 - val_loss: 1.7885e-05\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.5690e-04 - val_loss: 1.8556e-05\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.4543e-04 - val_loss: 2.0725e-05\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.4086e-04 - val_loss: 1.7948e-05\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.5106e-04 - val_loss: 1.9216e-05\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.4125e-04 - val_loss: 1.9210e-05\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.4116e-04 - val_loss: 2.1760e-05\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.4219e-04 - val_loss: 1.8180e-05\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.4902e-04 - val_loss: 1.9883e-05\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 6ms/step - loss: 4.4801e-04 - val_loss: 2.5599e-05\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.5833e-04 - val_loss: 1.8441e-05\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.4921e-04 - val_loss: 2.0152e-05\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.3561e-04 - val_loss: 1.8140e-05\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.3800e-04 - val_loss: 2.1123e-05\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.4232e-04 - val_loss: 1.7969e-05\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.4579e-04 - val_loss: 1.9677e-05\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.4215e-04 - val_loss: 1.8679e-05\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.3514e-04 - val_loss: 1.8063e-05\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 4.3588e-04 - val_loss: 2.1224e-05\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.4303e-04 - val_loss: 2.7558e-05\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.3536e-04 - val_loss: 1.9158e-05\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.3440e-04 - val_loss: 1.8163e-05\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.3873e-04 - val_loss: 2.3743e-05\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.3268e-04 - val_loss: 2.2368e-05\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.4161e-04 - val_loss: 1.8980e-05\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.3636e-04 - val_loss: 1.8815e-05\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.4286e-04 - val_loss: 1.8232e-05\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.2612e-04 - val_loss: 1.7655e-05\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.2655e-04 - val_loss: 1.7748e-05\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.3328e-04 - val_loss: 1.7726e-05\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.2508e-04 - val_loss: 3.0716e-05\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.3282e-04 - val_loss: 1.9165e-05\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.2741e-04 - val_loss: 1.8280e-05\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.3210e-04 - val_loss: 2.0159e-05\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.3130e-04 - val_loss: 2.8025e-05\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.2860e-04 - val_loss: 2.0553e-05\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.3364e-04 - val_loss: 1.8113e-05\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.2466e-04 - val_loss: 1.7924e-05\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.2654e-04 - val_loss: 1.9816e-05\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.2289e-04 - val_loss: 1.7683e-05\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.1651e-04 - val_loss: 2.3063e-05\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.1850e-04 - val_loss: 1.7740e-05\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.2770e-04 - val_loss: 1.7569e-05\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.1811e-04 - val_loss: 1.7502e-05\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.2341e-04 - val_loss: 2.2965e-05\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.1517e-04 - val_loss: 2.4208e-05\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.1772e-04 - val_loss: 1.8636e-05\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.2008e-04 - val_loss: 2.2854e-05\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.2063e-04 - val_loss: 2.2844e-05\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.1523e-04 - val_loss: 1.7714e-05\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.1365e-04 - val_loss: 3.3482e-05\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.0765e-04 - val_loss: 2.7221e-05\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.0735e-04 - val_loss: 1.7096e-05\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.1711e-04 - val_loss: 2.3412e-05\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.1220e-04 - val_loss: 1.8192e-05\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.0403e-04 - val_loss: 1.7587e-05\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.0941e-04 - val_loss: 2.5123e-05\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.0666e-04 - val_loss: 1.7875e-05\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.0863e-04 - val_loss: 1.6956e-05\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.0643e-04 - val_loss: 3.1366e-05\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.1222e-04 - val_loss: 2.3867e-05\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.1430e-04 - val_loss: 2.0474e-05\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.2099e-04 - val_loss: 2.0058e-05\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.0351e-04 - val_loss: 2.2836e-05\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.0965e-04 - val_loss: 2.1470e-05\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.0747e-04 - val_loss: 2.0765e-05\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.9749e-04 - val_loss: 1.7571e-05\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.0181e-04 - val_loss: 2.2794e-05\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.9689e-04 - val_loss: 1.6676e-05\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.9373e-04 - val_loss: 1.6735e-05\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.8866e-04 - val_loss: 3.9626e-05\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.1705e-04 - val_loss: 1.6586e-05\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.0794e-04 - val_loss: 2.3588e-05\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.9050e-04 - val_loss: 2.0405e-05\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.9061e-04 - val_loss: 1.8030e-05\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.8999e-04 - val_loss: 2.3011e-05\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.9591e-04 - val_loss: 2.0570e-05\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.8835e-04 - val_loss: 2.0989e-05\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.8183e-04 - val_loss: 2.3006e-05\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.9059e-04 - val_loss: 1.8510e-05\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.9695e-04 - val_loss: 2.3316e-05\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.8856e-04 - val_loss: 2.6759e-05\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.8275e-04 - val_loss: 1.7944e-05\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.8724e-04 - val_loss: 1.6403e-05\n",
      "Epoch 136/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 6ms/step - loss: 3.8637e-04 - val_loss: 1.6668e-05\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.8136e-04 - val_loss: 2.0769e-05\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.8629e-04 - val_loss: 2.2670e-05\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.8078e-04 - val_loss: 2.2202e-05\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.8537e-04 - val_loss: 1.6403e-05\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.9450e-04 - val_loss: 1.6368e-05\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.7983e-04 - val_loss: 2.6542e-05\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.7343e-04 - val_loss: 2.5611e-05\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 4.0708e-04 - val_loss: 3.4811e-05\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.7012e-04 - val_loss: 2.1149e-05\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.7390e-04 - val_loss: 2.0277e-05\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.7478e-04 - val_loss: 1.8140e-05\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.7593e-04 - val_loss: 2.2225e-05\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.7083e-04 - val_loss: 1.7812e-05\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.6588e-04 - val_loss: 1.9400e-05\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.7040e-04 - val_loss: 1.5537e-05\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.6923e-04 - val_loss: 1.6916e-05\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.7637e-04 - val_loss: 1.6074e-05\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.6692e-04 - val_loss: 1.8613e-05\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.6346e-04 - val_loss: 1.8331e-05\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.5530e-04 - val_loss: 4.2340e-05\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.6175e-04 - val_loss: 1.5862e-05\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.5734e-04 - val_loss: 1.6590e-05\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.6093e-04 - val_loss: 1.5937e-05\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.6151e-04 - val_loss: 1.6018e-05\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.6873e-04 - val_loss: 2.1906e-05\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.5691e-04 - val_loss: 2.3337e-05\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.6823e-04 - val_loss: 2.3692e-05\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.5504e-04 - val_loss: 1.6509e-05\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.5238e-04 - val_loss: 1.7901e-05\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.5560e-04 - val_loss: 1.7770e-05\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.5030e-04 - val_loss: 1.7347e-05\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.5533e-04 - val_loss: 1.6226e-05\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.5035e-04 - val_loss: 2.8502e-05\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.5130e-04 - val_loss: 1.5533e-05\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.5185e-04 - val_loss: 2.0202e-05\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.4443e-04 - val_loss: 2.8829e-05\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.4660e-04 - val_loss: 2.3046e-05\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.4929e-04 - val_loss: 1.9362e-05\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.4066e-04 - val_loss: 3.6377e-05\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.5830e-04 - val_loss: 2.1303e-05\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.4010e-04 - val_loss: 1.4935e-05\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.4253e-04 - val_loss: 1.4669e-05\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.5647e-04 - val_loss: 1.7561e-05\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.3259e-04 - val_loss: 1.4491e-05\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.3060e-04 - val_loss: 1.8730e-05\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.4824e-04 - val_loss: 1.9623e-05\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.4480e-04 - val_loss: 1.7472e-05\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.3707e-04 - val_loss: 1.4566e-05\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.3238e-04 - val_loss: 1.9839e-05\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.5546e-04 - val_loss: 2.3582e-05\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.3042e-04 - val_loss: 1.5620e-05\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.2778e-04 - val_loss: 1.9613e-05\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.3197e-04 - val_loss: 1.6190e-05\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.2971e-04 - val_loss: 1.7198e-05\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.3011e-04 - val_loss: 1.3960e-05\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.2368e-04 - val_loss: 1.4344e-05\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.2184e-04 - val_loss: 1.5021e-05\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.2044e-04 - val_loss: 1.4064e-05\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.2510e-04 - val_loss: 1.4411e-05\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.3307e-04 - val_loss: 1.8415e-05\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.2104e-04 - val_loss: 1.4718e-05\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.1625e-04 - val_loss: 2.5858e-05\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 3.2362e-04 - val_loss: 1.7002e-05\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 3.3027e-04 - val_loss: 2.2234e-05\n",
      "Thời gian huấn luyện:  53.44896125793457\n",
      "Model: \"sequential_130\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_32 (LSTM)              (None, 5, 116)            54752     \n",
      "                                                                 \n",
      " flatten_130 (Flatten)       (None, 580)               0         \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 1)                 581       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,333\n",
      "Trainable params: 55,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "47/47 [==============================] - 2s 12ms/step - loss: 0.0667 - val_loss: 0.0038\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 3.6101e-05\n",
      "Epoch 3/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 4.1586e-04 - val_loss: 1.4871e-05\n",
      "Epoch 4/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 4.1659e-04 - val_loss: 1.5460e-05\n",
      "Epoch 5/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 4.1403e-04 - val_loss: 3.5998e-05\n",
      "Epoch 6/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 4.1899e-04 - val_loss: 1.8878e-05\n",
      "Epoch 7/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 4.1163e-04 - val_loss: 1.7716e-05\n",
      "Epoch 8/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 4.1100e-04 - val_loss: 1.7181e-05\n",
      "Epoch 9/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 4.0761e-04 - val_loss: 2.4228e-05\n",
      "Epoch 10/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 4.0778e-04 - val_loss: 1.4816e-05\n",
      "Epoch 11/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 4.0671e-04 - val_loss: 1.6894e-05\n",
      "Epoch 12/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 4.0470e-04 - val_loss: 1.4070e-05\n",
      "Epoch 13/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 4.0555e-04 - val_loss: 1.9763e-05\n",
      "Epoch 14/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 4.0268e-04 - val_loss: 1.8238e-05\n",
      "Epoch 15/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 4.0257e-04 - val_loss: 2.0823e-05\n",
      "Epoch 16/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 4.0867e-04 - val_loss: 1.6340e-05\n",
      "Epoch 17/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.9724e-04 - val_loss: 1.3949e-05\n",
      "Epoch 18/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.9720e-04 - val_loss: 1.6137e-05\n",
      "Epoch 19/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.9666e-04 - val_loss: 1.3819e-05\n",
      "Epoch 20/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.9858e-04 - val_loss: 2.3150e-05\n",
      "Epoch 21/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 4.0350e-04 - val_loss: 1.4792e-05\n",
      "Epoch 22/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 4.0296e-04 - val_loss: 1.8721e-05\n",
      "Epoch 23/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.9411e-04 - val_loss: 1.8224e-05\n",
      "Epoch 24/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.9444e-04 - val_loss: 1.8002e-05\n",
      "Epoch 25/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 3.8914e-04 - val_loss: 1.4454e-05\n",
      "Epoch 26/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.8645e-04 - val_loss: 1.3769e-05\n",
      "Epoch 27/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.8789e-04 - val_loss: 2.1789e-05\n",
      "Epoch 28/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.9480e-04 - val_loss: 1.3517e-05\n",
      "Epoch 29/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.8286e-04 - val_loss: 1.5047e-05\n",
      "Epoch 30/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.9498e-04 - val_loss: 1.5171e-05\n",
      "Epoch 31/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 3.8294e-04 - val_loss: 1.4974e-05\n",
      "Epoch 32/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.8245e-04 - val_loss: 1.3521e-05\n",
      "Epoch 33/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.8121e-04 - val_loss: 1.3313e-05\n",
      "Epoch 34/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.7786e-04 - val_loss: 2.0942e-05\n",
      "Epoch 35/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.7950e-04 - val_loss: 1.4254e-05\n",
      "Epoch 36/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.7232e-04 - val_loss: 1.6978e-05\n",
      "Epoch 37/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.7139e-04 - val_loss: 1.3157e-05\n",
      "Epoch 38/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.7040e-04 - val_loss: 1.3400e-05\n",
      "Epoch 39/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.7160e-04 - val_loss: 1.3312e-05\n",
      "Epoch 40/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.6920e-04 - val_loss: 1.3079e-05\n",
      "Epoch 41/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.7252e-04 - val_loss: 1.3124e-05\n",
      "Epoch 42/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.7728e-04 - val_loss: 1.2974e-05\n",
      "Epoch 43/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.6574e-04 - val_loss: 1.3013e-05\n",
      "Epoch 44/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 3.6635e-04 - val_loss: 1.4689e-05\n",
      "Epoch 45/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 3.6688e-04 - val_loss: 1.3245e-05\n",
      "Epoch 46/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 3.6511e-04 - val_loss: 1.3480e-05\n",
      "Epoch 47/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 3.6502e-04 - val_loss: 1.2849e-05\n",
      "Epoch 48/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 3.5667e-04 - val_loss: 1.5834e-05\n",
      "Epoch 49/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 3.6202e-04 - val_loss: 1.2933e-05\n",
      "Epoch 50/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 3.6279e-04 - val_loss: 1.9163e-05\n",
      "Epoch 51/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 3.6175e-04 - val_loss: 1.3295e-05\n",
      "Epoch 52/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 3.5478e-04 - val_loss: 1.5188e-05\n",
      "Epoch 53/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.5323e-04 - val_loss: 1.5853e-05\n",
      "Epoch 54/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.5830e-04 - val_loss: 1.2959e-05\n",
      "Epoch 55/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.5190e-04 - val_loss: 1.2751e-05\n",
      "Epoch 56/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.6459e-04 - val_loss: 1.3828e-05\n",
      "Epoch 57/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 3.4101e-04 - val_loss: 1.5338e-05\n",
      "Epoch 58/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.5015e-04 - val_loss: 1.3269e-05\n",
      "Epoch 59/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.4167e-04 - val_loss: 1.6187e-05\n",
      "Epoch 60/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.4718e-04 - val_loss: 1.3425e-05\n",
      "Epoch 61/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.3836e-04 - val_loss: 1.2294e-05\n",
      "Epoch 62/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.3400e-04 - val_loss: 1.6928e-05\n",
      "Epoch 63/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 3.3723e-04 - val_loss: 1.9059e-05\n",
      "Epoch 64/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.3321e-04 - val_loss: 1.2012e-05\n",
      "Epoch 65/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.3304e-04 - val_loss: 1.6326e-05\n",
      "Epoch 66/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.2786e-04 - val_loss: 1.5843e-05\n",
      "Epoch 67/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.2587e-04 - val_loss: 2.2834e-05\n",
      "Epoch 68/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.3985e-04 - val_loss: 1.2973e-05\n",
      "Epoch 69/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.2611e-04 - val_loss: 1.7461e-05\n",
      "Epoch 70/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.2800e-04 - val_loss: 1.7144e-05\n",
      "Epoch 71/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.3098e-04 - val_loss: 1.2810e-05\n",
      "Epoch 72/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 3.2932e-04 - val_loss: 1.2004e-05\n",
      "Epoch 73/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.1734e-04 - val_loss: 1.1872e-05\n",
      "Epoch 74/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 3.1999e-04 - val_loss: 1.1508e-05\n",
      "Epoch 75/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 3.1733e-04 - val_loss: 1.1753e-05\n",
      "Epoch 76/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 3.1162e-04 - val_loss: 1.1600e-05\n",
      "Epoch 77/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 3.2572e-04 - val_loss: 1.4182e-05\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 5ms/step - loss: 3.1683e-04 - val_loss: 1.9545e-05\n",
      "Epoch 79/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.1464e-04 - val_loss: 1.1417e-05\n",
      "Epoch 80/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.0785e-04 - val_loss: 1.6156e-05\n",
      "Epoch 81/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.0320e-04 - val_loss: 1.1723e-05\n",
      "Epoch 82/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.1076e-04 - val_loss: 1.3282e-05\n",
      "Epoch 83/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.4552e-04 - val_loss: 1.3062e-05\n",
      "Epoch 84/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.0328e-04 - val_loss: 1.5455e-05\n",
      "Epoch 85/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.0195e-04 - val_loss: 1.2063e-05\n",
      "Epoch 86/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.9943e-04 - val_loss: 1.8736e-05\n",
      "Epoch 87/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.0492e-04 - val_loss: 1.3078e-05\n",
      "Epoch 88/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.0913e-04 - val_loss: 1.0904e-05\n",
      "Epoch 89/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.9073e-04 - val_loss: 1.2280e-05\n",
      "Epoch 90/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.9462e-04 - val_loss: 1.3351e-05\n",
      "Epoch 91/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.8837e-04 - val_loss: 1.0848e-05\n",
      "Epoch 92/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.8624e-04 - val_loss: 1.1268e-05\n",
      "Epoch 93/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.8604e-04 - val_loss: 1.1356e-05\n",
      "Epoch 94/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.8701e-04 - val_loss: 1.2334e-05\n",
      "Epoch 95/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.8145e-04 - val_loss: 2.5955e-05\n",
      "Epoch 96/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.9526e-04 - val_loss: 1.1343e-05\n",
      "Epoch 97/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.8422e-04 - val_loss: 1.0975e-05\n",
      "Epoch 98/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.8407e-04 - val_loss: 1.1567e-05\n",
      "Epoch 99/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7509e-04 - val_loss: 1.1215e-05\n",
      "Epoch 100/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.7334e-04 - val_loss: 1.2202e-05\n",
      "Epoch 101/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7690e-04 - val_loss: 1.0300e-05\n",
      "Epoch 102/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.7387e-04 - val_loss: 1.0301e-05\n",
      "Epoch 103/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.9726e-04 - val_loss: 1.0354e-05\n",
      "Epoch 104/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.7440e-04 - val_loss: 1.0175e-05\n",
      "Epoch 105/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.6226e-04 - val_loss: 1.2515e-05\n",
      "Epoch 106/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.6838e-04 - val_loss: 1.0077e-05\n",
      "Epoch 107/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.6436e-04 - val_loss: 1.0223e-05\n",
      "Epoch 108/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.6113e-04 - val_loss: 1.3936e-05\n",
      "Epoch 109/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.6572e-04 - val_loss: 1.3921e-05\n",
      "Epoch 110/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.6224e-04 - val_loss: 1.2959e-05\n",
      "Epoch 111/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.5431e-04 - val_loss: 9.9060e-06\n",
      "Epoch 112/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.6457e-04 - val_loss: 2.4421e-05\n",
      "Epoch 113/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.6760e-04 - val_loss: 1.5324e-05\n",
      "Epoch 114/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.5444e-04 - val_loss: 1.4893e-05\n",
      "Epoch 115/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.5138e-04 - val_loss: 1.2897e-05\n",
      "Epoch 116/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.5305e-04 - val_loss: 1.4596e-05\n",
      "Epoch 117/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.5240e-04 - val_loss: 2.4496e-05\n",
      "Epoch 118/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.5209e-04 - val_loss: 1.3668e-05\n",
      "Epoch 119/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.4072e-04 - val_loss: 1.2882e-05\n",
      "Epoch 120/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.5385e-04 - val_loss: 2.6674e-05\n",
      "Epoch 121/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.9249e-04 - val_loss: 1.6443e-05\n",
      "Epoch 122/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.4459e-04 - val_loss: 1.1647e-05\n",
      "Epoch 123/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.3960e-04 - val_loss: 9.9358e-06\n",
      "Epoch 124/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.4681e-04 - val_loss: 1.0771e-05\n",
      "Epoch 125/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4537e-04 - val_loss: 2.6329e-05\n",
      "Epoch 126/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4930e-04 - val_loss: 1.0700e-05\n",
      "Epoch 127/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.3632e-04 - val_loss: 1.0109e-05\n",
      "Epoch 128/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.3777e-04 - val_loss: 1.8786e-05\n",
      "Epoch 129/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.3720e-04 - val_loss: 1.6247e-05\n",
      "Epoch 130/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.3039e-04 - val_loss: 9.2335e-06\n",
      "Epoch 131/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4052e-04 - val_loss: 1.2474e-05\n",
      "Epoch 132/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.3141e-04 - val_loss: 1.0100e-05\n",
      "Epoch 133/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.3148e-04 - val_loss: 9.2743e-06\n",
      "Epoch 134/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.3103e-04 - val_loss: 1.8051e-05\n",
      "Epoch 135/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.3284e-04 - val_loss: 1.7135e-05\n",
      "Epoch 136/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.2747e-04 - val_loss: 1.1298e-05\n",
      "Epoch 137/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.2378e-04 - val_loss: 1.5956e-05\n",
      "Epoch 138/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.3531e-04 - val_loss: 1.2928e-05\n",
      "Epoch 139/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.3967e-04 - val_loss: 9.7630e-06\n",
      "Epoch 140/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4931e-04 - val_loss: 1.4893e-05\n",
      "Epoch 141/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.2916e-04 - val_loss: 1.8398e-05\n",
      "Epoch 142/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.1972e-04 - val_loss: 1.4240e-05\n",
      "Epoch 143/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.2179e-04 - val_loss: 1.4887e-05\n",
      "Epoch 144/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.1441e-04 - val_loss: 9.7712e-06\n",
      "Epoch 145/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.1501e-04 - val_loss: 1.5470e-05\n",
      "Epoch 146/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.1376e-04 - val_loss: 2.1007e-05\n",
      "Epoch 147/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.1714e-04 - val_loss: 1.9528e-05\n",
      "Epoch 148/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.1701e-04 - val_loss: 8.5203e-06\n",
      "Epoch 149/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.1283e-04 - val_loss: 2.3801e-05\n",
      "Epoch 150/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.1577e-04 - val_loss: 1.8415e-05\n",
      "Epoch 151/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.1257e-04 - val_loss: 1.5880e-05\n",
      "Epoch 152/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.1153e-04 - val_loss: 8.9718e-06\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 5ms/step - loss: 2.1018e-04 - val_loss: 2.9455e-05\n",
      "Epoch 154/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.1012e-04 - val_loss: 1.2324e-05\n",
      "Epoch 155/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0736e-04 - val_loss: 4.2151e-05\n",
      "Epoch 156/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.1566e-04 - val_loss: 8.5042e-06\n",
      "Epoch 157/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.2348e-04 - val_loss: 1.4582e-05\n",
      "Epoch 158/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0878e-04 - val_loss: 8.2335e-06\n",
      "Epoch 159/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0569e-04 - val_loss: 8.1071e-06\n",
      "Epoch 160/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0992e-04 - val_loss: 8.3935e-06\n",
      "Epoch 161/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0193e-04 - val_loss: 2.5482e-05\n",
      "Epoch 162/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0519e-04 - val_loss: 1.8670e-05\n",
      "Epoch 163/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0138e-04 - val_loss: 1.0790e-05\n",
      "Epoch 164/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.9889e-04 - val_loss: 1.4035e-05\n",
      "Epoch 165/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0757e-04 - val_loss: 2.0002e-05\n",
      "Epoch 166/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0670e-04 - val_loss: 1.5136e-05\n",
      "Epoch 167/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.1523e-04 - val_loss: 8.0798e-06\n",
      "Epoch 168/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0150e-04 - val_loss: 1.9281e-05\n",
      "Epoch 169/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0542e-04 - val_loss: 1.7670e-05\n",
      "Epoch 170/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0702e-04 - val_loss: 9.3445e-06\n",
      "Epoch 171/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.9973e-04 - val_loss: 1.0115e-05\n",
      "Epoch 172/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.9529e-04 - val_loss: 1.4527e-05\n",
      "Epoch 173/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.9360e-04 - val_loss: 2.7084e-05\n",
      "Epoch 174/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.9930e-04 - val_loss: 1.0393e-05\n",
      "Epoch 175/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.9500e-04 - val_loss: 7.7509e-06\n",
      "Epoch 176/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.9208e-04 - val_loss: 2.5126e-05\n",
      "Epoch 177/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.0295e-04 - val_loss: 8.6790e-06\n",
      "Epoch 178/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.9083e-04 - val_loss: 7.6349e-06\n",
      "Epoch 179/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.8916e-04 - val_loss: 1.1603e-05\n",
      "Epoch 180/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.9728e-04 - val_loss: 8.3302e-06\n",
      "Epoch 181/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.9221e-04 - val_loss: 7.5077e-06\n",
      "Epoch 182/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.8504e-04 - val_loss: 7.5946e-06\n",
      "Epoch 183/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.9456e-04 - val_loss: 1.2311e-05\n",
      "Epoch 184/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.9091e-04 - val_loss: 8.9675e-06\n",
      "Epoch 185/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.9146e-04 - val_loss: 7.7995e-06\n",
      "Epoch 186/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.9064e-04 - val_loss: 7.8895e-06\n",
      "Epoch 187/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.9022e-04 - val_loss: 1.1235e-05\n",
      "Epoch 188/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.9068e-04 - val_loss: 8.4750e-06\n",
      "Epoch 189/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.8764e-04 - val_loss: 7.2898e-06\n",
      "Epoch 190/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.8757e-04 - val_loss: 7.4150e-06\n",
      "Epoch 191/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.9847e-04 - val_loss: 2.3446e-05\n",
      "Epoch 192/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.8401e-04 - val_loss: 1.1845e-05\n",
      "Epoch 193/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.8320e-04 - val_loss: 2.7386e-05\n",
      "Epoch 194/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.9411e-04 - val_loss: 7.4324e-06\n",
      "Epoch 195/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.8992e-04 - val_loss: 1.0526e-05\n",
      "Epoch 196/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.8677e-04 - val_loss: 1.1140e-05\n",
      "Epoch 197/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.1994e-04 - val_loss: 7.3124e-06\n",
      "Epoch 198/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.7987e-04 - val_loss: 1.2126e-05\n",
      "Epoch 199/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.8788e-04 - val_loss: 7.6763e-06\n",
      "Epoch 200/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.8350e-04 - val_loss: 1.7971e-05\n",
      "Thời gian huấn luyện:  53.5725998878479\n",
      "Model: \"sequential_131\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_31 (GRU)                (None, 5, 116)            41412     \n",
      "                                                                 \n",
      " flatten_131 (Flatten)       (None, 580)               0         \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 1)                 581       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,993\n",
      "Trainable params: 41,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0844 - val_loss: 0.0365\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0196\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0131\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0059\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 8.0467e-04 - val_loss: 7.0666e-04\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.7455e-04 - val_loss: 3.7005e-04\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.3158e-04 - val_loss: 2.4291e-04\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.0894e-04 - val_loss: 2.0158e-04\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.0014e-04 - val_loss: 1.4380e-04\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.9601e-04 - val_loss: 1.2103e-04\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.8992e-04 - val_loss: 9.2669e-05\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.8635e-04 - val_loss: 8.9222e-05\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.8511e-04 - val_loss: 8.3385e-05\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.8107e-04 - val_loss: 6.5857e-05\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7975e-04 - val_loss: 5.9758e-05\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7508e-04 - val_loss: 5.4022e-05\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7622e-04 - val_loss: 5.3282e-05\n",
      "Epoch 20/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7009e-04 - val_loss: 5.0950e-05\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6860e-04 - val_loss: 4.9898e-05\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7060e-04 - val_loss: 4.6833e-05\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6290e-04 - val_loss: 4.6784e-05\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6285e-04 - val_loss: 4.5998e-05\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6046e-04 - val_loss: 4.3482e-05\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6174e-04 - val_loss: 4.1680e-05\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5937e-04 - val_loss: 4.0593e-05\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5815e-04 - val_loss: 4.0618e-05\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5561e-04 - val_loss: 4.0396e-05\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5367e-04 - val_loss: 3.9083e-05\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5175e-04 - val_loss: 3.8688e-05\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5358e-04 - val_loss: 3.6621e-05\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4755e-04 - val_loss: 3.6315e-05\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4744e-04 - val_loss: 3.5783e-05\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5064e-04 - val_loss: 3.7429e-05\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4441e-04 - val_loss: 3.6231e-05\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4141e-04 - val_loss: 3.5275e-05\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3944e-04 - val_loss: 3.6944e-05\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4158e-04 - val_loss: 3.2837e-05\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3633e-04 - val_loss: 3.3567e-05\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3283e-04 - val_loss: 4.3668e-05\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4338e-04 - val_loss: 3.1787e-05\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3407e-04 - val_loss: 3.1633e-05\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3025e-04 - val_loss: 3.5790e-05\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3596e-04 - val_loss: 3.8203e-05\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2818e-04 - val_loss: 2.9851e-05\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2387e-04 - val_loss: 3.3348e-05\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3624e-04 - val_loss: 3.6378e-05\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2669e-04 - val_loss: 3.1496e-05\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.1952e-04 - val_loss: 2.8405e-05\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.1792e-04 - val_loss: 2.8594e-05\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2039e-04 - val_loss: 2.9207e-05\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.1674e-04 - val_loss: 2.7611e-05\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.1571e-04 - val_loss: 2.7810e-05\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.1120e-04 - val_loss: 2.7750e-05\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.0631e-04 - val_loss: 3.6482e-05\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.0882e-04 - val_loss: 2.6847e-05\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.0384e-04 - val_loss: 3.0336e-05\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.0284e-04 - val_loss: 3.2647e-05\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.0135e-04 - val_loss: 3.2140e-05\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.9864e-04 - val_loss: 2.5874e-05\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.9838e-04 - val_loss: 2.7166e-05\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.9336e-04 - val_loss: 2.7900e-05\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.9625e-04 - val_loss: 2.7433e-05\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.9194e-04 - val_loss: 2.8264e-05\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.8837e-04 - val_loss: 2.7021e-05\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.8678e-04 - val_loss: 2.4557e-05\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.8663e-04 - val_loss: 3.2663e-05\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.8605e-04 - val_loss: 2.6233e-05\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.8180e-04 - val_loss: 4.0281e-05\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.8179e-04 - val_loss: 2.4084e-05\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.8455e-04 - val_loss: 3.6358e-05\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.8028e-04 - val_loss: 2.4310e-05\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.7637e-04 - val_loss: 3.2190e-05\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.7710e-04 - val_loss: 2.3366e-05\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.6591e-04 - val_loss: 3.8779e-05\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.7081e-04 - val_loss: 2.3275e-05\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.6536e-04 - val_loss: 2.6536e-05\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.6781e-04 - val_loss: 3.3733e-05\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.6335e-04 - val_loss: 2.6122e-05\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.5766e-04 - val_loss: 2.3153e-05\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.5938e-04 - val_loss: 2.6860e-05\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.5085e-04 - val_loss: 3.6682e-05\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.5352e-04 - val_loss: 2.4601e-05\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.5062e-04 - val_loss: 2.2298e-05\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.4589e-04 - val_loss: 2.4528e-05\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.4493e-04 - val_loss: 3.0992e-05\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.4555e-04 - val_loss: 2.3251e-05\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.4342e-04 - val_loss: 2.9304e-05\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.3894e-04 - val_loss: 2.5758e-05\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.6304e-04 - val_loss: 3.3305e-05\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.3555e-04 - val_loss: 2.3284e-05\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.3485e-04 - val_loss: 2.3718e-05\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.3163e-04 - val_loss: 2.0440e-05\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.2951e-04 - val_loss: 4.2402e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.3043e-04 - val_loss: 2.8133e-05\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.2019e-04 - val_loss: 2.0861e-05\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.2800e-04 - val_loss: 2.8759e-05\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.2097e-04 - val_loss: 2.2337e-05\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.1434e-04 - val_loss: 2.0132e-05\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.1435e-04 - val_loss: 2.2829e-05\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.1170e-04 - val_loss: 3.5278e-05\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.1238e-04 - val_loss: 2.2663e-05\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.0891e-04 - val_loss: 1.9752e-05\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.0784e-04 - val_loss: 2.5470e-05\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.0778e-04 - val_loss: 1.9924e-05\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.9970e-04 - val_loss: 2.6320e-05\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.9788e-04 - val_loss: 2.3128e-05\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.9591e-04 - val_loss: 2.6214e-05\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.9337e-04 - val_loss: 3.5660e-05\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.9405e-04 - val_loss: 1.8989e-05\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.8859e-04 - val_loss: 2.3539e-05\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.9431e-04 - val_loss: 1.8616e-05\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.9694e-04 - val_loss: 3.7202e-05\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.8680e-04 - val_loss: 2.0237e-05\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.9575e-04 - val_loss: 1.9074e-05\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.9538e-04 - val_loss: 4.2004e-05\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.8408e-04 - val_loss: 2.0176e-05\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.7202e-04 - val_loss: 2.3742e-05\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.7717e-04 - val_loss: 2.0293e-05\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.7493e-04 - val_loss: 2.3861e-05\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.7232e-04 - val_loss: 1.6965e-05\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.6728e-04 - val_loss: 2.9521e-05\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.8441e-04 - val_loss: 2.0212e-05\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.6583e-04 - val_loss: 2.3247e-05\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.6293e-04 - val_loss: 1.8099e-05\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5824e-04 - val_loss: 1.8500e-05\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5483e-04 - val_loss: 1.6694e-05\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5522e-04 - val_loss: 2.1968e-05\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5402e-04 - val_loss: 2.3499e-05\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4940e-04 - val_loss: 2.6818e-05\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4791e-04 - val_loss: 1.8235e-05\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4876e-04 - val_loss: 2.5987e-05\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4371e-04 - val_loss: 2.1685e-05\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4061e-04 - val_loss: 2.3290e-05\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4363e-04 - val_loss: 1.5783e-05\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4415e-04 - val_loss: 1.9486e-05\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3797e-04 - val_loss: 1.7667e-05\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3963e-04 - val_loss: 2.1689e-05\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3798e-04 - val_loss: 1.5305e-05\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3232e-04 - val_loss: 1.6407e-05\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2865e-04 - val_loss: 1.9629e-05\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2904e-04 - val_loss: 1.4993e-05\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2781e-04 - val_loss: 2.1412e-05\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2637e-04 - val_loss: 1.8993e-05\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2180e-04 - val_loss: 1.7802e-05\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2361e-04 - val_loss: 1.4549e-05\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2204e-04 - val_loss: 1.6352e-05\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1812e-04 - val_loss: 2.5354e-05\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1515e-04 - val_loss: 2.2015e-05\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1700e-04 - val_loss: 1.9367e-05\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2310e-04 - val_loss: 1.7176e-05\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0910e-04 - val_loss: 1.4519e-05\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1109e-04 - val_loss: 4.0257e-05\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1285e-04 - val_loss: 1.4442e-05\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0441e-04 - val_loss: 1.5547e-05\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0212e-04 - val_loss: 2.2710e-05\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1125e-04 - val_loss: 1.8890e-05\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0880e-04 - val_loss: 1.6198e-05\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9736e-04 - val_loss: 1.3417e-05\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0066e-04 - val_loss: 1.3798e-05\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0138e-04 - val_loss: 1.6774e-05\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0564e-04 - val_loss: 4.3171e-05\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9866e-04 - val_loss: 1.7599e-05\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9110e-04 - val_loss: 2.2252e-05\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9041e-04 - val_loss: 2.1049e-05\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9704e-04 - val_loss: 1.3443e-05\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9288e-04 - val_loss: 1.8425e-05\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8513e-04 - val_loss: 1.4404e-05\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9114e-04 - val_loss: 1.7526e-05\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8554e-04 - val_loss: 1.6989e-05\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8952e-04 - val_loss: 1.2858e-05\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8526e-04 - val_loss: 1.2623e-05\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8974e-04 - val_loss: 1.4912e-05\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8048e-04 - val_loss: 1.7954e-05\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7676e-04 - val_loss: 1.2888e-05\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8681e-04 - val_loss: 1.4200e-05\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7761e-04 - val_loss: 1.2747e-05\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7304e-04 - val_loss: 1.3874e-05\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7637e-04 - val_loss: 1.3390e-05\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6846e-04 - val_loss: 1.6039e-05\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7617e-04 - val_loss: 1.5582e-05\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6936e-04 - val_loss: 1.2630e-05\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7073e-04 - val_loss: 1.2075e-05\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7017e-04 - val_loss: 1.3281e-05\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6563e-04 - val_loss: 1.8032e-05\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6359e-04 - val_loss: 1.2299e-05\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6651e-04 - val_loss: 1.2409e-05\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6469e-04 - val_loss: 1.3386e-05\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7185e-04 - val_loss: 4.1809e-05\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7515e-04 - val_loss: 2.3626e-05\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6887e-04 - val_loss: 1.3174e-05\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6444e-04 - val_loss: 1.5142e-05\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.6408e-04 - val_loss: 1.5423e-05\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5539e-04 - val_loss: 1.2114e-05\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5499e-04 - val_loss: 1.2508e-05\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5360e-04 - val_loss: 1.9412e-05\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5545e-04 - val_loss: 1.1549e-05\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5818e-04 - val_loss: 1.6576e-05\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.5465e-04 - val_loss: 1.1708e-05\n",
      "Thời gian huấn luyện:  16.848083972930908\n",
      "Model: \"sequential_132\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_166 (Dense)           (None, 10, 116)           232       \n",
      "                                                                 \n",
      " flatten_132 (Flatten)       (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 924us/step\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "44/44 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 9.5226e-05\n",
      "Epoch 2/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.5966e-04 - val_loss: 7.4344e-05\n",
      "Epoch 3/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.8225e-04 - val_loss: 5.3804e-05\n",
      "Epoch 4/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.9676e-04 - val_loss: 2.2085e-05\n",
      "Epoch 5/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.2014e-04 - val_loss: 2.0702e-05\n",
      "Epoch 6/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.4072e-04 - val_loss: 1.9514e-05\n",
      "Epoch 7/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.8604e-04 - val_loss: 2.1395e-05\n",
      "Epoch 8/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.7603e-04 - val_loss: 1.7248e-05\n",
      "Epoch 9/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.6763e-04 - val_loss: 1.6839e-05\n",
      "Epoch 10/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.8247e-04 - val_loss: 1.8960e-05\n",
      "Epoch 11/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1908e-04 - val_loss: 1.7224e-05\n",
      "Epoch 12/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1919e-04 - val_loss: 1.9192e-05\n",
      "Epoch 13/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.7486e-04 - val_loss: 2.1219e-05\n",
      "Epoch 14/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.8177e-04 - val_loss: 1.5298e-05\n",
      "Epoch 15/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.7667e-04 - val_loss: 1.7715e-05\n",
      "Epoch 16/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.9662e-04 - val_loss: 1.5159e-05\n",
      "Epoch 17/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.2560e-04 - val_loss: 1.4573e-05\n",
      "Epoch 18/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.9143e-04 - val_loss: 1.4009e-05\n",
      "Epoch 19/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.6279e-04 - val_loss: 2.1248e-05\n",
      "Epoch 20/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.6482e-04 - val_loss: 1.5080e-05\n",
      "Epoch 21/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.7097e-04 - val_loss: 1.3805e-05\n",
      "Epoch 22/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.4258e-04 - val_loss: 1.4831e-05\n",
      "Epoch 23/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.0595e-04 - val_loss: 1.4420e-05\n",
      "Epoch 24/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.5389e-04 - val_loss: 1.7319e-05\n",
      "Epoch 25/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.3811e-04 - val_loss: 1.2495e-05\n",
      "Epoch 26/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.2173e-04 - val_loss: 1.3119e-05\n",
      "Epoch 27/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.3779e-04 - val_loss: 1.4579e-05\n",
      "Epoch 28/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.2358e-04 - val_loss: 2.1323e-05\n",
      "Epoch 29/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.3050e-04 - val_loss: 1.4903e-05\n",
      "Epoch 30/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0650e-04 - val_loss: 1.1861e-05\n",
      "Epoch 31/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0245e-04 - val_loss: 1.1397e-05\n",
      "Epoch 32/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.2590e-04 - val_loss: 1.1437e-05\n",
      "Epoch 33/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.1107e-04 - val_loss: 1.4107e-05\n",
      "Epoch 34/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.8340e-04 - val_loss: 1.1878e-05\n",
      "Epoch 35/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.4454e-04 - val_loss: 1.1534e-05\n",
      "Epoch 36/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.2607e-04 - val_loss: 1.1794e-05\n",
      "Epoch 37/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0064e-04 - val_loss: 1.4298e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9607e-04 - val_loss: 1.5568e-05\n",
      "Epoch 39/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.2343e-04 - val_loss: 1.1403e-05\n",
      "Epoch 40/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9151e-04 - val_loss: 2.0747e-05\n",
      "Epoch 41/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.1312e-04 - val_loss: 1.2698e-05\n",
      "Epoch 42/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0017e-04 - val_loss: 1.3729e-05\n",
      "Epoch 43/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7804e-04 - val_loss: 1.1330e-05\n",
      "Epoch 44/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7423e-04 - val_loss: 1.6579e-05\n",
      "Epoch 45/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7268e-04 - val_loss: 1.0286e-05\n",
      "Epoch 46/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6818e-04 - val_loss: 9.9109e-06\n",
      "Epoch 47/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7113e-04 - val_loss: 1.0203e-05\n",
      "Epoch 48/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6783e-04 - val_loss: 1.3082e-05\n",
      "Epoch 49/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6384e-04 - val_loss: 1.0061e-05\n",
      "Epoch 50/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6975e-04 - val_loss: 9.8417e-06\n",
      "Epoch 51/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7387e-04 - val_loss: 1.1336e-05\n",
      "Epoch 52/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5655e-04 - val_loss: 1.8321e-05\n",
      "Epoch 53/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7193e-04 - val_loss: 9.5542e-06\n",
      "Epoch 54/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3929e-04 - val_loss: 9.2448e-06\n",
      "Epoch 55/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8566e-04 - val_loss: 1.0335e-05\n",
      "Epoch 56/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5127e-04 - val_loss: 1.1912e-05\n",
      "Epoch 57/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7816e-04 - val_loss: 1.0562e-05\n",
      "Epoch 58/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5804e-04 - val_loss: 9.1738e-06\n",
      "Epoch 59/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.4479e-04 - val_loss: 9.2813e-06\n",
      "Epoch 60/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5551e-04 - val_loss: 1.4634e-05\n",
      "Epoch 61/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6294e-04 - val_loss: 9.2685e-06\n",
      "Epoch 62/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.4624e-04 - val_loss: 8.8064e-06\n",
      "Epoch 63/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3863e-04 - val_loss: 1.2197e-05\n",
      "Epoch 64/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2660e-04 - val_loss: 8.6039e-06\n",
      "Epoch 65/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3986e-04 - val_loss: 1.1228e-05\n",
      "Epoch 66/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7891e-04 - val_loss: 1.1592e-05\n",
      "Epoch 67/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3739e-04 - val_loss: 1.0037e-05\n",
      "Epoch 68/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3343e-04 - val_loss: 9.8844e-06\n",
      "Epoch 69/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2907e-04 - val_loss: 8.3756e-06\n",
      "Epoch 70/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2573e-04 - val_loss: 8.6436e-06\n",
      "Epoch 71/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3321e-04 - val_loss: 9.9647e-06\n",
      "Epoch 72/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1866e-04 - val_loss: 2.0947e-05\n",
      "Epoch 73/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3887e-04 - val_loss: 9.5786e-06\n",
      "Epoch 74/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.5270e-04 - val_loss: 1.1005e-05\n",
      "Epoch 75/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7102e-04 - val_loss: 9.6859e-06\n",
      "Epoch 76/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2285e-04 - val_loss: 9.7014e-06\n",
      "Epoch 77/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2775e-04 - val_loss: 9.5880e-06\n",
      "Epoch 78/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1741e-04 - val_loss: 7.9739e-06\n",
      "Epoch 79/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1155e-04 - val_loss: 8.0246e-06\n",
      "Epoch 80/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0635e-04 - val_loss: 8.8755e-06\n",
      "Epoch 81/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1385e-04 - val_loss: 7.9850e-06\n",
      "Epoch 82/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0991e-04 - val_loss: 9.9865e-06\n",
      "Epoch 83/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0478e-04 - val_loss: 8.2881e-06\n",
      "Epoch 84/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0406e-04 - val_loss: 7.7580e-06\n",
      "Epoch 85/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0962e-04 - val_loss: 7.7317e-06\n",
      "Epoch 86/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.3251e-04 - val_loss: 1.2259e-05\n",
      "Epoch 87/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1348e-04 - val_loss: 7.8147e-06\n",
      "Epoch 88/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0126e-04 - val_loss: 9.6945e-06\n",
      "Epoch 89/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1274e-04 - val_loss: 1.5960e-05\n",
      "Epoch 90/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2459e-04 - val_loss: 1.2495e-05\n",
      "Epoch 91/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9549e-04 - val_loss: 9.0574e-06\n",
      "Epoch 92/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9601e-04 - val_loss: 1.2401e-05\n",
      "Epoch 93/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0295e-04 - val_loss: 7.4792e-06\n",
      "Epoch 94/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0714e-04 - val_loss: 8.7650e-06\n",
      "Epoch 95/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0931e-04 - val_loss: 9.4234e-06\n",
      "Epoch 96/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2695e-04 - val_loss: 8.3829e-06\n",
      "Epoch 97/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0411e-04 - val_loss: 7.9818e-06\n",
      "Epoch 98/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1785e-04 - val_loss: 9.4439e-06\n",
      "Epoch 99/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8645e-04 - val_loss: 9.9416e-06\n",
      "Epoch 100/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8777e-04 - val_loss: 7.3973e-06\n",
      "Epoch 101/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8809e-04 - val_loss: 7.2494e-06\n",
      "Epoch 102/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8954e-04 - val_loss: 7.1982e-06\n",
      "Epoch 103/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1081e-04 - val_loss: 7.0778e-06\n",
      "Epoch 104/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9265e-04 - val_loss: 7.8936e-06\n",
      "Epoch 105/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9383e-04 - val_loss: 8.3666e-06\n",
      "Epoch 106/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1783e-04 - val_loss: 9.1697e-06\n",
      "Epoch 107/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0362e-04 - val_loss: 9.3863e-06\n",
      "Epoch 108/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9585e-04 - val_loss: 7.1946e-06\n",
      "Epoch 109/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8070e-04 - val_loss: 6.8446e-06\n",
      "Epoch 110/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0101e-04 - val_loss: 7.5100e-06\n",
      "Epoch 111/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8716e-04 - val_loss: 1.2696e-05\n",
      "Epoch 112/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1482e-04 - val_loss: 7.4291e-06\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 4ms/step - loss: 2.2095e-04 - val_loss: 8.9965e-06\n",
      "Epoch 114/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8222e-04 - val_loss: 8.8758e-06\n",
      "Epoch 115/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8153e-04 - val_loss: 7.7552e-06\n",
      "Epoch 116/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8596e-04 - val_loss: 6.6337e-06\n",
      "Epoch 117/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9150e-04 - val_loss: 9.0792e-06\n",
      "Epoch 118/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9302e-04 - val_loss: 1.2055e-05\n",
      "Epoch 119/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0371e-04 - val_loss: 1.2967e-05\n",
      "Epoch 120/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7961e-04 - val_loss: 7.6457e-06\n",
      "Epoch 121/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7354e-04 - val_loss: 6.4717e-06\n",
      "Epoch 122/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1627e-04 - val_loss: 2.2844e-05\n",
      "Epoch 123/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0293e-04 - val_loss: 1.1397e-05\n",
      "Epoch 124/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7712e-04 - val_loss: 6.6985e-06\n",
      "Epoch 125/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8070e-04 - val_loss: 8.3925e-06\n",
      "Epoch 126/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.0221e-04 - val_loss: 1.0574e-05\n",
      "Epoch 127/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8315e-04 - val_loss: 6.6204e-06\n",
      "Epoch 128/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7399e-04 - val_loss: 6.4946e-06\n",
      "Epoch 129/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7394e-04 - val_loss: 7.4608e-06\n",
      "Epoch 130/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.1951e-04 - val_loss: 7.2249e-06\n",
      "Epoch 131/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6951e-04 - val_loss: 6.4811e-06\n",
      "Epoch 132/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6821e-04 - val_loss: 6.4714e-06\n",
      "Epoch 133/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6545e-04 - val_loss: 6.6081e-06\n",
      "Epoch 134/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8902e-04 - val_loss: 6.7513e-06\n",
      "Epoch 135/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8064e-04 - val_loss: 9.2803e-06\n",
      "Epoch 136/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6595e-04 - val_loss: 7.2215e-06\n",
      "Epoch 137/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7666e-04 - val_loss: 7.2225e-06\n",
      "Epoch 138/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6935e-04 - val_loss: 8.2355e-06\n",
      "Epoch 139/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.5910e-04 - val_loss: 9.1649e-06\n",
      "Epoch 140/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6233e-04 - val_loss: 7.0254e-06\n",
      "Epoch 141/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7119e-04 - val_loss: 7.4734e-06\n",
      "Epoch 142/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8636e-04 - val_loss: 6.3036e-06\n",
      "Epoch 143/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6034e-04 - val_loss: 6.3104e-06\n",
      "Epoch 144/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6440e-04 - val_loss: 1.0893e-05\n",
      "Epoch 145/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7542e-04 - val_loss: 1.0866e-05\n",
      "Epoch 146/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7006e-04 - val_loss: 8.8944e-06\n",
      "Epoch 147/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6860e-04 - val_loss: 6.3732e-06\n",
      "Epoch 148/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6215e-04 - val_loss: 6.1999e-06\n",
      "Epoch 149/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9070e-04 - val_loss: 6.4273e-06\n",
      "Epoch 150/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6763e-04 - val_loss: 9.3038e-06\n",
      "Epoch 151/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.9354e-04 - val_loss: 6.6718e-06\n",
      "Epoch 152/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7287e-04 - val_loss: 6.2267e-06\n",
      "Epoch 153/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6112e-04 - val_loss: 1.0350e-05\n",
      "Epoch 154/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6752e-04 - val_loss: 6.2200e-06\n",
      "Epoch 155/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7624e-04 - val_loss: 7.8717e-06\n",
      "Epoch 156/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.5979e-04 - val_loss: 8.0748e-06\n",
      "Epoch 157/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8023e-04 - val_loss: 6.6379e-06\n",
      "Epoch 158/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.5872e-04 - val_loss: 6.4394e-06\n",
      "Epoch 159/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8612e-04 - val_loss: 7.2627e-06\n",
      "Epoch 160/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6412e-04 - val_loss: 9.2742e-06\n",
      "Epoch 161/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.5932e-04 - val_loss: 5.9324e-06\n",
      "Epoch 162/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.5548e-04 - val_loss: 8.2909e-06\n",
      "Epoch 163/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7009e-04 - val_loss: 6.5649e-06\n",
      "Epoch 164/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7350e-04 - val_loss: 6.2061e-06\n",
      "Epoch 165/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.5976e-04 - val_loss: 6.2312e-06\n",
      "Epoch 166/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7662e-04 - val_loss: 1.2729e-05\n",
      "Epoch 167/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6888e-04 - val_loss: 6.1772e-06\n",
      "Epoch 168/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6082e-04 - val_loss: 7.5295e-06\n",
      "Epoch 169/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6606e-04 - val_loss: 1.2094e-05\n",
      "Epoch 170/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.4946e-04 - val_loss: 6.6990e-06\n",
      "Epoch 171/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.5830e-04 - val_loss: 6.1491e-06\n",
      "Epoch 172/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.5707e-04 - val_loss: 6.8031e-06\n",
      "Epoch 173/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.5136e-04 - val_loss: 6.5967e-06\n",
      "Epoch 174/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.5370e-04 - val_loss: 5.8533e-06\n",
      "Epoch 175/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6471e-04 - val_loss: 9.5036e-06\n",
      "Epoch 176/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6716e-04 - val_loss: 6.0159e-06\n",
      "Epoch 177/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.5897e-04 - val_loss: 1.2317e-05\n",
      "Epoch 178/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.5271e-04 - val_loss: 1.0747e-05\n",
      "Epoch 179/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.8231e-04 - val_loss: 7.1930e-06\n",
      "Epoch 180/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.5573e-04 - val_loss: 8.3387e-06\n",
      "Epoch 181/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6363e-04 - val_loss: 1.3322e-05\n",
      "Epoch 182/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.4780e-04 - val_loss: 6.6823e-06\n",
      "Epoch 183/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.5247e-04 - val_loss: 5.8202e-06\n",
      "Epoch 184/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.5849e-04 - val_loss: 8.0663e-06\n",
      "Epoch 185/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.5361e-04 - val_loss: 5.6784e-06\n",
      "Epoch 186/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.4910e-04 - val_loss: 5.6829e-06\n",
      "Epoch 187/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.5732e-04 - val_loss: 6.5746e-06\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 4ms/step - loss: 1.5634e-04 - val_loss: 5.7212e-06\n",
      "Epoch 189/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7168e-04 - val_loss: 8.1203e-06\n",
      "Epoch 190/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6756e-04 - val_loss: 6.8345e-06\n",
      "Epoch 191/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6257e-04 - val_loss: 6.0204e-06\n",
      "Epoch 192/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.4395e-04 - val_loss: 6.1617e-06\n",
      "Epoch 193/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.5681e-04 - val_loss: 6.0039e-06\n",
      "Epoch 194/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.4962e-04 - val_loss: 5.6944e-06\n",
      "Epoch 195/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.6235e-04 - val_loss: 7.0133e-06\n",
      "Epoch 196/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.7383e-04 - val_loss: 8.8375e-06\n",
      "Epoch 197/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.4570e-04 - val_loss: 6.5028e-06\n",
      "Epoch 198/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.4895e-04 - val_loss: 6.9157e-06\n",
      "Epoch 199/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.5283e-04 - val_loss: 1.0313e-05\n",
      "Epoch 200/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.5613e-04 - val_loss: 6.4071e-06\n",
      "Thời gian huấn luyện:  34.96804356575012\n",
      "Model: \"sequential_133\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_33 (SimpleRNN)   (None, 10, 116)           13688     \n",
      "                                                                 \n",
      " flatten_133 (Flatten)       (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,849\n",
      "Trainable params: 14,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 2s 18ms/step - loss: 0.0309 - val_loss: 7.2882e-04\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 1.8483e-04\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 8.0240e-04 - val_loss: 4.6207e-05\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.8049e-04 - val_loss: 4.2948e-05\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.7709e-04 - val_loss: 4.2319e-05\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.8275e-04 - val_loss: 4.6035e-05\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.6736e-04 - val_loss: 3.5554e-05\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.6956e-04 - val_loss: 3.2625e-05\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.6390e-04 - val_loss: 4.1126e-05\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.5981e-04 - val_loss: 3.2912e-05\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.7123e-04 - val_loss: 3.2388e-05\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.5840e-04 - val_loss: 3.2776e-05\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.6704e-04 - val_loss: 4.2070e-05\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.5928e-04 - val_loss: 3.2563e-05\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.4864e-04 - val_loss: 3.7533e-05\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.5747e-04 - val_loss: 3.2996e-05\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.5312e-04 - val_loss: 3.2147e-05\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.5442e-04 - val_loss: 3.2099e-05\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.5031e-04 - val_loss: 3.4475e-05\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.4421e-04 - val_loss: 3.3064e-05\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.3570e-04 - val_loss: 3.2498e-05\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.3333e-04 - val_loss: 3.2170e-05\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.3153e-04 - val_loss: 3.2153e-05\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.4206e-04 - val_loss: 3.2026e-05\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.2977e-04 - val_loss: 3.2852e-05\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.2364e-04 - val_loss: 3.2472e-05\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.3604e-04 - val_loss: 3.2073e-05\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.2374e-04 - val_loss: 3.2339e-05\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.2382e-04 - val_loss: 3.2600e-05\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.3512e-04 - val_loss: 3.1767e-05\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.3054e-04 - val_loss: 3.2866e-05\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.1135e-04 - val_loss: 4.3267e-05\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.2343e-04 - val_loss: 3.1691e-05\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.1181e-04 - val_loss: 4.0308e-05\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.0403e-04 - val_loss: 4.4068e-05\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.1216e-04 - val_loss: 4.2633e-05\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.0091e-04 - val_loss: 3.2813e-05\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.0006e-04 - val_loss: 3.4446e-05\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.0326e-04 - val_loss: 3.1619e-05\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.0379e-04 - val_loss: 3.1424e-05\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.1645e-04 - val_loss: 3.2269e-05\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.8544e-04 - val_loss: 3.2983e-05\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.8838e-04 - val_loss: 3.1633e-05\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.7723e-04 - val_loss: 3.1598e-05\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.7897e-04 - val_loss: 3.4030e-05\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.6635e-04 - val_loss: 5.1198e-05\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.9120e-04 - val_loss: 3.4997e-05\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.6073e-04 - val_loss: 4.1359e-05\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.7092e-04 - val_loss: 3.7190e-05\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.7002e-04 - val_loss: 3.5976e-05\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.6049e-04 - val_loss: 3.5596e-05\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.6677e-04 - val_loss: 3.6456e-05\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.5579e-04 - val_loss: 3.1038e-05\n",
      "Epoch 54/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 10ms/step - loss: 6.5303e-04 - val_loss: 3.2136e-05\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.5898e-04 - val_loss: 2.9746e-05\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.4127e-04 - val_loss: 4.3834e-05\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.4464e-04 - val_loss: 4.7419e-05\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.5996e-04 - val_loss: 3.9775e-05\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.3409e-04 - val_loss: 3.1114e-05\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.5912e-04 - val_loss: 5.9442e-05\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.4494e-04 - val_loss: 3.4283e-05\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.2631e-04 - val_loss: 3.4235e-05\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.2561e-04 - val_loss: 4.0994e-05\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.3046e-04 - val_loss: 3.4856e-05\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.0961e-04 - val_loss: 4.0815e-05\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.2778e-04 - val_loss: 5.3750e-05\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.3801e-04 - val_loss: 4.1418e-05\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.1022e-04 - val_loss: 4.0277e-05\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.1769e-04 - val_loss: 2.8449e-05\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.1046e-04 - val_loss: 3.5096e-05\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.0411e-04 - val_loss: 3.6681e-05\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.0339e-04 - val_loss: 3.4912e-05\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.8543e-04 - val_loss: 3.0950e-05\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.8742e-04 - val_loss: 3.4034e-05\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.8725e-04 - val_loss: 3.5088e-05\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.8467e-04 - val_loss: 2.7596e-05\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.9822e-04 - val_loss: 2.9746e-05\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.8573e-04 - val_loss: 2.7217e-05\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.6042e-04 - val_loss: 3.4491e-05\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.6347e-04 - val_loss: 6.8163e-05\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.0149e-04 - val_loss: 5.3168e-05\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.7185e-04 - val_loss: 7.2123e-05\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.6089e-04 - val_loss: 5.5609e-05\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.7091e-04 - val_loss: 3.9182e-05\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.5394e-04 - val_loss: 2.8438e-05\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.4876e-04 - val_loss: 2.5870e-05\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.5231e-04 - val_loss: 3.2452e-05\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.5343e-04 - val_loss: 4.2303e-05\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.3168e-04 - val_loss: 3.1083e-05\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.3148e-04 - val_loss: 4.8742e-05\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.4027e-04 - val_loss: 2.9783e-05\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.2168e-04 - val_loss: 3.9383e-05\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.1471e-04 - val_loss: 4.8859e-05\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.3270e-04 - val_loss: 2.5711e-05\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.1473e-04 - val_loss: 4.4105e-05\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.0156e-04 - val_loss: 4.0655e-05\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.1443e-04 - val_loss: 2.6702e-05\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.0866e-04 - val_loss: 4.4543e-05\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.9030e-04 - val_loss: 3.7783e-05\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.2703e-04 - val_loss: 2.6970e-05\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.1231e-04 - val_loss: 3.6022e-05\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.8827e-04 - val_loss: 4.6449e-05\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.9276e-04 - val_loss: 2.6048e-05\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.7850e-04 - val_loss: 4.1311e-05\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.7384e-04 - val_loss: 5.8410e-05\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.7024e-04 - val_loss: 3.9807e-05\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.0942e-04 - val_loss: 4.2535e-05\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.7446e-04 - val_loss: 3.8554e-05\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.7710e-04 - val_loss: 4.0788e-05\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.6439e-04 - val_loss: 3.1753e-05\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.9005e-04 - val_loss: 2.2811e-05\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.7088e-04 - val_loss: 2.6282e-05\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.8049e-04 - val_loss: 3.1784e-05\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.7014e-04 - val_loss: 2.2680e-05\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.1139e-04 - val_loss: 3.7397e-05\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.5781e-04 - val_loss: 4.5499e-05\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.7736e-04 - val_loss: 2.9921e-05\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.0620e-04 - val_loss: 4.6177e-05\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.5109e-04 - val_loss: 2.2655e-05\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.6462e-04 - val_loss: 3.4187e-05\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.4069e-04 - val_loss: 3.7394e-05\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.6372e-04 - val_loss: 3.5070e-05\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.3338e-04 - val_loss: 4.2074e-05\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.5128e-04 - val_loss: 4.0729e-05\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.4590e-04 - val_loss: 2.7327e-05\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.4094e-04 - val_loss: 3.5615e-05\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.3781e-04 - val_loss: 2.1467e-05\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.6494e-04 - val_loss: 4.2405e-05\n",
      "Epoch 129/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 10ms/step - loss: 4.4202e-04 - val_loss: 2.2872e-05\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.3350e-04 - val_loss: 2.7573e-05\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.3882e-04 - val_loss: 3.4844e-05\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.3543e-04 - val_loss: 3.3568e-05\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.1979e-04 - val_loss: 3.1958e-05\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.2872e-04 - val_loss: 2.7749e-05\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.2172e-04 - val_loss: 3.4690e-05\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.1119e-04 - val_loss: 2.0842e-05\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.3346e-04 - val_loss: 2.0825e-05\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.5454e-04 - val_loss: 4.9701e-05\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.2831e-04 - val_loss: 2.0578e-05\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.3669e-04 - val_loss: 2.5337e-05\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.0567e-04 - val_loss: 2.1344e-05\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 4.2576e-04 - val_loss: 2.0822e-05\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 1s 12ms/step - loss: 4.4388e-04 - val_loss: 2.0454e-05\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 4.1839e-04 - val_loss: 2.1353e-05\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 4.0113e-04 - val_loss: 3.9693e-05\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 4.1817e-04 - val_loss: 2.1224e-05\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 4.0412e-04 - val_loss: 2.1267e-05\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 4.1886e-04 - val_loss: 2.2089e-05\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 4.0109e-04 - val_loss: 2.2019e-05\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 3.9542e-04 - val_loss: 2.6797e-05\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 3.9606e-04 - val_loss: 2.2867e-05\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 3.8816e-04 - val_loss: 1.9265e-05\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 3.9183e-04 - val_loss: 1.9927e-05\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.8619e-04 - val_loss: 2.3652e-05\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.0172e-04 - val_loss: 2.4414e-05\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.0534e-04 - val_loss: 2.1282e-05\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.9231e-04 - val_loss: 2.0185e-05\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.9171e-04 - val_loss: 2.0218e-05\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.1355e-04 - val_loss: 2.6131e-05\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.8695e-04 - val_loss: 2.3580e-05\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.7652e-04 - val_loss: 1.9078e-05\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.0618e-04 - val_loss: 1.8607e-05\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.8066e-04 - val_loss: 1.8845e-05\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.0311e-04 - val_loss: 1.8859e-05\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.7933e-04 - val_loss: 1.9325e-05\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.7268e-04 - val_loss: 2.4239e-05\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.8039e-04 - val_loss: 2.0744e-05\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.6868e-04 - val_loss: 2.1692e-05\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.6992e-04 - val_loss: 2.1852e-05\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.9989e-04 - val_loss: 3.0786e-05\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.7437e-04 - val_loss: 2.2332e-05\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.6259e-04 - val_loss: 2.6772e-05\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.6985e-04 - val_loss: 2.1978e-05\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.6099e-04 - val_loss: 2.0383e-05\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.6811e-04 - val_loss: 1.7778e-05\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.6453e-04 - val_loss: 2.3339e-05\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.7025e-04 - val_loss: 2.0041e-05\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.5149e-04 - val_loss: 2.1111e-05\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.6745e-04 - val_loss: 3.7693e-05\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.6677e-04 - val_loss: 3.9553e-05\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.5571e-04 - val_loss: 1.7865e-05\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 3.5175e-04 - val_loss: 2.5842e-05\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 3.5409e-04 - val_loss: 2.5915e-05\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.4852e-04 - val_loss: 2.2622e-05\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.5807e-04 - val_loss: 1.8311e-05\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.7772e-04 - val_loss: 1.9084e-05\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.5460e-04 - val_loss: 1.8071e-05\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.5086e-04 - val_loss: 1.9079e-05\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.6170e-04 - val_loss: 2.3873e-05\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.3929e-04 - val_loss: 2.0292e-05\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.3956e-04 - val_loss: 1.7407e-05\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.3783e-04 - val_loss: 1.7912e-05\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.5923e-04 - val_loss: 3.9131e-05\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.3857e-04 - val_loss: 2.4256e-05\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.3651e-04 - val_loss: 1.8642e-05\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.5052e-04 - val_loss: 1.7043e-05\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.2951e-04 - val_loss: 1.6940e-05\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.4024e-04 - val_loss: 2.2085e-05\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.5873e-04 - val_loss: 2.3404e-05\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 3.2759e-04 - val_loss: 1.8694e-05\n",
      "Thời gian huấn luyện:  85.12328934669495\n",
      "Model: \"sequential_134\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_33 (LSTM)              (None, 10, 116)           54752     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " flatten_134 (Flatten)       (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,913\n",
      "Trainable params: 55,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Epoch 1/200\n",
      "46/46 [==============================] - 2s 16ms/step - loss: 0.0486 - val_loss: 3.9759e-04\n",
      "Epoch 2/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 7.5024e-04 - val_loss: 2.8641e-05\n",
      "Epoch 3/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.5552e-04 - val_loss: 2.6801e-05\n",
      "Epoch 4/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.4675e-04 - val_loss: 3.0135e-05\n",
      "Epoch 5/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.6516e-04 - val_loss: 2.6185e-05\n",
      "Epoch 6/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3343e-04 - val_loss: 2.7392e-05\n",
      "Epoch 7/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3135e-04 - val_loss: 2.5673e-05\n",
      "Epoch 8/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.2824e-04 - val_loss: 2.8796e-05\n",
      "Epoch 9/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3188e-04 - val_loss: 5.1838e-05\n",
      "Epoch 10/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.2834e-04 - val_loss: 2.9083e-05\n",
      "Epoch 11/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.1221e-04 - val_loss: 2.9552e-05\n",
      "Epoch 12/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.1046e-04 - val_loss: 2.6165e-05\n",
      "Epoch 13/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.0206e-04 - val_loss: 2.6665e-05\n",
      "Epoch 14/200\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 5.9696e-04 - val_loss: 2.7876e-05\n",
      "Epoch 15/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.9457e-04 - val_loss: 2.6682e-05\n",
      "Epoch 16/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.8772e-04 - val_loss: 2.3915e-05\n",
      "Epoch 17/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.9412e-04 - val_loss: 2.9284e-05\n",
      "Epoch 18/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.7987e-04 - val_loss: 3.9151e-05\n",
      "Epoch 19/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.8166e-04 - val_loss: 2.7637e-05\n",
      "Epoch 20/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.7104e-04 - val_loss: 2.3525e-05\n",
      "Epoch 21/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.7065e-04 - val_loss: 2.3030e-05\n",
      "Epoch 22/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.7097e-04 - val_loss: 2.6645e-05\n",
      "Epoch 23/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.6182e-04 - val_loss: 2.2941e-05\n",
      "Epoch 24/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.6964e-04 - val_loss: 2.2903e-05\n",
      "Epoch 25/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.5394e-04 - val_loss: 3.4668e-05\n",
      "Epoch 26/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.3592e-04 - val_loss: 3.5539e-05\n",
      "Epoch 27/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.3615e-04 - val_loss: 2.1935e-05\n",
      "Epoch 28/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.3051e-04 - val_loss: 2.3155e-05\n",
      "Epoch 29/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.2803e-04 - val_loss: 2.2255e-05\n",
      "Epoch 30/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.1895e-04 - val_loss: 2.2937e-05\n",
      "Epoch 31/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.1523e-04 - val_loss: 2.4156e-05\n",
      "Epoch 32/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.2873e-04 - val_loss: 2.3341e-05\n",
      "Epoch 33/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.0327e-04 - val_loss: 2.5505e-05\n",
      "Epoch 34/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.9881e-04 - val_loss: 2.0929e-05\n",
      "Epoch 35/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.9652e-04 - val_loss: 2.7611e-05\n",
      "Epoch 36/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.8426e-04 - val_loss: 2.0682e-05\n",
      "Epoch 37/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.8402e-04 - val_loss: 2.0125e-05\n",
      "Epoch 38/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.7685e-04 - val_loss: 2.2386e-05\n",
      "Epoch 39/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.7139e-04 - val_loss: 1.9559e-05\n",
      "Epoch 40/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.8108e-04 - val_loss: 2.3995e-05\n",
      "Epoch 41/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.6014e-04 - val_loss: 2.7697e-05\n",
      "Epoch 42/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.5572e-04 - val_loss: 2.1853e-05\n",
      "Epoch 43/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.4713e-04 - val_loss: 2.7532e-05\n",
      "Epoch 44/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.4937e-04 - val_loss: 4.7164e-05\n",
      "Epoch 45/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.5030e-04 - val_loss: 2.2161e-05\n",
      "Epoch 46/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.3679e-04 - val_loss: 1.9601e-05\n",
      "Epoch 47/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.4933e-04 - val_loss: 1.8216e-05\n",
      "Epoch 48/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.2765e-04 - val_loss: 1.8651e-05\n",
      "Epoch 49/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.2221e-04 - val_loss: 2.6114e-05\n",
      "Epoch 50/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.3153e-04 - val_loss: 3.7534e-05\n",
      "Epoch 51/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.2365e-04 - val_loss: 1.7713e-05\n",
      "Epoch 52/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.1851e-04 - val_loss: 2.6859e-05\n",
      "Epoch 53/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.1694e-04 - val_loss: 3.2970e-05\n",
      "Epoch 54/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.9829e-04 - val_loss: 1.6816e-05\n",
      "Epoch 55/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.0024e-04 - val_loss: 2.2521e-05\n",
      "Epoch 56/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.9006e-04 - val_loss: 2.2056e-05\n",
      "Epoch 57/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.8665e-04 - val_loss: 1.6193e-05\n",
      "Epoch 58/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.8738e-04 - val_loss: 1.5756e-05\n",
      "Epoch 59/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.8125e-04 - val_loss: 2.0132e-05\n",
      "Epoch 60/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.7961e-04 - val_loss: 2.7918e-05\n",
      "Epoch 61/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.7381e-04 - val_loss: 2.3701e-05\n",
      "Epoch 62/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.9370e-04 - val_loss: 1.5449e-05\n",
      "Epoch 63/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.6692e-04 - val_loss: 3.5830e-05\n",
      "Epoch 64/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.9174e-04 - val_loss: 1.5273e-05\n",
      "Epoch 65/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.7492e-04 - val_loss: 1.5787e-05\n",
      "Epoch 66/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.6043e-04 - val_loss: 1.7926e-05\n",
      "Epoch 67/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.5439e-04 - val_loss: 1.7862e-05\n",
      "Epoch 68/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.5529e-04 - val_loss: 1.4930e-05\n",
      "Epoch 69/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.5105e-04 - val_loss: 1.4414e-05\n",
      "Epoch 70/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.4502e-04 - val_loss: 1.9371e-05\n",
      "Epoch 71/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 9ms/step - loss: 3.5439e-04 - val_loss: 2.7895e-05\n",
      "Epoch 72/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.4339e-04 - val_loss: 2.3375e-05\n",
      "Epoch 73/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.4216e-04 - val_loss: 1.3989e-05\n",
      "Epoch 74/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.5059e-04 - val_loss: 1.4139e-05\n",
      "Epoch 75/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.4914e-04 - val_loss: 1.8597e-05\n",
      "Epoch 76/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.3575e-04 - val_loss: 1.4012e-05\n",
      "Epoch 77/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.2647e-04 - val_loss: 1.3481e-05\n",
      "Epoch 78/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.2760e-04 - val_loss: 1.5747e-05\n",
      "Epoch 79/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.2720e-04 - val_loss: 1.3728e-05\n",
      "Epoch 80/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.3319e-04 - val_loss: 1.3140e-05\n",
      "Epoch 81/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.1465e-04 - val_loss: 1.3492e-05\n",
      "Epoch 82/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.2729e-04 - val_loss: 1.6032e-05\n",
      "Epoch 83/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.1233e-04 - val_loss: 1.3180e-05\n",
      "Epoch 84/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.1182e-04 - val_loss: 1.4729e-05\n",
      "Epoch 85/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.0516e-04 - val_loss: 5.0309e-05\n",
      "Epoch 86/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.3368e-04 - val_loss: 1.6607e-05\n",
      "Epoch 87/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.1571e-04 - val_loss: 1.3865e-05\n",
      "Epoch 88/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.9648e-04 - val_loss: 3.4316e-05\n",
      "Epoch 89/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.0239e-04 - val_loss: 1.6737e-05\n",
      "Epoch 90/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.9756e-04 - val_loss: 2.0405e-05\n",
      "Epoch 91/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.9436e-04 - val_loss: 1.8433e-05\n",
      "Epoch 92/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.9656e-04 - val_loss: 1.2247e-05\n",
      "Epoch 93/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.9421e-04 - val_loss: 1.6596e-05\n",
      "Epoch 94/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.9649e-04 - val_loss: 2.0086e-05\n",
      "Epoch 95/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.8917e-04 - val_loss: 1.4418e-05\n",
      "Epoch 96/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.9902e-04 - val_loss: 1.3212e-05\n",
      "Epoch 97/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.9014e-04 - val_loss: 1.8998e-05\n",
      "Epoch 98/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.8196e-04 - val_loss: 1.2835e-05\n",
      "Epoch 99/200\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 2.8488e-04 - val_loss: 1.8533e-05\n",
      "Epoch 100/200\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.8143e-04 - val_loss: 1.1648e-05\n",
      "Epoch 101/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.8020e-04 - val_loss: 1.6066e-05\n",
      "Epoch 102/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.8105e-04 - val_loss: 1.3333e-05\n",
      "Epoch 103/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.8110e-04 - val_loss: 1.1236e-05\n",
      "Epoch 104/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.7410e-04 - val_loss: 1.1148e-05\n",
      "Epoch 105/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.6724e-04 - val_loss: 3.1214e-05\n",
      "Epoch 106/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.8442e-04 - val_loss: 2.8280e-05\n",
      "Epoch 107/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.8032e-04 - val_loss: 1.6466e-05\n",
      "Epoch 108/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.7689e-04 - val_loss: 1.1532e-05\n",
      "Epoch 109/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.6488e-04 - val_loss: 1.8554e-05\n",
      "Epoch 110/200\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.7157e-04 - val_loss: 1.2331e-05\n",
      "Epoch 111/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.0417e-04 - val_loss: 1.8314e-05\n",
      "Epoch 112/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.6069e-04 - val_loss: 1.3902e-05\n",
      "Epoch 113/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.6287e-04 - val_loss: 1.0783e-05\n",
      "Epoch 114/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.6366e-04 - val_loss: 1.1250e-05\n",
      "Epoch 115/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.5746e-04 - val_loss: 2.0002e-05\n",
      "Epoch 116/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.5925e-04 - val_loss: 1.1375e-05\n",
      "Epoch 117/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.5508e-04 - val_loss: 1.8572e-05\n",
      "Epoch 118/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.6773e-04 - val_loss: 5.1235e-05\n",
      "Epoch 119/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.5705e-04 - val_loss: 2.4075e-05\n",
      "Epoch 120/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.5189e-04 - val_loss: 1.0623e-05\n",
      "Epoch 121/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.4853e-04 - val_loss: 1.0636e-05\n",
      "Epoch 122/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.5098e-04 - val_loss: 1.4118e-05\n",
      "Epoch 123/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.4269e-04 - val_loss: 1.4595e-05\n",
      "Epoch 124/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.4524e-04 - val_loss: 1.1968e-05\n",
      "Epoch 125/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.4657e-04 - val_loss: 1.0192e-05\n",
      "Epoch 126/200\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.5592e-04 - val_loss: 1.3522e-05\n",
      "Epoch 127/200\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.5054e-04 - val_loss: 1.7755e-05\n",
      "Epoch 128/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.4104e-04 - val_loss: 1.5427e-05\n",
      "Epoch 129/200\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.8626e-04 - val_loss: 1.0015e-05\n",
      "Epoch 130/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.4063e-04 - val_loss: 1.5493e-05\n",
      "Epoch 131/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.3912e-04 - val_loss: 1.1559e-05\n",
      "Epoch 132/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.5902e-04 - val_loss: 1.4872e-05\n",
      "Epoch 133/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.3511e-04 - val_loss: 1.1788e-05\n",
      "Epoch 134/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.3522e-04 - val_loss: 1.0632e-05\n",
      "Epoch 135/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.2917e-04 - val_loss: 1.1656e-05\n",
      "Epoch 136/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.3571e-04 - val_loss: 9.3720e-06\n",
      "Epoch 137/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.3146e-04 - val_loss: 1.7164e-05\n",
      "Epoch 138/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.5703e-04 - val_loss: 2.0339e-05\n",
      "Epoch 139/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.2970e-04 - val_loss: 1.5479e-05\n",
      "Epoch 140/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.2641e-04 - val_loss: 9.5760e-06\n",
      "Epoch 141/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.3047e-04 - val_loss: 1.0514e-05\n",
      "Epoch 142/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.2489e-04 - val_loss: 1.4018e-05\n",
      "Epoch 143/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.2809e-04 - val_loss: 1.2191e-05\n",
      "Epoch 144/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.2636e-04 - val_loss: 9.1070e-06\n",
      "Epoch 145/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.2074e-04 - val_loss: 1.0409e-05\n",
      "Epoch 146/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 9ms/step - loss: 2.1710e-04 - val_loss: 1.0110e-05\n",
      "Epoch 147/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.2396e-04 - val_loss: 9.4557e-06\n",
      "Epoch 148/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.1837e-04 - val_loss: 9.0587e-06\n",
      "Epoch 149/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.1886e-04 - val_loss: 1.1295e-05\n",
      "Epoch 150/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.1524e-04 - val_loss: 2.1860e-05\n",
      "Epoch 151/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.2699e-04 - val_loss: 1.2025e-05\n",
      "Epoch 152/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.1091e-04 - val_loss: 1.1284e-05\n",
      "Epoch 153/200\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.1927e-04 - val_loss: 9.0063e-06\n",
      "Epoch 154/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.1530e-04 - val_loss: 1.4322e-05\n",
      "Epoch 155/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.3450e-04 - val_loss: 1.9561e-05\n",
      "Epoch 156/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.2023e-04 - val_loss: 8.8474e-06\n",
      "Epoch 157/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.1689e-04 - val_loss: 9.7363e-06\n",
      "Epoch 158/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.0516e-04 - val_loss: 1.6398e-05\n",
      "Epoch 159/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.0939e-04 - val_loss: 3.0332e-05\n",
      "Epoch 160/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.2594e-04 - val_loss: 1.2421e-05\n",
      "Epoch 161/200\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.0523e-04 - val_loss: 8.4066e-06\n",
      "Epoch 162/200\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.0119e-04 - val_loss: 8.5756e-06\n",
      "Epoch 163/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.0858e-04 - val_loss: 8.4503e-06\n",
      "Epoch 164/200\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.0721e-04 - val_loss: 1.0565e-05\n",
      "Epoch 165/200\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.0700e-04 - val_loss: 1.1073e-05\n",
      "Epoch 166/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.9753e-04 - val_loss: 9.2362e-06\n",
      "Epoch 167/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.0906e-04 - val_loss: 9.1777e-06\n",
      "Epoch 168/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.2653e-04 - val_loss: 8.9458e-06\n",
      "Epoch 169/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.1910e-04 - val_loss: 9.4282e-06\n",
      "Epoch 170/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.2336e-04 - val_loss: 9.7992e-06\n",
      "Epoch 171/200\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.0041e-04 - val_loss: 9.5906e-06\n",
      "Epoch 172/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.0345e-04 - val_loss: 1.0608e-05\n",
      "Epoch 173/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.0216e-04 - val_loss: 9.5111e-06\n",
      "Epoch 174/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.2101e-04 - val_loss: 8.3782e-06\n",
      "Epoch 175/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.0627e-04 - val_loss: 1.3697e-05\n",
      "Epoch 176/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.9589e-04 - val_loss: 1.0319e-05\n",
      "Epoch 177/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.9214e-04 - val_loss: 8.5710e-06\n",
      "Epoch 178/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.9339e-04 - val_loss: 1.1461e-05\n",
      "Epoch 179/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.8989e-04 - val_loss: 9.1164e-06\n",
      "Epoch 180/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.9219e-04 - val_loss: 1.7631e-05\n",
      "Epoch 181/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.0609e-04 - val_loss: 8.2913e-06\n",
      "Epoch 182/200\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.8919e-04 - val_loss: 1.5167e-05\n",
      "Epoch 183/200\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.8653e-04 - val_loss: 8.7965e-06\n",
      "Epoch 184/200\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.8730e-04 - val_loss: 1.6495e-05\n",
      "Epoch 185/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.8812e-04 - val_loss: 8.4886e-06\n",
      "Epoch 186/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.8847e-04 - val_loss: 1.0585e-05\n",
      "Epoch 187/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.8527e-04 - val_loss: 9.1403e-06\n",
      "Epoch 188/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.9221e-04 - val_loss: 1.4168e-05\n",
      "Epoch 189/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.0709e-04 - val_loss: 1.2668e-05\n",
      "Epoch 190/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.8250e-04 - val_loss: 1.1709e-05\n",
      "Epoch 191/200\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.9075e-04 - val_loss: 1.6735e-05\n",
      "Epoch 192/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.9415e-04 - val_loss: 7.6045e-06\n",
      "Epoch 193/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.8956e-04 - val_loss: 1.1751e-05\n",
      "Epoch 194/200\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.8262e-04 - val_loss: 7.5232e-06\n",
      "Epoch 195/200\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.8097e-04 - val_loss: 7.4523e-06\n",
      "Epoch 196/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.8371e-04 - val_loss: 9.0194e-06\n",
      "Epoch 197/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.7890e-04 - val_loss: 1.0307e-05\n",
      "Epoch 198/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.8617e-04 - val_loss: 9.5451e-06\n",
      "Epoch 199/200\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.7703e-04 - val_loss: 7.2321e-06\n",
      "Epoch 200/200\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.8998e-04 - val_loss: 1.2228e-05\n",
      "Thời gian huấn luyện:  84.8051688671112\n",
      "Model: \"sequential_135\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_32 (GRU)                (None, 10, 116)           41412     \n",
      "                                                                 \n",
      " flatten_135 (Flatten)       (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,573\n",
      "Trainable params: 42,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.0029\n",
      "Thời gian huấn luyện:  18.873573064804077\n",
      "Model: \"sequential_136\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_171 (Dense)           (None, 20, 116)           232       \n",
      "                                                                 \n",
      " flatten_136 (Flatten)       (None, 2320)              0         \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 1)                 2321      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,553\n",
      "Trainable params: 2,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "44/44 [==============================] - 1s 9ms/step - loss: 0.0261 - val_loss: 0.0017\n",
      "Epoch 2/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 7.4442e-04\n",
      "Epoch 3/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 3.4127e-04\n",
      "Epoch 4/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 2.3993e-04\n",
      "Epoch 5/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 1.1686e-04\n",
      "Epoch 6/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 8.3168e-05\n",
      "Epoch 7/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.2102e-05\n",
      "Epoch 8/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.9863e-05\n",
      "Epoch 9/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 4.9698e-05\n",
      "Epoch 10/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 9.9820e-04 - val_loss: 4.2665e-05\n",
      "Epoch 11/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 9.7116e-04 - val_loss: 4.5708e-05\n",
      "Epoch 12/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 9.5955e-04 - val_loss: 4.0049e-05\n",
      "Epoch 13/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 3.8495e-05\n",
      "Epoch 14/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 8.9192e-04 - val_loss: 3.9797e-05\n",
      "Epoch 15/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 9.4058e-04 - val_loss: 3.5570e-05\n",
      "Epoch 16/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 8.8329e-04 - val_loss: 3.5211e-05\n",
      "Epoch 17/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 8.6214e-04 - val_loss: 3.4004e-05\n",
      "Epoch 18/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 8.5762e-04 - val_loss: 3.5252e-05\n",
      "Epoch 19/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 7.4927e-04 - val_loss: 3.2758e-05\n",
      "Epoch 20/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 7.4410e-04 - val_loss: 3.0890e-05\n",
      "Epoch 21/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 7.4724e-04 - val_loss: 3.6938e-05\n",
      "Epoch 22/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 7.3629e-04 - val_loss: 2.9025e-05\n",
      "Epoch 23/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 7.4063e-04 - val_loss: 3.2758e-05\n",
      "Epoch 24/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 7.2218e-04 - val_loss: 3.2199e-05\n",
      "Epoch 25/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 6.7254e-04 - val_loss: 3.8210e-05\n",
      "Epoch 26/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 6.7841e-04 - val_loss: 2.7947e-05\n",
      "Epoch 27/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 6.4830e-04 - val_loss: 2.7289e-05\n",
      "Epoch 28/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 6.3309e-04 - val_loss: 2.8107e-05\n",
      "Epoch 29/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 6.2688e-04 - val_loss: 2.6898e-05\n",
      "Epoch 30/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 6.3177e-04 - val_loss: 2.6088e-05\n",
      "Epoch 31/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 6.4882e-04 - val_loss: 2.6100e-05\n",
      "Epoch 32/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 6.0376e-04 - val_loss: 3.0020e-05\n",
      "Epoch 33/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 6.1936e-04 - val_loss: 2.5267e-05\n",
      "Epoch 34/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 5.9934e-04 - val_loss: 2.4243e-05\n",
      "Epoch 35/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 6.2667e-04 - val_loss: 4.6209e-05\n",
      "Epoch 36/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 6.2431e-04 - val_loss: 2.6156e-05\n",
      "Epoch 37/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 5.7711e-04 - val_loss: 2.3934e-05\n",
      "Epoch 38/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 5.6771e-04 - val_loss: 2.3601e-05\n",
      "Epoch 39/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 5.3323e-04 - val_loss: 2.2875e-05\n",
      "Epoch 40/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 5.2650e-04 - val_loss: 3.4674e-05\n",
      "Epoch 41/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 5.3755e-04 - val_loss: 2.5060e-05\n",
      "Epoch 42/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 5.1733e-04 - val_loss: 2.1917e-05\n",
      "Epoch 43/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 5.6168e-04 - val_loss: 2.1217e-05\n",
      "Epoch 44/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 5.2531e-04 - val_loss: 2.5101e-05\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 6ms/step - loss: 5.0105e-04 - val_loss: 2.0973e-05\n",
      "Epoch 46/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 5.2379e-04 - val_loss: 2.4145e-05\n",
      "Epoch 47/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 5.7415e-04 - val_loss: 2.0529e-05\n",
      "Epoch 48/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.6226e-04 - val_loss: 2.5258e-05\n",
      "Epoch 49/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.9443e-04 - val_loss: 1.9609e-05\n",
      "Epoch 50/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.9007e-04 - val_loss: 2.2193e-05\n",
      "Epoch 51/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.6346e-04 - val_loss: 2.0472e-05\n",
      "Epoch 52/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.4091e-04 - val_loss: 1.8490e-05\n",
      "Epoch 53/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.4658e-04 - val_loss: 1.8367e-05\n",
      "Epoch 54/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.5252e-04 - val_loss: 1.8195e-05\n",
      "Epoch 55/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.3658e-04 - val_loss: 1.8877e-05\n",
      "Epoch 56/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.3458e-04 - val_loss: 1.7529e-05\n",
      "Epoch 57/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.1151e-04 - val_loss: 1.7285e-05\n",
      "Epoch 58/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.3946e-04 - val_loss: 1.7614e-05\n",
      "Epoch 59/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.1103e-04 - val_loss: 1.7897e-05\n",
      "Epoch 60/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.2402e-04 - val_loss: 1.6703e-05\n",
      "Epoch 61/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.0173e-04 - val_loss: 1.5941e-05\n",
      "Epoch 62/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.0685e-04 - val_loss: 1.6270e-05\n",
      "Epoch 63/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.2426e-04 - val_loss: 1.7424e-05\n",
      "Epoch 64/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 5.5255e-04 - val_loss: 2.0281e-05\n",
      "Epoch 65/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.8676e-04 - val_loss: 1.6598e-05\n",
      "Epoch 66/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.8092e-04 - val_loss: 1.5739e-05\n",
      "Epoch 67/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.6981e-04 - val_loss: 1.6452e-05\n",
      "Epoch 68/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.7119e-04 - val_loss: 1.5498e-05\n",
      "Epoch 69/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.8354e-04 - val_loss: 1.4964e-05\n",
      "Epoch 70/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.7970e-04 - val_loss: 1.5593e-05\n",
      "Epoch 71/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.7667e-04 - val_loss: 1.5648e-05\n",
      "Epoch 72/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.5019e-04 - val_loss: 1.4900e-05\n",
      "Epoch 73/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.6931e-04 - val_loss: 2.2616e-05\n",
      "Epoch 74/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.7715e-04 - val_loss: 2.4840e-05\n",
      "Epoch 75/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.0294e-04 - val_loss: 1.4615e-05\n",
      "Epoch 76/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.3830e-04 - val_loss: 1.4290e-05\n",
      "Epoch 77/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.6136e-04 - val_loss: 2.1256e-05\n",
      "Epoch 78/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.5503e-04 - val_loss: 1.4257e-05\n",
      "Epoch 79/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.5343e-04 - val_loss: 1.4666e-05\n",
      "Epoch 80/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.4882e-04 - val_loss: 1.7324e-05\n",
      "Epoch 81/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.3500e-04 - val_loss: 1.4444e-05\n",
      "Epoch 82/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.8570e-04 - val_loss: 1.3387e-05\n",
      "Epoch 83/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.8650e-04 - val_loss: 1.2479e-05\n",
      "Epoch 84/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.4589e-04 - val_loss: 1.5211e-05\n",
      "Epoch 85/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.7333e-04 - val_loss: 2.7820e-05\n",
      "Epoch 86/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.3727e-04 - val_loss: 1.3790e-05\n",
      "Epoch 87/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.2930e-04 - val_loss: 1.3063e-05\n",
      "Epoch 88/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.0768e-04 - val_loss: 1.7556e-05\n",
      "Epoch 89/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.0380e-04 - val_loss: 1.5265e-05\n",
      "Epoch 90/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.0527e-04 - val_loss: 1.1993e-05\n",
      "Epoch 91/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.4220e-04 - val_loss: 1.2795e-05\n",
      "Epoch 92/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.1287e-04 - val_loss: 1.2848e-05\n",
      "Epoch 93/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.2759e-04 - val_loss: 1.1660e-05\n",
      "Epoch 94/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.3505e-04 - val_loss: 1.2269e-05\n",
      "Epoch 95/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.1247e-04 - val_loss: 1.2243e-05\n",
      "Epoch 96/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.6985e-04 - val_loss: 1.1451e-05\n",
      "Epoch 97/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.0292e-04 - val_loss: 1.2111e-05\n",
      "Epoch 98/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.8062e-04 - val_loss: 1.1452e-05\n",
      "Epoch 99/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.0384e-04 - val_loss: 1.9529e-05\n",
      "Epoch 100/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.2031e-04 - val_loss: 1.4661e-05\n",
      "Epoch 101/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.9588e-04 - val_loss: 1.1253e-05\n",
      "Epoch 102/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.7804e-04 - val_loss: 1.0757e-05\n",
      "Epoch 103/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.8790e-04 - val_loss: 1.0998e-05\n",
      "Epoch 104/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.7469e-04 - val_loss: 1.6903e-05\n",
      "Epoch 105/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.9656e-04 - val_loss: 1.1131e-05\n",
      "Epoch 106/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.1390e-04 - val_loss: 1.6132e-05\n",
      "Epoch 107/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.9515e-04 - val_loss: 1.0705e-05\n",
      "Epoch 108/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.0949e-04 - val_loss: 1.0426e-05\n",
      "Epoch 109/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.8215e-04 - val_loss: 1.7935e-05\n",
      "Epoch 110/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.8276e-04 - val_loss: 1.7999e-05\n",
      "Epoch 111/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.6927e-04 - val_loss: 1.6599e-05\n",
      "Epoch 112/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.6766e-04 - val_loss: 1.2120e-05\n",
      "Epoch 113/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.6122e-04 - val_loss: 1.1578e-05\n",
      "Epoch 114/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.6346e-04 - val_loss: 1.3710e-05\n",
      "Epoch 115/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.4594e-04 - val_loss: 1.1092e-05\n",
      "Epoch 116/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.4981e-04 - val_loss: 1.0429e-05\n",
      "Epoch 117/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.7302e-04 - val_loss: 1.0040e-05\n",
      "Epoch 118/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.5922e-04 - val_loss: 1.0218e-05\n",
      "Epoch 119/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.7232e-04 - val_loss: 1.0195e-05\n",
      "Epoch 120/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.5175e-04 - val_loss: 1.0249e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.6949e-04 - val_loss: 1.0507e-05\n",
      "Epoch 122/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.6244e-04 - val_loss: 2.3651e-05\n",
      "Epoch 123/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.6971e-04 - val_loss: 1.4539e-05\n",
      "Epoch 124/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.4178e-04 - val_loss: 9.7486e-06\n",
      "Epoch 125/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.7252e-04 - val_loss: 1.0755e-05\n",
      "Epoch 126/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.3259e-04 - val_loss: 1.0049e-05\n",
      "Epoch 127/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.4047e-04 - val_loss: 1.0026e-05\n",
      "Epoch 128/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.4901e-04 - val_loss: 8.9103e-06\n",
      "Epoch 129/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.2340e-04 - val_loss: 9.4791e-06\n",
      "Epoch 130/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.1715e-04 - val_loss: 8.7537e-06\n",
      "Epoch 131/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.3950e-04 - val_loss: 8.8699e-06\n",
      "Epoch 132/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.7113e-04 - val_loss: 9.0532e-06\n",
      "Epoch 133/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.2207e-04 - val_loss: 1.2005e-05\n",
      "Epoch 134/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.1753e-04 - val_loss: 9.9889e-06\n",
      "Epoch 135/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.6609e-04 - val_loss: 9.9590e-06\n",
      "Epoch 136/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.2421e-04 - val_loss: 1.3110e-05\n",
      "Epoch 137/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.2539e-04 - val_loss: 1.0003e-05\n",
      "Epoch 138/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.3740e-04 - val_loss: 1.1890e-05\n",
      "Epoch 139/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.3476e-04 - val_loss: 1.3908e-05\n",
      "Epoch 140/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.0970e-04 - val_loss: 8.4420e-06\n",
      "Epoch 141/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.0751e-04 - val_loss: 8.7486e-06\n",
      "Epoch 142/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.4956e-04 - val_loss: 9.2529e-06\n",
      "Epoch 143/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.3336e-04 - val_loss: 1.4052e-05\n",
      "Epoch 144/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.3669e-04 - val_loss: 8.3664e-06\n",
      "Epoch 145/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.0566e-04 - val_loss: 1.1692e-05\n",
      "Epoch 146/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.3409e-04 - val_loss: 9.9866e-06\n",
      "Epoch 147/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.1775e-04 - val_loss: 1.1108e-05\n",
      "Epoch 148/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.6560e-04 - val_loss: 8.8112e-06\n",
      "Epoch 149/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.0395e-04 - val_loss: 8.2332e-06\n",
      "Epoch 150/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.1058e-04 - val_loss: 1.3368e-05\n",
      "Epoch 151/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.2193e-04 - val_loss: 7.8027e-06\n",
      "Epoch 152/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.0065e-04 - val_loss: 1.2572e-05\n",
      "Epoch 153/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.1311e-04 - val_loss: 1.2010e-05\n",
      "Epoch 154/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.2709e-04 - val_loss: 9.1472e-06\n",
      "Epoch 155/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.3083e-04 - val_loss: 8.8638e-06\n",
      "Epoch 156/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.0114e-04 - val_loss: 1.3958e-05\n",
      "Epoch 157/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.1504e-04 - val_loss: 1.2326e-05\n",
      "Epoch 158/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.0359e-04 - val_loss: 1.0645e-05\n",
      "Epoch 159/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.9853e-04 - val_loss: 8.8257e-06\n",
      "Epoch 160/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.9825e-04 - val_loss: 1.1440e-05\n",
      "Epoch 161/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.2708e-04 - val_loss: 9.3621e-06\n",
      "Epoch 162/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.5493e-04 - val_loss: 7.6415e-06\n",
      "Epoch 163/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.9166e-04 - val_loss: 1.8654e-05\n",
      "Epoch 164/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.5198e-04 - val_loss: 7.9585e-06\n",
      "Epoch 165/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.1658e-04 - val_loss: 7.4000e-06\n",
      "Epoch 166/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.9602e-04 - val_loss: 8.9814e-06\n",
      "Epoch 167/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.0511e-04 - val_loss: 7.4349e-06\n",
      "Epoch 168/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.9433e-04 - val_loss: 7.8811e-06\n",
      "Epoch 169/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.4885e-04 - val_loss: 1.1090e-05\n",
      "Epoch 170/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.8398e-04 - val_loss: 7.2436e-06\n",
      "Epoch 171/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.9530e-04 - val_loss: 7.5144e-06\n",
      "Epoch 172/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.0314e-04 - val_loss: 8.7018e-06\n",
      "Epoch 173/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.0015e-04 - val_loss: 8.8325e-06\n",
      "Epoch 174/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.2678e-04 - val_loss: 7.4861e-06\n",
      "Epoch 175/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.0191e-04 - val_loss: 1.0224e-05\n",
      "Epoch 176/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.9926e-04 - val_loss: 1.1163e-05\n",
      "Epoch 177/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.7622e-04 - val_loss: 7.5164e-06\n",
      "Epoch 178/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.8113e-04 - val_loss: 1.2479e-05\n",
      "Epoch 179/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.0051e-04 - val_loss: 1.3284e-05\n",
      "Epoch 180/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.6174e-04 - val_loss: 8.1707e-06\n",
      "Epoch 181/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.0403e-04 - val_loss: 7.0153e-06\n",
      "Epoch 182/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.8981e-04 - val_loss: 7.1216e-06\n",
      "Epoch 183/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.8046e-04 - val_loss: 7.7136e-06\n",
      "Epoch 184/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.0210e-04 - val_loss: 7.0243e-06\n",
      "Epoch 185/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.8022e-04 - val_loss: 7.6876e-06\n",
      "Epoch 186/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.8102e-04 - val_loss: 1.4607e-05\n",
      "Epoch 187/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.7218e-04 - val_loss: 7.9872e-06\n",
      "Epoch 188/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.7083e-04 - val_loss: 7.0836e-06\n",
      "Epoch 189/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.7938e-04 - val_loss: 6.8573e-06\n",
      "Epoch 190/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.8874e-04 - val_loss: 7.6860e-06\n",
      "Epoch 191/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.7854e-04 - val_loss: 2.3210e-05\n",
      "Epoch 192/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.8070e-04 - val_loss: 7.0130e-06\n",
      "Epoch 193/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.8381e-04 - val_loss: 7.0801e-06\n",
      "Epoch 194/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.7188e-04 - val_loss: 1.3755e-05\n",
      "Epoch 195/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.7062e-04 - val_loss: 6.5376e-06\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 6ms/step - loss: 1.7721e-04 - val_loss: 6.5494e-06\n",
      "Epoch 197/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.8594e-04 - val_loss: 8.2705e-06\n",
      "Epoch 198/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.7165e-04 - val_loss: 9.0866e-06\n",
      "Epoch 199/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.7450e-04 - val_loss: 7.5711e-06\n",
      "Epoch 200/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.7481e-04 - val_loss: 8.5969e-06\n",
      "Thời gian huấn luyện:  51.68769979476929\n",
      "Model: \"sequential_137\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_34 (SimpleRNN)   (None, 20, 116)           13688     \n",
      "                                                                 \n",
      " flatten_137 (Flatten)       (None, 2320)              0         \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 1)                 2321      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,009\n",
      "Trainable params: 16,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "51/51 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 2s 25ms/step - loss: 0.0271 - val_loss: 3.8510e-04\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0016 - val_loss: 7.4153e-05\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0013 - val_loss: 1.0112e-04\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0013 - val_loss: 1.0515e-04\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0013 - val_loss: 1.0727e-04\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0013 - val_loss: 8.7609e-05\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0012 - val_loss: 1.3186e-04\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0012 - val_loss: 1.1088e-04\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0012 - val_loss: 9.1183e-05\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0012 - val_loss: 9.2364e-05\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0012 - val_loss: 1.0253e-04\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0011 - val_loss: 6.8137e-05\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0012 - val_loss: 1.1443e-04\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0011 - val_loss: 9.2136e-05\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0011 - val_loss: 1.0686e-04\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0011 - val_loss: 9.4163e-05\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0011 - val_loss: 8.3187e-05\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0011 - val_loss: 1.0425e-04\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0011 - val_loss: 1.1863e-04\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0011 - val_loss: 6.6426e-05\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0011 - val_loss: 1.0787e-04\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0011 - val_loss: 8.7403e-05\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0011 - val_loss: 7.4790e-05\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0010 - val_loss: 9.2878e-05\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 9.9598e-04 - val_loss: 9.1521e-05\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 9.8064e-04 - val_loss: 9.1327e-05\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 9.9026e-04 - val_loss: 9.8666e-05\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0010 - val_loss: 8.0222e-05\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 9.5290e-04 - val_loss: 8.7050e-05\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 9.2658e-04 - val_loss: 6.2607e-05\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 9.4885e-04 - val_loss: 5.8406e-05\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 9.0794e-04 - val_loss: 6.3126e-05\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 9.0105e-04 - val_loss: 6.3995e-05\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 8.7357e-04 - val_loss: 7.0581e-05\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 8.6385e-04 - val_loss: 5.8332e-05\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 8.6309e-04 - val_loss: 7.3081e-05\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 8.3468e-04 - val_loss: 6.8499e-05\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 8.2193e-04 - val_loss: 9.2858e-05\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 8.4194e-04 - val_loss: 6.6142e-05\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 8.0361e-04 - val_loss: 5.6054e-05\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 8.0735e-04 - val_loss: 4.9241e-05\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 8.4121e-04 - val_loss: 9.4844e-05\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 8.3216e-04 - val_loss: 5.4382e-05\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 7.8304e-04 - val_loss: 6.6943e-05\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 7.6069e-04 - val_loss: 6.3008e-05\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 7.6930e-04 - val_loss: 6.6723e-05\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 7.4261e-04 - val_loss: 6.8648e-05\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 7.4271e-04 - val_loss: 1.0314e-04\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 7.4143e-04 - val_loss: 8.3101e-05\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 7.0876e-04 - val_loss: 6.6094e-05\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 7.2939e-04 - val_loss: 5.3155e-05\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 7.2956e-04 - val_loss: 6.1733e-05\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 7.4105e-04 - val_loss: 6.1836e-05\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 6.8843e-04 - val_loss: 8.0507e-05\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 6.8497e-04 - val_loss: 6.5767e-05\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 6.6062e-04 - val_loss: 8.8956e-05\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 6.6867e-04 - val_loss: 1.2501e-04\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 6.7709e-04 - val_loss: 6.9810e-05\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 6.5483e-04 - val_loss: 9.8227e-05\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 6.7202e-04 - val_loss: 6.9401e-05\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 6.3097e-04 - val_loss: 1.1062e-04\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 6.8176e-04 - val_loss: 7.6495e-05\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 17ms/step - loss: 6.4562e-04 - val_loss: 4.7421e-05\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 7.0141e-04 - val_loss: 5.6279e-05\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 6.1403e-04 - val_loss: 1.1836e-04\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 6.3476e-04 - val_loss: 4.8698e-05\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 7.0345e-04 - val_loss: 8.4685e-05\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 6.2463e-04 - val_loss: 7.9319e-05\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 6.2648e-04 - val_loss: 5.0932e-05\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 6.0142e-04 - val_loss: 7.7031e-05\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 5.9429e-04 - val_loss: 4.4736e-05\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 5.9206e-04 - val_loss: 6.9799e-05\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 5.9770e-04 - val_loss: 8.5613e-05\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 5.9705e-04 - val_loss: 4.2018e-05\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 5.8842e-04 - val_loss: 8.2921e-05\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 5.8237e-04 - val_loss: 5.1502e-05\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 5.8962e-04 - val_loss: 5.2684e-05\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 5.7264e-04 - val_loss: 6.0613e-05\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 5.8328e-04 - val_loss: 5.5724e-05\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 5.9233e-04 - val_loss: 5.8214e-05\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 5.5851e-04 - val_loss: 6.1075e-05\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 5.5582e-04 - val_loss: 4.5075e-05\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 5.6337e-04 - val_loss: 7.7617e-05\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 5.5132e-04 - val_loss: 3.2468e-05\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 5.7354e-04 - val_loss: 5.7123e-05\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 5.3436e-04 - val_loss: 5.5198e-05\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 5.3072e-04 - val_loss: 3.8477e-05\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 5.4942e-04 - val_loss: 7.3470e-05\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 5.3139e-04 - val_loss: 5.4868e-05\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 5.3335e-04 - val_loss: 4.8045e-05\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 5.2565e-04 - val_loss: 4.3384e-05\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 5.1101e-04 - val_loss: 3.4347e-05\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 5.4310e-04 - val_loss: 4.3574e-05\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 5.1842e-04 - val_loss: 4.7361e-05\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 5.0801e-04 - val_loss: 5.9077e-05\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 5.0716e-04 - val_loss: 3.8507e-05\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 5.1058e-04 - val_loss: 4.0176e-05\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 5.0789e-04 - val_loss: 2.9495e-05\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 5.2966e-04 - val_loss: 2.9269e-05\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 5.2399e-04 - val_loss: 4.9016e-05\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 4.9311e-04 - val_loss: 4.7798e-05\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 4.7508e-04 - val_loss: 5.8124e-05\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 5.2913e-04 - val_loss: 3.5739e-05\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 4.9155e-04 - val_loss: 2.9158e-05\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 4.8429e-04 - val_loss: 5.2507e-05\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 4.7203e-04 - val_loss: 4.9027e-05\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 4.7528e-04 - val_loss: 4.4058e-05\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 4.9637e-04 - val_loss: 2.9512e-05\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 5.4714e-04 - val_loss: 4.5810e-05\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 4.8907e-04 - val_loss: 5.0508e-05\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 4.8564e-04 - val_loss: 2.5337e-05\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 4.7575e-04 - val_loss: 3.7213e-05\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 4.5461e-04 - val_loss: 5.7516e-05\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 4.5901e-04 - val_loss: 4.3106e-05\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 4.5007e-04 - val_loss: 4.3191e-05\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 4.5321e-04 - val_loss: 4.1717e-05\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 4.5187e-04 - val_loss: 4.3315e-05\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 4.7942e-04 - val_loss: 2.5163e-05\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 4.7903e-04 - val_loss: 3.6715e-05\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 4.3821e-04 - val_loss: 3.9813e-05\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 4.5332e-04 - val_loss: 2.8449e-05\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 4.4782e-04 - val_loss: 3.6988e-05\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 4.3787e-04 - val_loss: 5.4728e-05\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 4.5044e-04 - val_loss: 3.7962e-05\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 4.2051e-04 - val_loss: 2.7903e-05\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 4.3021e-04 - val_loss: 5.5277e-05\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 4.1959e-04 - val_loss: 4.8627e-05\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 4.2084e-04 - val_loss: 3.5416e-05\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 4.4915e-04 - val_loss: 3.0842e-05\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 4.3417e-04 - val_loss: 3.7425e-05\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 4.3201e-04 - val_loss: 3.5313e-05\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 4.1037e-04 - val_loss: 4.1924e-05\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 4.2530e-04 - val_loss: 2.4487e-05\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 4.1985e-04 - val_loss: 3.2923e-05\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 4.1128e-04 - val_loss: 4.6075e-05\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 4.0664e-04 - val_loss: 4.8637e-05\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 4.0774e-04 - val_loss: 2.9924e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 4.0573e-04 - val_loss: 2.7730e-05\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.9580e-04 - val_loss: 3.1041e-05\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.9669e-04 - val_loss: 2.9009e-05\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.8511e-04 - val_loss: 2.3649e-05\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 4.1320e-04 - val_loss: 3.0535e-05\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.8294e-04 - val_loss: 4.1108e-05\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 3.9140e-04 - val_loss: 3.1621e-05\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.8458e-04 - val_loss: 4.2599e-05\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 4.2236e-04 - val_loss: 2.3303e-05\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.9592e-04 - val_loss: 3.1025e-05\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 3.9079e-04 - val_loss: 3.3638e-05\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 3.8650e-04 - val_loss: 3.2231e-05\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 4.2087e-04 - val_loss: 2.4564e-05\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 3.9627e-04 - val_loss: 3.5666e-05\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 3.6855e-04 - val_loss: 2.6101e-05\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 3.7285e-04 - val_loss: 6.4105e-05\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 3.6403e-04 - val_loss: 3.8104e-05\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 4.0320e-04 - val_loss: 3.0098e-05\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.7482e-04 - val_loss: 2.6169e-05\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 3.7410e-04 - val_loss: 2.3415e-05\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 3.6914e-04 - val_loss: 2.6376e-05\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 3.8344e-04 - val_loss: 5.7674e-05\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.6389e-04 - val_loss: 2.5067e-05\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.6097e-04 - val_loss: 2.2210e-05\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 3.6599e-04 - val_loss: 2.4401e-05\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.4809e-04 - val_loss: 3.5051e-05\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.4246e-04 - val_loss: 2.4837e-05\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.4519e-04 - val_loss: 2.1390e-05\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.9439e-04 - val_loss: 3.3117e-05\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.5560e-04 - val_loss: 2.7378e-05\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 3.6098e-04 - val_loss: 2.5649e-05\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 3.4142e-04 - val_loss: 2.0742e-05\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 3.4469e-04 - val_loss: 2.8487e-05\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.3549e-04 - val_loss: 2.9938e-05\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.3228e-04 - val_loss: 3.2545e-05\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.2965e-04 - val_loss: 3.6343e-05\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.3763e-04 - val_loss: 1.8472e-05\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 3.2952e-04 - val_loss: 3.5290e-05\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 3.3058e-04 - val_loss: 3.2313e-05\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 3.4170e-04 - val_loss: 2.4173e-05\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 3.4446e-04 - val_loss: 2.6732e-05\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.4308e-04 - val_loss: 3.6372e-05\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 3.6640e-04 - val_loss: 3.0644e-05\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.1401e-04 - val_loss: 2.3647e-05\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.2999e-04 - val_loss: 1.7671e-05\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.2636e-04 - val_loss: 2.0181e-05\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 3.2787e-04 - val_loss: 2.5161e-05\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 3.1376e-04 - val_loss: 2.2878e-05\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 3.1664e-04 - val_loss: 3.1577e-05\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.2917e-04 - val_loss: 2.1502e-05\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.2689e-04 - val_loss: 2.6605e-05\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.1176e-04 - val_loss: 1.6889e-05\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.1352e-04 - val_loss: 1.5890e-05\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 3.1305e-04 - val_loss: 2.1339e-05\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 3.2506e-04 - val_loss: 2.1289e-05\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 3.1113e-04 - val_loss: 3.4876e-05\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 3.2262e-04 - val_loss: 1.6878e-05\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 3.0930e-04 - val_loss: 1.9686e-05\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 2.9286e-04 - val_loss: 2.6422e-05\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 2.9634e-04 - val_loss: 2.6482e-05\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 2.9244e-04 - val_loss: 3.3732e-05\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 3.0948e-04 - val_loss: 2.1802e-05\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 2.9475e-04 - val_loss: 2.0249e-05\n",
      "Thời gian huấn luyện:  143.23818349838257\n",
      "Model: \"sequential_138\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_34 (LSTM)              (None, 20, 116)           54752     \n",
      "                                                                 \n",
      " flatten_138 (Flatten)       (None, 2320)              0         \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 1)                 2321      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,073\n",
      "Trainable params: 57,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "51/51 [==============================] - 1s 6ms/step\n",
      "13/13 [==============================] - 0s 6ms/step\n",
      "Epoch 1/200\n",
      "46/46 [==============================] - 3s 23ms/step - loss: 0.0187 - val_loss: 4.4123e-05\n",
      "Epoch 2/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 9.5163e-04 - val_loss: 5.3747e-05\n",
      "Epoch 3/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 8.6452e-04 - val_loss: 4.8216e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 8.5255e-04 - val_loss: 4.4043e-05\n",
      "Epoch 5/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 8.2812e-04 - val_loss: 4.7876e-05\n",
      "Epoch 6/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 8.1417e-04 - val_loss: 4.5605e-05\n",
      "Epoch 7/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 7.9905e-04 - val_loss: 3.9489e-05\n",
      "Epoch 8/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 7.8332e-04 - val_loss: 4.0364e-05\n",
      "Epoch 9/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 7.6911e-04 - val_loss: 4.9716e-05\n",
      "Epoch 10/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 7.5460e-04 - val_loss: 4.8573e-05\n",
      "Epoch 11/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 7.4124e-04 - val_loss: 3.4984e-05\n",
      "Epoch 12/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 7.2638e-04 - val_loss: 4.5035e-05\n",
      "Epoch 13/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 7.1163e-04 - val_loss: 3.2067e-05\n",
      "Epoch 14/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 7.0940e-04 - val_loss: 5.2851e-05\n",
      "Epoch 15/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 6.8363e-04 - val_loss: 3.2622e-05\n",
      "Epoch 16/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 6.6118e-04 - val_loss: 2.9753e-05\n",
      "Epoch 17/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 6.6617e-04 - val_loss: 3.1637e-05\n",
      "Epoch 18/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 6.4255e-04 - val_loss: 2.9445e-05\n",
      "Epoch 19/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 6.3636e-04 - val_loss: 3.0407e-05\n",
      "Epoch 20/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 6.2486e-04 - val_loss: 2.9138e-05\n",
      "Epoch 21/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 6.0087e-04 - val_loss: 4.4337e-05\n",
      "Epoch 22/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 5.9236e-04 - val_loss: 2.5786e-05\n",
      "Epoch 23/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 5.8818e-04 - val_loss: 2.6551e-05\n",
      "Epoch 24/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 5.8417e-04 - val_loss: 2.6233e-05\n",
      "Epoch 25/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 5.6589e-04 - val_loss: 2.6604e-05\n",
      "Epoch 26/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 5.4606e-04 - val_loss: 3.1336e-05\n",
      "Epoch 27/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 5.6912e-04 - val_loss: 2.3528e-05\n",
      "Epoch 28/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 5.2230e-04 - val_loss: 2.2801e-05\n",
      "Epoch 29/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 5.2214e-04 - val_loss: 2.6513e-05\n",
      "Epoch 30/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 5.1709e-04 - val_loss: 2.9736e-05\n",
      "Epoch 31/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 4.9937e-04 - val_loss: 2.2821e-05\n",
      "Epoch 32/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 4.9326e-04 - val_loss: 2.6120e-05\n",
      "Epoch 33/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 4.9090e-04 - val_loss: 2.0773e-05\n",
      "Epoch 34/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 4.8675e-04 - val_loss: 2.3594e-05\n",
      "Epoch 35/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 4.5929e-04 - val_loss: 1.9367e-05\n",
      "Epoch 36/200\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 4.6901e-04 - val_loss: 2.2415e-05\n",
      "Epoch 37/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 4.6739e-04 - val_loss: 2.2857e-05\n",
      "Epoch 38/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 4.4740e-04 - val_loss: 3.0487e-05\n",
      "Epoch 39/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 4.4094e-04 - val_loss: 2.2403e-05\n",
      "Epoch 40/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 4.3889e-04 - val_loss: 1.9257e-05\n",
      "Epoch 41/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 4.2531e-04 - val_loss: 1.8994e-05\n",
      "Epoch 42/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 4.4031e-04 - val_loss: 2.5608e-05\n",
      "Epoch 43/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 4.2838e-04 - val_loss: 2.4201e-05\n",
      "Epoch 44/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 4.4178e-04 - val_loss: 1.7422e-05\n",
      "Epoch 45/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 4.1313e-04 - val_loss: 1.6789e-05\n",
      "Epoch 46/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 4.1398e-04 - val_loss: 2.9285e-05\n",
      "Epoch 47/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 4.1141e-04 - val_loss: 1.8107e-05\n",
      "Epoch 48/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 4.0266e-04 - val_loss: 1.7049e-05\n",
      "Epoch 49/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 4.4740e-04 - val_loss: 4.7679e-05\n",
      "Epoch 50/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.9932e-04 - val_loss: 1.7750e-05\n",
      "Epoch 51/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.9983e-04 - val_loss: 2.2246e-05\n",
      "Epoch 52/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.8779e-04 - val_loss: 2.1394e-05\n",
      "Epoch 53/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.8398e-04 - val_loss: 3.2060e-05\n",
      "Epoch 54/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.8831e-04 - val_loss: 1.5506e-05\n",
      "Epoch 55/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.7011e-04 - val_loss: 1.7494e-05\n",
      "Epoch 56/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.7283e-04 - val_loss: 1.9377e-05\n",
      "Epoch 57/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.8126e-04 - val_loss: 1.5800e-05\n",
      "Epoch 58/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 4.0934e-04 - val_loss: 2.3524e-05\n",
      "Epoch 59/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.9342e-04 - val_loss: 1.5128e-05\n",
      "Epoch 60/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.6716e-04 - val_loss: 1.7207e-05\n",
      "Epoch 61/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.5230e-04 - val_loss: 1.6031e-05\n",
      "Epoch 62/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.4525e-04 - val_loss: 2.2377e-05\n",
      "Epoch 63/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.5556e-04 - val_loss: 2.0896e-05\n",
      "Epoch 64/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.4109e-04 - val_loss: 2.0780e-05\n",
      "Epoch 65/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 3.4733e-04 - val_loss: 1.4492e-05\n",
      "Epoch 66/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.5543e-04 - val_loss: 1.5315e-05\n",
      "Epoch 67/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.4133e-04 - val_loss: 1.6427e-05\n",
      "Epoch 68/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.3538e-04 - val_loss: 1.3901e-05\n",
      "Epoch 69/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.4829e-04 - val_loss: 1.3847e-05\n",
      "Epoch 70/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.3261e-04 - val_loss: 1.3717e-05\n",
      "Epoch 71/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.5359e-04 - val_loss: 1.6153e-05\n",
      "Epoch 72/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.2445e-04 - val_loss: 1.3694e-05\n",
      "Epoch 73/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.2339e-04 - val_loss: 2.2699e-05\n",
      "Epoch 74/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.1612e-04 - val_loss: 1.6524e-05\n",
      "Epoch 75/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.2102e-04 - val_loss: 1.3095e-05\n",
      "Epoch 76/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.3110e-04 - val_loss: 2.4487e-05\n",
      "Epoch 77/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.1416e-04 - val_loss: 1.3038e-05\n",
      "Epoch 78/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.1753e-04 - val_loss: 1.3998e-05\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 15ms/step - loss: 3.5177e-04 - val_loss: 1.2974e-05\n",
      "Epoch 80/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.4704e-04 - val_loss: 1.2874e-05\n",
      "Epoch 81/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.3624e-04 - val_loss: 1.2600e-05\n",
      "Epoch 82/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 3.1564e-04 - val_loss: 1.3470e-05\n",
      "Epoch 83/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 3.0093e-04 - val_loss: 1.4211e-05\n",
      "Epoch 84/200\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 3.0653e-04 - val_loss: 1.4638e-05\n",
      "Epoch 85/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.9741e-04 - val_loss: 1.4032e-05\n",
      "Epoch 86/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 3.1517e-04 - val_loss: 1.5205e-05\n",
      "Epoch 87/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.8547e-04 - val_loss: 1.1691e-05\n",
      "Epoch 88/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.9258e-04 - val_loss: 1.2438e-05\n",
      "Epoch 89/200\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 3.0567e-04 - val_loss: 1.2912e-05\n",
      "Epoch 90/200\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 2.8208e-04 - val_loss: 1.3732e-05\n",
      "Epoch 91/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.9136e-04 - val_loss: 1.2806e-05\n",
      "Epoch 92/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.8694e-04 - val_loss: 1.5374e-05\n",
      "Epoch 93/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.8586e-04 - val_loss: 1.4683e-05\n",
      "Epoch 94/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.8036e-04 - val_loss: 5.0949e-05\n",
      "Epoch 95/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.8516e-04 - val_loss: 1.7218e-05\n",
      "Epoch 96/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.8761e-04 - val_loss: 3.3943e-05\n",
      "Epoch 97/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.8830e-04 - val_loss: 1.3974e-05\n",
      "Epoch 98/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.7301e-04 - val_loss: 1.0837e-05\n",
      "Epoch 99/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.8230e-04 - val_loss: 1.1769e-05\n",
      "Epoch 100/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.7011e-04 - val_loss: 2.3187e-05\n",
      "Epoch 101/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.6355e-04 - val_loss: 1.1222e-05\n",
      "Epoch 102/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.7861e-04 - val_loss: 1.1953e-05\n",
      "Epoch 103/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.8809e-04 - val_loss: 2.8008e-05\n",
      "Epoch 104/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.7800e-04 - val_loss: 2.1092e-05\n",
      "Epoch 105/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.6926e-04 - val_loss: 1.5878e-05\n",
      "Epoch 106/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.7279e-04 - val_loss: 1.2156e-05\n",
      "Epoch 107/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.6751e-04 - val_loss: 1.2309e-05\n",
      "Epoch 108/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.5785e-04 - val_loss: 1.0779e-05\n",
      "Epoch 109/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.5668e-04 - val_loss: 1.0223e-05\n",
      "Epoch 110/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.5291e-04 - val_loss: 1.1152e-05\n",
      "Epoch 111/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.4467e-04 - val_loss: 1.0263e-05\n",
      "Epoch 112/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.7290e-04 - val_loss: 1.6545e-05\n",
      "Epoch 113/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.7468e-04 - val_loss: 1.2906e-05\n",
      "Epoch 114/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.5624e-04 - val_loss: 9.8584e-06\n",
      "Epoch 115/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.5083e-04 - val_loss: 1.1414e-05\n",
      "Epoch 116/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.4739e-04 - val_loss: 1.1750e-05\n",
      "Epoch 117/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.5062e-04 - val_loss: 9.7363e-06\n",
      "Epoch 118/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.4531e-04 - val_loss: 1.2979e-05\n",
      "Epoch 119/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.4663e-04 - val_loss: 2.3282e-05\n",
      "Epoch 120/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.4012e-04 - val_loss: 9.4902e-06\n",
      "Epoch 121/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.6349e-04 - val_loss: 1.8572e-05\n",
      "Epoch 122/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.4458e-04 - val_loss: 1.3815e-05\n",
      "Epoch 123/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.3480e-04 - val_loss: 1.5438e-05\n",
      "Epoch 124/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.3237e-04 - val_loss: 9.5495e-06\n",
      "Epoch 125/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.4459e-04 - val_loss: 9.6650e-06\n",
      "Epoch 126/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.3607e-04 - val_loss: 1.1196e-05\n",
      "Epoch 127/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.2968e-04 - val_loss: 9.2821e-06\n",
      "Epoch 128/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.2959e-04 - val_loss: 1.0377e-05\n",
      "Epoch 129/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.2213e-04 - val_loss: 1.3598e-05\n",
      "Epoch 130/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.2856e-04 - val_loss: 9.2521e-06\n",
      "Epoch 131/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.2498e-04 - val_loss: 1.2921e-05\n",
      "Epoch 132/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.2281e-04 - val_loss: 9.2155e-06\n",
      "Epoch 133/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.3084e-04 - val_loss: 9.0107e-06\n",
      "Epoch 134/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.1934e-04 - val_loss: 1.2146e-05\n",
      "Epoch 135/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.2261e-04 - val_loss: 9.8049e-06\n",
      "Epoch 136/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.2136e-04 - val_loss: 8.9682e-06\n",
      "Epoch 137/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.2116e-04 - val_loss: 1.0601e-05\n",
      "Epoch 138/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.3513e-04 - val_loss: 9.5340e-06\n",
      "Epoch 139/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.4107e-04 - val_loss: 1.1495e-05\n",
      "Epoch 140/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.3280e-04 - val_loss: 2.4238e-05\n",
      "Epoch 141/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.3867e-04 - val_loss: 9.7403e-06\n",
      "Epoch 142/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.1048e-04 - val_loss: 1.2658e-05\n",
      "Epoch 143/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.0554e-04 - val_loss: 1.2032e-05\n",
      "Epoch 144/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.1664e-04 - val_loss: 1.3748e-05\n",
      "Epoch 145/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.0729e-04 - val_loss: 8.4874e-06\n",
      "Epoch 146/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.0439e-04 - val_loss: 8.6162e-06\n",
      "Epoch 147/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.1727e-04 - val_loss: 1.2153e-05\n",
      "Epoch 148/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.1197e-04 - val_loss: 1.4223e-05\n",
      "Epoch 149/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.0553e-04 - val_loss: 8.2680e-06\n",
      "Epoch 150/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.0867e-04 - val_loss: 8.1023e-06\n",
      "Epoch 151/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.0381e-04 - val_loss: 8.1931e-06\n",
      "Epoch 152/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.2082e-04 - val_loss: 8.9148e-06\n",
      "Epoch 153/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 1.9702e-04 - val_loss: 8.4772e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.1899e-04 - val_loss: 8.3105e-06\n",
      "Epoch 155/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 1.9789e-04 - val_loss: 1.7738e-05\n",
      "Epoch 156/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.1136e-04 - val_loss: 9.4414e-06\n",
      "Epoch 157/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.9757e-04 - val_loss: 8.4294e-06\n",
      "Epoch 158/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.8870e-04 - val_loss: 8.4921e-06\n",
      "Epoch 159/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.0677e-04 - val_loss: 9.2081e-06\n",
      "Epoch 160/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.8856e-04 - val_loss: 8.2146e-06\n",
      "Epoch 161/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.9569e-04 - val_loss: 9.1974e-06\n",
      "Epoch 162/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 2.2493e-04 - val_loss: 9.9240e-06\n",
      "Epoch 163/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.9021e-04 - val_loss: 8.8113e-06\n",
      "Epoch 164/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.8797e-04 - val_loss: 8.7425e-06\n",
      "Epoch 165/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.9151e-04 - val_loss: 1.0756e-05\n",
      "Epoch 166/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.9776e-04 - val_loss: 8.3192e-06\n",
      "Epoch 167/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.9816e-04 - val_loss: 1.2693e-05\n",
      "Epoch 168/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.8213e-04 - val_loss: 1.4478e-05\n",
      "Epoch 169/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.8646e-04 - val_loss: 1.1332e-05\n",
      "Epoch 170/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.8366e-04 - val_loss: 9.8647e-06\n",
      "Epoch 171/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.9821e-04 - val_loss: 7.3280e-06\n",
      "Epoch 172/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.9023e-04 - val_loss: 7.5004e-06\n",
      "Epoch 173/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.8133e-04 - val_loss: 1.0608e-05\n",
      "Epoch 174/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.7856e-04 - val_loss: 8.4815e-06\n",
      "Epoch 175/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.9415e-04 - val_loss: 7.3736e-06\n",
      "Epoch 176/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.7741e-04 - val_loss: 7.2756e-06\n",
      "Epoch 177/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.8538e-04 - val_loss: 7.1869e-06\n",
      "Epoch 178/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 1.7909e-04 - val_loss: 7.4094e-06\n",
      "Epoch 179/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.9750e-04 - val_loss: 1.0013e-05\n",
      "Epoch 180/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.9046e-04 - val_loss: 7.0544e-06\n",
      "Epoch 181/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.7430e-04 - val_loss: 7.9888e-06\n",
      "Epoch 182/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.7560e-04 - val_loss: 6.9997e-06\n",
      "Epoch 183/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.9291e-04 - val_loss: 7.7228e-06\n",
      "Epoch 184/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.7996e-04 - val_loss: 1.1430e-05\n",
      "Epoch 185/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.7773e-04 - val_loss: 7.9042e-06\n",
      "Epoch 186/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.7419e-04 - val_loss: 6.9204e-06\n",
      "Epoch 187/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.8747e-04 - val_loss: 1.4347e-05\n",
      "Epoch 188/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.9152e-04 - val_loss: 7.1888e-06\n",
      "Epoch 189/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.7333e-04 - val_loss: 8.0787e-06\n",
      "Epoch 190/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.6607e-04 - val_loss: 1.2005e-05\n",
      "Epoch 191/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.7158e-04 - val_loss: 1.1342e-05\n",
      "Epoch 192/200\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 1.7643e-04 - val_loss: 6.8047e-06\n",
      "Epoch 193/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.7702e-04 - val_loss: 7.3611e-06\n",
      "Epoch 194/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.8535e-04 - val_loss: 2.0223e-05\n",
      "Epoch 195/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.7761e-04 - val_loss: 8.2724e-06\n",
      "Epoch 196/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.6637e-04 - val_loss: 1.1130e-05\n",
      "Epoch 197/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.7119e-04 - val_loss: 1.1261e-05\n",
      "Epoch 198/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.6352e-04 - val_loss: 7.8101e-06\n",
      "Epoch 199/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.6962e-04 - val_loss: 9.6986e-06\n",
      "Epoch 200/200\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 1.6569e-04 - val_loss: 6.8676e-06\n",
      "Thời gian huấn luyện:  139.74518203735352\n",
      "Model: \"sequential_139\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_33 (GRU)                (None, 20, 116)           41412     \n",
      "                                                                 \n",
      " flatten_139 (Flatten)       (None, 2320)              0         \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 1)                 2321      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,733\n",
      "Trainable params: 43,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "51/51 [==============================] - 1s 4ms/step\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 21/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 103/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 184/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0029\n",
      "Thời gian huấn luyện:  20.919647455215454\n",
      "Model: \"sequential_140\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_176 (Dense)           (None, 30, 115)           230       \n",
      "                                                                 \n",
      " flatten_140 (Flatten)       (None, 3450)              0         \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 1)                 3451      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,681\n",
      "Trainable params: 3,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 1s 12ms/step - loss: 0.0427 - val_loss: 0.0014\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 3.8082e-04\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 2.2166e-04\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 2.1353e-04\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 9.0136e-05\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 9.2003e-05\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 5.7101e-05\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 5.6454e-05\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 4.4832e-05\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 9.6834e-04 - val_loss: 4.2673e-05\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 9.2250e-04 - val_loss: 4.4117e-05\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 9.6439e-04 - val_loss: 4.7305e-05\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 8.6954e-04 - val_loss: 3.5873e-05\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 8.3685e-04 - val_loss: 3.6811e-05\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 8.2851e-04 - val_loss: 3.3722e-05\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 8.2277e-04 - val_loss: 3.2892e-05\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 7.5532e-04 - val_loss: 3.3918e-05\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 7.5664e-04 - val_loss: 3.2935e-05\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 7.1061e-04 - val_loss: 3.6857e-05\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 6.7633e-04 - val_loss: 3.0738e-05\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 6.6126e-04 - val_loss: 3.0268e-05\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 6.5426e-04 - val_loss: 3.0060e-05\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 6.6752e-04 - val_loss: 2.8630e-05\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 6.4548e-04 - val_loss: 2.7783e-05\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 6.2126e-04 - val_loss: 2.9251e-05\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 6.1655e-04 - val_loss: 3.1553e-05\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 5.8828e-04 - val_loss: 3.1268e-05\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 5.9360e-04 - val_loss: 2.7295e-05\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 5.6340e-04 - val_loss: 2.8133e-05\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 5.5640e-04 - val_loss: 2.5292e-05\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 5.6821e-04 - val_loss: 3.3350e-05\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 5.3557e-04 - val_loss: 2.3570e-05\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 5.4502e-04 - val_loss: 3.6752e-05\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 6.3200e-04 - val_loss: 2.2884e-05\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 5.4764e-04 - val_loss: 2.8694e-05\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 5.2494e-04 - val_loss: 3.3012e-05\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 5.0025e-04 - val_loss: 2.4912e-05\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 5.9222e-04 - val_loss: 2.5152e-05\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 5.2835e-04 - val_loss: 2.3518e-05\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 4.9805e-04 - val_loss: 2.1102e-05\n",
      "Epoch 41/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 5.0017e-04 - val_loss: 2.7871e-05\n",
      "Epoch 42/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 4.8693e-04 - val_loss: 2.4362e-05\n",
      "Epoch 43/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 4.6094e-04 - val_loss: 2.0990e-05\n",
      "Epoch 44/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 4.6148e-04 - val_loss: 2.5833e-05\n",
      "Epoch 45/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 5.1177e-04 - val_loss: 2.1375e-05\n",
      "Epoch 46/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 4.4560e-04 - val_loss: 2.3022e-05\n",
      "Epoch 47/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 4.4345e-04 - val_loss: 2.5872e-05\n",
      "Epoch 48/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 4.9167e-04 - val_loss: 2.1691e-05\n",
      "Epoch 49/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 4.3193e-04 - val_loss: 1.7746e-05\n",
      "Epoch 50/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 4.2684e-04 - val_loss: 1.9000e-05\n",
      "Epoch 51/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 5.5027e-04 - val_loss: 2.4313e-05\n",
      "Epoch 52/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 9ms/step - loss: 4.2637e-04 - val_loss: 1.7722e-05\n",
      "Epoch 53/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 4.3777e-04 - val_loss: 2.8468e-05\n",
      "Epoch 54/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 4.2783e-04 - val_loss: 1.7609e-05\n",
      "Epoch 55/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 4.2265e-04 - val_loss: 1.7101e-05\n",
      "Epoch 56/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 4.1356e-04 - val_loss: 2.4958e-05\n",
      "Epoch 57/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 4.2054e-04 - val_loss: 1.9818e-05\n",
      "Epoch 58/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 4.1812e-04 - val_loss: 1.7455e-05\n",
      "Epoch 59/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 4.0672e-04 - val_loss: 1.9001e-05\n",
      "Epoch 60/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 4.2305e-04 - val_loss: 1.6235e-05\n",
      "Epoch 61/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 4.4462e-04 - val_loss: 2.7253e-05\n",
      "Epoch 62/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.9918e-04 - val_loss: 1.5384e-05\n",
      "Epoch 63/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.8453e-04 - val_loss: 1.6065e-05\n",
      "Epoch 64/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 3.9360e-04 - val_loss: 1.5213e-05\n",
      "Epoch 65/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 3.8439e-04 - val_loss: 3.0515e-05\n",
      "Epoch 66/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 4.1332e-04 - val_loss: 1.7081e-05\n",
      "Epoch 67/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 3.7104e-04 - val_loss: 1.7441e-05\n",
      "Epoch 68/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 3.6238e-04 - val_loss: 1.5202e-05\n",
      "Epoch 69/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.6029e-04 - val_loss: 1.5256e-05\n",
      "Epoch 70/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 3.8561e-04 - val_loss: 1.4313e-05\n",
      "Epoch 71/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 3.6499e-04 - val_loss: 1.6498e-05\n",
      "Epoch 72/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 3.7428e-04 - val_loss: 1.3556e-05\n",
      "Epoch 73/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 3.3684e-04 - val_loss: 3.2120e-05\n",
      "Epoch 74/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.9738e-04 - val_loss: 1.7303e-05\n",
      "Epoch 75/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.6022e-04 - val_loss: 1.4152e-05\n",
      "Epoch 76/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.3690e-04 - val_loss: 1.4804e-05\n",
      "Epoch 77/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.3481e-04 - val_loss: 1.4610e-05\n",
      "Epoch 78/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.2283e-04 - val_loss: 2.0363e-05\n",
      "Epoch 79/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.6119e-04 - val_loss: 1.3187e-05\n",
      "Epoch 80/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.3492e-04 - val_loss: 1.5060e-05\n",
      "Epoch 81/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.1792e-04 - val_loss: 1.3144e-05\n",
      "Epoch 82/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.4137e-04 - val_loss: 2.6448e-05\n",
      "Epoch 83/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 4.2977e-04 - val_loss: 1.2532e-05\n",
      "Epoch 84/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.6733e-04 - val_loss: 1.3283e-05\n",
      "Epoch 85/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.5169e-04 - val_loss: 1.2620e-05\n",
      "Epoch 86/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.1698e-04 - val_loss: 1.2959e-05\n",
      "Epoch 87/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.9885e-04 - val_loss: 1.5542e-05\n",
      "Epoch 88/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.1191e-04 - val_loss: 1.9020e-05\n",
      "Epoch 89/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.0308e-04 - val_loss: 1.2817e-05\n",
      "Epoch 90/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.8153e-04 - val_loss: 2.0811e-05\n",
      "Epoch 91/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.9916e-04 - val_loss: 1.4662e-05\n",
      "Epoch 92/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.8824e-04 - val_loss: 1.5559e-05\n",
      "Epoch 93/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.9681e-04 - val_loss: 1.2864e-05\n",
      "Epoch 94/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.8765e-04 - val_loss: 1.4023e-05\n",
      "Epoch 95/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.1869e-04 - val_loss: 1.1786e-05\n",
      "Epoch 96/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.3721e-04 - val_loss: 1.6205e-05\n",
      "Epoch 97/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.8928e-04 - val_loss: 1.1327e-05\n",
      "Epoch 98/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.8873e-04 - val_loss: 1.3290e-05\n",
      "Epoch 99/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.8384e-04 - val_loss: 1.2820e-05\n",
      "Epoch 100/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.4318e-04 - val_loss: 1.1706e-05\n",
      "Epoch 101/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.0296e-04 - val_loss: 2.5234e-05\n",
      "Epoch 102/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.8691e-04 - val_loss: 1.1100e-05\n",
      "Epoch 103/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.7921e-04 - val_loss: 1.1478e-05\n",
      "Epoch 104/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.3675e-04 - val_loss: 1.8809e-05\n",
      "Epoch 105/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 2.7430e-04 - val_loss: 1.2381e-05\n",
      "Epoch 106/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 2.6847e-04 - val_loss: 2.0727e-05\n",
      "Epoch 107/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 2.9916e-04 - val_loss: 1.1145e-05\n",
      "Epoch 108/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 2.6992e-04 - val_loss: 1.0833e-05\n",
      "Epoch 109/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 2.9147e-04 - val_loss: 1.1357e-05\n",
      "Epoch 110/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 3.0982e-04 - val_loss: 1.0547e-05\n",
      "Epoch 111/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 2.8742e-04 - val_loss: 2.3178e-05\n",
      "Epoch 112/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 3.0872e-04 - val_loss: 2.2570e-05\n",
      "Epoch 113/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.6006e-04 - val_loss: 1.9190e-05\n",
      "Epoch 114/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 2.6373e-04 - val_loss: 1.0408e-05\n",
      "Epoch 115/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.6243e-04 - val_loss: 9.7232e-06\n",
      "Epoch 116/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.7988e-04 - val_loss: 1.3847e-05\n",
      "Epoch 117/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.8293e-04 - val_loss: 1.0549e-05\n",
      "Epoch 118/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.0266e-04 - val_loss: 1.0926e-05\n",
      "Epoch 119/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.0719e-04 - val_loss: 1.2845e-05\n",
      "Epoch 120/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.6098e-04 - val_loss: 1.0665e-05\n",
      "Epoch 121/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.4909e-04 - val_loss: 9.8039e-06\n",
      "Epoch 122/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.4878e-04 - val_loss: 1.1489e-05\n",
      "Epoch 123/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.4266e-04 - val_loss: 9.8385e-06\n",
      "Epoch 124/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.4774e-04 - val_loss: 1.0324e-05\n",
      "Epoch 125/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.0462e-04 - val_loss: 9.5297e-06\n",
      "Epoch 126/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.4753e-04 - val_loss: 9.6609e-06\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 8ms/step - loss: 2.8871e-04 - val_loss: 1.0269e-05\n",
      "Epoch 128/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.7966e-04 - val_loss: 8.9541e-06\n",
      "Epoch 129/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.1456e-04 - val_loss: 1.3340e-05\n",
      "Epoch 130/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.4751e-04 - val_loss: 9.2258e-06\n",
      "Epoch 131/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.3193e-04 - val_loss: 1.0230e-05\n",
      "Epoch 132/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.3606e-04 - val_loss: 9.7310e-06\n",
      "Epoch 133/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.3655e-04 - val_loss: 1.0898e-05\n",
      "Epoch 134/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.4321e-04 - val_loss: 9.1505e-06\n",
      "Epoch 135/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.5413e-04 - val_loss: 1.0460e-05\n",
      "Epoch 136/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.6206e-04 - val_loss: 1.2976e-05\n",
      "Epoch 137/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.5841e-04 - val_loss: 1.1418e-05\n",
      "Epoch 138/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.3149e-04 - val_loss: 1.1001e-05\n",
      "Epoch 139/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.8428e-04 - val_loss: 1.2798e-05\n",
      "Epoch 140/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.1989e-04 - val_loss: 1.1781e-05\n",
      "Epoch 141/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.5488e-04 - val_loss: 1.1758e-05\n",
      "Epoch 142/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.3359e-04 - val_loss: 8.8883e-06\n",
      "Epoch 143/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.1339e-04 - val_loss: 1.0606e-05\n",
      "Epoch 144/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.2048e-04 - val_loss: 9.3196e-06\n",
      "Epoch 145/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.8508e-04 - val_loss: 1.8019e-05\n",
      "Epoch 146/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.0851e-04 - val_loss: 1.3004e-05\n",
      "Epoch 147/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.2402e-04 - val_loss: 8.5988e-06\n",
      "Epoch 148/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.3876e-04 - val_loss: 8.8139e-06\n",
      "Epoch 149/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.2358e-04 - val_loss: 1.1089e-05\n",
      "Epoch 150/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.2153e-04 - val_loss: 8.5199e-06\n",
      "Epoch 151/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.0906e-04 - val_loss: 1.0752e-05\n",
      "Epoch 152/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.1487e-04 - val_loss: 8.6133e-06\n",
      "Epoch 153/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.1129e-04 - val_loss: 9.9550e-06\n",
      "Epoch 154/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.1503e-04 - val_loss: 8.3261e-06\n",
      "Epoch 155/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.3859e-04 - val_loss: 1.2405e-05\n",
      "Epoch 156/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.1953e-04 - val_loss: 8.1560e-06\n",
      "Epoch 157/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.5018e-04 - val_loss: 9.1982e-06\n",
      "Epoch 158/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.1426e-04 - val_loss: 8.5740e-06\n",
      "Epoch 159/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.2287e-04 - val_loss: 1.0407e-05\n",
      "Epoch 160/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.2658e-04 - val_loss: 9.0925e-06\n",
      "Epoch 161/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.0804e-04 - val_loss: 8.3266e-06\n",
      "Epoch 162/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.1828e-04 - val_loss: 8.3687e-06\n",
      "Epoch 163/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.2301e-04 - val_loss: 8.3194e-06\n",
      "Epoch 164/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.1478e-04 - val_loss: 1.0264e-05\n",
      "Epoch 165/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.2833e-04 - val_loss: 7.9435e-06\n",
      "Epoch 166/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.0660e-04 - val_loss: 1.1996e-05\n",
      "Epoch 167/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.0982e-04 - val_loss: 2.1363e-05\n",
      "Epoch 168/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.0341e-04 - val_loss: 1.9752e-05\n",
      "Epoch 169/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.4421e-04 - val_loss: 1.5407e-05\n",
      "Epoch 170/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.0282e-04 - val_loss: 1.0424e-05\n",
      "Epoch 171/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.1879e-04 - val_loss: 1.0822e-05\n",
      "Epoch 172/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.2757e-04 - val_loss: 1.9280e-05\n",
      "Epoch 173/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.2385e-04 - val_loss: 9.6635e-06\n",
      "Epoch 174/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.1904e-04 - val_loss: 2.1111e-05\n",
      "Epoch 175/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.0237e-04 - val_loss: 8.3664e-06\n",
      "Epoch 176/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.1389e-04 - val_loss: 7.7305e-06\n",
      "Epoch 177/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.1642e-04 - val_loss: 8.6920e-06\n",
      "Epoch 178/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.9794e-04 - val_loss: 8.1896e-06\n",
      "Epoch 179/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.8318e-04 - val_loss: 1.4707e-05\n",
      "Epoch 180/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.0431e-04 - val_loss: 7.7133e-06\n",
      "Epoch 181/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.9723e-04 - val_loss: 1.6756e-05\n",
      "Epoch 182/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.1027e-04 - val_loss: 1.6148e-05\n",
      "Epoch 183/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.9044e-04 - val_loss: 7.5044e-06\n",
      "Epoch 184/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.1160e-04 - val_loss: 7.6720e-06\n",
      "Epoch 185/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.0068e-04 - val_loss: 2.1090e-05\n",
      "Epoch 186/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.8522e-04 - val_loss: 7.9146e-06\n",
      "Epoch 187/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 1.7822e-04 - val_loss: 7.4639e-06\n",
      "Epoch 188/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.7457e-04 - val_loss: 9.1289e-06\n",
      "Epoch 189/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.8904e-04 - val_loss: 8.2575e-06\n",
      "Epoch 190/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.8563e-04 - val_loss: 1.5447e-05\n",
      "Epoch 191/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.8239e-04 - val_loss: 7.5163e-06\n",
      "Epoch 192/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.9890e-04 - val_loss: 8.7387e-06\n",
      "Epoch 193/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.7173e-04 - val_loss: 7.9933e-06\n",
      "Epoch 194/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.7252e-04 - val_loss: 1.2928e-05\n",
      "Epoch 195/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.7749e-04 - val_loss: 1.1751e-05\n",
      "Epoch 196/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.7445e-04 - val_loss: 7.0596e-06\n",
      "Epoch 197/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.7166e-04 - val_loss: 7.8687e-06\n",
      "Epoch 198/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.8816e-04 - val_loss: 8.6185e-06\n",
      "Epoch 199/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.7598e-04 - val_loss: 7.6279e-06\n",
      "Epoch 200/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.8216e-04 - val_loss: 8.1889e-06\n",
      "Thời gian huấn luyện:  71.35315895080566\n",
      "Model: \"sequential_141\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      " simple_rnn_35 (SimpleRNN)   (None, 30, 115)           13455     \n",
      "                                                                 \n",
      " flatten_141 (Flatten)       (None, 3450)              0         \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 1)                 3451      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,906\n",
      "Trainable params: 16,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "51/51 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 3s 36ms/step - loss: 0.0449 - val_loss: 1.9196e-04\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0021 - val_loss: 2.1151e-04\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0016 - val_loss: 2.0391e-04\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0016 - val_loss: 2.3405e-04\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0015 - val_loss: 2.2842e-04\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0016 - val_loss: 1.5308e-04\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0015 - val_loss: 2.6948e-04\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0014 - val_loss: 2.2148e-04\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0014 - val_loss: 1.8667e-04\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0013 - val_loss: 1.5422e-04\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0014 - val_loss: 1.3120e-04\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0013 - val_loss: 2.0634e-04\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0013 - val_loss: 1.3569e-04\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0012 - val_loss: 1.3074e-04\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0012 - val_loss: 1.3799e-04\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0012 - val_loss: 1.4013e-04\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0012 - val_loss: 1.3000e-04\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0011 - val_loss: 1.0916e-04\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0011 - val_loss: 1.1888e-04\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0011 - val_loss: 9.8239e-05\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0011 - val_loss: 8.4989e-05\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0011 - val_loss: 8.3274e-05\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0010 - val_loss: 1.0162e-04\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 9.6293e-04 - val_loss: 1.2560e-04\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0010 - val_loss: 1.1734e-04\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 9.3597e-04 - val_loss: 7.8324e-05\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 9.2207e-04 - val_loss: 6.7101e-05\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 9.0266e-04 - val_loss: 8.1237e-05\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 9.0618e-04 - val_loss: 1.0634e-04\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 8.7226e-04 - val_loss: 7.5184e-05\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 8.6517e-04 - val_loss: 6.6543e-05\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 8.3910e-04 - val_loss: 9.3461e-05\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 8.3580e-04 - val_loss: 1.2045e-04\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 8.8968e-04 - val_loss: 6.0265e-05\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 7.9137e-04 - val_loss: 9.9397e-05\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 7.9088e-04 - val_loss: 1.0993e-04\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 8.1596e-04 - val_loss: 8.4291e-05\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 7.9273e-04 - val_loss: 1.1642e-04\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 7.8189e-04 - val_loss: 8.8023e-05\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 7.6750e-04 - val_loss: 1.0038e-04\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 7.6545e-04 - val_loss: 1.3023e-04\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 8.1042e-04 - val_loss: 8.3339e-05\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 7.6493e-04 - val_loss: 1.0632e-04\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 7.7233e-04 - val_loss: 1.0056e-04\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 7.3605e-04 - val_loss: 8.0050e-05\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 7.0978e-04 - val_loss: 6.9932e-05\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 7.3936e-04 - val_loss: 1.1944e-04\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 7.0056e-04 - val_loss: 9.4326e-05\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 7.1761e-04 - val_loss: 1.2565e-04\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 6.9285e-04 - val_loss: 6.8821e-05\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 6.7969e-04 - val_loss: 8.0145e-05\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 7.2477e-04 - val_loss: 1.1945e-04\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 6.9866e-04 - val_loss: 1.2019e-04\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 7.1063e-04 - val_loss: 6.8120e-05\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 6.6578e-04 - val_loss: 6.1842e-05\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 6.6068e-04 - val_loss: 7.1147e-05\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 6.4115e-04 - val_loss: 7.0099e-05\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 6.4871e-04 - val_loss: 7.5726e-05\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 6.5097e-04 - val_loss: 7.7310e-05\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 6.4218e-04 - val_loss: 5.1831e-05\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 6.4914e-04 - val_loss: 5.4768e-05\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 6.5137e-04 - val_loss: 8.2428e-05\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 6.3109e-04 - val_loss: 7.0361e-05\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 6.3485e-04 - val_loss: 7.1292e-05\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 6.8474e-04 - val_loss: 7.5138e-05\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 6.1876e-04 - val_loss: 6.0256e-05\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 5.9901e-04 - val_loss: 4.5932e-05\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 6.4071e-04 - val_loss: 7.5102e-05\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 6.3048e-04 - val_loss: 6.7544e-05\n",
      "Epoch 70/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 26ms/step - loss: 6.0284e-04 - val_loss: 6.5765e-05\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 5.8172e-04 - val_loss: 5.6270e-05\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 6.0194e-04 - val_loss: 5.2594e-05\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 5.8283e-04 - val_loss: 8.3066e-05\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 5.9467e-04 - val_loss: 4.6957e-05\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 6.0163e-04 - val_loss: 5.8501e-05\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 5.8324e-04 - val_loss: 7.8993e-05\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 5.7263e-04 - val_loss: 7.7828e-05\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 5.5597e-04 - val_loss: 5.4266e-05\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 5.6495e-04 - val_loss: 5.9571e-05\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 5.5688e-04 - val_loss: 3.6284e-05\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 5.7704e-04 - val_loss: 3.8249e-05\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 5.4901e-04 - val_loss: 7.2064e-05\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 5.4446e-04 - val_loss: 5.7084e-05\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 5.5963e-04 - val_loss: 8.8121e-05\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 5.5957e-04 - val_loss: 3.6877e-05\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 5.4792e-04 - val_loss: 4.1889e-05\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 5.3022e-04 - val_loss: 3.7811e-05\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 5.2908e-04 - val_loss: 5.6059e-05\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 5.3697e-04 - val_loss: 4.0360e-05\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 5.5355e-04 - val_loss: 3.2586e-05\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 5.3387e-04 - val_loss: 4.5090e-05\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 5.5305e-04 - val_loss: 6.2219e-05\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 5.4197e-04 - val_loss: 4.5471e-05\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 5.2745e-04 - val_loss: 6.6322e-05\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 5.5867e-04 - val_loss: 6.7607e-05\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 5.1504e-04 - val_loss: 5.1458e-05\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 5.0055e-04 - val_loss: 6.9851e-05\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 5.8369e-04 - val_loss: 5.1369e-05\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 4.9512e-04 - val_loss: 5.1252e-05\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 4.9967e-04 - val_loss: 4.3513e-05\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 4.9694e-04 - val_loss: 5.0036e-05\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 5.2453e-04 - val_loss: 7.5661e-05\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 4.9485e-04 - val_loss: 3.8389e-05\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 5.1643e-04 - val_loss: 7.1885e-05\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 5.3530e-04 - val_loss: 3.4976e-05\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 4.9412e-04 - val_loss: 4.5124e-05\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 4.7387e-04 - val_loss: 4.1794e-05\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 4.6246e-04 - val_loss: 3.5861e-05\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 4.6014e-04 - val_loss: 5.3287e-05\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 4.7043e-04 - val_loss: 4.6696e-05\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 4.5921e-04 - val_loss: 4.7356e-05\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 4.6461e-04 - val_loss: 5.6125e-05\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 4.6990e-04 - val_loss: 3.7167e-05\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 4.5682e-04 - val_loss: 3.9318e-05\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 4.8409e-04 - val_loss: 2.7955e-05\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 4.6786e-04 - val_loss: 3.8766e-05\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 4.7151e-04 - val_loss: 3.9756e-05\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 4.4971e-04 - val_loss: 7.1202e-05\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 4.4697e-04 - val_loss: 5.8195e-05\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 4.7375e-04 - val_loss: 4.4782e-05\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 4.5839e-04 - val_loss: 4.0588e-05\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 4.4907e-04 - val_loss: 3.9475e-05\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 4.4232e-04 - val_loss: 7.5091e-05\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 4.8943e-04 - val_loss: 4.2147e-05\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 4.2813e-04 - val_loss: 5.8703e-05\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 5.1498e-04 - val_loss: 3.1301e-05\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 4.5794e-04 - val_loss: 4.0132e-05\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 4.3618e-04 - val_loss: 2.7264e-05\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 4.2098e-04 - val_loss: 3.2858e-05\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 4.4816e-04 - val_loss: 4.1708e-05\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 4.1359e-04 - val_loss: 4.4706e-05\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 4.0752e-04 - val_loss: 2.6548e-05\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 4.1302e-04 - val_loss: 3.8821e-05\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 4.0989e-04 - val_loss: 4.8915e-05\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 4.2677e-04 - val_loss: 3.1633e-05\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 4.3775e-04 - val_loss: 4.3728e-05\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 3.9555e-04 - val_loss: 2.7084e-05\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 4.2602e-04 - val_loss: 2.9338e-05\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 4.3167e-04 - val_loss: 3.5793e-05\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 4.1162e-04 - val_loss: 4.0986e-05\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 4.1714e-04 - val_loss: 2.1778e-05\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 4.0849e-04 - val_loss: 3.6723e-05\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 3.9417e-04 - val_loss: 3.2699e-05\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 4.5425e-04 - val_loss: 3.0505e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 4.1545e-04 - val_loss: 3.9169e-05\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 3.8836e-04 - val_loss: 3.3183e-05\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 3.8886e-04 - val_loss: 3.7371e-05\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 3.9854e-04 - val_loss: 2.3416e-05\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 3.8173e-04 - val_loss: 3.0678e-05\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 4.0008e-04 - val_loss: 2.2779e-05\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 3.6857e-04 - val_loss: 3.7609e-05\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 4.0361e-04 - val_loss: 2.4146e-05\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 3.8879e-04 - val_loss: 3.5755e-05\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 3.8759e-04 - val_loss: 3.6116e-05\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 3.9814e-04 - val_loss: 2.2289e-05\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 3.7376e-04 - val_loss: 1.9920e-05\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 4.0945e-04 - val_loss: 2.9014e-05\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 3.8486e-04 - val_loss: 2.9136e-05\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 3.8194e-04 - val_loss: 2.4317e-05\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 3.6983e-04 - val_loss: 3.2961e-05\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 3.5702e-04 - val_loss: 2.7641e-05\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 3.8203e-04 - val_loss: 2.5375e-05\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 3.5126e-04 - val_loss: 2.2923e-05\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 3.6643e-04 - val_loss: 4.1167e-05\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 3.4677e-04 - val_loss: 2.3091e-05\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 3.4555e-04 - val_loss: 1.9811e-05\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 3.5682e-04 - val_loss: 1.9352e-05\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 3.5209e-04 - val_loss: 2.6759e-05\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 3.5134e-04 - val_loss: 2.3858e-05\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 3.3629e-04 - val_loss: 3.0464e-05\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 3.3417e-04 - val_loss: 2.3807e-05\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 3.4515e-04 - val_loss: 2.7248e-05\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 3.4395e-04 - val_loss: 2.5041e-05\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 3.3664e-04 - val_loss: 1.8943e-05\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 3.3508e-04 - val_loss: 2.8797e-05\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 3.2932e-04 - val_loss: 2.1710e-05\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 3.8885e-04 - val_loss: 2.8735e-05\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 3.8370e-04 - val_loss: 1.8015e-05\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 3.4762e-04 - val_loss: 2.3176e-05\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 3.2488e-04 - val_loss: 3.0630e-05\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 3.2273e-04 - val_loss: 2.7638e-05\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 3.4521e-04 - val_loss: 2.7759e-05\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 3.2191e-04 - val_loss: 4.3347e-05\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 3.1494e-04 - val_loss: 2.6588e-05\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 3.1674e-04 - val_loss: 1.8061e-05\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 3.5713e-04 - val_loss: 3.3357e-05\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 3.3030e-04 - val_loss: 4.6221e-05\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 3.0137e-04 - val_loss: 1.9638e-05\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 3.1830e-04 - val_loss: 1.6649e-05\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 3.2663e-04 - val_loss: 3.3209e-05\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 3.1407e-04 - val_loss: 2.1149e-05\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 3.0601e-04 - val_loss: 2.2173e-05\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 3.0156e-04 - val_loss: 1.7697e-05\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 3.3302e-04 - val_loss: 1.8269e-05\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 3.3302e-04 - val_loss: 2.3794e-05\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 3.1770e-04 - val_loss: 4.2630e-05\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 2.9661e-04 - val_loss: 2.3042e-05\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 3.0273e-04 - val_loss: 2.2565e-05\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 3.0090e-04 - val_loss: 2.5998e-05\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 2.9514e-04 - val_loss: 2.5460e-05\n",
      "Thời gian huấn luyện:  212.957017660141\n",
      "Model: \"sequential_142\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_35 (LSTM)              (None, 30, 115)           53820     \n",
      "                                                                 \n",
      " flatten_142 (Flatten)       (None, 3450)              0         \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 1)                 3451      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,271\n",
      "Trainable params: 57,271\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "51/51 [==============================] - 1s 7ms/step\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "Epoch 1/200\n",
      "46/46 [==============================] - 3s 32ms/step - loss: 0.0160 - val_loss: 2.9853e-04\n",
      "Epoch 2/200\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.0013 - val_loss: 7.7330e-05\n",
      "Epoch 3/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 8.1031e-05\n",
      "Epoch 4/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.0011 - val_loss: 5.7659e-05\n",
      "Epoch 5/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.0011 - val_loss: 1.4297e-04\n",
      "Epoch 6/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 8.4874e-05\n",
      "Epoch 7/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 9.8675e-04 - val_loss: 7.3279e-05\n",
      "Epoch 8/200\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 9.9841e-04 - val_loss: 6.9633e-05\n",
      "Epoch 9/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 9.3280e-04 - val_loss: 5.1346e-05\n",
      "Epoch 10/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 9.0051e-04 - val_loss: 6.7402e-05\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 22ms/step - loss: 8.7750e-04 - val_loss: 6.6381e-05\n",
      "Epoch 12/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 8.4880e-04 - val_loss: 4.7134e-05\n",
      "Epoch 13/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 8.2976e-04 - val_loss: 5.2359e-05\n",
      "Epoch 14/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 8.0360e-04 - val_loss: 5.7070e-05\n",
      "Epoch 15/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 7.7980e-04 - val_loss: 5.3386e-05\n",
      "Epoch 16/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 7.5319e-04 - val_loss: 5.0761e-05\n",
      "Epoch 17/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 7.3545e-04 - val_loss: 4.4801e-05\n",
      "Epoch 18/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 7.1961e-04 - val_loss: 3.4492e-05\n",
      "Epoch 19/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 7.0462e-04 - val_loss: 4.0675e-05\n",
      "Epoch 20/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 7.0610e-04 - val_loss: 3.1700e-05\n",
      "Epoch 21/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 6.8175e-04 - val_loss: 3.2390e-05\n",
      "Epoch 22/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 6.6486e-04 - val_loss: 4.5724e-05\n",
      "Epoch 23/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 6.4275e-04 - val_loss: 3.2013e-05\n",
      "Epoch 24/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 6.7014e-04 - val_loss: 5.5749e-05\n",
      "Epoch 25/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 6.1298e-04 - val_loss: 7.2742e-05\n",
      "Epoch 26/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 6.3776e-04 - val_loss: 4.4564e-05\n",
      "Epoch 27/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 6.1060e-04 - val_loss: 2.8869e-05\n",
      "Epoch 28/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 6.0143e-04 - val_loss: 3.9257e-05\n",
      "Epoch 29/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 5.6368e-04 - val_loss: 2.8817e-05\n",
      "Epoch 30/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 5.7480e-04 - val_loss: 2.4992e-05\n",
      "Epoch 31/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 5.4779e-04 - val_loss: 2.5438e-05\n",
      "Epoch 32/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 5.5673e-04 - val_loss: 2.5792e-05\n",
      "Epoch 33/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 5.3415e-04 - val_loss: 3.0825e-05\n",
      "Epoch 34/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 5.5137e-04 - val_loss: 2.4050e-05\n",
      "Epoch 35/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 5.4787e-04 - val_loss: 2.3903e-05\n",
      "Epoch 36/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 5.3401e-04 - val_loss: 5.2640e-05\n",
      "Epoch 37/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 5.1782e-04 - val_loss: 2.8921e-05\n",
      "Epoch 38/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 4.9379e-04 - val_loss: 2.1663e-05\n",
      "Epoch 39/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 4.7617e-04 - val_loss: 2.6314e-05\n",
      "Epoch 40/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 4.7785e-04 - val_loss: 2.6282e-05\n",
      "Epoch 41/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 4.8749e-04 - val_loss: 2.0559e-05\n",
      "Epoch 42/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 5.0364e-04 - val_loss: 2.2897e-05\n",
      "Epoch 43/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 4.7321e-04 - val_loss: 2.3484e-05\n",
      "Epoch 44/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 4.5398e-04 - val_loss: 2.3423e-05\n",
      "Epoch 45/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 4.5772e-04 - val_loss: 2.0577e-05\n",
      "Epoch 46/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 4.4525e-04 - val_loss: 3.7018e-05\n",
      "Epoch 47/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 4.8619e-04 - val_loss: 2.0851e-05\n",
      "Epoch 48/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 4.4151e-04 - val_loss: 1.8534e-05\n",
      "Epoch 49/200\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 4.3825e-04 - val_loss: 2.2231e-05\n",
      "Epoch 50/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 4.6889e-04 - val_loss: 1.8201e-05\n",
      "Epoch 51/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 4.5126e-04 - val_loss: 1.9199e-05\n",
      "Epoch 52/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 4.1731e-04 - val_loss: 1.8464e-05\n",
      "Epoch 53/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 4.1560e-04 - val_loss: 3.3054e-05\n",
      "Epoch 54/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 4.0667e-04 - val_loss: 2.9839e-05\n",
      "Epoch 55/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.9942e-04 - val_loss: 1.8036e-05\n",
      "Epoch 56/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 4.3502e-04 - val_loss: 1.6407e-05\n",
      "Epoch 57/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.9685e-04 - val_loss: 1.6784e-05\n",
      "Epoch 58/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 4.1488e-04 - val_loss: 2.2715e-05\n",
      "Epoch 59/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 4.2008e-04 - val_loss: 2.0294e-05\n",
      "Epoch 60/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 4.1382e-04 - val_loss: 1.6006e-05\n",
      "Epoch 61/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.8668e-04 - val_loss: 1.9101e-05\n",
      "Epoch 62/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 3.8183e-04 - val_loss: 1.5460e-05\n",
      "Epoch 63/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.8987e-04 - val_loss: 1.7816e-05\n",
      "Epoch 64/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 3.7726e-04 - val_loss: 3.5687e-05\n",
      "Epoch 65/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.6566e-04 - val_loss: 1.5470e-05\n",
      "Epoch 66/200\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 3.7607e-04 - val_loss: 1.5251e-05\n",
      "Epoch 67/200\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 3.5463e-04 - val_loss: 1.4498e-05\n",
      "Epoch 68/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 3.6221e-04 - val_loss: 1.5500e-05\n",
      "Epoch 69/200\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 3.7714e-04 - val_loss: 1.4941e-05\n",
      "Epoch 70/200\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 3.6640e-04 - val_loss: 2.6425e-05\n",
      "Epoch 71/200\n",
      "46/46 [==============================] - 1s 27ms/step - loss: 3.6505e-04 - val_loss: 1.6760e-05\n",
      "Epoch 72/200\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 3.7652e-04 - val_loss: 1.6975e-05\n",
      "Epoch 73/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.4761e-04 - val_loss: 2.7541e-05\n",
      "Epoch 74/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.5683e-04 - val_loss: 2.4155e-05\n",
      "Epoch 75/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.3235e-04 - val_loss: 1.8471e-05\n",
      "Epoch 76/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 3.6172e-04 - val_loss: 1.8948e-05\n",
      "Epoch 77/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 3.3318e-04 - val_loss: 1.5242e-05\n",
      "Epoch 78/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 3.3358e-04 - val_loss: 1.5267e-05\n",
      "Epoch 79/200\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 3.2636e-04 - val_loss: 1.3085e-05\n",
      "Epoch 80/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.1244e-04 - val_loss: 2.1067e-05\n",
      "Epoch 81/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.1925e-04 - val_loss: 1.3362e-05\n",
      "Epoch 82/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.0746e-04 - val_loss: 2.0641e-05\n",
      "Epoch 83/200\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 3.2698e-04 - val_loss: 1.3311e-05\n",
      "Epoch 84/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.1115e-04 - val_loss: 1.2335e-05\n",
      "Epoch 85/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.1653e-04 - val_loss: 1.5630e-05\n",
      "Epoch 86/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 23ms/step - loss: 3.0485e-04 - val_loss: 1.2569e-05\n",
      "Epoch 87/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.0301e-04 - val_loss: 2.3433e-05\n",
      "Epoch 88/200\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 2.9558e-04 - val_loss: 1.3652e-05\n",
      "Epoch 89/200\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 3.0821e-04 - val_loss: 1.2533e-05\n",
      "Epoch 90/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.0145e-04 - val_loss: 2.0219e-05\n",
      "Epoch 91/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.9767e-04 - val_loss: 1.1725e-05\n",
      "Epoch 92/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.9562e-04 - val_loss: 1.3154e-05\n",
      "Epoch 93/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.8751e-04 - val_loss: 1.1809e-05\n",
      "Epoch 94/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.8459e-04 - val_loss: 1.1894e-05\n",
      "Epoch 95/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.8646e-04 - val_loss: 1.8836e-05\n",
      "Epoch 96/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.7673e-04 - val_loss: 1.1569e-05\n",
      "Epoch 97/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.7461e-04 - val_loss: 1.4919e-05\n",
      "Epoch 98/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.0787e-04 - val_loss: 1.2143e-05\n",
      "Epoch 99/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.7592e-04 - val_loss: 1.3056e-05\n",
      "Epoch 100/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.6952e-04 - val_loss: 1.6793e-05\n",
      "Epoch 101/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.7650e-04 - val_loss: 1.1353e-05\n",
      "Epoch 102/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.8515e-04 - val_loss: 1.1324e-05\n",
      "Epoch 103/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.6907e-04 - val_loss: 1.1662e-05\n",
      "Epoch 104/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.6909e-04 - val_loss: 1.4112e-05\n",
      "Epoch 105/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.5669e-04 - val_loss: 1.1392e-05\n",
      "Epoch 106/200\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 2.8296e-04 - val_loss: 1.7245e-05\n",
      "Epoch 107/200\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 2.5928e-04 - val_loss: 1.0760e-05\n",
      "Epoch 108/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.8408e-04 - val_loss: 1.3189e-05\n",
      "Epoch 109/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.7465e-04 - val_loss: 1.1584e-05\n",
      "Epoch 110/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.5926e-04 - val_loss: 1.3371e-05\n",
      "Epoch 111/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.5528e-04 - val_loss: 1.7280e-05\n",
      "Epoch 112/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.9111e-04 - val_loss: 1.2027e-05\n",
      "Epoch 113/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.8672e-04 - val_loss: 2.1846e-05\n",
      "Epoch 114/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.7100e-04 - val_loss: 1.2441e-05\n",
      "Epoch 115/200\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 2.6721e-04 - val_loss: 1.1178e-05\n",
      "Epoch 116/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.4075e-04 - val_loss: 1.4334e-05\n",
      "Epoch 117/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.5757e-04 - val_loss: 1.0346e-05\n",
      "Epoch 118/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.4863e-04 - val_loss: 1.2386e-05\n",
      "Epoch 119/200\n",
      "46/46 [==============================] - 1s 27ms/step - loss: 2.4222e-04 - val_loss: 1.0988e-05\n",
      "Epoch 120/200\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 2.3610e-04 - val_loss: 1.0347e-05\n",
      "Epoch 121/200\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 2.3031e-04 - val_loss: 1.7834e-05\n",
      "Epoch 122/200\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 2.4089e-04 - val_loss: 1.0365e-05\n",
      "Epoch 123/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.4973e-04 - val_loss: 1.2076e-05\n",
      "Epoch 124/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.5799e-04 - val_loss: 1.6429e-05\n",
      "Epoch 125/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.2632e-04 - val_loss: 9.5861e-06\n",
      "Epoch 126/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.2802e-04 - val_loss: 9.6723e-06\n",
      "Epoch 127/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.4273e-04 - val_loss: 9.9773e-06\n",
      "Epoch 128/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.2765e-04 - val_loss: 9.2398e-06\n",
      "Epoch 129/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.6932e-04 - val_loss: 1.0352e-05\n",
      "Epoch 130/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.3536e-04 - val_loss: 1.2506e-05\n",
      "Epoch 131/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.1961e-04 - val_loss: 9.1314e-06\n",
      "Epoch 132/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.2075e-04 - val_loss: 9.6881e-06\n",
      "Epoch 133/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.3078e-04 - val_loss: 1.0231e-05\n",
      "Epoch 134/200\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 2.3242e-04 - val_loss: 1.0172e-05\n",
      "Epoch 135/200\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 2.1641e-04 - val_loss: 9.7683e-06\n",
      "Epoch 136/200\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 2.1529e-04 - val_loss: 9.3436e-06\n",
      "Epoch 137/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.3095e-04 - val_loss: 8.8186e-06\n",
      "Epoch 138/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.3536e-04 - val_loss: 1.7745e-05\n",
      "Epoch 139/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.3634e-04 - val_loss: 1.0930e-05\n",
      "Epoch 140/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.0365e-04 - val_loss: 1.0401e-05\n",
      "Epoch 141/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.1049e-04 - val_loss: 1.0766e-05\n",
      "Epoch 142/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.0431e-04 - val_loss: 9.6212e-06\n",
      "Epoch 143/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.0591e-04 - val_loss: 8.5024e-06\n",
      "Epoch 144/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.1522e-04 - val_loss: 9.3886e-06\n",
      "Epoch 145/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.0089e-04 - val_loss: 1.1464e-05\n",
      "Epoch 146/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.1929e-04 - val_loss: 8.7308e-06\n",
      "Epoch 147/200\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 2.0274e-04 - val_loss: 8.2381e-06\n",
      "Epoch 148/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.9775e-04 - val_loss: 1.6847e-05\n",
      "Epoch 149/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.0244e-04 - val_loss: 8.3563e-06\n",
      "Epoch 150/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.0209e-04 - val_loss: 8.2660e-06\n",
      "Epoch 151/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.4256e-04 - val_loss: 2.0368e-05\n",
      "Epoch 152/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.0256e-04 - val_loss: 8.4403e-06\n",
      "Epoch 153/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.9837e-04 - val_loss: 8.2009e-06\n",
      "Epoch 154/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.0228e-04 - val_loss: 8.6590e-06\n",
      "Epoch 155/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.1733e-04 - val_loss: 8.4950e-06\n",
      "Epoch 156/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.1628e-04 - val_loss: 1.0278e-05\n",
      "Epoch 157/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.9116e-04 - val_loss: 7.8980e-06\n",
      "Epoch 158/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.1045e-04 - val_loss: 7.9305e-06\n",
      "Epoch 159/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.9600e-04 - val_loss: 9.4727e-06\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 22ms/step - loss: 1.8450e-04 - val_loss: 8.9024e-06\n",
      "Epoch 161/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.9299e-04 - val_loss: 7.6747e-06\n",
      "Epoch 162/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.8103e-04 - val_loss: 9.5202e-06\n",
      "Epoch 163/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.8696e-04 - val_loss: 8.3591e-06\n",
      "Epoch 164/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.8704e-04 - val_loss: 7.9329e-06\n",
      "Epoch 165/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.8605e-04 - val_loss: 9.1262e-06\n",
      "Epoch 166/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.9200e-04 - val_loss: 7.5270e-06\n",
      "Epoch 167/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.7813e-04 - val_loss: 7.5402e-06\n",
      "Epoch 168/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.9163e-04 - val_loss: 7.6241e-06\n",
      "Epoch 169/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.8945e-04 - val_loss: 7.5800e-06\n",
      "Epoch 170/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.8036e-04 - val_loss: 7.3216e-06\n",
      "Epoch 171/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.7655e-04 - val_loss: 1.0229e-05\n",
      "Epoch 172/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.9525e-04 - val_loss: 7.1874e-06\n",
      "Epoch 173/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.9969e-04 - val_loss: 8.7448e-06\n",
      "Epoch 174/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.7791e-04 - val_loss: 7.5640e-06\n",
      "Epoch 175/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.8393e-04 - val_loss: 7.3630e-06\n",
      "Epoch 176/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.8962e-04 - val_loss: 8.0256e-06\n",
      "Epoch 177/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.8253e-04 - val_loss: 1.4504e-05\n",
      "Epoch 178/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.8832e-04 - val_loss: 7.2893e-06\n",
      "Epoch 179/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.7232e-04 - val_loss: 7.2105e-06\n",
      "Epoch 180/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.7063e-04 - val_loss: 7.7696e-06\n",
      "Epoch 181/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.9640e-04 - val_loss: 7.1534e-06\n",
      "Epoch 182/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.8464e-04 - val_loss: 8.0113e-06\n",
      "Epoch 183/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.8193e-04 - val_loss: 1.0168e-05\n",
      "Epoch 184/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.6574e-04 - val_loss: 8.0396e-06\n",
      "Epoch 185/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.9699e-04 - val_loss: 7.2607e-06\n",
      "Epoch 186/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.7498e-04 - val_loss: 8.5026e-06\n",
      "Epoch 187/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.7321e-04 - val_loss: 6.8274e-06\n",
      "Epoch 188/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.9539e-04 - val_loss: 7.5082e-06\n",
      "Epoch 189/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.7708e-04 - val_loss: 6.9015e-06\n",
      "Epoch 190/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.7153e-04 - val_loss: 1.3188e-05\n",
      "Epoch 191/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.8941e-04 - val_loss: 9.5479e-06\n",
      "Epoch 192/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.6419e-04 - val_loss: 7.1822e-06\n",
      "Epoch 193/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.7096e-04 - val_loss: 1.2308e-05\n",
      "Epoch 194/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.7973e-04 - val_loss: 6.6632e-06\n",
      "Epoch 195/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.7383e-04 - val_loss: 6.5132e-06\n",
      "Epoch 196/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.8507e-04 - val_loss: 1.2183e-05\n",
      "Epoch 197/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.6473e-04 - val_loss: 7.2615e-06\n",
      "Epoch 198/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.6314e-04 - val_loss: 6.7802e-06\n",
      "Epoch 199/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.6291e-04 - val_loss: 8.4914e-06\n",
      "Epoch 200/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.6923e-04 - val_loss: 6.7396e-06\n",
      "Thời gian huấn luyện:  210.14590215682983\n",
      "Model: \"sequential_143\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_34 (GRU)                (None, 30, 115)           40710     \n",
      "                                                                 \n",
      " flatten_143 (Flatten)       (None, 3450)              0         \n",
      "                                                                 \n",
      " dense_180 (Dense)           (None, 1)                 3451      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,161\n",
      "Trainable params: 44,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "51/51 [==============================] - 1s 6ms/step\n",
      "12/12 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "rmse_bag = [] # Ex: rmse_bag[1] == [0.9, 0.8, 0.9, 0.9] --> FFNN, RNN, LSTM, GRU\n",
    "\n",
    "FFNN_model, RNN_model, LSTM_model, GRU_model = None, None, None, None\n",
    "\n",
    "for look_back in [1, 3, 5, 10, 20, 30]:\n",
    "    FFNN_data, FFNN_params = prepare_best_params(information_FFNN_df,ds, look_back, opt)\n",
    "    FFNN_delta, FFNN_model = create_ffnn_model(*FFNN_params)\n",
    "    FFNN_mse, FFNN_mae, FFNN_mape, FFNN_rmse, FFNN_trainPredict, FFNN_testPredict = create_accuracy(FFNN_model, scaler, *FFNN_data)\n",
    "    \n",
    "    RNN_data, RNN_params = prepare_best_params(information_RNN_df,ds, look_back, opt)\n",
    "    RNN_delta, RNN_model = create_rnn_model(*RNN_params)\n",
    "    RNN_mse, RNN_mae, RNN_mape, RNN_rmse, RNN_trainPredict, RNN_testPredict = create_accuracy(RNN_model, scaler, *RNN_data)\n",
    "    \n",
    "    LSTM_data, LSTM_params = prepare_best_params(information_LSTM_df,ds, look_back, opt)\n",
    "    LSTM_delta, LSTM_model = create_lstm_model(*LSTM_params)\n",
    "    LSTM_mse, LSTM_mae, LSTM_mape, LSTM_rmse, LSTM_trainPredict, LSTM_testPredict = create_accuracy(LSTM_model, scaler, *LSTM_data)\n",
    "    \n",
    "    GRU_data, GRU_params = prepare_best_params(information_GRU_df,ds, look_back, opt)\n",
    "    GRU_delta, GRU_model = create_gru_model(*GRU_params)\n",
    "    GRU_mse, GRU_mae, GRU_mape, GRU_rmse, GRU_trainPredict, GRU_testPredict = create_accuracy(GRU_model, scaler, *GRU_data)\n",
    "    \n",
    "    # Lưu các RMSE\n",
    "    rmse_bag.append([FFNN_rmse, RNN_rmse, LSTM_rmse, GRU_rmse])\n",
    "    \n",
    "#Save models\n",
    "FFNN_model.save('ffnn_model.h5')\n",
    "RNN_model.save('rnn_model.h5')\n",
    "LSTM_model.save('lstm_model.h5')\n",
    "GRU_model.save('gru_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7209307b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFNN</th>\n",
       "      <th>RNN</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>GRU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.310</td>\n",
       "      <td>3.327</td>\n",
       "      <td>3.492</td>\n",
       "      <td>123.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.102</td>\n",
       "      <td>3.533</td>\n",
       "      <td>123.455</td>\n",
       "      <td>4.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.430</td>\n",
       "      <td>3.525</td>\n",
       "      <td>5.336</td>\n",
       "      <td>4.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.370</td>\n",
       "      <td>3.840</td>\n",
       "      <td>5.052</td>\n",
       "      <td>4.184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>122.203</td>\n",
       "      <td>3.710</td>\n",
       "      <td>4.688</td>\n",
       "      <td>4.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>121.433</td>\n",
       "      <td>3.845</td>\n",
       "      <td>4.767</td>\n",
       "      <td>3.792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       FFNN    RNN     LSTM      GRU\n",
       "1     3.310  3.327    3.492  123.603\n",
       "3     4.102  3.533  123.455    4.046\n",
       "5     4.430  3.525    5.336    4.039\n",
       "10    4.370  3.840    5.052    4.184\n",
       "20  122.203  3.710    4.688    4.004\n",
       "30  121.433  3.845    4.767    3.792"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_bag = pd.DataFrame(rmse_bag, index=[1, 3, 5, 10, 20, 30], columns=['FFNN', 'RNN', 'LSTM', 'GRU'])\n",
    "rmse_bag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bc3d79",
   "metadata": {},
   "source": [
    "### So the chosen look_back is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67a4d4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back=30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d18bca3",
   "metadata": {},
   "source": [
    "## Chose the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ceb9782",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_table = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13103ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0488 - val_loss: 0.0109\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 7.5242e-04\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 2.5904e-04\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 1.3192e-04\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.6728e-05\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.4578e-05\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.8380e-05\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.8489e-05\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.3198e-05\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.8631e-05\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 8.7256e-05\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 1.1116e-04\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 8.7055e-05\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 8.7215e-05\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 8.0579e-05\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.5119e-05\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 1.1505e-04\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 1.1413e-04\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 7.1352e-05\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.3568e-05\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 1.0842e-04\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 1.3920e-04\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 8.4824e-05\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 1.3379e-04\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 6.1127e-05\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 1.4200e-04\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 9.9757e-04 - val_loss: 6.8616e-05\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 9.8771e-04 - val_loss: 8.4133e-05\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 7.1142e-05\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 9.6244e-04 - val_loss: 7.1343e-05\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 9.5102e-04 - val_loss: 7.7334e-05\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 9.4610e-04 - val_loss: 8.1437e-05\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 9.4675e-04 - val_loss: 9.2105e-05\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 9.3636e-04 - val_loss: 9.5583e-05\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 9.0747e-04 - val_loss: 7.7058e-05\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 8.9940e-04 - val_loss: 9.4699e-05\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 8.8663e-04 - val_loss: 9.9727e-05\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 8.8147e-04 - val_loss: 7.5673e-05\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 8.6525e-04 - val_loss: 7.3932e-05\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 8.5626e-04 - val_loss: 8.1847e-05\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 8.4823e-04 - val_loss: 6.9716e-05\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 8.3254e-04 - val_loss: 9.3679e-05\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 8.4762e-04 - val_loss: 5.6989e-05\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 8.1843e-04 - val_loss: 1.0273e-04\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 8.1280e-04 - val_loss: 9.1885e-05\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 8.1511e-04 - val_loss: 4.5529e-05\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 8.2186e-04 - val_loss: 8.6728e-05\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 7.7616e-04 - val_loss: 6.6197e-05\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 7.6083e-04 - val_loss: 6.0997e-05\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 7.6133e-04 - val_loss: 5.8070e-05\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 7.3546e-04 - val_loss: 9.2958e-05\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 7.2973e-04 - val_loss: 6.6398e-05\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 7.2184e-04 - val_loss: 6.7348e-05\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 7.1453e-04 - val_loss: 4.4866e-05\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.9893e-04 - val_loss: 4.6917e-05\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.9443e-04 - val_loss: 8.3424e-05\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.8693e-04 - val_loss: 4.4046e-05\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.7961e-04 - val_loss: 5.2588e-05\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 6.6438e-04 - val_loss: 4.7146e-05\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 6.5769e-04 - val_loss: 4.6528e-05\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 6.5170e-04 - val_loss: 3.6050e-05\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 6.4678e-04 - val_loss: 7.1820e-05\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.4017e-04 - val_loss: 5.0562e-05\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 6.2609e-04 - val_loss: 5.3762e-05\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 6.4426e-04 - val_loss: 3.6988e-05\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.1158e-04 - val_loss: 6.5557e-05\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 6.0301e-04 - val_loss: 4.5020e-05\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.9384e-04 - val_loss: 3.6749e-05\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.9476e-04 - val_loss: 4.5721e-05\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7294e-04 - val_loss: 5.0457e-05\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7627e-04 - val_loss: 5.9782e-05\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6739e-04 - val_loss: 3.8749e-05\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7231e-04 - val_loss: 4.7877e-05\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.6650e-04 - val_loss: 2.7638e-05\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.5041e-04 - val_loss: 4.4720e-05\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.4213e-04 - val_loss: 3.0907e-05\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3805e-04 - val_loss: 7.1594e-05\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4134e-04 - val_loss: 5.7355e-05\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3173e-04 - val_loss: 4.1369e-05\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.3232e-04 - val_loss: 2.4497e-05\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.1212e-04 - val_loss: 5.8138e-05\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.1085e-04 - val_loss: 4.2705e-05\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.1254e-04 - val_loss: 3.7133e-05\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.9337e-04 - val_loss: 3.3270e-05\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.9176e-04 - val_loss: 3.9493e-05\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.9383e-04 - val_loss: 3.6255e-05\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.8172e-04 - val_loss: 2.2791e-05\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.7844e-04 - val_loss: 2.2428e-05\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.7459e-04 - val_loss: 3.2348e-05\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.7040e-04 - val_loss: 2.8475e-05\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.6390e-04 - val_loss: 4.0627e-05\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.6386e-04 - val_loss: 2.5847e-05\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.6067e-04 - val_loss: 2.9880e-05\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.5103e-04 - val_loss: 3.0194e-05\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.7626e-04 - val_loss: 2.3919e-05\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.4715e-04 - val_loss: 3.6868e-05\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.4095e-04 - val_loss: 2.0799e-05\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.3776e-04 - val_loss: 2.7170e-05\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.3474e-04 - val_loss: 2.7077e-05\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.4213e-04 - val_loss: 2.2013e-05\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.2628e-04 - val_loss: 2.2590e-05\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.4744e-04 - val_loss: 2.3316e-05\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.3021e-04 - val_loss: 2.4664e-05\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.2021e-04 - val_loss: 2.0004e-05\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.3441e-04 - val_loss: 2.3908e-05\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.2170e-04 - val_loss: 4.0412e-05\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.3984e-04 - val_loss: 1.9432e-05\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.0724e-04 - val_loss: 3.6799e-05\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.1820e-04 - val_loss: 3.3065e-05\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4.1503e-04 - val_loss: 2.6743e-05\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.9375e-04 - val_loss: 2.0044e-05\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.9738e-04 - val_loss: 2.8146e-05\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.9227e-04 - val_loss: 1.8285e-05\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.9317e-04 - val_loss: 1.7955e-05\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.1747e-04 - val_loss: 1.8194e-05\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.9799e-04 - val_loss: 2.3739e-05\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.9208e-04 - val_loss: 1.9797e-05\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.8228e-04 - val_loss: 2.0795e-05\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.8152e-04 - val_loss: 1.9516e-05\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.8105e-04 - val_loss: 2.1591e-05\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.7384e-04 - val_loss: 1.7399e-05\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.8423e-04 - val_loss: 2.3924e-05\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.7413e-04 - val_loss: 3.9239e-05\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.8382e-04 - val_loss: 1.9983e-05\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.6847e-04 - val_loss: 1.7151e-05\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.7659e-04 - val_loss: 2.4205e-05\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.9019e-04 - val_loss: 4.2766e-05\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.7588e-04 - val_loss: 2.6281e-05\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.6375e-04 - val_loss: 2.0063e-05\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.6120e-04 - val_loss: 1.6229e-05\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5763e-04 - val_loss: 1.6781e-05\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.5810e-04 - val_loss: 1.6264e-05\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.5623e-04 - val_loss: 1.9176e-05\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.7651e-04 - val_loss: 2.1876e-05\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.6765e-04 - val_loss: 2.1173e-05\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.6213e-04 - val_loss: 1.5772e-05\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.6090e-04 - val_loss: 1.5826e-05\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4964e-04 - val_loss: 1.8602e-05\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.4988e-04 - val_loss: 1.8367e-05\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.5294e-04 - val_loss: 1.7799e-05\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4002e-04 - val_loss: 1.7441e-05\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.4265e-04 - val_loss: 1.5302e-05\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.4697e-04 - val_loss: 1.5826e-05\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4424e-04 - val_loss: 1.5262e-05\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.4982e-04 - val_loss: 2.0621e-05\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.3648e-04 - val_loss: 1.5131e-05\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.4818e-04 - val_loss: 1.9813e-05\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3004e-04 - val_loss: 1.9019e-05\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.2653e-04 - val_loss: 2.0145e-05\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.2646e-04 - val_loss: 1.5503e-05\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2609e-04 - val_loss: 1.7798e-05\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 3ms/step - loss: 3.2261e-04 - val_loss: 2.0540e-05\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.2209e-04 - val_loss: 1.7018e-05\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.2583e-04 - val_loss: 1.6965e-05\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.2260e-04 - val_loss: 2.0922e-05\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.3747e-04 - val_loss: 1.4925e-05\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.1955e-04 - val_loss: 2.6781e-05\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.1166e-04 - val_loss: 1.8459e-05\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1392e-04 - val_loss: 1.4790e-05\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1344e-04 - val_loss: 1.4476e-05\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1157e-04 - val_loss: 1.4251e-05\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1231e-04 - val_loss: 1.5925e-05\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.0909e-04 - val_loss: 1.5857e-05\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.1228e-04 - val_loss: 1.5361e-05\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.0724e-04 - val_loss: 1.7394e-05\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 3.1394e-04 - val_loss: 1.8683e-05\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.0383e-04 - val_loss: 1.8717e-05\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.1237e-04 - val_loss: 1.4687e-05\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9952e-04 - val_loss: 1.6012e-05\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.0557e-04 - val_loss: 1.5833e-05\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.1703e-04 - val_loss: 1.7117e-05\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.0340e-04 - val_loss: 1.6050e-05\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.9632e-04 - val_loss: 1.9721e-05\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.9574e-04 - val_loss: 2.9808e-05\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.9636e-04 - val_loss: 1.3369e-05\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.0684e-04 - val_loss: 1.5721e-05\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.9274e-04 - val_loss: 2.3052e-05\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.9919e-04 - val_loss: 1.4900e-05\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9122e-04 - val_loss: 1.2773e-05\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9787e-04 - val_loss: 2.0576e-05\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9938e-04 - val_loss: 1.2624e-05\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9392e-04 - val_loss: 1.2726e-05\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.8905e-04 - val_loss: 2.1590e-05\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.9265e-04 - val_loss: 1.5511e-05\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.9799e-04 - val_loss: 1.2440e-05\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.8251e-04 - val_loss: 1.3736e-05\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.8249e-04 - val_loss: 1.8089e-05\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.8587e-04 - val_loss: 1.6539e-05\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9198e-04 - val_loss: 1.4868e-05\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7886e-04 - val_loss: 1.3323e-05\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.8202e-04 - val_loss: 1.2566e-05\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.8926e-04 - val_loss: 1.4838e-05\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.9447e-04 - val_loss: 1.2232e-05\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.9943e-04 - val_loss: 1.8122e-05\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.8329e-04 - val_loss: 1.5455e-05\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7576e-04 - val_loss: 2.2247e-05\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.7559e-04 - val_loss: 1.2563e-05\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.8171e-04 - val_loss: 2.1539e-05\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.7753e-04 - val_loss: 1.3734e-05\n",
      "Thời gian huấn luyện:  21.841185092926025\n",
      "Model: \"sequential_153\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_194 (Dense)           (None, 30, 115)           230       \n",
      "                                                                 \n",
      " flatten_153 (Flatten)       (None, 3450)              0         \n",
      "                                                                 \n",
      " dense_195 (Dense)           (None, 1)                 3451      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,681\n",
      "Trainable params: 3,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 1s 11ms/step - loss: 0.0143 - val_loss: 4.0413e-04\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 8.2870e-05\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 5.5216e-05\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 4.3392e-05\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 9.4361e-04 - val_loss: 4.1133e-05\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 8.8371e-04 - val_loss: 3.8786e-05\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 8.3256e-04 - val_loss: 5.7354e-05\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 8.1483e-04 - val_loss: 4.0140e-05\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 7.6375e-04 - val_loss: 3.6768e-05\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 7.6049e-04 - val_loss: 3.5798e-05\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 7.2108e-04 - val_loss: 3.3284e-05\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 6.5404e-04 - val_loss: 3.8851e-05\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 6.5475e-04 - val_loss: 3.0310e-05\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 6.2585e-04 - val_loss: 3.6335e-05\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 6.6571e-04 - val_loss: 5.1302e-05\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 6.1285e-04 - val_loss: 4.6268e-05\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 6.1256e-04 - val_loss: 3.0934e-05\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 5.8158e-04 - val_loss: 3.2647e-05\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 6.1673e-04 - val_loss: 4.1783e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 5.1936e-04 - val_loss: 2.7066e-05\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 5.2090e-04 - val_loss: 2.9217e-05\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 5.1337e-04 - val_loss: 2.8010e-05\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 5.2011e-04 - val_loss: 3.1597e-05\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 5.3765e-04 - val_loss: 4.5372e-05\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 5.4898e-04 - val_loss: 3.5222e-05\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 5.8335e-04 - val_loss: 2.4924e-05\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 5.7596e-04 - val_loss: 2.6284e-05\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 4.7863e-04 - val_loss: 2.2557e-05\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 5.5805e-04 - val_loss: 2.2984e-05\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 5.3185e-04 - val_loss: 4.3046e-05\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 4.6777e-04 - val_loss: 2.4547e-05\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 4.6427e-04 - val_loss: 2.5814e-05\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 4.5281e-04 - val_loss: 2.7402e-05\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 4.6213e-04 - val_loss: 2.9244e-05\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 4.4321e-04 - val_loss: 2.1419e-05\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 4.6942e-04 - val_loss: 1.9678e-05\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 4.2627e-04 - val_loss: 2.8241e-05\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 4.8032e-04 - val_loss: 2.6220e-05\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 5.0665e-04 - val_loss: 2.2885e-05\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 4.2976e-04 - val_loss: 1.9163e-05\n",
      "Epoch 41/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 4.0848e-04 - val_loss: 3.1931e-05\n",
      "Epoch 42/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 3.9882e-04 - val_loss: 4.4078e-05\n",
      "Epoch 43/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 4.0941e-04 - val_loss: 2.2723e-05\n",
      "Epoch 44/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 4.2537e-04 - val_loss: 2.3716e-05\n",
      "Epoch 45/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 4.6570e-04 - val_loss: 2.8909e-05\n",
      "Epoch 46/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 3.9749e-04 - val_loss: 1.8124e-05\n",
      "Epoch 47/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 3.7896e-04 - val_loss: 1.6503e-05\n",
      "Epoch 48/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 4.1305e-04 - val_loss: 1.8400e-05\n",
      "Epoch 49/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 4.0930e-04 - val_loss: 2.6795e-05\n",
      "Epoch 50/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.6973e-04 - val_loss: 1.5462e-05\n",
      "Epoch 51/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 4.3704e-04 - val_loss: 2.0903e-05\n",
      "Epoch 52/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 4.1944e-04 - val_loss: 1.6800e-05\n",
      "Epoch 53/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.6499e-04 - val_loss: 1.9554e-05\n",
      "Epoch 54/200\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 4.2118e-04 - val_loss: 1.6401e-05\n",
      "Epoch 55/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 3.6660e-04 - val_loss: 1.6949e-05\n",
      "Epoch 56/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 3.5341e-04 - val_loss: 1.4624e-05\n",
      "Epoch 57/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.8780e-04 - val_loss: 2.7814e-05\n",
      "Epoch 58/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.7073e-04 - val_loss: 2.5000e-05\n",
      "Epoch 59/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 4.3275e-04 - val_loss: 2.5920e-05\n",
      "Epoch 60/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 3.4041e-04 - val_loss: 1.4136e-05\n",
      "Epoch 61/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 3.6596e-04 - val_loss: 2.2287e-05\n",
      "Epoch 62/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.2431e-04 - val_loss: 2.1749e-05\n",
      "Epoch 63/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 3.9343e-04 - val_loss: 2.6405e-05\n",
      "Epoch 64/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 3.2622e-04 - val_loss: 1.6371e-05\n",
      "Epoch 65/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 3.2908e-04 - val_loss: 1.9800e-05\n",
      "Epoch 66/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 3.3524e-04 - val_loss: 1.4123e-05\n",
      "Epoch 67/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 3.4073e-04 - val_loss: 3.8428e-05\n",
      "Epoch 68/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.6187e-04 - val_loss: 1.3062e-05\n",
      "Epoch 69/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.0137e-04 - val_loss: 1.6040e-05\n",
      "Epoch 70/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 3.2891e-04 - val_loss: 2.7062e-05\n",
      "Epoch 71/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.0496e-04 - val_loss: 1.9602e-05\n",
      "Epoch 72/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.2282e-04 - val_loss: 2.2458e-05\n",
      "Epoch 73/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.1609e-04 - val_loss: 1.4066e-05\n",
      "Epoch 74/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.9567e-04 - val_loss: 1.3616e-05\n",
      "Epoch 75/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 2.9693e-04 - val_loss: 1.7721e-05\n",
      "Epoch 76/200\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 2.9876e-04 - val_loss: 1.5320e-05\n",
      "Epoch 77/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.8200e-04 - val_loss: 2.3515e-05\n",
      "Epoch 78/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.1524e-04 - val_loss: 1.9282e-05\n",
      "Epoch 79/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 3.0304e-04 - val_loss: 1.5277e-05\n",
      "Epoch 80/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.8593e-04 - val_loss: 1.7179e-05\n",
      "Epoch 81/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 3.1451e-04 - val_loss: 2.2310e-05\n",
      "Epoch 82/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.5348e-04 - val_loss: 1.6075e-05\n",
      "Epoch 83/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.9033e-04 - val_loss: 1.3272e-05\n",
      "Epoch 84/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.2572e-04 - val_loss: 1.3538e-05\n",
      "Epoch 85/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.8068e-04 - val_loss: 1.2021e-05\n",
      "Epoch 86/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.1526e-04 - val_loss: 1.4650e-05\n",
      "Epoch 87/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.2800e-04 - val_loss: 1.1589e-05\n",
      "Epoch 88/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.7540e-04 - val_loss: 1.1295e-05\n",
      "Epoch 89/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.7164e-04 - val_loss: 1.1270e-05\n",
      "Epoch 90/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.5652e-04 - val_loss: 1.1513e-05\n",
      "Epoch 91/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.8435e-04 - val_loss: 1.0581e-05\n",
      "Epoch 92/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.6201e-04 - val_loss: 1.0985e-05\n",
      "Epoch 93/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.7124e-04 - val_loss: 1.1581e-05\n",
      "Epoch 94/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.5916e-04 - val_loss: 1.5017e-05\n",
      "Epoch 95/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.5259e-04 - val_loss: 1.6644e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.6305e-04 - val_loss: 1.1827e-05\n",
      "Epoch 97/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.5361e-04 - val_loss: 2.0062e-05\n",
      "Epoch 98/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.4584e-04 - val_loss: 1.3736e-05\n",
      "Epoch 99/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.5950e-04 - val_loss: 1.6069e-05\n",
      "Epoch 100/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 2.6322e-04 - val_loss: 1.7080e-05\n",
      "Epoch 101/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.7660e-04 - val_loss: 2.3082e-05\n",
      "Epoch 102/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.5566e-04 - val_loss: 1.0155e-05\n",
      "Epoch 103/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.7686e-04 - val_loss: 9.8295e-06\n",
      "Epoch 104/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.5389e-04 - val_loss: 1.1779e-05\n",
      "Epoch 105/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.4627e-04 - val_loss: 1.0025e-05\n",
      "Epoch 106/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.4054e-04 - val_loss: 9.4747e-06\n",
      "Epoch 107/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.2556e-04 - val_loss: 9.5957e-06\n",
      "Epoch 108/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.4324e-04 - val_loss: 1.1547e-05\n",
      "Epoch 109/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.4652e-04 - val_loss: 1.6196e-05\n",
      "Epoch 110/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.0228e-04 - val_loss: 1.8848e-05\n",
      "Epoch 111/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.5791e-04 - val_loss: 8.9714e-06\n",
      "Epoch 112/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.8701e-04 - val_loss: 2.1824e-05\n",
      "Epoch 113/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.5014e-04 - val_loss: 1.1640e-05\n",
      "Epoch 114/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.4266e-04 - val_loss: 1.0237e-05\n",
      "Epoch 115/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.5312e-04 - val_loss: 9.7619e-06\n",
      "Epoch 116/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.6839e-04 - val_loss: 1.0962e-05\n",
      "Epoch 117/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.2896e-04 - val_loss: 1.3888e-05\n",
      "Epoch 118/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 2.1998e-04 - val_loss: 1.1959e-05\n",
      "Epoch 119/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.3659e-04 - val_loss: 8.9575e-06\n",
      "Epoch 120/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 2.2338e-04 - val_loss: 1.2862e-05\n",
      "Epoch 121/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.5036e-04 - val_loss: 1.0083e-05\n",
      "Epoch 122/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.1829e-04 - val_loss: 1.3511e-05\n",
      "Epoch 123/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.2177e-04 - val_loss: 1.0873e-05\n",
      "Epoch 124/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.6914e-04 - val_loss: 1.0404e-05\n",
      "Epoch 125/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.2456e-04 - val_loss: 1.7632e-05\n",
      "Epoch 126/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.1235e-04 - val_loss: 2.0215e-05\n",
      "Epoch 127/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.4382e-04 - val_loss: 1.0355e-05\n",
      "Epoch 128/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.1955e-04 - val_loss: 1.2451e-05\n",
      "Epoch 129/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.3999e-04 - val_loss: 8.5728e-06\n",
      "Epoch 130/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 2.0636e-04 - val_loss: 8.5697e-06\n",
      "Epoch 131/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 2.1435e-04 - val_loss: 9.1504e-06\n",
      "Epoch 132/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 2.1462e-04 - val_loss: 9.3477e-06\n",
      "Epoch 133/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 2.0577e-04 - val_loss: 1.1371e-05\n",
      "Epoch 134/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 2.3418e-04 - val_loss: 9.3330e-06\n",
      "Epoch 135/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 2.0048e-04 - val_loss: 8.6439e-06\n",
      "Epoch 136/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 2.1066e-04 - val_loss: 1.3470e-05\n",
      "Epoch 137/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.0009e-04 - val_loss: 9.3986e-06\n",
      "Epoch 138/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 2.3422e-04 - val_loss: 1.1656e-05\n",
      "Epoch 139/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 2.0503e-04 - val_loss: 8.4693e-06\n",
      "Epoch 140/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 1.9372e-04 - val_loss: 1.1005e-05\n",
      "Epoch 141/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 2.1089e-04 - val_loss: 1.2615e-05\n",
      "Epoch 142/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.2354e-04 - val_loss: 3.0195e-05\n",
      "Epoch 143/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.2797e-04 - val_loss: 1.2981e-05\n",
      "Epoch 144/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.2564e-04 - val_loss: 9.3007e-06\n",
      "Epoch 145/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.9231e-04 - val_loss: 8.2824e-06\n",
      "Epoch 146/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.1750e-04 - val_loss: 9.9265e-06\n",
      "Epoch 147/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.8594e-04 - val_loss: 2.2394e-05\n",
      "Epoch 148/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 1.9239e-04 - val_loss: 8.6909e-06\n",
      "Epoch 149/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.9810e-04 - val_loss: 1.0960e-05\n",
      "Epoch 150/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.9778e-04 - val_loss: 7.6333e-06\n",
      "Epoch 151/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.9155e-04 - val_loss: 7.8546e-06\n",
      "Epoch 152/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 1.8531e-04 - val_loss: 9.4996e-06\n",
      "Epoch 153/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 1.7854e-04 - val_loss: 8.0414e-06\n",
      "Epoch 154/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.1811e-04 - val_loss: 7.7363e-06\n",
      "Epoch 155/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 2.0016e-04 - val_loss: 7.9459e-06\n",
      "Epoch 156/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 2.1075e-04 - val_loss: 9.2904e-06\n",
      "Epoch 157/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.3065e-04 - val_loss: 8.9786e-06\n",
      "Epoch 158/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.9006e-04 - val_loss: 1.2638e-05\n",
      "Epoch 159/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.8839e-04 - val_loss: 7.5017e-06\n",
      "Epoch 160/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 1.8160e-04 - val_loss: 9.1206e-06\n",
      "Epoch 161/200\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 1.7562e-04 - val_loss: 7.9314e-06\n",
      "Epoch 162/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.9913e-04 - val_loss: 7.6474e-06\n",
      "Epoch 163/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.9021e-04 - val_loss: 1.5586e-05\n",
      "Epoch 164/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.7190e-04 - val_loss: 7.1366e-06\n",
      "Epoch 165/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.1591e-04 - val_loss: 1.0015e-05\n",
      "Epoch 166/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.9885e-04 - val_loss: 7.7614e-06\n",
      "Epoch 167/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.7117e-04 - val_loss: 7.3544e-06\n",
      "Epoch 168/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.8435e-04 - val_loss: 1.0207e-05\n",
      "Epoch 169/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.1418e-04 - val_loss: 7.9238e-06\n",
      "Epoch 170/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.0839e-04 - val_loss: 8.7643e-06\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 8ms/step - loss: 1.8298e-04 - val_loss: 1.4860e-05\n",
      "Epoch 172/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.7823e-04 - val_loss: 8.0265e-06\n",
      "Epoch 173/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.8842e-04 - val_loss: 1.3057e-05\n",
      "Epoch 174/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.8522e-04 - val_loss: 1.7738e-05\n",
      "Epoch 175/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.8156e-04 - val_loss: 7.6812e-06\n",
      "Epoch 176/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.7400e-04 - val_loss: 1.1832e-05\n",
      "Epoch 177/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.7672e-04 - val_loss: 9.4408e-06\n",
      "Epoch 178/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.6755e-04 - val_loss: 6.9154e-06\n",
      "Epoch 179/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.6446e-04 - val_loss: 1.7795e-05\n",
      "Epoch 180/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.9038e-04 - val_loss: 8.4094e-06\n",
      "Epoch 181/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.2656e-04 - val_loss: 1.0291e-05\n",
      "Epoch 182/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.7416e-04 - val_loss: 7.5608e-06\n",
      "Epoch 183/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.8006e-04 - val_loss: 7.2029e-06\n",
      "Epoch 184/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.7874e-04 - val_loss: 1.0283e-05\n",
      "Epoch 185/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.6951e-04 - val_loss: 9.0750e-06\n",
      "Epoch 186/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.6179e-04 - val_loss: 7.4619e-06\n",
      "Epoch 187/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.8182e-04 - val_loss: 7.6955e-06\n",
      "Epoch 188/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.0999e-04 - val_loss: 1.3063e-05\n",
      "Epoch 189/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.3514e-04 - val_loss: 7.1323e-06\n",
      "Epoch 190/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.6380e-04 - val_loss: 8.7472e-06\n",
      "Epoch 191/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.6653e-04 - val_loss: 6.8353e-06\n",
      "Epoch 192/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 1.7939e-04 - val_loss: 7.1290e-06\n",
      "Epoch 193/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.9369e-04 - val_loss: 9.5282e-06\n",
      "Epoch 194/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.6159e-04 - val_loss: 7.9030e-06\n",
      "Epoch 195/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.9401e-04 - val_loss: 7.2381e-06\n",
      "Epoch 196/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.9310e-04 - val_loss: 7.9414e-06\n",
      "Epoch 197/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.5552e-04 - val_loss: 1.2721e-05\n",
      "Epoch 198/200\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 1.5824e-04 - val_loss: 7.2061e-06\n",
      "Epoch 199/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.7442e-04 - val_loss: 7.1426e-06\n",
      "Epoch 200/200\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.7434e-04 - val_loss: 1.3847e-05\n",
      "Thời gian huấn luyện:  69.43097949028015\n",
      "Model: \"sequential_154\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_38 (SimpleRNN)   (None, 30, 115)           13455     \n",
      "                                                                 \n",
      " flatten_154 (Flatten)       (None, 3450)              0         \n",
      "                                                                 \n",
      " dense_196 (Dense)           (None, 1)                 3451      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,906\n",
      "Trainable params: 16,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "51/51 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 3s 29ms/step - loss: 0.0239 - val_loss: 1.6616e-04\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0015 - val_loss: 2.4667e-04\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 2.0018e-04\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 2.0266e-04\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 1.7572e-04\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 1.8802e-04\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 1.4875e-04\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 1.7415e-04\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 1.3597e-04\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 1.6713e-04\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0012 - val_loss: 1.7634e-04\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0012 - val_loss: 1.4414e-04\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0012 - val_loss: 1.1148e-04\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0012 - val_loss: 1.2939e-04\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0012 - val_loss: 1.6855e-04\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0012 - val_loss: 9.9888e-05\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 1.4914e-04\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 1.0574e-04\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 8.5019e-05\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 7.7037e-05\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 1.6710e-04\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 1.1389e-04\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0010 - val_loss: 9.8828e-05\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 9.8077e-04 - val_loss: 1.1399e-04\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 9.7156e-04 - val_loss: 1.0128e-04\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 9.8440e-04 - val_loss: 1.1120e-04\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 9.6089e-04 - val_loss: 7.1956e-05\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 9.2310e-04 - val_loss: 7.1399e-05\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 9.1841e-04 - val_loss: 8.3421e-05\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 9.0228e-04 - val_loss: 6.9654e-05\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 8.9910e-04 - val_loss: 5.5509e-05\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 9.0685e-04 - val_loss: 8.7765e-05\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 8.6494e-04 - val_loss: 7.7090e-05\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 8.3927e-04 - val_loss: 5.8005e-05\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 8.6994e-04 - val_loss: 9.4638e-05\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 8.4902e-04 - val_loss: 7.1449e-05\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 8.1282e-04 - val_loss: 7.6415e-05\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 20ms/step - loss: 7.9473e-04 - val_loss: 4.9845e-05\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 7.9648e-04 - val_loss: 5.6831e-05\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 7.7785e-04 - val_loss: 6.2491e-05\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 7.7313e-04 - val_loss: 4.9144e-05\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 7.8203e-04 - val_loss: 6.2754e-05\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 7.6072e-04 - val_loss: 4.5995e-05\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 7.5797e-04 - val_loss: 6.6454e-05\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 7.2810e-04 - val_loss: 7.3748e-05\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 7.2733e-04 - val_loss: 9.0086e-05\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 7.8049e-04 - val_loss: 8.1621e-05\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 7.6629e-04 - val_loss: 4.2519e-05\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 7.0595e-04 - val_loss: 4.4400e-05\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 7.0640e-04 - val_loss: 6.5655e-05\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 7.1011e-04 - val_loss: 6.0167e-05\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 6.8065e-04 - val_loss: 7.3181e-05\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 7.1189e-04 - val_loss: 5.3911e-05\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 6.7055e-04 - val_loss: 6.9552e-05\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 6.7611e-04 - val_loss: 5.8171e-05\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 6.6661e-04 - val_loss: 9.7454e-05\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 6.7207e-04 - val_loss: 6.2052e-05\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 7.0103e-04 - val_loss: 6.1590e-05\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 6.4743e-04 - val_loss: 5.2787e-05\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 6.3615e-04 - val_loss: 5.8307e-05\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 6.2726e-04 - val_loss: 7.5934e-05\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 6.4632e-04 - val_loss: 3.3995e-05\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 6.3666e-04 - val_loss: 6.9433e-05\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 6.5544e-04 - val_loss: 7.0984e-05\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 6.2998e-04 - val_loss: 6.5023e-05\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 7.0853e-04 - val_loss: 8.2576e-05\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 6.9067e-04 - val_loss: 4.7914e-05\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 6.1700e-04 - val_loss: 7.7670e-05\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 6.0212e-04 - val_loss: 6.7049e-05\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 5.9178e-04 - val_loss: 4.6282e-05\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 5.8663e-04 - val_loss: 4.5778e-05\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 5.7188e-04 - val_loss: 5.5593e-05\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 5.7201e-04 - val_loss: 3.2884e-05\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 5.8223e-04 - val_loss: 4.6061e-05\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 5.7139e-04 - val_loss: 5.4727e-05\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 5.7298e-04 - val_loss: 5.7895e-05\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 5.6830e-04 - val_loss: 4.4981e-05\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 5.5461e-04 - val_loss: 5.9945e-05\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 5.7204e-04 - val_loss: 3.7070e-05\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 5.6109e-04 - val_loss: 5.0190e-05\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 5.4757e-04 - val_loss: 5.6341e-05\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 5.6884e-04 - val_loss: 5.3368e-05\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 5.5678e-04 - val_loss: 4.7101e-05\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 5.5941e-04 - val_loss: 3.0049e-05\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 5.8651e-04 - val_loss: 4.7240e-05\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 5.2321e-04 - val_loss: 2.8568e-05\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 5.3556e-04 - val_loss: 4.3864e-05\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 5.2381e-04 - val_loss: 5.1011e-05\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 5.3134e-04 - val_loss: 3.4570e-05\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 5.3984e-04 - val_loss: 7.5126e-05\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 5.2664e-04 - val_loss: 3.2061e-05\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 5.1850e-04 - val_loss: 3.5279e-05\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 5.3341e-04 - val_loss: 4.3328e-05\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 5.0303e-04 - val_loss: 3.5776e-05\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 5.4328e-04 - val_loss: 4.6818e-05\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 4.9289e-04 - val_loss: 4.4690e-05\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 4.8265e-04 - val_loss: 3.9086e-05\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 4.9754e-04 - val_loss: 3.3463e-05\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 4.8452e-04 - val_loss: 5.6232e-05\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 4.8169e-04 - val_loss: 2.6878e-05\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 4.8793e-04 - val_loss: 3.9991e-05\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 4.8064e-04 - val_loss: 5.1311e-05\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 4.9681e-04 - val_loss: 2.8326e-05\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 4.7668e-04 - val_loss: 2.7092e-05\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 4.8101e-04 - val_loss: 3.4846e-05\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 4.7172e-04 - val_loss: 5.8008e-05\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 4.7773e-04 - val_loss: 3.8280e-05\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 4.6209e-04 - val_loss: 3.4680e-05\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 4.4916e-04 - val_loss: 2.9696e-05\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 4.5663e-04 - val_loss: 3.6878e-05\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 4.5081e-04 - val_loss: 3.6343e-05\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 4.6861e-04 - val_loss: 5.5657e-05\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 20ms/step - loss: 4.6775e-04 - val_loss: 5.6404e-05\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 4.6643e-04 - val_loss: 4.6436e-05\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 4.3811e-04 - val_loss: 4.9857e-05\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 4.3049e-04 - val_loss: 3.6211e-05\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 4.3316e-04 - val_loss: 4.0275e-05\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 4.3870e-04 - val_loss: 3.2457e-05\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 4.3321e-04 - val_loss: 2.9072e-05\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 4.3011e-04 - val_loss: 3.6556e-05\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 4.4819e-04 - val_loss: 3.9916e-05\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 4.1993e-04 - val_loss: 2.5616e-05\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 4.3144e-04 - val_loss: 2.6951e-05\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 4.3357e-04 - val_loss: 2.5222e-05\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 4.0828e-04 - val_loss: 3.6471e-05\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 4.0659e-04 - val_loss: 2.3321e-05\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 4.0858e-04 - val_loss: 2.9814e-05\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 4.3078e-04 - val_loss: 2.5007e-05\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 4.0263e-04 - val_loss: 4.1863e-05\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 3.9513e-04 - val_loss: 2.7081e-05\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 4.0724e-04 - val_loss: 2.8697e-05\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 4.2341e-04 - val_loss: 2.5729e-05\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 4.0533e-04 - val_loss: 2.6652e-05\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.8850e-04 - val_loss: 2.5611e-05\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 4.0342e-04 - val_loss: 2.4235e-05\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 3.9242e-04 - val_loss: 4.3389e-05\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.7701e-04 - val_loss: 1.9983e-05\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.8239e-04 - val_loss: 2.4538e-05\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.7436e-04 - val_loss: 3.4410e-05\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.8137e-04 - val_loss: 2.6258e-05\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.7661e-04 - val_loss: 2.9568e-05\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.8715e-04 - val_loss: 3.8090e-05\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.8495e-04 - val_loss: 4.1954e-05\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.7237e-04 - val_loss: 1.9986e-05\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.9698e-04 - val_loss: 2.7494e-05\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.6315e-04 - val_loss: 2.7263e-05\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.7775e-04 - val_loss: 4.0360e-05\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.6350e-04 - val_loss: 1.9088e-05\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.5637e-04 - val_loss: 2.1948e-05\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.7294e-04 - val_loss: 1.9259e-05\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.8635e-04 - val_loss: 1.9577e-05\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.9524e-04 - val_loss: 2.2287e-05\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.4609e-04 - val_loss: 2.3992e-05\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.5874e-04 - val_loss: 4.2607e-05\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.7570e-04 - val_loss: 2.2991e-05\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.5231e-04 - val_loss: 1.9130e-05\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.8573e-04 - val_loss: 3.0128e-05\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.3778e-04 - val_loss: 2.0302e-05\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.4193e-04 - val_loss: 2.1730e-05\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.6016e-04 - val_loss: 2.0670e-05\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.7400e-04 - val_loss: 2.9073e-05\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.7780e-04 - val_loss: 2.4933e-05\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 3.9739e-04 - val_loss: 2.2054e-05\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.3364e-04 - val_loss: 2.3311e-05\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.2131e-04 - val_loss: 2.2248e-05\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.3218e-04 - val_loss: 1.9240e-05\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.5325e-04 - val_loss: 1.8124e-05\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.3014e-04 - val_loss: 2.4744e-05\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.2101e-04 - val_loss: 1.8673e-05\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.3126e-04 - val_loss: 1.8248e-05\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.3639e-04 - val_loss: 2.2389e-05\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.1919e-04 - val_loss: 2.2632e-05\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.4415e-04 - val_loss: 2.5655e-05\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.1775e-04 - val_loss: 2.0238e-05\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.2609e-04 - val_loss: 1.8095e-05\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.5384e-04 - val_loss: 1.7545e-05\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.1635e-04 - val_loss: 3.6743e-05\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.2610e-04 - val_loss: 1.7049e-05\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.3602e-04 - val_loss: 1.8080e-05\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.5317e-04 - val_loss: 3.5186e-05\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.4370e-04 - val_loss: 1.6840e-05\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.2141e-04 - val_loss: 1.7971e-05\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.0417e-04 - val_loss: 2.7597e-05\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.0933e-04 - val_loss: 2.7492e-05\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 2.9402e-04 - val_loss: 2.1144e-05\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.3307e-04 - val_loss: 1.6013e-05\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 20ms/step - loss: 3.0779e-04 - val_loss: 1.9384e-05\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 2.8907e-04 - val_loss: 2.1662e-05\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 2.9133e-04 - val_loss: 2.2857e-05\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.0370e-04 - val_loss: 1.6856e-05\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.1231e-04 - val_loss: 1.5098e-05\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 2.8607e-04 - val_loss: 1.5351e-05\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 2.8586e-04 - val_loss: 1.9819e-05\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 2.9556e-04 - val_loss: 1.7407e-05\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.0151e-04 - val_loss: 1.5247e-05\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.1103e-04 - val_loss: 2.6829e-05\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 2.8995e-04 - val_loss: 1.6512e-05\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.1013e-04 - val_loss: 1.8412e-05\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 2.8605e-04 - val_loss: 2.0755e-05\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 3.0187e-04 - val_loss: 1.6401e-05\n",
      "Thời gian huấn luyện:  172.2610948085785\n",
      "Model: \"sequential_155\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_38 (LSTM)              (None, 30, 115)           53820     \n",
      "                                                                 \n",
      " flatten_155 (Flatten)       (None, 3450)              0         \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 1)                 3451      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,271\n",
      "Trainable params: 57,271\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "51/51 [==============================] - 1s 7ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "Epoch 1/200\n",
      "46/46 [==============================] - 3s 26ms/step - loss: 0.0371 - val_loss: 1.1266e-04\n",
      "Epoch 2/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 8.0248e-05\n",
      "Epoch 3/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 9.5693e-05\n",
      "Epoch 4/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 7.1486e-05\n",
      "Epoch 5/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 7.8865e-05\n",
      "Epoch 6/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 6.9421e-05\n",
      "Epoch 7/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.0010 - val_loss: 8.4112e-05\n",
      "Epoch 8/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.0010 - val_loss: 6.7959e-05\n",
      "Epoch 9/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 9.7856e-04 - val_loss: 7.8101e-05\n",
      "Epoch 10/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 9.5454e-04 - val_loss: 8.6431e-05\n",
      "Epoch 11/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 9.2516e-04 - val_loss: 6.3169e-05\n",
      "Epoch 12/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 8.9021e-04 - val_loss: 4.5905e-05\n",
      "Epoch 13/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 8.8085e-04 - val_loss: 5.5673e-05\n",
      "Epoch 14/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 8.4804e-04 - val_loss: 4.2116e-05\n",
      "Epoch 15/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 8.3048e-04 - val_loss: 7.5429e-05\n",
      "Epoch 16/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 7.9263e-04 - val_loss: 4.6735e-05\n",
      "Epoch 17/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 7.8360e-04 - val_loss: 4.3638e-05\n",
      "Epoch 18/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 7.4291e-04 - val_loss: 4.2510e-05\n",
      "Epoch 19/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 7.1999e-04 - val_loss: 3.5193e-05\n",
      "Epoch 20/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 7.3818e-04 - val_loss: 3.3602e-05\n",
      "Epoch 21/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 6.8453e-04 - val_loss: 5.3761e-05\n",
      "Epoch 22/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 6.6646e-04 - val_loss: 3.7743e-05\n",
      "Epoch 23/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 6.5232e-04 - val_loss: 4.0277e-05\n",
      "Epoch 24/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 6.2994e-04 - val_loss: 3.4961e-05\n",
      "Epoch 25/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 6.1142e-04 - val_loss: 3.5089e-05\n",
      "Epoch 26/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 6.0653e-04 - val_loss: 3.1357e-05\n",
      "Epoch 27/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 5.8259e-04 - val_loss: 2.9894e-05\n",
      "Epoch 28/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 5.7208e-04 - val_loss: 4.3728e-05\n",
      "Epoch 29/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 5.6500e-04 - val_loss: 3.3368e-05\n",
      "Epoch 30/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 5.4709e-04 - val_loss: 2.3714e-05\n",
      "Epoch 31/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 5.5203e-04 - val_loss: 2.3355e-05\n",
      "Epoch 32/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 5.3837e-04 - val_loss: 2.3536e-05\n",
      "Epoch 33/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 5.4475e-04 - val_loss: 2.6195e-05\n",
      "Epoch 34/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 5.2897e-04 - val_loss: 2.2296e-05\n",
      "Epoch 35/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 5.2155e-04 - val_loss: 2.6528e-05\n",
      "Epoch 36/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 4.9723e-04 - val_loss: 2.2312e-05\n",
      "Epoch 37/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 5.1521e-04 - val_loss: 2.3600e-05\n",
      "Epoch 38/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 5.0378e-04 - val_loss: 2.1385e-05\n",
      "Epoch 39/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 4.8820e-04 - val_loss: 2.2048e-05\n",
      "Epoch 40/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 4.7875e-04 - val_loss: 2.8229e-05\n",
      "Epoch 41/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 4.8092e-04 - val_loss: 2.1914e-05\n",
      "Epoch 42/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 4.6631e-04 - val_loss: 1.9262e-05\n",
      "Epoch 43/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 4.6444e-04 - val_loss: 1.8802e-05\n",
      "Epoch 44/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 4.7236e-04 - val_loss: 2.0598e-05\n",
      "Epoch 45/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 4.4506e-04 - val_loss: 2.0494e-05\n",
      "Epoch 46/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 4.4961e-04 - val_loss: 1.8715e-05\n",
      "Epoch 47/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 4.5812e-04 - val_loss: 2.0556e-05\n",
      "Epoch 48/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 4.2841e-04 - val_loss: 2.5043e-05\n",
      "Epoch 49/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 4.2823e-04 - val_loss: 2.6096e-05\n",
      "Epoch 50/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 4.1726e-04 - val_loss: 2.7266e-05\n",
      "Epoch 51/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 4.2137e-04 - val_loss: 1.8935e-05\n",
      "Epoch 52/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 4.0659e-04 - val_loss: 2.7467e-05\n",
      "Epoch 53/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 19ms/step - loss: 4.2534e-04 - val_loss: 3.1078e-05\n",
      "Epoch 54/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 4.0949e-04 - val_loss: 2.1719e-05\n",
      "Epoch 55/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 4.0505e-04 - val_loss: 2.0349e-05\n",
      "Epoch 56/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 4.0221e-04 - val_loss: 1.6935e-05\n",
      "Epoch 57/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 4.0473e-04 - val_loss: 1.6540e-05\n",
      "Epoch 58/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.9421e-04 - val_loss: 2.6541e-05\n",
      "Epoch 59/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 4.0929e-04 - val_loss: 1.9486e-05\n",
      "Epoch 60/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.7807e-04 - val_loss: 1.7457e-05\n",
      "Epoch 61/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 4.1736e-04 - val_loss: 2.4981e-05\n",
      "Epoch 62/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.7272e-04 - val_loss: 1.9867e-05\n",
      "Epoch 63/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.8091e-04 - val_loss: 1.8278e-05\n",
      "Epoch 64/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.7229e-04 - val_loss: 2.0264e-05\n",
      "Epoch 65/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.8321e-04 - val_loss: 1.9394e-05\n",
      "Epoch 66/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.6560e-04 - val_loss: 2.0569e-05\n",
      "Epoch 67/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.6380e-04 - val_loss: 1.6276e-05\n",
      "Epoch 68/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.6975e-04 - val_loss: 1.4882e-05\n",
      "Epoch 69/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.7036e-04 - val_loss: 1.4342e-05\n",
      "Epoch 70/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.7065e-04 - val_loss: 1.4477e-05\n",
      "Epoch 71/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.4272e-04 - val_loss: 1.8052e-05\n",
      "Epoch 72/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.3742e-04 - val_loss: 2.2669e-05\n",
      "Epoch 73/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.5196e-04 - val_loss: 2.2877e-05\n",
      "Epoch 74/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.5188e-04 - val_loss: 1.8287e-05\n",
      "Epoch 75/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.3862e-04 - val_loss: 2.0947e-05\n",
      "Epoch 76/200\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 3.3648e-04 - val_loss: 2.0858e-05\n",
      "Epoch 77/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 3.3971e-04 - val_loss: 1.3950e-05\n",
      "Epoch 78/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.8044e-04 - val_loss: 1.9329e-05\n",
      "Epoch 79/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.4731e-04 - val_loss: 1.7599e-05\n",
      "Epoch 80/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.3357e-04 - val_loss: 1.4969e-05\n",
      "Epoch 81/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 3.2366e-04 - val_loss: 2.7043e-05\n",
      "Epoch 82/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.2742e-04 - val_loss: 2.3056e-05\n",
      "Epoch 83/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.2388e-04 - val_loss: 1.3514e-05\n",
      "Epoch 84/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.4803e-04 - val_loss: 1.2902e-05\n",
      "Epoch 85/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.0965e-04 - val_loss: 1.3952e-05\n",
      "Epoch 86/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.1082e-04 - val_loss: 3.1330e-05\n",
      "Epoch 87/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 3.1806e-04 - val_loss: 1.7895e-05\n",
      "Epoch 88/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.0944e-04 - val_loss: 1.5464e-05\n",
      "Epoch 89/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 3.0683e-04 - val_loss: 1.3914e-05\n",
      "Epoch 90/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 3.1764e-04 - val_loss: 1.2622e-05\n",
      "Epoch 91/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.9308e-04 - val_loss: 2.8072e-05\n",
      "Epoch 92/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.0930e-04 - val_loss: 1.2481e-05\n",
      "Epoch 93/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.5406e-04 - val_loss: 1.2574e-05\n",
      "Epoch 94/200\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 3.2731e-04 - val_loss: 1.4722e-05\n",
      "Epoch 95/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.0609e-04 - val_loss: 1.2194e-05\n",
      "Epoch 96/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9389e-04 - val_loss: 1.7181e-05\n",
      "Epoch 97/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8755e-04 - val_loss: 1.2164e-05\n",
      "Epoch 98/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8521e-04 - val_loss: 1.5983e-05\n",
      "Epoch 99/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8489e-04 - val_loss: 1.1957e-05\n",
      "Epoch 100/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8966e-04 - val_loss: 1.2132e-05\n",
      "Epoch 101/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8687e-04 - val_loss: 1.9180e-05\n",
      "Epoch 102/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.1951e-04 - val_loss: 2.9463e-05\n",
      "Epoch 103/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.2038e-04 - val_loss: 1.1219e-05\n",
      "Epoch 104/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7111e-04 - val_loss: 1.5558e-05\n",
      "Epoch 105/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7588e-04 - val_loss: 1.2388e-05\n",
      "Epoch 106/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7895e-04 - val_loss: 1.1276e-05\n",
      "Epoch 107/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9031e-04 - val_loss: 1.2459e-05\n",
      "Epoch 108/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7277e-04 - val_loss: 1.0966e-05\n",
      "Epoch 109/200\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 2.7210e-04 - val_loss: 1.8135e-05\n",
      "Epoch 110/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.0098e-04 - val_loss: 1.2318e-05\n",
      "Epoch 111/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7574e-04 - val_loss: 1.1701e-05\n",
      "Epoch 112/200\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.8893e-04 - val_loss: 1.3257e-05\n",
      "Epoch 113/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9127e-04 - val_loss: 1.0533e-05\n",
      "Epoch 114/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6187e-04 - val_loss: 1.3216e-05\n",
      "Epoch 115/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9001e-04 - val_loss: 1.4315e-05\n",
      "Epoch 116/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6100e-04 - val_loss: 1.3893e-05\n",
      "Epoch 117/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9004e-04 - val_loss: 1.0938e-05\n",
      "Epoch 118/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.4832e-04 - val_loss: 1.1588e-05\n",
      "Epoch 119/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7313e-04 - val_loss: 1.0462e-05\n",
      "Epoch 120/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7506e-04 - val_loss: 1.2516e-05\n",
      "Epoch 121/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5372e-04 - val_loss: 3.1910e-05\n",
      "Epoch 122/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9000e-04 - val_loss: 1.1430e-05\n",
      "Epoch 123/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6245e-04 - val_loss: 1.0447e-05\n",
      "Epoch 124/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5212e-04 - val_loss: 1.3310e-05\n",
      "Epoch 125/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.4572e-04 - val_loss: 1.1085e-05\n",
      "Epoch 126/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5091e-04 - val_loss: 1.5304e-05\n",
      "Epoch 127/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.3457e-04 - val_loss: 1.1350e-05\n",
      "Epoch 128/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 21ms/step - loss: 2.5131e-04 - val_loss: 1.3702e-05\n",
      "Epoch 129/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5661e-04 - val_loss: 9.9625e-06\n",
      "Epoch 130/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5444e-04 - val_loss: 1.0041e-05\n",
      "Epoch 131/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5116e-04 - val_loss: 1.2062e-05\n",
      "Epoch 132/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.3978e-04 - val_loss: 9.6782e-06\n",
      "Epoch 133/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.3772e-04 - val_loss: 9.6512e-06\n",
      "Epoch 134/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.3191e-04 - val_loss: 9.6184e-06\n",
      "Epoch 135/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7171e-04 - val_loss: 1.4694e-05\n",
      "Epoch 136/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.4254e-04 - val_loss: 1.2353e-05\n",
      "Epoch 137/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.1760e-04 - val_loss: 1.0195e-05\n",
      "Epoch 138/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.3786e-04 - val_loss: 1.1716e-05\n",
      "Epoch 139/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.3589e-04 - val_loss: 9.4698e-06\n",
      "Epoch 140/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.2467e-04 - val_loss: 9.7539e-06\n",
      "Epoch 141/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.3372e-04 - val_loss: 1.0451e-05\n",
      "Epoch 142/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.2994e-04 - val_loss: 1.1058e-05\n",
      "Epoch 143/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.2187e-04 - val_loss: 1.4398e-05\n",
      "Epoch 144/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.2328e-04 - val_loss: 9.0854e-06\n",
      "Epoch 145/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.2076e-04 - val_loss: 9.5147e-06\n",
      "Epoch 146/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.1641e-04 - val_loss: 9.1016e-06\n",
      "Epoch 147/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.1736e-04 - val_loss: 9.6183e-06\n",
      "Epoch 148/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.1184e-04 - val_loss: 8.9557e-06\n",
      "Epoch 149/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.1854e-04 - val_loss: 9.4624e-06\n",
      "Epoch 150/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.0454e-04 - val_loss: 8.6505e-06\n",
      "Epoch 151/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.2965e-04 - val_loss: 1.8792e-05\n",
      "Epoch 152/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.0841e-04 - val_loss: 9.8362e-06\n",
      "Epoch 153/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.3259e-04 - val_loss: 1.0808e-05\n",
      "Epoch 154/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.1399e-04 - val_loss: 1.1327e-05\n",
      "Epoch 155/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.3069e-04 - val_loss: 8.6942e-06\n",
      "Epoch 156/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.0976e-04 - val_loss: 9.8536e-06\n",
      "Epoch 157/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.0940e-04 - val_loss: 2.6074e-05\n",
      "Epoch 158/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.2011e-04 - val_loss: 9.7713e-06\n",
      "Epoch 159/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.1935e-04 - val_loss: 8.3642e-06\n",
      "Epoch 160/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.0272e-04 - val_loss: 8.7188e-06\n",
      "Epoch 161/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.1075e-04 - val_loss: 9.8608e-06\n",
      "Epoch 162/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.9624e-04 - val_loss: 8.0687e-06\n",
      "Epoch 163/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.0552e-04 - val_loss: 1.3416e-05\n",
      "Epoch 164/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.0105e-04 - val_loss: 1.4179e-05\n",
      "Epoch 165/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.1313e-04 - val_loss: 9.6510e-06\n",
      "Epoch 166/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.9826e-04 - val_loss: 1.2617e-05\n",
      "Epoch 167/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.9090e-04 - val_loss: 8.2986e-06\n",
      "Epoch 168/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.2164e-04 - val_loss: 9.2457e-06\n",
      "Epoch 169/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.0331e-04 - val_loss: 1.3080e-05\n",
      "Epoch 170/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.9860e-04 - val_loss: 9.3163e-06\n",
      "Epoch 171/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.1107e-04 - val_loss: 8.0169e-06\n",
      "Epoch 172/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.1604e-04 - val_loss: 8.2809e-06\n",
      "Epoch 173/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.8776e-04 - val_loss: 8.6021e-06\n",
      "Epoch 174/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.8728e-04 - val_loss: 7.7444e-06\n",
      "Epoch 175/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.8408e-04 - val_loss: 7.8275e-06\n",
      "Epoch 176/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.8014e-04 - val_loss: 7.9567e-06\n",
      "Epoch 177/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.8646e-04 - val_loss: 7.8304e-06\n",
      "Epoch 178/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.9289e-04 - val_loss: 7.5661e-06\n",
      "Epoch 179/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.0243e-04 - val_loss: 1.0234e-05\n",
      "Epoch 180/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.9831e-04 - val_loss: 7.4312e-06\n",
      "Epoch 181/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.8343e-04 - val_loss: 7.7714e-06\n",
      "Epoch 182/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 1.8033e-04 - val_loss: 7.6276e-06\n",
      "Epoch 183/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 1.7445e-04 - val_loss: 8.1198e-06\n",
      "Epoch 184/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.8931e-04 - val_loss: 1.3377e-05\n",
      "Epoch 185/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 1.8765e-04 - val_loss: 1.2401e-05\n",
      "Epoch 186/200\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 1.9829e-04 - val_loss: 8.3646e-06\n",
      "Epoch 187/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.0610e-04 - val_loss: 7.4249e-06\n",
      "Epoch 188/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.7524e-04 - val_loss: 7.2935e-06\n",
      "Epoch 189/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.9522e-04 - val_loss: 7.6961e-06\n",
      "Epoch 190/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.7696e-04 - val_loss: 7.9978e-06\n",
      "Epoch 191/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 1.7971e-04 - val_loss: 7.6360e-06\n",
      "Epoch 192/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.6867e-04 - val_loss: 1.3327e-05\n",
      "Epoch 193/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 1.8024e-04 - val_loss: 7.8819e-06\n",
      "Epoch 194/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 1.7408e-04 - val_loss: 7.3435e-06\n",
      "Epoch 195/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.7039e-04 - val_loss: 1.0538e-05\n",
      "Epoch 196/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.6643e-04 - val_loss: 7.3677e-06\n",
      "Epoch 197/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.7032e-04 - val_loss: 7.1991e-06\n",
      "Epoch 198/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.6821e-04 - val_loss: 7.5443e-06\n",
      "Epoch 199/200\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.7073e-04 - val_loss: 7.0463e-06\n",
      "Epoch 200/200\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 1.6896e-04 - val_loss: 1.1438e-05\n",
      "Thời gian huấn luyện:  189.1181514263153\n",
      "Model: \"sequential_156\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      " gru_36 (GRU)                (None, 30, 115)           40710     \n",
      "                                                                 \n",
      " flatten_156 (Flatten)       (None, 3450)              0         \n",
      "                                                                 \n",
      " dense_198 (Dense)           (None, 1)                 3451      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,161\n",
      "Trainable params: 44,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "51/51 [==============================] - 1s 6ms/step\n",
      "12/12 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "FFNN_data, FFNN_params = prepare_best_params(information_FFNN_df,ds, look_back, opt)\n",
    "FFNN_delta, FFNN_model = create_ffnn_model(*FFNN_params)\n",
    "FFNN_mse, FFNN_mae, FFNN_mape, FFNN_rmse, FFNN_trainPredict, FFNN_testPredict = create_accuracy(FFNN_model, scaler, *FFNN_data)\n",
    "compare_table.append([FFNN_mse, FFNN_mae, FFNN_mape, FFNN_rmse, FFNN_delta])\n",
    "    \n",
    "RNN_data, RNN_params = prepare_best_params(information_RNN_df,ds, look_back, opt)\n",
    "RNN_delta, RNN_model = create_rnn_model(*RNN_params)\n",
    "RNN_mse, RNN_mae, RNN_mape, RNN_rmse, RNN_trainPredict, RNN_testPredict = create_accuracy(RNN_model, scaler, *RNN_data)\n",
    "compare_table.append([RNN_mse, RNN_mae, RNN_mape, RNN_rmse, RNN_delta])\n",
    "    \n",
    "LSTM_data, LSTM_params = prepare_best_params(information_LSTM_df,ds, look_back, opt)\n",
    "LSTM_delta, LSTM_model = create_lstm_model(*LSTM_params)\n",
    "LSTM_mse, LSTM_mae, LSTM_mape, LSTM_rmse, LSTM_trainPredict, LSTM_testPredict = create_accuracy(LSTM_model, scaler, *LSTM_data)\n",
    "compare_table.append([LSTM_mse, LSTM_mae, LSTM_mape, LSTM_rmse, LSTM_delta])\n",
    "    \n",
    "GRU_data, GRU_params = prepare_best_params(information_GRU_df,ds, look_back, opt)\n",
    "GRU_delta, GRU_model = create_gru_model(*GRU_params)\n",
    "GRU_mse, GRU_mae, GRU_mape, GRU_rmse, GRU_trainPredict, GRU_testPredict = create_accuracy(GRU_model, scaler, *GRU_data)\n",
    "compare_table.append([GRU_mse, GRU_mae, GRU_mape, GRU_rmse, GRU_delta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "911fde1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FFNN</th>\n",
       "      <td>20.554</td>\n",
       "      <td>2.599</td>\n",
       "      <td>1.891</td>\n",
       "      <td>4.534</td>\n",
       "      <td>21.849180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RNN</th>\n",
       "      <td>12.106</td>\n",
       "      <td>2.114</td>\n",
       "      <td>1.637</td>\n",
       "      <td>3.479</td>\n",
       "      <td>69.440982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>20.577</td>\n",
       "      <td>2.701</td>\n",
       "      <td>2.033</td>\n",
       "      <td>4.536</td>\n",
       "      <td>172.268095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU</th>\n",
       "      <td>13.741</td>\n",
       "      <td>2.275</td>\n",
       "      <td>1.784</td>\n",
       "      <td>3.707</td>\n",
       "      <td>189.129154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MSE    MAE   MAPE   RMSE  Training Time\n",
       "FFNN  20.554  2.599  1.891  4.534      21.849180\n",
       "RNN   12.106  2.114  1.637  3.479      69.440982\n",
       "LSTM  20.577  2.701  2.033  4.536     172.268095\n",
       "GRU   13.741  2.275  1.784  3.707     189.129154"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_table = pd.DataFrame(compare_table, index=[\"FFNN\", \"RNN\", \"LSTM\", \"GRU\"], columns=[\"MSE\", \"MAE\", \"MAPE\", \"RMSE\", \"Training Time\"])\n",
    "compare_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f283c24",
   "metadata": {},
   "source": [
    "### So best params are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18ff8be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "look_back, opt, epochs, batch_size, validation\n",
      "FFNN [30, <keras.optimizers.optimizer_v2.adam.Adam object at 0x00000198C4687A30>, 200, 32, 0.2]\n",
      "RNN [30, <keras.optimizers.optimizer_v2.adam.Adam object at 0x00000198C4687A30>, 200, 32, 0.15]\n",
      "LSTM [30, <keras.optimizers.optimizer_v2.adam.Adam object at 0x00000198C4687A30>, 200, 32, 0.2]\n",
      "GRU [30, <keras.optimizers.optimizer_v2.adam.Adam object at 0x00000198C4687A30>, 200, 32, 0.1]\n"
     ]
    }
   ],
   "source": [
    "print(\"look_back, opt, epochs, batch_size, validation\")\n",
    "print(\"FFNN\", FFNN_params[2:])\n",
    "print(\"RNN\", RNN_params[2:])\n",
    "print(\"LSTM\", LSTM_params[2:])\n",
    "print(\"GRU\", GRU_params[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439069e2",
   "metadata": {},
   "source": [
    "## So the best model in this case is RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da7f1900",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RNN_model\n",
    "trainPredict = RNN_trainPredict\n",
    "testPredict = RNN_testPredict\n",
    "model_name = \"RNN\"\n",
    "mse, mae, mape, rmse = LSTM_mse, LSTM_mae, LSTM_mape, LSTM_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e64dbe3",
   "metadata": {},
   "source": [
    "## Trực quan hóa kết quả dự đoán của best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51247994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1430x770 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RNN</th>\n",
       "      <td>20.577</td>\n",
       "      <td>2.701</td>\n",
       "      <td>2.033</td>\n",
       "      <td>4.536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MSE    MAE   MAPE   RMSE\n",
       "RNN  20.577  2.701  2.033  4.536"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_plot(ds, trainPredict, testPredict, scaler, look_back, model_name, stock_name)\n",
    "pd.DataFrame([[mse, mae, mape, rmse]], index=[model_name], columns=[\"MSE\", \"MAE\", \"MAPE\", \"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1945ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
